# Run ID: 21547211240
# Commit: 775fbc4cd21718b53a033856822ff9f53b6b28cc
# Job: multi-node (multi-node-dpsk3.2-2node, DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml, 2) / DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
# Date: 2026-01-31
============================================================

ï»¿2026-01-31T18:25:33.5027104Z Current runner version: '2.330.0'
2026-01-31T18:25:33.5031373Z Runner name: 'linux-aarch64-a3-0-wgt9d-runner-dgrf2'
2026-01-31T18:25:33.5032380Z Runner group name: 'Default'
2026-01-31T18:25:33.5033207Z Machine name: 'linux-aarch64-a3-0-wgt9d-runner-dgrf2'
2026-01-31T18:25:33.5036613Z ##[group]GITHUB_TOKEN Permissions
2026-01-31T18:25:33.5038556Z Actions: write
2026-01-31T18:25:33.5038975Z ArtifactMetadata: write
2026-01-31T18:25:33.5039386Z Attestations: write
2026-01-31T18:25:33.5039784Z Checks: write
2026-01-31T18:25:33.5040145Z Contents: write
2026-01-31T18:25:33.5040528Z Deployments: write
2026-01-31T18:25:33.5040916Z Discussions: write
2026-01-31T18:25:33.5041267Z Issues: write
2026-01-31T18:25:33.5041730Z Metadata: read
2026-01-31T18:25:33.5042354Z Models: read
2026-01-31T18:25:33.5042731Z Packages: write
2026-01-31T18:25:33.5043128Z Pages: write
2026-01-31T18:25:33.5043552Z PullRequests: write
2026-01-31T18:25:33.5043930Z RepositoryProjects: write
2026-01-31T18:25:33.5044504Z SecurityEvents: write
2026-01-31T18:25:33.5044929Z Statuses: write
2026-01-31T18:25:33.5045335Z ##[endgroup]
2026-01-31T18:25:33.5047020Z Secret source: Actions
2026-01-31T18:25:33.5047517Z Prepare workflow directory
2026-01-31T18:25:33.5580549Z Prepare all required actions
2026-01-31T18:25:33.5612554Z Getting action download info
2026-01-31T18:25:34.5375225Z Download action repository 'actions/checkout@v6' (SHA:8e8c483db84b4bee98b60c0593521ed34d9990e8)
2026-01-31T18:25:38.9362823Z Download action repository 'actions/upload-artifact@v6' (SHA:b7c566a772e6b6bfb58ed0dc250532a479d7789f)
2026-01-31T18:25:46.4569965Z Uses: vllm-project/vllm-ascend/.github/workflows/_e2e_nightly_multi_node.yaml@refs/heads/main (775fbc4cd21718b53a033856822ff9f53b6b28cc)
2026-01-31T18:25:46.4573295Z ##[group] Inputs
2026-01-31T18:25:46.4573595Z   soc_version: a3
2026-01-31T18:25:46.4573861Z   runner: linux-aarch64-a3-0
2026-01-31T18:25:46.4574241Z   image: swr.cn-southwest-2.myhuaweicloud.com/base_image/ascend-ci/vllm-ascend:nightly-a3
2026-01-31T18:25:46.4574823Z   config_file_path: DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-01-31T18:25:46.4575135Z   replicas: 1
2026-01-31T18:25:46.4575307Z   size: 2
2026-01-31T18:25:46.4575536Z   vllm_version: v0.14.1
2026-01-31T18:25:46.4576020Z   vllm_ascend_remote_url: https://github.com/vllm-project/vllm-ascend.git
2026-01-31T18:25:46.4576357Z   vllm_ascend_ref: main
2026-01-31T18:25:46.4576629Z ##[endgroup]
2026-01-31T18:25:46.4577115Z Complete job name: multi-node (multi-node-dpsk3.2-2node, DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml, 2) / DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-01-31T18:25:46.5091193Z ##[group]Run '/home/runner/k8s/index.js'
2026-01-31T18:25:46.5093892Z shell: /home/runner/externals/node20/bin/node {0}
2026-01-31T18:25:46.5094528Z ##[endgroup]
2026-01-31T18:26:02.0843520Z (node:70) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-01-31T18:26:02.0844313Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-01-31T18:26:28.6174189Z ##[group]Run # Decode and save kubeconfig
2026-01-31T18:26:28.6174649Z [36;1m# Decode and save kubeconfig[0m
2026-01-31T18:26:28.6206976Z [36;1mecho "***" | base64 -d > $KUBECONFIG[0m
2026-01-31T18:26:28.6207646Z shell: bash -el {0}
2026-01-31T18:26:28.6207990Z ##[endgroup]
2026-01-31T18:26:28.6334960Z ##[group]Run '/home/runner/k8s/index.js'
2026-01-31T18:26:28.6335841Z shell: /home/runner/externals/node20/bin/node {0}
2026-01-31T18:26:28.6336137Z ##[endgroup]
2026-01-31T18:26:29.0054764Z (node:5667) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-01-31T18:26:29.0055570Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-01-31T18:27:04.8002619Z ##[group]Run actions/checkout@v6
2026-01-31T18:27:04.8002987Z with:
2026-01-31T18:27:04.8003248Z   repository: vllm-project/vllm-ascend
2026-01-31T18:27:04.8003959Z   token: ***
2026-01-31T18:27:04.8004305Z   ssh-strict: true
2026-01-31T18:27:04.8004500Z   ssh-user: git
2026-01-31T18:27:04.8004736Z   persist-credentials: true
2026-01-31T18:27:04.8004989Z   clean: true
2026-01-31T18:27:04.8005200Z   sparse-checkout-cone-mode: true
2026-01-31T18:27:04.8005473Z   fetch-depth: 1
2026-01-31T18:27:04.8005668Z   fetch-tags: false
2026-01-31T18:27:04.8005894Z   show-progress: true
2026-01-31T18:27:04.8006126Z   lfs: false
2026-01-31T18:27:04.8006316Z   submodules: false
2026-01-31T18:27:04.8006547Z   set-safe-directory: true
2026-01-31T18:27:04.8006970Z ##[endgroup]
2026-01-31T18:27:04.8093609Z ##[group]Run '/home/runner/k8s/index.js'
2026-01-31T18:27:04.8094470Z shell: /home/runner/externals/node20/bin/node {0}
2026-01-31T18:27:04.8094741Z ##[endgroup]
2026-01-31T18:27:05.1721690Z (node:6093) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-01-31T18:27:05.1722661Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-01-31T18:27:23.0158269Z Syncing repository: vllm-project/vllm-ascend
2026-01-31T18:27:23.0159475Z ##[group]Getting Git version info
2026-01-31T18:27:23.0159763Z Working directory is '/__w/vllm-ascend/vllm-ascend'
2026-01-31T18:27:23.0160254Z [command]/usr/bin/git version
2026-01-31T18:27:23.0269864Z git version 2.34.1
2026-01-31T18:27:23.0286359Z ##[endgroup]
2026-01-31T18:27:23.0296444Z Copying '/root/.gitconfig' to '/__w/_temp/5cc0ddbc-4fd2-445f-824c-ee464ac050ed/.gitconfig'
2026-01-31T18:27:23.0308829Z Temporarily overriding HOME='/__w/_temp/5cc0ddbc-4fd2-445f-824c-ee464ac050ed' before making global git config changes
2026-01-31T18:27:23.0309493Z Adding repository directory to the temporary git global config as a safe directory
2026-01-31T18:27:23.0312404Z [command]/usr/bin/git config --global --add safe.directory /__w/vllm-ascend/vllm-ascend
2026-01-31T18:27:23.0349341Z Deleting the contents of '/__w/vllm-ascend/vllm-ascend'
2026-01-31T18:27:23.0352305Z ##[group]Initializing the repository
2026-01-31T18:27:23.0355563Z [command]/usr/bin/git init /__w/vllm-ascend/vllm-ascend
2026-01-31T18:27:23.0469284Z hint: Using 'master' as the name for the initial branch. This default branch name
2026-01-31T18:27:23.0469743Z hint: is subject to change. To configure the initial branch name to use in all
2026-01-31T18:27:23.0470242Z hint: of your new repositories, which will suppress this warning, call:
2026-01-31T18:27:23.0470533Z hint: 
2026-01-31T18:27:23.0470877Z hint: 	git config --global init.defaultBranch <name>
2026-01-31T18:27:23.0471202Z hint: 
2026-01-31T18:27:23.0471496Z hint: Names commonly chosen instead of 'master' are 'main', 'trunk' and
2026-01-31T18:27:23.0471950Z hint: 'development'. The just-created branch can be renamed via this command:
2026-01-31T18:27:23.0472390Z hint: 
2026-01-31T18:27:23.0472635Z hint: 	git branch -m <name>
2026-01-31T18:27:23.0480875Z Initialized empty Git repository in /__w/vllm-ascend/vllm-ascend/.git/
2026-01-31T18:27:23.0488573Z [command]/usr/bin/git remote add origin https://github.com/vllm-project/vllm-ascend
2026-01-31T18:27:23.0537913Z ##[endgroup]
2026-01-31T18:27:23.0538329Z ##[group]Disabling automatic garbage collection
2026-01-31T18:27:23.0541047Z [command]/usr/bin/git config --local gc.auto 0
2026-01-31T18:27:23.0570716Z ##[endgroup]
2026-01-31T18:27:23.0571055Z ##[group]Setting up auth
2026-01-31T18:27:23.0572150Z Removing SSH command configuration
2026-01-31T18:27:23.0577052Z [command]/usr/bin/git config --local --name-only --get-regexp core\.sshCommand
2026-01-31T18:27:23.0603885Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'core\.sshCommand' && git config --local --unset-all 'core.sshCommand' || :"
2026-01-31T18:27:23.1016702Z Removing HTTP extra header
2026-01-31T18:27:23.1019297Z [command]/usr/bin/git config --local --name-only --get-regexp http\.https\:\/\/github\.com\/\.extraheader
2026-01-31T18:27:23.1044038Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'http\.https\:\/\/github\.com\/\.extraheader' && git config --local --unset-all 'http.https://github.com/.extraheader' || :"
2026-01-31T18:27:23.1239337Z Removing includeIf entries pointing to credentials config files
2026-01-31T18:27:23.1243851Z [command]/usr/bin/git config --local --name-only --get-regexp ^includeIf\.gitdir:
2026-01-31T18:27:23.1269283Z [command]/usr/bin/git submodule foreach --recursive git config --local --show-origin --name-only --get-regexp remote.origin.url
2026-01-31T18:27:23.1451625Z [command]/usr/bin/git config --file /__w/_temp/git-credentials-45083731-d67b-488c-a240-ba3fb1b780c0.config http.https://github.com/.extraheader AUTHORIZATION: basic ***
2026-01-31T18:27:23.1484267Z [command]/usr/bin/git config --local includeIf.gitdir:/__w/vllm-ascend/vllm-ascend/.git.path /__w/_temp/git-credentials-45083731-d67b-488c-a240-ba3fb1b780c0.config
2026-01-31T18:27:23.1511461Z [command]/usr/bin/git config --local includeIf.gitdir:/__w/vllm-ascend/vllm-ascend/.git/worktrees/*.path /__w/_temp/git-credentials-45083731-d67b-488c-a240-ba3fb1b780c0.config
2026-01-31T18:27:23.1541229Z [command]/usr/bin/git config --local includeIf.gitdir:/github/workspace/.git.path /github/runner_temp/git-credentials-45083731-d67b-488c-a240-ba3fb1b780c0.config
2026-01-31T18:27:23.1566538Z [command]/usr/bin/git config --local includeIf.gitdir:/github/workspace/.git/worktrees/*.path /github/runner_temp/git-credentials-45083731-d67b-488c-a240-ba3fb1b780c0.config
2026-01-31T18:27:23.1593804Z ##[endgroup]
2026-01-31T18:27:23.1594199Z ##[group]Fetching the repository
2026-01-31T18:27:23.1601434Z [command]/usr/bin/git -c protocol.version=2 fetch --no-tags --prune --no-recurse-submodules --depth=1 origin +775fbc4cd21718b53a033856822ff9f53b6b28cc:refs/remotes/origin/main
2026-01-31T18:27:24.7908313Z From https://gh-proxy.test.osinfra.cn/https://github.com/vllm-project/vllm-ascend
2026-01-31T18:27:24.7909052Z  * [new ref]         775fbc4cd21718b53a033856822ff9f53b6b28cc -> origin/main
2026-01-31T18:27:24.7921485Z ##[endgroup]
2026-01-31T18:27:24.7922182Z ##[group]Determining the checkout info
2026-01-31T18:27:24.7923501Z ##[endgroup]
2026-01-31T18:27:24.7927332Z [command]/usr/bin/git sparse-checkout disable
2026-01-31T18:27:24.7967542Z [command]/usr/bin/git config --local --unset-all extensions.worktreeConfig
2026-01-31T18:27:24.7990289Z ##[group]Checking out the ref
2026-01-31T18:27:24.7993824Z [command]/usr/bin/git checkout --progress --force -B main refs/remotes/origin/main
2026-01-31T18:27:24.8817144Z Switched to a new branch 'main'
2026-01-31T18:27:24.8817588Z Branch 'main' set up to track remote branch 'main' from 'origin'.
2026-01-31T18:27:24.8824917Z ##[endgroup]
2026-01-31T18:27:24.8868468Z [command]/usr/bin/git log -1 --format=%H
2026-01-31T18:27:24.8888152Z 775fbc4cd21718b53a033856822ff9f53b6b28cc
2026-01-31T18:27:42.5609544Z ##[group]Run # prepare for lws entrypoint scripts
2026-01-31T18:27:42.5609930Z [36;1m# prepare for lws entrypoint scripts[0m
2026-01-31T18:27:42.5610352Z [36;1minstall -D tests/e2e/nightly/multi_node/scripts/run.sh /root/.cache/tests/run.sh[0m
2026-01-31T18:27:42.5610854Z shell: bash -el {0}
2026-01-31T18:27:42.5611062Z ##[endgroup]
2026-01-31T18:27:42.5683405Z ##[group]Run '/home/runner/k8s/index.js'
2026-01-31T18:27:42.5684191Z shell: /home/runner/externals/node20/bin/node {0}
2026-01-31T18:27:42.5684440Z ##[endgroup]
2026-01-31T18:27:42.9278858Z (node:6685) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-01-31T18:27:42.9279802Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-01-31T18:28:18.8138436Z ##[group]Run set -euo pipefail
2026-01-31T18:28:18.8138796Z [36;1mset -euo pipefail[0m
2026-01-31T18:28:18.8139041Z [36;1m[0m
2026-01-31T18:28:18.8139237Z [36;1mCRD_NAME="${CRD_NAME:-vllm}"[0m
2026-01-31T18:28:18.8139670Z [36;1mTIMEOUT=${TIMEOUT:-120}[0m
2026-01-31T18:28:18.8139908Z [36;1mSLEEP_INTERVAL=2[0m
2026-01-31T18:28:18.8140157Z [36;1m[0m
2026-01-31T18:28:18.8140485Z [36;1mecho "Deleting leaderworkerset [$CRD_NAME] in namespace [$NAMESPACE]..."[0m
2026-01-31T18:28:18.8140987Z [36;1mkubectl delete leaderworkerset "$CRD_NAME" -n "$NAMESPACE" --ignore-not-found[0m
2026-01-31T18:28:18.8141357Z [36;1m[0m
2026-01-31T18:28:18.8141645Z [36;1mecho "Waiting for all pods starting with 'vllm' to be deleted..."[0m
2026-01-31T18:28:18.8141952Z [36;1mSTART_TIME=$(date +%s)[0m
2026-01-31T18:28:18.8142372Z [36;1m[0m
2026-01-31T18:28:18.8142599Z [36;1mwhile true; do[0m
2026-01-31T18:28:18.8142806Z [36;1m  NOW=$(date +%s)[0m
2026-01-31T18:28:18.8143142Z [36;1m  ELAPSED=$((NOW - START_TIME))[0m
2026-01-31T18:28:18.8143382Z [36;1m[0m
2026-01-31T18:28:18.8143616Z [36;1m  if [[ $ELAPSED -ge $TIMEOUT ]]; then[0m
2026-01-31T18:28:18.8143958Z [36;1m    echo "Timeout reached ($TIMEOUT seconds), some pods still exist:"[0m
2026-01-31T18:28:18.8144436Z [36;1m    kubectl get pods -n "$NAMESPACE" | grep '^vllm' || true[0m
2026-01-31T18:28:18.8144750Z [36;1m    exit 1[0m
2026-01-31T18:28:18.8144960Z [36;1m  fi[0m
2026-01-31T18:28:18.8145147Z [36;1m[0m
2026-01-31T18:28:18.8145589Z [36;1m  PODS_EXIST=$(kubectl get pods -n "$NAMESPACE" -o jsonpath='{.items[*].metadata.name}' 2>/dev/null | tr ' ' '\n' | grep '^vllm' || true)[0m
2026-01-31T18:28:18.8146051Z [36;1m[0m
2026-01-31T18:28:18.8146247Z [36;1m  if [[ -z "$PODS_EXIST" ]]; then[0m
2026-01-31T18:28:18.8146605Z [36;1m    echo "All vllm pods deleted."[0m
2026-01-31T18:28:18.8146867Z [36;1m    break[0m
2026-01-31T18:28:18.8147071Z [36;1m  else[0m
2026-01-31T18:28:18.8147341Z [36;1m    echo "Waiting for pods to be deleted: $PODS_EXIST"[0m
2026-01-31T18:28:18.8147652Z [36;1m    sleep $SLEEP_INTERVAL[0m
2026-01-31T18:28:18.8147952Z [36;1m  fi[0m
2026-01-31T18:28:18.8148160Z [36;1mdone[0m
2026-01-31T18:28:18.8148485Z shell: bash -el {0}
2026-01-31T18:28:18.8148740Z ##[endgroup]
2026-01-31T18:28:18.8221574Z ##[group]Run '/home/runner/k8s/index.js'
2026-01-31T18:28:18.8222573Z shell: /home/runner/externals/node20/bin/node {0}
2026-01-31T18:28:18.8222852Z ##[endgroup]
2026-01-31T18:28:19.1829980Z (node:7466) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-01-31T18:28:19.1830805Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-01-31T18:28:37.2279968Z Deleting leaderworkerset [vllm] in namespace [vllm-project]...
2026-01-31T18:28:37.5204964Z Waiting for all pods starting with 'vllm' to be deleted...
2026-01-31T18:28:37.5990642Z All vllm pods deleted.
2026-01-31T18:28:55.5964413Z ##[group]Run set -e
2026-01-31T18:28:55.5964732Z [36;1mset -e[0m
2026-01-31T18:28:55.5964955Z [36;1m[0m
2026-01-31T18:28:55.5965157Z [36;1msize="2"[0m
2026-01-31T18:28:55.5965385Z [36;1mreplicas="1"[0m
2026-01-31T18:28:55.5965795Z [36;1mimage="swr.cn-southwest-2.myhuaweicloud.com/base_image/ascend-ci/vllm-ascend:nightly-a3"[0m
2026-01-31T18:28:55.5966282Z [36;1mconfig_file_path="DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml"[0m
2026-01-31T18:28:55.5966863Z [36;1mfail_tag=FAIL_TAG_"DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml"[0m
2026-01-31T18:28:55.5967224Z [36;1mecho "FAIL_TAG=${fail_tag}" >> $GITHUB_ENV[0m
2026-01-31T18:28:55.5967492Z [36;1m[0m
2026-01-31T18:28:55.5967832Z [36;1mrequired_params=("size" "replicas" "image" "config_file_path")[0m
2026-01-31T18:28:55.5968192Z [36;1mfor param in "${required_params[@]}"; do[0m
2026-01-31T18:28:55.5968478Z [36;1m  if [ -z "${!param}" ]; then[0m
2026-01-31T18:28:55.5968879Z [36;1m    echo "Error: Parameter '$param' is required but empty"[0m
2026-01-31T18:28:55.5969182Z [36;1m    exit 1[0m
2026-01-31T18:28:55.5969408Z [36;1m  fi[0m
2026-01-31T18:28:55.5969615Z [36;1mdone[0m
2026-01-31T18:28:55.5969811Z [36;1m[0m
2026-01-31T18:28:55.5970175Z [36;1mif [ "a3" = "a3" ]; then[0m
2026-01-31T18:28:55.5970415Z [36;1m  npu_per_node=16[0m
2026-01-31T18:28:55.5970761Z [36;1m  TEMPLATE_FILE="tests/e2e/nightly/multi_node/scripts/lws.yaml.jinja2"[0m
2026-01-31T18:28:55.5971112Z [36;1melse[0m
2026-01-31T18:28:55.5971305Z [36;1m  npu_per_node=8[0m
2026-01-31T18:28:55.5971648Z [36;1m  TEMPLATE_FILE="tests/e2e/nightly/multi_node/scripts/lws-a2.yaml.jinja2"[0m
2026-01-31T18:28:55.5972168Z [36;1mfi[0m
2026-01-31T18:28:55.5972360Z [36;1m[0m
2026-01-31T18:28:55.5972597Z [36;1mjinja2 $TEMPLATE_FILE \[0m
2026-01-31T18:28:55.5972871Z [36;1m  -D size="$size" \[0m
2026-01-31T18:28:55.5973102Z [36;1m  -D replicas="$replicas" \[0m
2026-01-31T18:28:55.5973378Z [36;1m  -D image="$image" \[0m
2026-01-31T18:28:55.5973757Z [36;1m  -D config_file_path="$config_file_path" \[0m
2026-01-31T18:28:55.5974031Z [36;1m  -D npu_per_node="$npu_per_node" \[0m
2026-01-31T18:28:55.5974308Z [36;1m  -D fail_tag="$fail_tag" \[0m
2026-01-31T18:28:55.5974547Z [36;1m  --outfile lws.yaml[0m
2026-01-31T18:28:55.5974793Z [36;1m[0m
2026-01-31T18:28:55.5975012Z [36;1mkubectl apply -f ./lws.yaml[0m
2026-01-31T18:28:55.5975384Z shell: bash -el {0}
2026-01-31T18:28:55.5975604Z ##[endgroup]
2026-01-31T18:28:55.6051539Z ##[group]Run '/home/runner/k8s/index.js'
2026-01-31T18:28:55.6052512Z shell: /home/runner/externals/node20/bin/node {0}
2026-01-31T18:28:55.6052816Z ##[endgroup]
2026-01-31T18:28:55.9625729Z (node:8429) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-01-31T18:28:55.9626560Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-01-31T18:29:14.6953849Z leaderworkerset.leaderworkerset.x-k8s.io/vllm created
2026-01-31T18:29:14.7158995Z service/vllm-leader created
2026-01-31T18:29:32.7660164Z ##[group]Run POD_PREFIX="${POD_PREFIX:-vllm-0}"
2026-01-31T18:29:32.7660474Z [36;1mPOD_PREFIX="${POD_PREFIX:-vllm-0}"[0m
2026-01-31T18:29:32.7660688Z [36;1mSIZE="2"[0m
2026-01-31T18:29:32.7660859Z [36;1mTIMEOUT=1200  # default timeout 20 minutes[0m
2026-01-31T18:29:32.7661062Z [36;1m[0m
2026-01-31T18:29:32.7661359Z [36;1mecho "Waiting for Pods in namespace [$NAMESPACE] to become Running and Ready (timeout ${TIMEOUT}s)..."[0m
2026-01-31T18:29:32.7661688Z [36;1m[0m
2026-01-31T18:29:32.7661828Z [36;1mSTART_TIME=$(date +%s)[0m
2026-01-31T18:29:32.7662171Z [36;1m[0m
2026-01-31T18:29:32.7662328Z [36;1mwhile true; do[0m
2026-01-31T18:29:32.7662498Z [36;1m  NOW=$(date +%s)[0m
2026-01-31T18:29:32.7662679Z [36;1m  ELAPSED=$((NOW - START_TIME))[0m
2026-01-31T18:29:32.7662893Z [36;1m  if [[ $ELAPSED -ge $TIMEOUT ]]; then[0m
2026-01-31T18:29:32.7663127Z [36;1m    echo "Timeout reached after ${ELAPSED}s"[0m
2026-01-31T18:29:32.7663393Z [36;1m    echo "Dumping pod status for debugging:"[0m
2026-01-31T18:29:32.7663612Z [36;1m    kubectl get pods -n "$NAMESPACE"[0m
2026-01-31T18:29:32.7663863Z [36;1m    kubectl describe pod "$LEADER_POD" -n "$NAMESPACE"[0m
2026-01-31T18:29:32.7664100Z [36;1m    exit 1[0m
2026-01-31T18:29:32.7664239Z [36;1m  fi[0m
2026-01-31T18:29:32.7664369Z [36;1m[0m
2026-01-31T18:29:32.7664512Z [36;1m  # 1) check follower pods[0m
2026-01-31T18:29:32.7664697Z [36;1m  ALL_FOLLOWERS_READY=true[0m
2026-01-31T18:29:32.7664888Z [36;1m  for ((i=1; i<SIZE; i++)); do[0m
2026-01-31T18:29:32.7665075Z [36;1m    POD="${POD_PREFIX}-${i}"[0m
2026-01-31T18:29:32.7665444Z [36;1m    PHASE=$(kubectl get pod "$POD" -n "$NAMESPACE" -o jsonpath='{.status.phase}' 2>/dev/null || echo "NotFound")[0m
2026-01-31T18:29:32.7665974Z [36;1m    READY=$(kubectl get pod "$POD" -n "$NAMESPACE" -o jsonpath='{.status.containerStatuses[*].ready}' 2>/dev/null)[0m
2026-01-31T18:29:32.7666331Z [36;1m[0m
2026-01-31T18:29:32.7666573Z [36;1m    echo "Follower [$POD] phase=$PHASE ready=$READY"[0m
2026-01-31T18:29:32.7666804Z [36;1m[0m
2026-01-31T18:29:32.7666979Z [36;1m    if [[ "$PHASE" != "Running" || "$READY" != "true" ]]; then[0m
2026-01-31T18:29:32.7667400Z [36;1m      echo "Follower [$POD] not Ready yet..."[0m
2026-01-31T18:29:32.7667622Z [36;1m      ALL_FOLLOWERS_READY=false[0m
2026-01-31T18:29:32.7667802Z [36;1m      break[0m
2026-01-31T18:29:32.7667953Z [36;1m    fi[0m
2026-01-31T18:29:32.7668092Z [36;1m  done[0m
2026-01-31T18:29:32.7668221Z [36;1m[0m
2026-01-31T18:29:32.7668362Z [36;1m  # 2) check leader pod[0m
2026-01-31T18:29:32.7668740Z [36;1m  LEADER_PHASE=$(kubectl get pod "$LEADER_POD" -n "$NAMESPACE" -o jsonpath='{.status.phase}' 2>/dev/null || echo "NotFound")[0m
2026-01-31T18:29:32.7669358Z [36;1m  LEADER_READY=$(kubectl get pod "$LEADER_POD" -n "$NAMESPACE" -o jsonpath='{.status.containerStatuses[*].ready}' 2>/dev/null)[0m
2026-01-31T18:29:32.7669735Z [36;1m[0m
2026-01-31T18:29:32.7669947Z [36;1m  echo "Leader [$LEADER_POD] phase=$LEADER_PHASE ready=$LEADER_READY"[0m
2026-01-31T18:29:32.7670194Z [36;1m[0m
2026-01-31T18:29:32.7670396Z [36;1m  if [[ "$LEADER_PHASE" != "Running" || "$LEADER_READY" != "true" ]]; then[0m
2026-01-31T18:29:32.7670672Z [36;1m    echo "Leader not Ready yet..."[0m
2026-01-31T18:29:32.7670869Z [36;1m    ALL_FOLLOWERS_READY=false[0m
2026-01-31T18:29:32.7671054Z [36;1m  fi[0m
2026-01-31T18:29:32.7671180Z [36;1m[0m
2026-01-31T18:29:32.7671344Z [36;1m  if [[ "$ALL_FOLLOWERS_READY" == "true" ]]; then[0m
2026-01-31T18:29:32.7671656Z [36;1m    echo "All follower pods and leader pod are Running and Ready â€” continuing."[0m
2026-01-31T18:29:32.7671930Z [36;1m    break[0m
2026-01-31T18:29:32.7672186Z [36;1m  fi[0m
2026-01-31T18:29:32.7672324Z [36;1m[0m
2026-01-31T18:29:32.7672450Z [36;1m  sleep 2[0m
2026-01-31T18:29:32.7672599Z [36;1mdone[0m
2026-01-31T18:29:32.7672904Z shell: bash -el {0}
2026-01-31T18:29:32.7673049Z env:
2026-01-31T18:29:32.7673398Z   FAIL_TAG: FAIL_TAG_DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-01-31T18:29:32.7673623Z ##[endgroup]
2026-01-31T18:29:32.7760147Z ##[group]Run '/home/runner/k8s/index.js'
2026-01-31T18:29:32.7760833Z shell: /home/runner/externals/node20/bin/node {0}
2026-01-31T18:29:32.7761050Z ##[endgroup]
2026-01-31T18:29:33.1357716Z (node:9571) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-01-31T18:29:33.1358376Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-01-31T18:29:51.6528300Z Waiting for Pods in namespace [vllm-project] to become Running and Ready (timeout 1200s)...
2026-01-31T18:29:51.7736809Z Follower [vllm-0-1] phase=Running ready=true
2026-01-31T18:29:51.9077604Z Leader [vllm-0] phase=Running ready=true
2026-01-31T18:29:51.9080144Z All follower pods and leader pod are Running and Ready â€” continuing.
2026-01-31T18:30:10.0804910Z ##[group]Run set -euo pipefail
2026-01-31T18:30:10.0805216Z [36;1mset -euo pipefail[0m
2026-01-31T18:30:10.0805457Z [36;1m[0m
2026-01-31T18:30:10.0805665Z [36;1msize="2"[0m
2026-01-31T18:30:10.0805890Z [36;1mpids=()[0m
2026-01-31T18:30:10.0806084Z [36;1m[0m
2026-01-31T18:30:10.0806299Z [36;1mcleanup() {[0m
2026-01-31T18:30:10.0806695Z [36;1m  echo "Cleaning up background log streams..."[0m
2026-01-31T18:30:10.0807019Z [36;1m  for pid in "${pids[@]}"; do[0m
2026-01-31T18:30:10.0807307Z [36;1m    kill "$pid" 2>/dev/null || true[0m
2026-01-31T18:30:10.0807535Z [36;1m  done[0m
2026-01-31T18:30:10.0807747Z [36;1m}[0m
2026-01-31T18:30:10.0807969Z [36;1mtrap cleanup EXIT[0m
2026-01-31T18:30:10.0808170Z [36;1m[0m
2026-01-31T18:30:10.0808443Z [36;1mfor i in $(seq 1 $((size - 1))); do[0m
2026-01-31T18:30:10.0808716Z [36;1m  POD="vllm-0-${i}"[0m
2026-01-31T18:30:10.0808918Z [36;1m[0m
2026-01-31T18:30:10.0809300Z [36;1m  echo "==== Collecting logs from worker pod: $POD ===="[0m
2026-01-31T18:30:10.0809699Z [36;1m  kubectl logs -f "$POD" -n "$NAMESPACE" \[0m
2026-01-31T18:30:10.0809991Z [36;1m    > "/tmp/${POD}_logs.txt" 2>&1 &[0m
2026-01-31T18:30:10.0810261Z [36;1m[0m
2026-01-31T18:30:10.0810577Z [36;1m  pids+=($!)[0m
2026-01-31T18:30:10.0810798Z [36;1mdone[0m
2026-01-31T18:30:10.0810994Z [36;1m[0m
2026-01-31T18:30:10.0811264Z [36;1mecho "==== Streaming logs from leader pod: $LEADER_POD ===="[0m
2026-01-31T18:30:10.0811615Z [36;1mecho "Looking for logs containing: $FAIL_TAG"[0m
2026-01-31T18:30:10.0811871Z [36;1m[0m
2026-01-31T18:30:10.0812276Z [36;1mkubectl logs -f "$LEADER_POD" -n "$NAMESPACE" | while IFS= read -r line; do[0m
2026-01-31T18:30:10.0812635Z [36;1m  echo "$line"[0m
2026-01-31T18:30:10.0812883Z [36;1m  if echo "$line" | grep -q "$FAIL_TAG"; then[0m
2026-01-31T18:30:10.0813229Z [36;1m    exit 1[0m
2026-01-31T18:30:10.0813443Z [36;1m  fi[0m
2026-01-31T18:30:10.0813632Z [36;1mdone[0m
2026-01-31T18:30:10.0814055Z shell: bash -el {0}
2026-01-31T18:30:10.0814277Z env:
2026-01-31T18:30:10.0814520Z   FAIL_TAG: FAIL_TAG_DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-01-31T18:30:10.0814817Z ##[endgroup]
2026-01-31T18:30:10.0900980Z ##[group]Run '/home/runner/k8s/index.js'
2026-01-31T18:30:10.0901744Z shell: /home/runner/externals/node20/bin/node {0}
2026-01-31T18:30:10.0902152Z ##[endgroup]
2026-01-31T18:30:10.4446314Z (node:10896) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-01-31T18:30:10.4447081Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-01-31T18:30:28.7303514Z ==== Collecting logs from worker pod: vllm-0-1 ====
2026-01-31T18:30:28.7303844Z ==== Streaming logs from leader pod: vllm-0 ====
2026-01-31T18:30:28.7304150Z Looking for logs containing: FAIL_TAG_DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-01-31T18:30:29.0218522Z ====> Check NPU info
2026-01-31T18:30:29.0261094Z +------------------------------------------------------------------------------------------------+
2026-01-31T18:30:29.0272149Z | npu-smi 25.5.0                   Version: 25.5.0                                               |
2026-01-31T18:30:29.0282338Z +---------------------------+---------------+----------------------------------------------------+
2026-01-31T18:30:29.0292167Z | NPU   Name                | Health        | Power(W)    Temp(C)           Hugepages-Usage(page)|
2026-01-31T18:30:29.0302416Z | Chip  Phy-ID              | Bus-Id        | AICore(%)   Memory-Usage(MB)  HBM-Usage(MB)        |
2026-01-31T18:30:29.0312379Z +===========================+===============+====================================================+
2026-01-31T18:30:29.0322045Z | 0     Ascend910           | OK            | 161.2       36                0    / 0             |
2026-01-31T18:30:29.0341418Z | 0     0                   | 0000:9D:00.0  | 0           0    / 0          3147 / 65536         |
2026-01-31T18:30:29.0342385Z +------------------------------------------------------------------------------------------------+
2026-01-31T18:30:29.0353301Z | 0     Ascend910           | OK            | -           34                0    / 0             |
2026-01-31T18:30:29.0359454Z | 1     1                   | 0000:9F:00.0  | 0           0    / 0          2900 / 65536         |
2026-01-31T18:30:29.0368599Z +===========================+===============+====================================================+
2026-01-31T18:30:29.0378031Z | 1     Ascend910           | OK            | 164.2       36                0    / 0             |
2026-01-31T18:30:29.0387483Z | 0     2                   | 0000:99:00.0  | 0           0    / 0          3156 / 65536         |
2026-01-31T18:30:29.0399253Z +------------------------------------------------------------------------------------------------+
2026-01-31T18:30:29.0406265Z | 1     Ascend910           | OK            | -           35                0    / 0             |
2026-01-31T18:30:29.0416099Z | 1     3                   | 0000:9B:00.0  | 0           0    / 0          2884 / 65536         |
2026-01-31T18:30:29.0425654Z +===========================+===============+====================================================+
2026-01-31T18:30:29.0446736Z | 2     Ascend910           | OK            | 163.2       36                0    / 0             |
2026-01-31T18:30:29.0447043Z | 0     4                   | 0000:95:00.0  | 0           0    / 0          3148 / 65536         |
2026-01-31T18:30:29.0454161Z +------------------------------------------------------------------------------------------------+
2026-01-31T18:30:29.0464134Z | 2     Ascend910           | OK            | -           36                0    / 0             |
2026-01-31T18:30:29.0473238Z | 1     5                   | 0000:97:00.0  | 0           0    / 0          2899 / 65536         |
2026-01-31T18:30:29.0483026Z +===========================+===============+====================================================+
2026-01-31T18:30:29.0491452Z | 3     Ascend910           | OK            | 169.3       36                0    / 0             |
2026-01-31T18:30:29.0500913Z | 0     6                   | 0000:91:00.0  | 0           0    / 0          3158 / 65536         |
2026-01-31T18:30:29.0510160Z +------------------------------------------------------------------------------------------------+
2026-01-31T18:30:29.0520368Z | 3     Ascend910           | OK            | -           35                0    / 0             |
2026-01-31T18:30:29.0530778Z | 1     7                   | 0000:93:00.0  | 0           0    / 0          2884 / 65536         |
2026-01-31T18:30:29.0540680Z +===========================+===============+====================================================+
2026-01-31T18:30:29.0550318Z | 4     Ascend910           | OK            | 165.4       36                0    / 0             |
2026-01-31T18:30:29.0559786Z | 0     8                   | 0000:8D:00.0  | 0           0    / 0          3144 / 65536         |
2026-01-31T18:30:29.0569381Z +------------------------------------------------------------------------------------------------+
2026-01-31T18:30:29.0578307Z | 4     Ascend910           | OK            | -           35                0    / 0             |
2026-01-31T18:30:29.0589473Z | 1     9                   | 0000:8F:00.0  | 0           0    / 0          2894 / 65536         |
2026-01-31T18:30:29.0597517Z +===========================+===============+====================================================+
2026-01-31T18:30:29.0606838Z | 5     Ascend910           | OK            | 162.2       34                0    / 0             |
2026-01-31T18:30:29.0616068Z | 0     10                  | 0000:89:00.0  | 0           0    / 0          3142 / 65536         |
2026-01-31T18:30:29.0626172Z +------------------------------------------------------------------------------------------------+
2026-01-31T18:30:29.0635523Z | 5     Ascend910           | OK            | -           36                0    / 0             |
2026-01-31T18:30:29.0644495Z | 1     11                  | 0000:8B:00.0  | 0           0    / 0          2897 / 65536         |
2026-01-31T18:30:29.0653793Z +===========================+===============+====================================================+
2026-01-31T18:30:29.0663620Z | 6     Ascend910           | OK            | 159.9       37                0    / 0             |
2026-01-31T18:30:29.0672542Z | 0     12                  | 0000:85:00.0  | 0           0    / 0          3145 / 65536         |
2026-01-31T18:30:29.0682834Z +------------------------------------------------------------------------------------------------+
2026-01-31T18:30:29.0692138Z | 6     Ascend910           | OK            | -           34                0    / 0             |
2026-01-31T18:30:29.0701421Z | 1     13                  | 0000:87:00.0  | 0           0    / 0          2899 / 65536         |
2026-01-31T18:30:29.0711020Z +===========================+===============+====================================================+
2026-01-31T18:30:29.0720817Z | 7     Ascend910           | OK            | 164.5       36                0    / 0             |
2026-01-31T18:30:29.0729523Z | 0     14                  | 0000:81:00.0  | 0           0    / 0          3157 / 65536         |
2026-01-31T18:30:29.0738958Z +------------------------------------------------------------------------------------------------+
2026-01-31T18:30:29.0748398Z | 7     Ascend910           | OK            | -           36                0    / 0             |
2026-01-31T18:30:29.0757994Z | 1     15                  | 0000:83:00.0  | 0           0    / 0          2887 / 65536         |
2026-01-31T18:30:29.0767268Z +===========================+===============+====================================================+
2026-01-31T18:30:29.0776658Z +---------------------------+---------------+----------------------------------------------------+
2026-01-31T18:30:29.0790595Z | NPU     Chip              | Process id    | Process name             | Process memory(MB)      |
2026-01-31T18:30:29.0795742Z +===========================+===============+====================================================+
2026-01-31T18:30:29.0805478Z | No running processes found in NPU 0                                                            |
2026-01-31T18:30:29.0814540Z +===========================+===============+====================================================+
2026-01-31T18:30:29.0824071Z | No running processes found in NPU 1                                                            |
2026-01-31T18:30:29.0834438Z +===========================+===============+====================================================+
2026-01-31T18:30:29.0843831Z | No running processes found in NPU 2                                                            |
2026-01-31T18:30:29.0852920Z +===========================+===============+====================================================+
2026-01-31T18:30:29.0862618Z | No running processes found in NPU 3                                                            |
2026-01-31T18:30:29.0871482Z +===========================+===============+====================================================+
2026-01-31T18:30:29.0881152Z | No running processes found in NPU 4                                                            |
2026-01-31T18:30:29.0890530Z +===========================+===============+====================================================+
2026-01-31T18:30:29.0900467Z | No running processes found in NPU 5                                                            |
2026-01-31T18:30:29.0909159Z +===========================+===============+====================================================+
2026-01-31T18:30:29.0919018Z | No running processes found in NPU 6                                                            |
2026-01-31T18:30:29.0928165Z +===========================+===============+====================================================+
2026-01-31T18:30:29.0937106Z | No running processes found in NPU 7                                                            |
2026-01-31T18:30:29.0947648Z +===========================+===============+====================================================+
2026-01-31T18:30:29.0956153Z package_name=Ascend-cann-toolkit
2026-01-31T18:30:29.0964997Z version=8.5.0
2026-01-31T18:30:29.0974457Z innerversion=V100R001C25SPC001B232
2026-01-31T18:30:29.0984136Z compatible_version=[V100R001C15],[V100R001C18],[V100R001C19],[V100R001C20],[V100R001C21],[V100R001C23]
2026-01-31T18:30:29.0992965Z arch=aarch64
2026-01-31T18:30:29.1002291Z os=linux
2026-01-31T18:30:29.1011398Z path=/usr/local/Ascend/cann-8.5.0
2026-01-31T18:30:29.1033416Z ====> Configure mirrors and git proxy
2026-01-31T18:30:29.1037165Z Writing to /root/.config/pip/pip.conf
2026-01-31T18:30:29.1049938Z Installed vLLM-related Python packages:
2026-01-31T18:30:29.1063868Z ais_bench_benchmark               3.0.20250930               /vllm-workspace/vllm-ascend/benchmark
2026-01-31T18:30:29.1082047Z vllm                              0.13.0+empty               /vllm-workspace/vllm
2026-01-31T18:30:29.1090917Z vllm_ascend                       0.13.0rc3.dev31+g70f0a067c /vllm-workspace/vllm-ascend
2026-01-31T18:30:29.1097084Z 
2026-01-31T18:30:29.1106809Z ============================
2026-01-31T18:30:29.1115616Z vLLM Git information
2026-01-31T18:30:29.1125025Z ============================
2026-01-31T18:30:29.1134516Z Branch:      HEAD
2026-01-31T18:30:29.1144001Z Commit hash: 72506c98349d6bcd32b4e33eec7b5513453c1502
2026-01-31T18:30:29.1153022Z Author:      Harry Mellor <19981378+hmellor@users.noreply.github.com>
2026-01-31T18:30:29.1163105Z Date:        2025-12-18 21:59:10 +0000
2026-01-31T18:30:29.1172892Z Message:     Check for truthy `rope_parameters` not the existence of it (#30983)
2026-01-31T18:30:29.1184640Z Tags:        v0.13.0
2026-01-31T18:30:29.1196699Z Remote:      origin	https://ghfast.top/https://github.com/vllm-project/vllm.git (fetch)
2026-01-31T18:30:29.1205257Z 
2026-01-31T18:30:29.1214474Z 
2026-01-31T18:30:29.1223498Z ============================
2026-01-31T18:30:29.1232820Z vLLM-Ascend Git information
2026-01-31T18:30:29.1242282Z ============================
2026-01-31T18:30:29.1251847Z Branch:      releases/v0.13.0
2026-01-31T18:30:29.1262830Z Commit hash: 70f0a067c56cb7863c8b4e2c8007cb827dd76859
2026-01-31T18:30:29.1270462Z Author:      wangxiyuan <wangxiyuan1007@gmail.com>
2026-01-31T18:30:29.1280265Z Date:        2026-01-30 23:46:16 +0800
2026-01-31T18:30:29.1289483Z Message:     [0.13.0][cherry-pick]pick from 6310 to fix rope op (#6444)
2026-01-31T18:30:29.1298236Z Tags:        
2026-01-31T18:30:29.1307958Z Remote:      origin	https://ghfast.top/https://github.com/vllm-project/vllm-ascend (fetch)
2026-01-31T18:30:29.1316968Z 
2026-01-31T18:30:29.1327201Z ====> Check triton ascend info
2026-01-31T18:30:29.1335657Z Ubuntu clang version 15.0.7
2026-01-31T18:30:29.1344789Z Target: aarch64-unknown-linux-gnu
2026-01-31T18:30:29.1354108Z Thread model: posix
2026-01-31T18:30:29.1363948Z InstalledDir: /usr/bin
2026-01-31T18:30:29.1373548Z Found candidate GCC installation: /usr/bin/../lib/gcc/aarch64-linux-gnu/11
2026-01-31T18:30:29.1382174Z Selected GCC installation: /usr/bin/../lib/gcc/aarch64-linux-gnu/11
2026-01-31T18:30:29.1429397Z Candidate multilib: .;@m64
2026-01-31T18:30:29.1429906Z Selected multilib: .;@m64
2026-01-31T18:30:29.1430242Z /usr/local/Ascend/ascend-toolkit/latest/bin/bishengir-compile
2026-01-31T18:30:29.1430507Z Name: triton-ascend
2026-01-31T18:30:29.1430658Z Version: 3.2.0
2026-01-31T18:30:29.1438262Z Summary: A language and compiler for custom Deep Learning operations on Ascend hardwares
2026-01-31T18:30:29.1447631Z Home-page: https://gitcode.com/Ascend/triton-ascend/
2026-01-31T18:30:29.1456263Z Author: 
2026-01-31T18:30:29.1465252Z Author-email: 
2026-01-31T18:30:29.1474793Z License: 
2026-01-31T18:30:29.1485098Z Location: /usr/local/python3.11.14/lib/python3.11/site-packages
2026-01-31T18:30:29.1493895Z Requires: 
2026-01-31T18:30:29.1502771Z Required-by: vllm_ascend
2026-01-31T18:30:29.1512532Z INFO 01-31 18:29:54 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-01-31T18:30:29.1530981Z INFO 01-31 18:29:54 [__init__.py:45] - ascend -> vllm_ascend:register
2026-01-31T18:30:29.1531429Z INFO 01-31 18:29:54 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-01-31T18:30:29.1539998Z INFO 01-31 18:29:54 [__init__.py:217] Platform plugin ascend is activated
2026-01-31T18:30:29.1549006Z ============================= test session starts ==============================
2026-01-31T18:30:29.1558501Z platform linux -- Python 3.11.14, pytest-8.4.2, pluggy-1.6.0 -- /usr/local/python3.11.14/bin/python3
2026-01-31T18:30:29.1567743Z cachedir: .pytest_cache
2026-01-31T18:30:29.1576426Z rootdir: /vllm-workspace/vllm-ascend
2026-01-31T18:30:29.1585551Z configfile: pyproject.toml
2026-01-31T18:30:29.1595137Z plugins: asyncio-1.3.0, mock-3.15.1, cov-7.0.0, anyio-4.12.1
2026-01-31T18:30:29.1605068Z asyncio: mode=Mode.STRICT, debug=False, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function
2026-01-31T18:30:29.1613497Z collecting ... collected 1 item
2026-01-31T18:30:29.1629065Z 
2026-01-31T18:30:29.1632413Z [2026-01-31 18:30:00] INFO multi_node_config.py:294: Loading config yaml: tests/e2e/nightly/multi_node/config/DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-01-31T18:30:29.1642085Z [2026-01-31 18:30:00] INFO multi_node_config.py:351: Resolving cluster IPs via DNS...
2026-01-31T18:30:29.1657532Z [2026-01-31 18:30:00] INFO multi_node_config.py:212: Node 0 envs: {'HCCL_OP_EXPANSION_MODE': 'AIV', 'VLLM_USE_MODELSCOPE': 'True', 'HCCL_BUFFSIZE': '1024', 'SERVER_PORT': '8080', 'OMP_PROC_BIND': 'False', 'OMP_NUM_THREADS': '1', 'VLLM_ASCEND_ENABLE_MLAPO': '1', 'PYTORCH_NPU_ALLOC_CONF': 'expandable_segments:True', 'VLLM_ASCEND_ENABLE_FLASHCOMM1': '1', 'ASCEND_A3_EBA_ENABLE': '1', 'HCCL_IF_IP': '10.0.0.188', 'HCCL_SOCKET_IFNAME': 'eth0', 'GLOO_SOCKET_IFNAME': 'eth0', 'TP_SOCKET_IFNAME': 'eth0', 'LOCAL_IP': '10.0.0.188', 'NIC_NAME': 'eth0', 'MASTER_IP': '10.0.0.188'}
2026-01-31T18:30:29.1667662Z [2026-01-31 18:30:00] INFO multi_node_config.py:137: Not launching proxy on non-master node
2026-01-31T18:30:29.1673786Z [2026-01-31 18:30:00] INFO conftest.py:107: Starting server with command: vllm serve vllm-ascend/DeepSeek-V3.2-W8A8 --host 0.0.0.0 --port 8080 --data-parallel-size 4 --data-parallel-size-local 2 --data-parallel-address 10.0.0.188 --data-parallel-rpc-port 13399 --tensor-parallel-size 8 --quantization ascend --seed 1024 --enable-expert-parallel --max-num-seqs 16 --max-model-len 8192 --max-num-batched-tokens 4096 --no-enable-prefix-caching --gpu-memory-utilization 0.85 --trust-remote-code --speculative-config {"num_speculative_tokens": 2, "method":"deepseek_mtp"} --tokenizer-mode deepseek_v32 --reasoning-parser deepseek_v3 --api-server-count 4
2026-01-31T18:30:29.1687020Z tests/e2e/nightly/multi_node/scripts/test_multi_node.py::test_multi_node INFO 01-31 18:30:07 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-01-31T18:30:29.1692109Z INFO 01-31 18:30:07 [__init__.py:45] - ascend -> vllm_ascend:register
2026-01-31T18:30:29.1700479Z INFO 01-31 18:30:07 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-01-31T18:30:29.1709375Z INFO 01-31 18:30:07 [__init__.py:217] Platform plugin ascend is activated
2026-01-31T18:30:29.1721607Z 2026-01-31 18:30:15,793 - 135 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.13.0+empty: default 1
2026-01-31T18:30:29.1733349Z INFO 01-31 18:30:15 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-01-31T18:30:29.1742574Z INFO 01-31 18:30:16 [api_server.py:1351] vLLM API server version 0.13.0
2026-01-31T18:30:29.1755168Z INFO 01-31 18:30:16 [utils.py:253] non-default args: {'model_tag': 'vllm-ascend/DeepSeek-V3.2-W8A8', 'api_server_count': 4, 'host': '0.0.0.0', 'port': 8080, 'model': 'vllm-ascend/DeepSeek-V3.2-W8A8', 'tokenizer_mode': 'deepseek_v32', 'trust_remote_code': True, 'seed': 1024, 'max_model_len': 8192, 'quantization': 'ascend', 'reasoning_parser': 'deepseek_v3', 'tensor_parallel_size': 8, 'data_parallel_size': 4, 'data_parallel_size_local': 2, 'data_parallel_address': '10.0.0.188', 'data_parallel_rpc_port': 13399, 'enable_expert_parallel': True, 'gpu_memory_utilization': 0.85, 'enable_prefix_caching': False, 'max_num_batched_tokens': 4096, 'max_num_seqs': 16, 'speculative_config': {'num_speculative_tokens': 2, 'method': 'deepseek_mtp'}}
2026-01-31T18:30:29.1763258Z 2026-01-31 18:30:16,143 - modelscope - WARNING - We can not confirm the cached file is for revision: master
2026-01-31T18:30:29.1773312Z INFO 01-31 18:30:16 [arg_utils.py:595] HF_HUB_OFFLINE is True, replace model_id [vllm-ascend/DeepSeek-V3.2-W8A8] to model_path [/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8]
2026-01-31T18:30:29.1782459Z The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-01-31T18:30:29.1793005Z You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-01-31T18:30:29.1806393Z INFO 01-31 18:30:25 [model.py:514] Resolved architecture: DeepseekV32ForCausalLM
2026-01-31T18:30:29.1815399Z INFO 01-31 18:30:25 [model.py:1661] Using max model len 8192
2026-01-31T18:30:29.1825165Z WARNING 01-31 18:30:25 [speculative.py:245] method `deepseek_mtp` is deprecated and replaced with mtp.
2026-01-31T18:30:29.1835416Z You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-01-31T18:30:35.0139196Z INFO 01-31 18:30:35 [model.py:514] Resolved architecture: DeepSeekMTPModel
2026-01-31T18:30:35.0174153Z INFO 01-31 18:30:35 [model.py:1661] Using max model len 163840
2026-01-31T18:30:35.0186013Z WARNING 01-31 18:30:35 [speculative.py:363] Enabling num_speculative_tokens > 1 will runmultiple times of forward on same MTP layer,which may result in lower acceptance rate
2026-01-31T18:30:35.0196676Z INFO 01-31 18:30:35 [scheduler.py:230] Chunked prefill is enabled with max_num_batched_tokens=4096.
2026-01-31T18:30:35.3025716Z WARNING 01-31 18:30:35 [platform.py:511] Speculative quantization is set but Ascend automatically uses the main model's quantization method. Resetting to None.
2026-01-31T18:30:35.3033250Z INFO 01-31 18:30:35 [ascend_config.py:55] Linear layer sharding enabled with config: None. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-01-31T18:30:35.3042902Z WARNING 01-31 18:30:35 [vllm.py:1003] Batch sizes [1, 2, 4] are removed because they are not multiple of tp_size 8 when sequence parallelism is enabled
2026-01-31T18:30:35.3053047Z INFO 01-31 18:30:35 [platform.py:254] PIECEWISE compilation enabled on NPU. use_inductor not supported - using only ACL Graph mode
2026-01-31T18:30:35.3062236Z INFO 01-31 18:30:35 [utils.py:498] Calculated maximum supported batch sizes for ACL graph: 2
2026-01-31T18:30:35.3072739Z INFO 01-31 18:30:35 [utils.py:543] Adjusted ACL graph batch sizes for DeepseekV32ForCausalLM model (layers: 61): 6 â†’ 2 sizes
2026-01-31T18:30:35.3082854Z INFO 01-31 18:30:35 [utils.py:821] Started DP Coordinator process (PID: 162)
2026-01-31T18:30:39.8231148Z INFO 01-31 18:30:39 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-01-31T18:30:39.8239404Z INFO 01-31 18:30:39 [__init__.py:45] - ascend -> vllm_ascend:register
2026-01-31T18:30:39.8250243Z INFO 01-31 18:30:39 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-01-31T18:30:39.8309504Z INFO 01-31 18:30:39 [__init__.py:217] Platform plugin ascend is activated
2026-01-31T18:30:39.9854936Z INFO 01-31 18:30:39 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-01-31T18:30:39.9864090Z INFO 01-31 18:30:39 [__init__.py:45] - ascend -> vllm_ascend:register
2026-01-31T18:30:39.9876013Z INFO 01-31 18:30:39 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-01-31T18:30:39.9925471Z INFO 01-31 18:30:39 [__init__.py:217] Platform plugin ascend is activated
2026-01-31T18:30:49.5546373Z INFO 01-31 18:30:49 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-01-31T18:30:49.5554294Z INFO 01-31 18:30:49 [__init__.py:45] - ascend -> vllm_ascend:register
2026-01-31T18:30:49.5564515Z INFO 01-31 18:30:49 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-01-31T18:30:49.5622380Z INFO 01-31 18:30:49 [__init__.py:217] Platform plugin ascend is activated
2026-01-31T18:30:54.7940333Z INFO 01-31 18:30:54 [utils.py:216] Started 4 API server processes
2026-01-31T18:30:55.1724227Z [0;36m(EngineCore_DP1 pid=184)[0;0m 2026-01-31 18:30:55,170 - 184 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.13.0+empty: default 1
2026-01-31T18:30:55.1744899Z [0;36m(EngineCore_DP0 pid=165)[0;0m 2026-01-31 18:30:55,170 - 165 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.13.0+empty: default 1
2026-01-31T18:30:55.1768106Z [0;36m(EngineCore_DP1 pid=184)[0;0m INFO 01-31 18:30:55 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-01-31T18:30:55.1778203Z [0;36m(EngineCore_DP0 pid=165)[0;0m INFO 01-31 18:30:55 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-01-31T18:30:55.1806081Z [0;36m(EngineCore_DP0 pid=165)[0;0m INFO 01-31 18:30:55 [core.py:93] Initializing a V1 LLM engine (v0.13.0) with config: model='/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8', speculative_config=SpeculativeConfig(method='mtp', model='/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8', num_spec_tokens=2), tokenizer='/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8', skip_tokenizer_init=False, tokenizer_mode=deepseek_v32, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=8, pipeline_parallel_size=1, data_parallel_size=4, disable_custom_all_reduce=True, quantization=ascend, enforce_eager=False, kv_cache_dtype=auto, device_config=npu, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='deepseek_v3', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01, cudagraph_metrics=False, enable_layerwise_nvtx_tracing=False), seed=1024, served_model_name=/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'vllm_ascend.compilation.compiler_interface.AscendCompiler', 'custom_ops': ['all'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer', 'vllm::mla_forward'], 'compile_mm_encoder': False, 'compile_sizes': [], 'compile_ranges_split_points': [4096], 'inductor_compile_config': {'enable_auto_functionalized_v2': False}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.PIECEWISE: 1>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [8, 48], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': True, 'fuse_act_quant': True, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 48, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>, 'evaluate_guards': False}, 'local_cache_dir': None}
2026-01-31T18:30:59.5118158Z INFO 01-31 18:30:59 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-01-31T18:30:59.5127923Z INFO 01-31 18:30:59 [__init__.py:45] - ascend -> vllm_ascend:register
2026-01-31T18:30:59.5139330Z INFO 01-31 18:30:59 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-01-31T18:30:59.5208350Z INFO 01-31 18:30:59 [__init__.py:217] Platform plugin ascend is activated
2026-01-31T18:30:59.9623992Z INFO 01-31 18:30:59 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-01-31T18:30:59.9630466Z INFO 01-31 18:30:59 [__init__.py:45] - ascend -> vllm_ascend:register
2026-01-31T18:30:59.9640563Z INFO 01-31 18:30:59 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-01-31T18:30:59.9727914Z INFO 01-31 18:30:59 [__init__.py:217] Platform plugin ascend is activated
2026-01-31T18:31:00.0571377Z INFO 01-31 18:31:00 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-01-31T18:31:00.0586526Z INFO 01-31 18:31:00 [__init__.py:45] - ascend -> vllm_ascend:register
2026-01-31T18:31:00.0587681Z INFO 01-31 18:31:00 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-01-31T18:31:00.0687430Z INFO 01-31 18:31:00 [__init__.py:217] Platform plugin ascend is activated
2026-01-31T18:31:00.0727880Z INFO 01-31 18:31:00 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-01-31T18:31:00.0736896Z INFO 01-31 18:31:00 [__init__.py:45] - ascend -> vllm_ascend:register
2026-01-31T18:31:00.0746974Z INFO 01-31 18:31:00 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-01-31T18:31:00.0779451Z INFO 01-31 18:31:00 [__init__.py:217] Platform plugin ascend is activated
2026-01-31T18:31:00.1974124Z INFO 01-31 18:31:00 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-01-31T18:31:00.1981044Z INFO 01-31 18:31:00 [__init__.py:45] - ascend -> vllm_ascend:register
2026-01-31T18:31:00.1991075Z INFO 01-31 18:31:00 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-01-31T18:31:00.2061413Z INFO 01-31 18:31:00 [__init__.py:217] Platform plugin ascend is activated
2026-01-31T18:31:00.2520283Z INFO 01-31 18:31:00 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-01-31T18:31:00.2529330Z INFO 01-31 18:31:00 [__init__.py:45] - ascend -> vllm_ascend:register
2026-01-31T18:31:00.2540689Z INFO 01-31 18:31:00 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-01-31T18:31:00.2613919Z INFO 01-31 18:31:00 [__init__.py:217] Platform plugin ascend is activated
2026-01-31T18:31:05.4560695Z [0;36m(ApiServer_1 pid=196)[0;0m 2026-01-31 18:31:05,453 - 196 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.13.0+empty: default 1
2026-01-31T18:31:05.4746555Z [0;36m(ApiServer_1 pid=196)[0;0m INFO 01-31 18:31:05 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-01-31T18:31:05.5094268Z [0;36m(ApiServer_1 pid=196)[0;0m 2026-01-31 18:31:05,497 - modelscope - WARNING - We can not confirm the cached file is for revision: master
2026-01-31T18:31:05.5103016Z [0;36m(ApiServer_1 pid=196)[0;0m INFO 01-31 18:31:05 [arg_utils.py:595] HF_HUB_OFFLINE is True, replace model_id [vllm-ascend/DeepSeek-V3.2-W8A8] to model_path [/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8]
2026-01-31T18:31:05.6157232Z [0;36m(ApiServer_1 pid=196)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-01-31T18:31:05.6189527Z [0;36m(ApiServer_1 pid=196)[0;0m You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-01-31T18:31:05.6315345Z [0;36m(ApiServer_1 pid=196)[0;0m INFO 01-31 18:31:05 [model.py:514] Resolved architecture: DeepseekV32ForCausalLM
2026-01-31T18:31:05.6396213Z [0;36m(ApiServer_1 pid=196)[0;0m INFO 01-31 18:31:05 [model.py:1661] Using max model len 8192
2026-01-31T18:31:05.7373953Z [0;36m(ApiServer_3 pid=198)[0;0m 2026-01-31 18:31:05,735 - 198 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.13.0+empty: default 1
2026-01-31T18:31:05.7588800Z [0;36m(ApiServer_3 pid=198)[0;0m INFO 01-31 18:31:05 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-01-31T18:31:05.7739391Z [0;36m(ApiServer_1 pid=196)[0;0m WARNING 01-31 18:31:05 [speculative.py:245] method `deepseek_mtp` is deprecated and replaced with mtp.
2026-01-31T18:31:05.7763517Z [0;36m(ApiServer_3 pid=198)[0;0m 2026-01-31 18:31:05,773 - modelscope - WARNING - We can not confirm the cached file is for revision: master
2026-01-31T18:31:05.7773666Z [0;36m(ApiServer_3 pid=198)[0;0m INFO 01-31 18:31:05 [arg_utils.py:595] HF_HUB_OFFLINE is True, replace model_id [vllm-ascend/DeepSeek-V3.2-W8A8] to model_path [/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8]
2026-01-31T18:31:05.7783310Z [0;36m(ApiServer_1 pid=196)[0;0m You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-01-31T18:31:05.7844597Z [0;36m(ApiServer_1 pid=196)[0;0m INFO 01-31 18:31:05 [model.py:514] Resolved architecture: DeepSeekMTPModel
2026-01-31T18:31:05.7867714Z [0;36m(ApiServer_1 pid=196)[0;0m INFO 01-31 18:31:05 [model.py:1661] Using max model len 163840
2026-01-31T18:31:05.7877955Z [0;36m(ApiServer_1 pid=196)[0;0m WARNING 01-31 18:31:05 [speculative.py:363] Enabling num_speculative_tokens > 1 will runmultiple times of forward on same MTP layer,which may result in lower acceptance rate
2026-01-31T18:31:05.7887727Z [0;36m(ApiServer_1 pid=196)[0;0m INFO 01-31 18:31:05 [scheduler.py:230] Chunked prefill is enabled with max_num_batched_tokens=4096.
2026-01-31T18:31:05.8873002Z [0;36m(ApiServer_3 pid=198)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-01-31T18:31:05.8894092Z [0;36m(ApiServer_0 pid=195)[0;0m 2026-01-31 18:31:05,887 - 195 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.13.0+empty: default 1
2026-01-31T18:31:05.8917440Z [0;36m(ApiServer_3 pid=198)[0;0m You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-01-31T18:31:05.8927574Z [0;36m(ApiServer_1 pid=196)[0;0m WARNING 01-31 18:31:05 [platform.py:511] Speculative quantization is set but Ascend automatically uses the main model's quantization method. Resetting to None.
2026-01-31T18:31:05.8938493Z [0;36m(ApiServer_1 pid=196)[0;0m INFO 01-31 18:31:05 [ascend_config.py:55] Linear layer sharding enabled with config: None. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-01-31T18:31:05.8947537Z [0;36m(ApiServer_1 pid=196)[0;0m WARNING 01-31 18:31:05 [vllm.py:1003] Batch sizes [1, 2, 4] are removed because they are not multiple of tp_size 8 when sequence parallelism is enabled
2026-01-31T18:31:05.8958079Z [0;36m(ApiServer_1 pid=196)[0;0m INFO 01-31 18:31:05 [platform.py:254] PIECEWISE compilation enabled on NPU. use_inductor not supported - using only ACL Graph mode
2026-01-31T18:31:05.8967624Z [0;36m(ApiServer_1 pid=196)[0;0m INFO 01-31 18:31:05 [utils.py:498] Calculated maximum supported batch sizes for ACL graph: 2
2026-01-31T18:31:05.8978435Z [0;36m(ApiServer_1 pid=196)[0;0m INFO 01-31 18:31:05 [utils.py:543] Adjusted ACL graph batch sizes for DeepseekV32ForCausalLM model (layers: 61): 6 â†’ 2 sizes
2026-01-31T18:31:05.8987729Z [0;36m(ApiServer_3 pid=198)[0;0m INFO 01-31 18:31:05 [model.py:514] Resolved architecture: DeepseekV32ForCausalLM
2026-01-31T18:31:05.8998178Z [0;36m(ApiServer_3 pid=198)[0;0m INFO 01-31 18:31:05 [model.py:1661] Using max model len 8192
2026-01-31T18:31:05.9073058Z [0;36m(ApiServer_0 pid=195)[0;0m INFO 01-31 18:31:05 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-01-31T18:31:05.9218752Z [0;36m(ApiServer_0 pid=195)[0;0m 2026-01-31 18:31:05,920 - modelscope - WARNING - We can not confirm the cached file is for revision: master
2026-01-31T18:31:05.9228662Z [0;36m(ApiServer_0 pid=195)[0;0m INFO 01-31 18:31:05 [arg_utils.py:595] HF_HUB_OFFLINE is True, replace model_id [vllm-ascend/DeepSeek-V3.2-W8A8] to model_path [/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8]
2026-01-31T18:31:05.9568901Z [0;36m(ApiServer_2 pid=197)[0;0m 2026-01-31 18:31:05,955 - 197 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.13.0+empty: default 1
2026-01-31T18:31:05.9755189Z [0;36m(ApiServer_2 pid=197)[0;0m INFO 01-31 18:31:05 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-01-31T18:31:05.9902870Z [0;36m(ApiServer_2 pid=197)[0;0m 2026-01-31 18:31:05,988 - modelscope - WARNING - We can not confirm the cached file is for revision: master
2026-01-31T18:31:05.9924776Z [0;36m(ApiServer_2 pid=197)[0;0m INFO 01-31 18:31:05 [arg_utils.py:595] HF_HUB_OFFLINE is True, replace model_id [vllm-ascend/DeepSeek-V3.2-W8A8] to model_path [/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8]
2026-01-31T18:31:06.0347791Z [0;36m(ApiServer_0 pid=195)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-01-31T18:31:06.0383856Z [0;36m(ApiServer_3 pid=198)[0;0m WARNING 01-31 18:31:06 [speculative.py:245] method `deepseek_mtp` is deprecated and replaced with mtp.
2026-01-31T18:31:06.0393291Z [0;36m(ApiServer_0 pid=195)[0;0m You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-01-31T18:31:06.0423989Z [0;36m(ApiServer_3 pid=198)[0;0m You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-01-31T18:31:06.0461558Z [0;36m(ApiServer_3 pid=198)[0;0m INFO 01-31 18:31:06 [model.py:514] Resolved architecture: DeepSeekMTPModel
2026-01-31T18:31:06.0481316Z [0;36m(ApiServer_3 pid=198)[0;0m INFO 01-31 18:31:06 [model.py:1661] Using max model len 163840
2026-01-31T18:31:06.0491003Z [0;36m(ApiServer_3 pid=198)[0;0m WARNING 01-31 18:31:06 [speculative.py:363] Enabling num_speculative_tokens > 1 will runmultiple times of forward on same MTP layer,which may result in lower acceptance rate
2026-01-31T18:31:06.0500403Z [0;36m(ApiServer_3 pid=198)[0;0m INFO 01-31 18:31:06 [scheduler.py:230] Chunked prefill is enabled with max_num_batched_tokens=4096.
2026-01-31T18:31:06.0509352Z [0;36m(ApiServer_0 pid=195)[0;0m INFO 01-31 18:31:06 [model.py:514] Resolved architecture: DeepseekV32ForCausalLM
2026-01-31T18:31:06.0518877Z [0;36m(ApiServer_0 pid=195)[0;0m INFO 01-31 18:31:06 [model.py:1661] Using max model len 8192
2026-01-31T18:31:06.1045214Z [0;36m(ApiServer_2 pid=197)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-01-31T18:31:06.1067661Z [0;36m(ApiServer_2 pid=197)[0;0m You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-01-31T18:31:06.1140107Z [0;36m(ApiServer_2 pid=197)[0;0m INFO 01-31 18:31:06 [model.py:514] Resolved architecture: DeepseekV32ForCausalLM
2026-01-31T18:31:06.1149374Z [0;36m(ApiServer_2 pid=197)[0;0m INFO 01-31 18:31:06 [model.py:1661] Using max model len 8192
2026-01-31T18:31:06.1448791Z 2026-01-31 18:31:06,143 - 213 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.13.0+empty: default 1
2026-01-31T18:31:06.1480132Z INFO 01-31 18:31:06 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-01-31T18:31:06.1513147Z [0;36m(ApiServer_3 pid=198)[0;0m WARNING 01-31 18:31:06 [platform.py:511] Speculative quantization is set but Ascend automatically uses the main model's quantization method. Resetting to None.
2026-01-31T18:31:06.1536951Z [0;36m(ApiServer_3 pid=198)[0;0m INFO 01-31 18:31:06 [ascend_config.py:55] Linear layer sharding enabled with config: None. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-01-31T18:31:06.1544444Z [0;36m(ApiServer_3 pid=198)[0;0m WARNING 01-31 18:31:06 [vllm.py:1003] Batch sizes [1, 2, 4] are removed because they are not multiple of tp_size 8 when sequence parallelism is enabled
2026-01-31T18:31:06.1553376Z [0;36m(ApiServer_3 pid=198)[0;0m INFO 01-31 18:31:06 [platform.py:254] PIECEWISE compilation enabled on NPU. use_inductor not supported - using only ACL Graph mode
2026-01-31T18:31:06.1564113Z [0;36m(ApiServer_3 pid=198)[0;0m INFO 01-31 18:31:06 [utils.py:498] Calculated maximum supported batch sizes for ACL graph: 2
2026-01-31T18:31:06.1572270Z [0;36m(ApiServer_3 pid=198)[0;0m INFO 01-31 18:31:06 [utils.py:543] Adjusted ACL graph batch sizes for DeepseekV32ForCausalLM model (layers: 61): 6 â†’ 2 sizes
2026-01-31T18:31:06.1915502Z [0;36m(ApiServer_0 pid=195)[0;0m WARNING 01-31 18:31:06 [speculative.py:245] method `deepseek_mtp` is deprecated and replaced with mtp.
2026-01-31T18:31:06.1938420Z [0;36m(ApiServer_0 pid=195)[0;0m You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-01-31T18:31:06.1993323Z [0;36m(ApiServer_0 pid=195)[0;0m INFO 01-31 18:31:06 [model.py:514] Resolved architecture: DeepSeekMTPModel
2026-01-31T18:31:06.2016167Z [0;36m(ApiServer_0 pid=195)[0;0m INFO 01-31 18:31:06 [model.py:1661] Using max model len 163840
2026-01-31T18:31:06.2025805Z [0;36m(ApiServer_0 pid=195)[0;0m WARNING 01-31 18:31:06 [speculative.py:363] Enabling num_speculative_tokens > 1 will runmultiple times of forward on same MTP layer,which may result in lower acceptance rate
2026-01-31T18:31:06.2034726Z [0;36m(ApiServer_0 pid=195)[0;0m INFO 01-31 18:31:06 [scheduler.py:230] Chunked prefill is enabled with max_num_batched_tokens=4096.
2026-01-31T18:31:06.2546433Z [0;36m(ApiServer_2 pid=197)[0;0m WARNING 01-31 18:31:06 [speculative.py:245] method `deepseek_mtp` is deprecated and replaced with mtp.
2026-01-31T18:31:06.2566406Z [0;36m(ApiServer_2 pid=197)[0;0m You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-01-31T18:31:06.2624954Z [0;36m(ApiServer_2 pid=197)[0;0m INFO 01-31 18:31:06 [model.py:514] Resolved architecture: DeepSeekMTPModel
2026-01-31T18:31:06.2671507Z [0;36m(ApiServer_2 pid=197)[0;0m INFO 01-31 18:31:06 [model.py:1661] Using max model len 163840
2026-01-31T18:31:06.2682670Z [0;36m(ApiServer_2 pid=197)[0;0m WARNING 01-31 18:31:06 [speculative.py:363] Enabling num_speculative_tokens > 1 will runmultiple times of forward on same MTP layer,which may result in lower acceptance rate
2026-01-31T18:31:06.2691248Z [0;36m(ApiServer_2 pid=197)[0;0m INFO 01-31 18:31:06 [scheduler.py:230] Chunked prefill is enabled with max_num_batched_tokens=4096.
2026-01-31T18:31:06.3080677Z [0;36m(ApiServer_0 pid=195)[0;0m WARNING 01-31 18:31:06 [platform.py:511] Speculative quantization is set but Ascend automatically uses the main model's quantization method. Resetting to None.
2026-01-31T18:31:06.3090139Z [0;36m(ApiServer_0 pid=195)[0;0m INFO 01-31 18:31:06 [ascend_config.py:55] Linear layer sharding enabled with config: None. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-01-31T18:31:06.3099347Z [0;36m(ApiServer_0 pid=195)[0;0m WARNING 01-31 18:31:06 [vllm.py:1003] Batch sizes [1, 2, 4] are removed because they are not multiple of tp_size 8 when sequence parallelism is enabled
2026-01-31T18:31:06.3109136Z [0;36m(ApiServer_0 pid=195)[0;0m INFO 01-31 18:31:06 [platform.py:254] PIECEWISE compilation enabled on NPU. use_inductor not supported - using only ACL Graph mode
2026-01-31T18:31:06.3119094Z [0;36m(ApiServer_0 pid=195)[0;0m INFO 01-31 18:31:06 [utils.py:498] Calculated maximum supported batch sizes for ACL graph: 2
2026-01-31T18:31:06.3128764Z [0;36m(ApiServer_0 pid=195)[0;0m INFO 01-31 18:31:06 [utils.py:543] Adjusted ACL graph batch sizes for DeepseekV32ForCausalLM model (layers: 61): 6 â†’ 2 sizes
2026-01-31T18:31:06.3671307Z [0;36m(ApiServer_2 pid=197)[0;0m WARNING 01-31 18:31:06 [platform.py:511] Speculative quantization is set but Ascend automatically uses the main model's quantization method. Resetting to None.
2026-01-31T18:31:06.3683015Z [0;36m(ApiServer_2 pid=197)[0;0m INFO 01-31 18:31:06 [ascend_config.py:55] Linear layer sharding enabled with config: None. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-01-31T18:31:06.3693893Z [0;36m(ApiServer_2 pid=197)[0;0m WARNING 01-31 18:31:06 [vllm.py:1003] Batch sizes [1, 2, 4] are removed because they are not multiple of tp_size 8 when sequence parallelism is enabled
2026-01-31T18:31:06.3703096Z [0;36m(ApiServer_2 pid=197)[0;0m INFO 01-31 18:31:06 [platform.py:254] PIECEWISE compilation enabled on NPU. use_inductor not supported - using only ACL Graph mode
2026-01-31T18:31:06.3712440Z [0;36m(ApiServer_2 pid=197)[0;0m INFO 01-31 18:31:06 [utils.py:498] Calculated maximum supported batch sizes for ACL graph: 2
2026-01-31T18:31:06.3722307Z [0;36m(ApiServer_2 pid=197)[0;0m INFO 01-31 18:31:06 [utils.py:543] Adjusted ACL graph batch sizes for DeepseekV32ForCausalLM model (layers: 61): 6 â†’ 2 sizes
2026-01-31T18:31:06.4696187Z 2026-01-31 18:31:06,467 - 212 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.13.0+empty: default 1
2026-01-31T18:31:06.4764228Z INFO 01-31 18:31:06 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-01-31T18:31:10.1534589Z INFO 01-31 18:31:10 [ascend_config.py:55] Linear layer sharding enabled with config: None. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-01-31T18:31:10.1543381Z INFO 01-31 18:31:10 [ascend_config.py:55] Linear layer sharding enabled with config: None. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-01-31T18:31:10.2276479Z INFO 01-31 18:31:10 [parallel_state.py:1203] world_size=32 rank=8 local_rank=0 distributed_init_method=tcp://10.0.0.188:54993 backend=hccl
2026-01-31T18:31:10.2297356Z INFO 01-31 18:31:10 [parallel_state.py:1203] world_size=32 rank=0 local_rank=0 distributed_init_method=tcp://10.0.0.188:54993 backend=hccl
2026-01-31T18:31:10.4825267Z INFO 01-31 18:31:10 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-01-31T18:31:10.4832267Z INFO 01-31 18:31:10 [__init__.py:45] - ascend -> vllm_ascend:register
2026-01-31T18:31:10.4843059Z INFO 01-31 18:31:10 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-01-31T18:31:10.4903105Z INFO 01-31 18:31:10 [__init__.py:217] Platform plugin ascend is activated
2026-01-31T18:31:10.8147954Z INFO 01-31 18:31:10 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-01-31T18:31:10.8155151Z INFO 01-31 18:31:10 [__init__.py:45] - ascend -> vllm_ascend:register
2026-01-31T18:31:10.8164924Z INFO 01-31 18:31:10 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-01-31T18:31:10.8241740Z INFO 01-31 18:31:10 [__init__.py:217] Platform plugin ascend is activated
2026-01-31T18:31:15.8814933Z 2026-01-31 18:31:15,877 - 268 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.13.0+empty: default 1
2026-01-31T18:31:15.8824256Z INFO 01-31 18:31:15 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-01-31T18:31:16.2177222Z 2026-01-31 18:31:16,215 - 277 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.13.0+empty: default 1
2026-01-31T18:31:16.2213131Z INFO 01-31 18:31:16 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-01-31T18:31:17.9290487Z INFO 01-31 18:31:17 [ascend_config.py:55] Linear layer sharding enabled with config: None. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-01-31T18:31:18.2704072Z INFO 01-31 18:31:18 [ascend_config.py:55] Linear layer sharding enabled with config: None. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-01-31T18:31:18.3658348Z INFO 01-31 18:31:18 [parallel_state.py:1203] world_size=32 rank=1 local_rank=1 distributed_init_method=tcp://10.0.0.188:54993 backend=hccl
2026-01-31T18:31:18.7109683Z INFO 01-31 18:31:18 [parallel_state.py:1203] world_size=32 rank=9 local_rank=1 distributed_init_method=tcp://10.0.0.188:54993 backend=hccl
2026-01-31T18:31:20.5832185Z INFO 01-31 18:31:20 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-01-31T18:31:20.5837971Z INFO 01-31 18:31:20 [__init__.py:45] - ascend -> vllm_ascend:register
2026-01-31T18:31:20.5847389Z INFO 01-31 18:31:20 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-01-31T18:31:20.5914357Z INFO 01-31 18:31:20 [__init__.py:217] Platform plugin ascend is activated
2026-01-31T18:31:20.6445130Z INFO 01-31 18:31:20 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-01-31T18:31:20.6453882Z INFO 01-31 18:31:20 [__init__.py:45] - ascend -> vllm_ascend:register
2026-01-31T18:31:20.6463065Z INFO 01-31 18:31:20 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-01-31T18:31:20.6526115Z INFO 01-31 18:31:20 [__init__.py:217] Platform plugin ascend is activated
2026-01-31T18:31:26.1381851Z 2026-01-31 18:31:26,128 - 381 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.13.0+empty: default 1
2026-01-31T18:31:26.1382543Z 2026-01-31 18:31:26,130 - 379 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.13.0+empty: default 1
2026-01-31T18:31:26.1383205Z INFO 01-31 18:31:26 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-01-31T18:31:26.1384400Z INFO 01-31 18:31:26 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-01-31T18:31:28.2270950Z INFO 01-31 18:31:28 [ascend_config.py:55] Linear layer sharding enabled with config: None. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-01-31T18:31:28.2495725Z INFO 01-31 18:31:28 [ascend_config.py:55] Linear layer sharding enabled with config: None. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-01-31T18:31:28.6706337Z INFO 01-31 18:31:28 [parallel_state.py:1203] world_size=32 rank=2 local_rank=2 distributed_init_method=tcp://10.0.0.188:54993 backend=hccl
2026-01-31T18:31:28.6869559Z INFO 01-31 18:31:28 [parallel_state.py:1203] world_size=32 rank=10 local_rank=2 distributed_init_method=tcp://10.0.0.188:54993 backend=hccl
2026-01-31T18:31:30.6113625Z INFO 01-31 18:31:30 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-01-31T18:31:30.6122835Z INFO 01-31 18:31:30 [__init__.py:45] - ascend -> vllm_ascend:register
2026-01-31T18:31:30.6137591Z INFO 01-31 18:31:30 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-01-31T18:31:30.6195369Z INFO 01-31 18:31:30 [__init__.py:217] Platform plugin ascend is activated
2026-01-31T18:31:30.6863673Z INFO 01-31 18:31:30 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-01-31T18:31:30.6877437Z INFO 01-31 18:31:30 [__init__.py:45] - ascend -> vllm_ascend:register
2026-01-31T18:31:30.6886771Z INFO 01-31 18:31:30 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-01-31T18:31:30.6943558Z INFO 01-31 18:31:30 [__init__.py:217] Platform plugin ascend is activated
2026-01-31T18:31:36.3263242Z 2026-01-31 18:31:36,324 - 481 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.13.0+empty: default 1
2026-01-31T18:31:36.3288206Z INFO 01-31 18:31:36 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-01-31T18:31:36.3486783Z 2026-01-31 18:31:36,347 - 480 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.13.0+empty: default 1
2026-01-31T18:31:36.3520981Z INFO 01-31 18:31:36 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-01-31T18:31:38.4432467Z INFO 01-31 18:31:38 [ascend_config.py:55] Linear layer sharding enabled with config: None. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-01-31T18:31:38.6692178Z INFO 01-31 18:31:38 [ascend_config.py:55] Linear layer sharding enabled with config: None. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-01-31T18:31:38.8814624Z INFO 01-31 18:31:38 [parallel_state.py:1203] world_size=32 rank=3 local_rank=3 distributed_init_method=tcp://10.0.0.188:54993 backend=hccl
2026-01-31T18:31:39.0992434Z INFO 01-31 18:31:39 [parallel_state.py:1203] world_size=32 rank=11 local_rank=3 distributed_init_method=tcp://10.0.0.188:54993 backend=hccl
2026-01-31T18:31:40.9820689Z INFO 01-31 18:31:40 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-01-31T18:31:40.9829447Z INFO 01-31 18:31:40 [__init__.py:45] - ascend -> vllm_ascend:register
2026-01-31T18:31:40.9838741Z INFO 01-31 18:31:40 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-01-31T18:31:40.9900581Z INFO 01-31 18:31:40 [__init__.py:217] Platform plugin ascend is activated
2026-01-31T18:31:41.2003002Z INFO 01-31 18:31:41 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-01-31T18:31:41.2008278Z INFO 01-31 18:31:41 [__init__.py:45] - ascend -> vllm_ascend:register
2026-01-31T18:31:41.2018642Z INFO 01-31 18:31:41 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-01-31T18:31:41.2084073Z INFO 01-31 18:31:41 [__init__.py:217] Platform plugin ascend is activated
2026-01-31T18:31:46.7721382Z 2026-01-31 18:31:46,770 - 583 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.13.0+empty: default 1
2026-01-31T18:31:46.7748365Z INFO 01-31 18:31:46 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-01-31T18:31:46.9475645Z 2026-01-31 18:31:46,945 - 582 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.13.0+empty: default 1
2026-01-31T18:31:46.9505936Z INFO 01-31 18:31:46 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-01-31T18:31:48.8555912Z INFO 01-31 18:31:48 [ascend_config.py:55] Linear layer sharding enabled with config: None. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-01-31T18:31:49.0768871Z INFO 01-31 18:31:49 [ascend_config.py:55] Linear layer sharding enabled with config: None. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-01-31T18:31:49.2840510Z INFO 01-31 18:31:49 [parallel_state.py:1203] world_size=32 rank=12 local_rank=4 distributed_init_method=tcp://10.0.0.188:54993 backend=hccl
2026-01-31T18:31:49.5090921Z INFO 01-31 18:31:49 [parallel_state.py:1203] world_size=32 rank=4 local_rank=4 distributed_init_method=tcp://10.0.0.188:54993 backend=hccl
2026-01-31T18:31:51.4870098Z INFO 01-31 18:31:51 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-01-31T18:31:51.4878344Z INFO 01-31 18:31:51 [__init__.py:45] - ascend -> vllm_ascend:register
2026-01-31T18:31:51.4888191Z INFO 01-31 18:31:51 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-01-31T18:31:51.4954261Z INFO 01-31 18:31:51 [__init__.py:217] Platform plugin ascend is activated
2026-01-31T18:31:51.5737642Z INFO 01-31 18:31:51 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-01-31T18:31:51.5745959Z INFO 01-31 18:31:51 [__init__.py:45] - ascend -> vllm_ascend:register
2026-01-31T18:31:51.5755271Z INFO 01-31 18:31:51 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-01-31T18:31:51.5840400Z INFO 01-31 18:31:51 [__init__.py:217] Platform plugin ascend is activated
2026-01-31T18:31:56.8942519Z 2026-01-31 18:31:56,891 - 686 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.13.0+empty: default 1
2026-01-31T18:31:56.8967244Z INFO 01-31 18:31:56 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-01-31T18:31:57.1367756Z 2026-01-31 18:31:57,134 - 687 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.13.0+empty: default 1
2026-01-31T18:31:57.1395300Z INFO 01-31 18:31:57 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-01-31T18:31:58.9372781Z INFO 01-31 18:31:58 [ascend_config.py:55] Linear layer sharding enabled with config: None. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-01-31T18:31:59.2081906Z INFO 01-31 18:31:59 [ascend_config.py:55] Linear layer sharding enabled with config: None. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-01-31T18:31:59.3740101Z INFO 01-31 18:31:59 [parallel_state.py:1203] world_size=32 rank=13 local_rank=5 distributed_init_method=tcp://10.0.0.188:54993 backend=hccl
2026-01-31T18:31:59.6357215Z INFO 01-31 18:31:59 [parallel_state.py:1203] world_size=32 rank=5 local_rank=5 distributed_init_method=tcp://10.0.0.188:54993 backend=hccl
2026-01-31T18:32:01.3013547Z INFO 01-31 18:32:01 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-01-31T18:32:01.3020454Z INFO 01-31 18:32:01 [__init__.py:45] - ascend -> vllm_ascend:register
2026-01-31T18:32:01.3029759Z INFO 01-31 18:32:01 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-01-31T18:32:01.3092575Z INFO 01-31 18:32:01 [__init__.py:217] Platform plugin ascend is activated
2026-01-31T18:32:01.6795355Z INFO 01-31 18:32:01 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-01-31T18:32:01.6801017Z INFO 01-31 18:32:01 [__init__.py:45] - ascend -> vllm_ascend:register
2026-01-31T18:32:01.6810971Z INFO 01-31 18:32:01 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-01-31T18:32:01.6882908Z INFO 01-31 18:32:01 [__init__.py:217] Platform plugin ascend is activated
2026-01-31T18:32:06.7380927Z 2026-01-31 18:32:06,735 - 786 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.13.0+empty: default 1
2026-01-31T18:32:06.7407879Z INFO 01-31 18:32:06 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-01-31T18:32:07.2328582Z 2026-01-31 18:32:07,230 - 789 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.13.0+empty: default 1
2026-01-31T18:32:07.2357907Z INFO 01-31 18:32:07 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-01-31T18:32:08.8108617Z INFO 01-31 18:32:08 [ascend_config.py:55] Linear layer sharding enabled with config: None. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-01-31T18:32:09.2346636Z INFO 01-31 18:32:09 [parallel_state.py:1203] world_size=32 rank=14 local_rank=6 distributed_init_method=tcp://10.0.0.188:54993 backend=hccl
2026-01-31T18:32:09.3266179Z INFO 01-31 18:32:09 [ascend_config.py:55] Linear layer sharding enabled with config: None. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-01-31T18:32:09.7664125Z INFO 01-31 18:32:09 [parallel_state.py:1203] world_size=32 rank=6 local_rank=6 distributed_init_method=tcp://10.0.0.188:54993 backend=hccl
2026-01-31T18:32:11.3790836Z INFO 01-31 18:32:11 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-01-31T18:32:11.3798325Z INFO 01-31 18:32:11 [__init__.py:45] - ascend -> vllm_ascend:register
2026-01-31T18:32:11.3808326Z INFO 01-31 18:32:11 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-01-31T18:32:11.3873326Z INFO 01-31 18:32:11 [__init__.py:217] Platform plugin ascend is activated
2026-01-31T18:32:11.8144963Z INFO 01-31 18:32:11 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-01-31T18:32:11.8151398Z INFO 01-31 18:32:11 [__init__.py:45] - ascend -> vllm_ascend:register
2026-01-31T18:32:11.8160286Z INFO 01-31 18:32:11 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-01-31T18:32:11.8240807Z INFO 01-31 18:32:11 [__init__.py:217] Platform plugin ascend is activated
2026-01-31T18:32:16.8543706Z 2026-01-31 18:32:16,849 - 888 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.13.0+empty: default 1
2026-01-31T18:32:16.8546959Z INFO 01-31 18:32:16 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-01-31T18:32:17.3688592Z 2026-01-31 18:32:17,367 - 891 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.13.0+empty: default 1
2026-01-31T18:32:17.3719902Z INFO 01-31 18:32:17 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-01-31T18:32:18.9814391Z INFO 01-31 18:32:18 [ascend_config.py:55] Linear layer sharding enabled with config: None. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-01-31T18:32:19.4000836Z INFO 01-31 18:32:19 [ascend_config.py:55] Linear layer sharding enabled with config: None. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-01-31T18:32:19.4136438Z INFO 01-31 18:32:19 [parallel_state.py:1203] world_size=32 rank=15 local_rank=7 distributed_init_method=tcp://10.0.0.188:54993 backend=hccl
2026-01-31T18:32:19.8283711Z INFO 01-31 18:32:19 [parallel_state.py:1203] world_size=32 rank=7 local_rank=7 distributed_init_method=tcp://10.0.0.188:54993 backend=hccl
2026-01-31T18:32:19.8735226Z [Gloo] Rank 0 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-01-31T18:32:19.8790204Z [Gloo] Rank 2 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-01-31T18:32:19.8799794Z [Gloo] Rank 3 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-01-31T18:32:19.8810760Z [Gloo] Rank 4 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-01-31T18:32:19.8820107Z [Gloo] Rank 5 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-01-31T18:32:19.8830428Z [Gloo] Rank 6 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-01-31T18:32:19.8840147Z [Gloo] Rank 7 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-01-31T18:32:19.9256467Z [Gloo] Rank 8 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-01-31T18:32:19.9261459Z [Gloo] Rank 9 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-01-31T18:32:19.9269860Z [Gloo] Rank 11 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-01-31T18:32:19.9279546Z [Gloo] Rank 10 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-01-31T18:32:19.9301017Z [Gloo] Rank 1 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-01-31T18:32:19.9425440Z [Gloo] Rank 12 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-01-31T18:32:19.9444872Z [Gloo] Rank 13 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-01-31T18:32:19.9453620Z [Gloo] Rank 14 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-01-31T18:32:19.9463610Z [Gloo] Rank 15 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-01-31T18:32:20.0294261Z [Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-01-31T18:32:20.0302969Z [Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-01-31T18:32:20.0311415Z [Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-01-31T18:32:20.0321282Z [Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-01-31T18:32:20.0330078Z [Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-01-31T18:32:20.0339392Z [Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-01-31T18:32:20.0348852Z [Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-01-31T18:32:20.0358068Z [Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-01-31T18:32:20.0368003Z [Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-01-31T18:32:20.0377706Z [Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-01-31T18:32:20.0387110Z [Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-01-31T18:32:20.0397627Z [Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-01-31T18:32:20.0406422Z [Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-01-31T18:32:20.0416071Z [Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-01-31T18:32:20.0425702Z [Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-01-31T18:32:20.0435155Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-31T18:32:20.0447833Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-31T18:32:20.0457845Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-31T18:32:20.0468063Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-31T18:32:20.0477849Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-31T18:32:20.0487502Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-31T18:32:20.0496671Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-31T18:32:20.0506231Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-31T18:32:20.0517674Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-31T18:32:20.0529550Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-31T18:32:20.0537195Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-31T18:32:20.0546091Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-31T18:32:20.0555885Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-31T18:32:20.0565071Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-31T18:32:20.0574284Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-31T18:32:20.0584325Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-31T18:32:20.0593025Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-31T18:32:20.0603705Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-31T18:32:20.0613002Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-31T18:32:20.0622502Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-31T18:32:20.0632658Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-31T18:32:20.0644263Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-31T18:32:20.0652972Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-31T18:32:20.0662539Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-31T18:32:20.0892233Z [Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-01-31T18:32:20.0971033Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-31T18:32:20.0991348Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-31T18:32:20.1000834Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-31T18:32:20.1010455Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-31T18:32:20.1020215Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-31T18:32:20.1029364Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-31T18:32:20.1038782Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-31T18:32:20.1048179Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-31T18:32:20.1057773Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-31T18:32:20.1066647Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-31T18:32:20.1076336Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-31T18:32:20.1086045Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-31T18:32:20.1095701Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-31T18:32:20.1105291Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-31T18:32:20.1115196Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-31T18:32:20.1125257Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-31T18:32:20.1134031Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-31T18:32:20.1143309Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-31T18:32:20.1153339Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-31T18:32:20.1163783Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-31T18:32:20.1174018Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-31T18:32:20.1182485Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-31T18:32:20.1191786Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-31T18:32:20.1201792Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-31T18:32:20.1212855Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-01-31T18:32:20.1325407Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-01-31T18:32:20.1338831Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-01-31T18:32:20.1344002Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-01-31T18:32:20.1352282Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-01-31T18:32:20.1363572Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-01-31T18:32:20.1383963Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-01-31T18:32:20.1406921Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-01-31T18:32:20.1416091Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-01-31T18:32:20.1426870Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-01-31T18:32:20.1436004Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-01-31T18:32:20.1445412Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-01-31T18:32:20.1455525Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-01-31T18:32:20.1502475Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-01-31T18:32:20.1502873Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-01-31T18:32:20.1503243Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-01-31T18:32:20.1503633Z [Gloo] Rank 0 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-01-31T18:32:20.1504139Z INFO 01-31 18:32:20 [parallel_state.py:1411] rank 0 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
2026-01-31T18:32:20.2228326Z [Gloo] Rank 1 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-01-31T18:32:20.2242888Z INFO 01-31 18:32:20 [parallel_state.py:1411] rank 1 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 1, EP rank 1
2026-01-31T18:32:20.2267122Z [Gloo] Rank 3 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-01-31T18:32:20.2284033Z [Gloo] Rank 4 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-01-31T18:32:20.2293551Z INFO 01-31 18:32:20 [parallel_state.py:1411] rank 3 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 3, EP rank 3
2026-01-31T18:32:20.2303375Z [Gloo] Rank 6 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-01-31T18:32:20.2312378Z INFO 01-31 18:32:20 [parallel_state.py:1411] rank 4 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 4, EP rank 4
2026-01-31T18:32:20.2321620Z [Gloo] Rank 8 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-01-31T18:32:20.2331715Z INFO 01-31 18:32:20 [parallel_state.py:1411] rank 6 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 6, EP rank 6
2026-01-31T18:32:20.2341226Z INFO 01-31 18:32:20 [parallel_state.py:1411] rank 8 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 0, EP rank 8
2026-01-31T18:32:20.2349853Z [Gloo] Rank 11 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-01-31T18:32:20.2359656Z [Gloo] Rank 12 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-01-31T18:32:20.2369866Z INFO 01-31 18:32:20 [parallel_state.py:1411] rank 11 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 3, EP rank 11
2026-01-31T18:32:20.2380028Z INFO 01-31 18:32:20 [parallel_state.py:1411] rank 12 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 4, EP rank 12
2026-01-31T18:32:20.2389544Z [Gloo] Rank 14 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-01-31T18:32:20.2398968Z [Gloo] Rank 15 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-01-31T18:32:20.2409208Z INFO 01-31 18:32:20 [parallel_state.py:1411] rank 14 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 6, EP rank 14
2026-01-31T18:32:20.2418877Z INFO 01-31 18:32:20 [parallel_state.py:1411] rank 15 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 7, EP rank 15
2026-01-31T18:32:20.2428623Z [Gloo] Rank 10 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-01-31T18:32:20.2438454Z [Gloo] Rank 7 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-01-31T18:32:20.2447712Z INFO 01-31 18:32:20 [parallel_state.py:1411] rank 7 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 7, EP rank 7
2026-01-31T18:32:20.2457866Z INFO 01-31 18:32:20 [parallel_state.py:1411] rank 10 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 2, EP rank 10
2026-01-31T18:32:20.2645473Z [Gloo] Rank 2 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-01-31T18:32:20.2667651Z INFO 01-31 18:32:20 [parallel_state.py:1411] rank 2 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 2, EP rank 2
2026-01-31T18:32:20.2998999Z [Gloo] Rank 5 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-01-31T18:32:20.3021129Z INFO 01-31 18:32:20 [parallel_state.py:1411] rank 5 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 5, EP rank 5
2026-01-31T18:32:20.3030102Z [Gloo] Rank 9 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-01-31T18:32:20.3041017Z [Gloo] Rank 13 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-01-31T18:32:20.3051163Z INFO 01-31 18:32:20 [parallel_state.py:1411] rank 9 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 1, EP rank 9
2026-01-31T18:32:20.3061582Z INFO 01-31 18:32:20 [parallel_state.py:1411] rank 13 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 5, EP rank 13
2026-01-31T18:32:20.3338654Z [Gloo] Rank 0 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-01-31T18:32:20.3360958Z [Gloo] Rank 2 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-01-31T18:32:20.3370665Z [Gloo] Rank 1 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-01-31T18:32:20.3380113Z [Gloo] Rank 3 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-01-31T18:32:20.3389369Z [Gloo] Rank 4 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-01-31T18:32:20.3399677Z [Gloo] Rank 5 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-01-31T18:32:20.3409086Z [Gloo] Rank 6 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-01-31T18:32:20.3418903Z [Gloo] Rank 7 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-01-31T18:32:20.3429676Z [Gloo] Rank 9 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-01-31T18:32:20.3440072Z [Gloo] Rank 8 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-01-31T18:32:20.3451286Z [Gloo] Rank 11 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-01-31T18:32:20.3460030Z [Gloo] Rank 10 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-01-31T18:32:20.3469246Z [Gloo] Rank 13 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-01-31T18:32:20.3478299Z [Gloo] Rank 12 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-01-31T18:32:20.3487216Z [Gloo] Rank 14 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-01-31T18:32:20.3497376Z [Gloo] Rank 15 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-01-31T18:32:20.4123969Z WARNING 01-31 18:32:20 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-01-31T18:32:20.4184808Z WARNING 01-31 18:32:20 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-01-31T18:32:20.4194276Z WARNING 01-31 18:32:20 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-01-31T18:32:20.4204510Z WARNING 01-31 18:32:20 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-01-31T18:32:20.4214110Z WARNING 01-31 18:32:20 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-01-31T18:32:20.4289530Z WARNING 01-31 18:32:20 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-01-31T18:32:20.4298953Z WARNING 01-31 18:32:20 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-01-31T18:32:20.4307957Z WARNING 01-31 18:32:20 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-01-31T18:32:20.4319961Z WARNING 01-31 18:32:20 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-01-31T18:32:20.4342652Z WARNING 01-31 18:32:20 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-01-31T18:32:20.4353292Z WARNING 01-31 18:32:20 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-01-31T18:32:20.4363203Z WARNING 01-31 18:32:20 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-01-31T18:32:20.4372620Z WARNING 01-31 18:32:20 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-01-31T18:32:20.4382379Z WARNING 01-31 18:32:20 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-01-31T18:32:20.4391594Z WARNING 01-31 18:32:20 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-01-31T18:32:20.4402564Z WARNING 01-31 18:32:20 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-01-31T18:32:20.4697787Z WARNING 01-31 18:32:20 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-01-31T18:32:20.4706536Z WARNING 01-31 18:32:20 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-01-31T18:32:20.4716074Z WARNING 01-31 18:32:20 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-01-31T18:32:20.4725512Z WARNING 01-31 18:32:20 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-01-31T18:32:20.4735527Z WARNING 01-31 18:32:20 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-01-31T18:32:20.4744744Z WARNING 01-31 18:32:20 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-01-31T18:32:20.4755007Z WARNING 01-31 18:32:20 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-01-31T18:32:20.4766003Z WARNING 01-31 18:32:20 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-01-31T18:32:20.4775334Z WARNING 01-31 18:32:20 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-01-31T18:32:20.4785027Z WARNING 01-31 18:32:20 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-01-31T18:32:20.4796106Z WARNING 01-31 18:32:20 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-01-31T18:32:20.4804709Z WARNING 01-31 18:32:20 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-01-31T18:32:20.4814207Z [0;36m(Worker_DP0_TP2_EP2 pid=379)[0;0m INFO 01-31 18:32:20 [model_runner_v1.py:2379] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-01-31T18:32:20.4823919Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m INFO 01-31 18:32:20 [model_runner_v1.py:2379] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-01-31T18:32:20.4834226Z [0;36m(Worker_DP1_TP5_EP13 pid=686)[0;0m INFO 01-31 18:32:20 [model_runner_v1.py:2379] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-01-31T18:32:20.4844124Z [0;36m(Worker_DP1_TP4_EP12 pid=583)[0;0m INFO 01-31 18:32:20 [model_runner_v1.py:2379] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-01-31T18:32:20.4853891Z WARNING 01-31 18:32:20 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-01-31T18:32:20.4863339Z [0;36m(Worker_DP0_TP4_EP4 pid=582)[0;0m INFO 01-31 18:32:20 [model_runner_v1.py:2379] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-01-31T18:32:20.4873578Z [0;36m(Worker_DP0_TP7_EP7 pid=891)[0;0m INFO 01-31 18:32:20 [model_runner_v1.py:2379] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-01-31T18:32:20.4883845Z [0;36m(Worker_DP1_TP3_EP11 pid=480)[0;0m INFO 01-31 18:32:20 [model_runner_v1.py:2379] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-01-31T18:32:20.4894588Z [0;36m(Worker_DP0_TP6_EP6 pid=789)[0;0m INFO 01-31 18:32:20 [model_runner_v1.py:2379] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-01-31T18:32:20.4903578Z [0;36m(Worker_DP1_TP0_EP8 pid=212)[0;0m INFO 01-31 18:32:20 [model_runner_v1.py:2379] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-01-31T18:32:20.4914178Z [0;36m(Worker_DP1_TP2_EP10 pid=381)[0;0m INFO 01-31 18:32:20 [model_runner_v1.py:2379] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-01-31T18:32:20.4924169Z [0;36m(Worker_DP1_TP1_EP9 pid=277)[0;0m INFO 01-31 18:32:20 [model_runner_v1.py:2379] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-01-31T18:32:20.4933636Z WARNING 01-31 18:32:20 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-01-31T18:32:20.4943412Z [0;36m(Worker_DP0_TP3_EP3 pid=481)[0;0m INFO 01-31 18:32:20 [model_runner_v1.py:2379] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-01-31T18:32:20.4953073Z [0;36m(Worker_DP1_TP6_EP14 pid=786)[0;0m INFO 01-31 18:32:20 [model_runner_v1.py:2379] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-01-31T18:32:20.4963158Z WARNING 01-31 18:32:20 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-01-31T18:32:20.4972767Z [0;36m(Worker_DP1_TP7_EP15 pid=888)[0;0m INFO 01-31 18:32:20 [model_runner_v1.py:2379] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-01-31T18:32:20.4981727Z WARNING 01-31 18:32:20 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-01-31T18:32:20.5072513Z [0;36m(Worker_DP0_TP5_EP5 pid=687)[0;0m INFO 01-31 18:32:20 [model_runner_v1.py:2379] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-01-31T18:32:20.5201853Z [0;36m(Worker_DP0_TP1_EP1 pid=268)[0;0m INFO 01-31 18:32:20 [model_runner_v1.py:2379] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-01-31T18:32:20.8241938Z [0;36m(Worker_DP0_TP7_EP7 pid=891)[0;0m INFO 01-31 18:32:20 [utils.py:99] Using the vLLM Ascend modelslim Quantization now!
2026-01-31T18:32:20.8304851Z [0;36m(Worker_DP1_TP5_EP13 pid=686)[0;0m INFO 01-31 18:32:20 [utils.py:99] Using the vLLM Ascend modelslim Quantization now!
2026-01-31T18:32:20.8365264Z [0;36m(Worker_DP0_TP2_EP2 pid=379)[0;0m INFO 01-31 18:32:20 [utils.py:99] Using the vLLM Ascend modelslim Quantization now!
2026-01-31T18:32:20.8394045Z [0;36m(Worker_DP1_TP4_EP12 pid=583)[0;0m INFO 01-31 18:32:20 [utils.py:99] Using the vLLM Ascend modelslim Quantization now!
2026-01-31T18:32:20.8523992Z [0;36m(Worker_DP0_TP4_EP4 pid=582)[0;0m INFO 01-31 18:32:20 [utils.py:99] Using the vLLM Ascend modelslim Quantization now!
2026-01-31T18:32:20.8563888Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m INFO 01-31 18:32:20 [utils.py:99] Using the vLLM Ascend modelslim Quantization now!
2026-01-31T18:32:20.8650193Z [0;36m(Worker_DP1_TP0_EP8 pid=212)[0;0m INFO 01-31 18:32:20 [utils.py:99] Using the vLLM Ascend modelslim Quantization now!
2026-01-31T18:32:20.8659361Z [0;36m(Worker_DP1_TP1_EP9 pid=277)[0;0m INFO 01-31 18:32:20 [utils.py:99] Using the vLLM Ascend modelslim Quantization now!
2026-01-31T18:32:20.9720243Z [0;36m(Worker_DP0_TP4_EP4 pid=582)[0;0m INFO 01-31 18:32:20 [layer.py:365] Disabling MoE shared_experts cuda stream
2026-01-31T18:32:20.9728757Z [0;36m(Worker_DP1_TP5_EP13 pid=686)[0;0m INFO 01-31 18:32:20 [layer.py:365] Disabling MoE shared_experts cuda stream
2026-01-31T18:32:20.9738396Z [0;36m(Worker_DP0_TP7_EP7 pid=891)[0;0m INFO 01-31 18:32:20 [layer.py:365] Disabling MoE shared_experts cuda stream
2026-01-31T18:32:20.9747591Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m INFO 01-31 18:32:20 [layer.py:365] Disabling MoE shared_experts cuda stream
2026-01-31T18:32:20.9757688Z [0;36m(Worker_DP1_TP1_EP9 pid=277)[0;0m INFO 01-31 18:32:20 [layer.py:365] Disabling MoE shared_experts cuda stream
2026-01-31T18:32:20.9767380Z [0;36m(Worker_DP1_TP0_EP8 pid=212)[0;0m INFO 01-31 18:32:20 [layer.py:365] Disabling MoE shared_experts cuda stream
2026-01-31T18:32:20.9777342Z [0;36m(Worker_DP0_TP2_EP2 pid=379)[0;0m INFO 01-31 18:32:20 [layer.py:365] Disabling MoE shared_experts cuda stream
2026-01-31T18:32:20.9786457Z [0;36m(Worker_DP1_TP4_EP12 pid=583)[0;0m INFO 01-31 18:32:20 [layer.py:365] Disabling MoE shared_experts cuda stream
2026-01-31T18:32:20.9836399Z [0;36m(Worker_DP1_TP2_EP10 pid=381)[0;0m INFO 01-31 18:32:20 [utils.py:99] Using the vLLM Ascend modelslim Quantization now!
2026-01-31T18:32:21.0227990Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m INFO 01-31 18:32:21 [layer.py:494] [EP Rank 0/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->0, 1->1, 2->2, 3->3, 4->4, 5->5, 6->6, 7->7.
2026-01-31T18:32:21.0237552Z [0;36m(Worker_DP1_TP1_EP9 pid=277)[0;0m INFO 01-31 18:32:21 [layer.py:494] [EP Rank 9/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->72, 1->73, 2->74, 3->75, 4->76, 5->77, 6->78, 7->79.
2026-01-31T18:32:21.0248447Z [0;36m(Worker_DP1_TP0_EP8 pid=212)[0;0m INFO 01-31 18:32:21 [layer.py:494] [EP Rank 8/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->64, 1->65, 2->66, 3->67, 4->68, 5->69, 6->70, 7->71.
2026-01-31T18:32:21.0257517Z [0;36m(Worker_DP1_TP4_EP12 pid=583)[0;0m INFO 01-31 18:32:21 [layer.py:494] [EP Rank 12/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->96, 1->97, 2->98, 3->99, 4->100, 5->101, 6->102, 7->103.
2026-01-31T18:32:21.0267400Z [0;36m(Worker_DP0_TP4_EP4 pid=582)[0;0m INFO 01-31 18:32:21 [layer.py:494] [EP Rank 4/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->32, 1->33, 2->34, 3->35, 4->36, 5->37, 6->38, 7->39.
2026-01-31T18:32:21.0277941Z [0;36m(Worker_DP1_TP5_EP13 pid=686)[0;0m INFO 01-31 18:32:21 [layer.py:494] [EP Rank 13/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->104, 1->105, 2->106, 3->107, 4->108, 5->109, 6->110, 7->111.
2026-01-31T18:32:21.0288061Z [0;36m(Worker_DP0_TP2_EP2 pid=379)[0;0m INFO 01-31 18:32:21 [layer.py:494] [EP Rank 2/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->16, 1->17, 2->18, 3->19, 4->20, 5->21, 6->22, 7->23.
2026-01-31T18:32:21.0298024Z [0;36m(Worker_DP0_TP7_EP7 pid=891)[0;0m INFO 01-31 18:32:21 [layer.py:494] [EP Rank 7/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->56, 1->57, 2->58, 3->59, 4->60, 5->61, 6->62, 7->63.
2026-01-31T18:32:21.0712379Z [0;36m(Worker_DP1_TP2_EP10 pid=381)[0;0m INFO 01-31 18:32:21 [layer.py:365] Disabling MoE shared_experts cuda stream
2026-01-31T18:32:21.0974614Z [0;36m(Worker_DP1_TP2_EP10 pid=381)[0;0m INFO 01-31 18:32:21 [layer.py:494] [EP Rank 10/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->80, 1->81, 2->82, 3->83, 4->84, 5->85, 6->86, 7->87.
2026-01-31T18:32:21.2632241Z [0;36m(Worker_DP0_TP3_EP3 pid=481)[0;0m INFO 01-31 18:32:21 [utils.py:99] Using the vLLM Ascend modelslim Quantization now!
2026-01-31T18:32:21.2841635Z [0;36m(Worker_DP0_TP6_EP6 pid=789)[0;0m INFO 01-31 18:32:21 [utils.py:99] Using the vLLM Ascend modelslim Quantization now!
2026-01-31T18:32:21.3020127Z [0;36m(Worker_DP1_TP6_EP14 pid=786)[0;0m INFO 01-31 18:32:21 [utils.py:99] Using the vLLM Ascend modelslim Quantization now!
2026-01-31T18:32:21.3627431Z [0;36m(Worker_DP0_TP3_EP3 pid=481)[0;0m INFO 01-31 18:32:21 [layer.py:365] Disabling MoE shared_experts cuda stream
2026-01-31T18:32:21.3756960Z [0;36m(Worker_DP0_TP6_EP6 pid=789)[0;0m INFO 01-31 18:32:21 [layer.py:365] Disabling MoE shared_experts cuda stream
2026-01-31T18:32:21.3868876Z [0;36m(Worker_DP0_TP3_EP3 pid=481)[0;0m INFO 01-31 18:32:21 [layer.py:494] [EP Rank 3/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->24, 1->25, 2->26, 3->27, 4->28, 5->29, 6->30, 7->31.
2026-01-31T18:32:21.3899232Z [0;36m(Worker_DP1_TP6_EP14 pid=786)[0;0m INFO 01-31 18:32:21 [layer.py:365] Disabling MoE shared_experts cuda stream
2026-01-31T18:32:21.4019104Z [0;36m(Worker_DP0_TP6_EP6 pid=789)[0;0m INFO 01-31 18:32:21 [layer.py:494] [EP Rank 6/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->48, 1->49, 2->50, 3->51, 4->52, 5->53, 6->54, 7->55.
2026-01-31T18:32:21.4147823Z [0;36m(Worker_DP1_TP6_EP14 pid=786)[0;0m INFO 01-31 18:32:21 [layer.py:494] [EP Rank 14/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->112, 1->113, 2->114, 3->115, 4->116, 5->117, 6->118, 7->119.
2026-01-31T18:32:21.5822322Z [0;36m(Worker_DP1_TP3_EP11 pid=480)[0;0m INFO 01-31 18:32:21 [utils.py:99] Using the vLLM Ascend modelslim Quantization now!
2026-01-31T18:32:21.6665208Z [0;36m(Worker_DP1_TP3_EP11 pid=480)[0;0m INFO 01-31 18:32:21 [layer.py:365] Disabling MoE shared_experts cuda stream
2026-01-31T18:32:21.6906161Z [0;36m(Worker_DP1_TP3_EP11 pid=480)[0;0m INFO 01-31 18:32:21 [layer.py:494] [EP Rank 11/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->88, 1->89, 2->90, 3->91, 4->92, 5->93, 6->94, 7->95.
2026-01-31T18:32:22.1841617Z [0;36m(Worker_DP0_TP5_EP5 pid=687)[0;0m INFO 01-31 18:32:22 [utils.py:99] Using the vLLM Ascend modelslim Quantization now!
2026-01-31T18:32:22.2417699Z [0;36m(Worker_DP1_TP7_EP15 pid=888)[0;0m INFO 01-31 18:32:22 [utils.py:99] Using the vLLM Ascend modelslim Quantization now!
2026-01-31T18:32:22.2663875Z [0;36m(Worker_DP0_TP5_EP5 pid=687)[0;0m INFO 01-31 18:32:22 [layer.py:365] Disabling MoE shared_experts cuda stream
2026-01-31T18:32:22.2889128Z [0;36m(Worker_DP0_TP5_EP5 pid=687)[0;0m INFO 01-31 18:32:22 [layer.py:494] [EP Rank 5/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->40, 1->41, 2->42, 3->43, 4->44, 5->45, 6->46, 7->47.
2026-01-31T18:32:22.3217015Z [0;36m(Worker_DP0_TP1_EP1 pid=268)[0;0m INFO 01-31 18:32:22 [utils.py:99] Using the vLLM Ascend modelslim Quantization now!
2026-01-31T18:32:22.3291472Z [0;36m(Worker_DP1_TP7_EP15 pid=888)[0;0m INFO 01-31 18:32:22 [layer.py:365] Disabling MoE shared_experts cuda stream
2026-01-31T18:32:22.3556228Z [0;36m(Worker_DP1_TP7_EP15 pid=888)[0;0m INFO 01-31 18:32:22 [layer.py:494] [EP Rank 15/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->120, 1->121, 2->122, 3->123, 4->124, 5->125, 6->126, 7->127.
2026-01-31T18:32:22.4137563Z [0;36m(Worker_DP0_TP1_EP1 pid=268)[0;0m INFO 01-31 18:32:22 [layer.py:365] Disabling MoE shared_experts cuda stream
2026-01-31T18:32:22.4387292Z [0;36m(Worker_DP0_TP1_EP1 pid=268)[0;0m INFO 01-31 18:32:22 [layer.py:494] [EP Rank 1/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->8, 1->9, 2->10, 3->11, 4->12, 5->13, 6->14, 7->15.
2026-01-31T18:32:23.0587396Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-01-31T18:32:23.0591291Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m   return func(*args, **kwargs)
2026-01-31T18:32:23.1180842Z [0;36m(Worker_DP0_TP3_EP3 pid=481)[0;0m /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-01-31T18:32:23.1204268Z [0;36m(Worker_DP0_TP3_EP3 pid=481)[0;0m   return func(*args, **kwargs)
2026-01-31T18:32:23.1564732Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m INFO 01-31 18:32:23 [fused_moe.py:220] [EP Rank 0/32] Expert parallelism is enabled. Local/global number of experts: 8/256. Experts local to global index map: 0->0, 1->1, 2->2, 3->3, 4->4, 5->5, 6->6, 7->7.
2026-01-31T18:32:23.1589304Z [0;36m(Worker_DP0_TP1_EP1 pid=268)[0;0m /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-01-31T18:32:23.1598247Z [0;36m(Worker_DP0_TP1_EP1 pid=268)[0;0m   return func(*args, **kwargs)
2026-01-31T18:32:23.1619321Z [0;36m(Worker_DP1_TP6_EP14 pid=786)[0;0m /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-01-31T18:32:23.1627890Z [0;36m(Worker_DP1_TP6_EP14 pid=786)[0;0m   return func(*args, **kwargs)
2026-01-31T18:32:23.1645500Z [0;36m(Worker_DP0_TP6_EP6 pid=789)[0;0m /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-01-31T18:32:23.1653937Z [0;36m(Worker_DP0_TP6_EP6 pid=789)[0;0m   return func(*args, **kwargs)
2026-01-31T18:32:23.1819540Z [0;36m(Worker_DP0_TP3_EP3 pid=481)[0;0m INFO 01-31 18:32:23 [fused_moe.py:220] [EP Rank 3/32] Expert parallelism is enabled. Local/global number of experts: 8/256. Experts local to global index map: 0->24, 1->25, 2->26, 3->27, 4->28, 5->29, 6->30, 7->31.
2026-01-31T18:32:23.2225876Z [0;36m(Worker_DP1_TP6_EP14 pid=786)[0;0m INFO 01-31 18:32:23 [fused_moe.py:220] [EP Rank 14/32] Expert parallelism is enabled. Local/global number of experts: 8/256. Experts local to global index map: 0->112, 1->113, 2->114, 3->115, 4->116, 5->117, 6->118, 7->119.
2026-01-31T18:32:23.2277259Z [0;36m(Worker_DP0_TP1_EP1 pid=268)[0;0m INFO 01-31 18:32:23 [fused_moe.py:220] [EP Rank 1/32] Expert parallelism is enabled. Local/global number of experts: 8/256. Experts local to global index map: 0->8, 1->9, 2->10, 3->11, 4->12, 5->13, 6->14, 7->15.
2026-01-31T18:32:23.2381594Z [0;36m(Worker_DP0_TP5_EP5 pid=687)[0;0m /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-01-31T18:32:23.2387940Z [0;36m(Worker_DP0_TP5_EP5 pid=687)[0;0m   return func(*args, **kwargs)
2026-01-31T18:32:23.2436656Z [0;36m(Worker_DP1_TP1_EP9 pid=277)[0;0m /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-01-31T18:32:23.2444536Z [0;36m(Worker_DP1_TP1_EP9 pid=277)[0;0m   return func(*args, **kwargs)
2026-01-31T18:32:23.2457912Z [0;36m(Worker_DP1_TP0_EP8 pid=212)[0;0m /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-01-31T18:32:23.2466876Z [0;36m(Worker_DP1_TP0_EP8 pid=212)[0;0m   return func(*args, **kwargs)
2026-01-31T18:32:23.2566359Z [0;36m(Worker_DP0_TP2_EP2 pid=379)[0;0m /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-01-31T18:32:23.2574976Z [0;36m(Worker_DP0_TP2_EP2 pid=379)[0;0m   return func(*args, **kwargs)
2026-01-31T18:32:23.2613872Z [0;36m(Worker_DP0_TP7_EP7 pid=891)[0;0m /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-01-31T18:32:23.2621903Z [0;36m(Worker_DP0_TP7_EP7 pid=891)[0;0m   return func(*args, **kwargs)
2026-01-31T18:32:23.2632816Z [0;36m(Worker_DP0_TP6_EP6 pid=789)[0;0m INFO 01-31 18:32:23 [fused_moe.py:220] [EP Rank 6/32] Expert parallelism is enabled. Local/global number of experts: 8/256. Experts local to global index map: 0->48, 1->49, 2->50, 3->51, 4->52, 5->53, 6->54, 7->55.
2026-01-31T18:32:23.2654247Z [0;36m(Worker_DP1_TP4_EP12 pid=583)[0;0m /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-01-31T18:32:23.2662934Z [0;36m(Worker_DP1_TP4_EP12 pid=583)[0;0m   return func(*args, **kwargs)
2026-01-31T18:32:23.2674294Z [0;36m(Worker_DP1_TP5_EP13 pid=686)[0;0m /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-01-31T18:32:23.2683231Z [0;36m(Worker_DP1_TP5_EP13 pid=686)[0;0m   return func(*args, **kwargs)
2026-01-31T18:32:23.2741840Z [0;36m(Worker_DP1_TP3_EP11 pid=480)[0;0m /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-01-31T18:32:23.2750517Z [0;36m(Worker_DP1_TP3_EP11 pid=480)[0;0m   return func(*args, **kwargs)
2026-01-31T18:32:23.2933467Z [0;36m(Worker_DP0_TP4_EP4 pid=582)[0;0m /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-01-31T18:32:23.2941920Z [0;36m(Worker_DP0_TP4_EP4 pid=582)[0;0m   return func(*args, **kwargs)
2026-01-31T18:32:23.2953207Z [0;36m(Worker_DP1_TP7_EP15 pid=888)[0;0m /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-01-31T18:32:23.2962232Z [0;36m(Worker_DP1_TP7_EP15 pid=888)[0;0m   return func(*args, **kwargs)
2026-01-31T18:32:23.3074024Z [0;36m(Worker_DP1_TP0_EP8 pid=212)[0;0m INFO 01-31 18:32:23 [fused_moe.py:220] [EP Rank 8/32] Expert parallelism is enabled. Local/global number of experts: 8/256. Experts local to global index map: 0->64, 1->65, 2->66, 3->67, 4->68, 5->69, 6->70, 7->71.
2026-01-31T18:32:23.3083707Z [0;36m(Worker_DP1_TP1_EP9 pid=277)[0;0m INFO 01-31 18:32:23 [fused_moe.py:220] [EP Rank 9/32] Expert parallelism is enabled. Local/global number of experts: 8/256. Experts local to global index map: 0->72, 1->73, 2->74, 3->75, 4->76, 5->77, 6->78, 7->79.
2026-01-31T18:32:23.3106941Z [0;36m(Worker_DP0_TP5_EP5 pid=687)[0;0m INFO 01-31 18:32:23 [fused_moe.py:220] [EP Rank 5/32] Expert parallelism is enabled. Local/global number of experts: 8/256. Experts local to global index map: 0->40, 1->41, 2->42, 3->43, 4->44, 5->45, 6->46, 7->47.
2026-01-31T18:32:23.3185516Z [0;36m(Worker_DP0_TP2_EP2 pid=379)[0;0m INFO 01-31 18:32:23 [fused_moe.py:220] [EP Rank 2/32] Expert parallelism is enabled. Local/global number of experts: 8/256. Experts local to global index map: 0->16, 1->17, 2->18, 3->19, 4->20, 5->21, 6->22, 7->23.
2026-01-31T18:32:23.3210071Z [0;36m(Worker_DP0_TP7_EP7 pid=891)[0;0m INFO 01-31 18:32:23 [fused_moe.py:220] [EP Rank 7/32] Expert parallelism is enabled. Local/global number of experts: 8/256. Experts local to global index map: 0->56, 1->57, 2->58, 3->59, 4->60, 5->61, 6->62, 7->63.
2026-01-31T18:32:23.3232630Z [0;36m(Worker_DP1_TP4_EP12 pid=583)[0;0m INFO 01-31 18:32:23 [fused_moe.py:220] [EP Rank 12/32] Expert parallelism is enabled. Local/global number of experts: 8/256. Experts local to global index map: 0->96, 1->97, 2->98, 3->99, 4->100, 5->101, 6->102, 7->103.
2026-01-31T18:32:23.3333445Z [0;36m(Worker_DP1_TP5_EP13 pid=686)[0;0m INFO 01-31 18:32:23 [fused_moe.py:220] [EP Rank 13/32] Expert parallelism is enabled. Local/global number of experts: 8/256. Experts local to global index map: 0->104, 1->105, 2->106, 3->107, 4->108, 5->109, 6->110, 7->111.
2026-01-31T18:32:23.3384926Z [0;36m(Worker_DP1_TP3_EP11 pid=480)[0;0m INFO 01-31 18:32:23 [fused_moe.py:220] [EP Rank 11/32] Expert parallelism is enabled. Local/global number of experts: 8/256. Experts local to global index map: 0->88, 1->89, 2->90, 3->91, 4->92, 5->93, 6->94, 7->95.
2026-01-31T18:32:23.3431266Z [0;36m(Worker_DP1_TP2_EP10 pid=381)[0;0m /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-01-31T18:32:23.3439665Z [0;36m(Worker_DP1_TP2_EP10 pid=381)[0;0m   return func(*args, **kwargs)
2026-01-31T18:32:23.3539911Z [0;36m(Worker_DP0_TP4_EP4 pid=582)[0;0m INFO 01-31 18:32:23 [fused_moe.py:220] [EP Rank 4/32] Expert parallelism is enabled. Local/global number of experts: 8/256. Experts local to global index map: 0->32, 1->33, 2->34, 3->35, 4->36, 5->37, 6->38, 7->39.
2026-01-31T18:32:23.3570256Z [0;36m(Worker_DP1_TP7_EP15 pid=888)[0;0m INFO 01-31 18:32:23 [fused_moe.py:220] [EP Rank 15/32] Expert parallelism is enabled. Local/global number of experts: 8/256. Experts local to global index map: 0->120, 1->121, 2->122, 3->123, 4->124, 5->125, 6->126, 7->127.
2026-01-31T18:32:23.4155647Z [0;36m(Worker_DP1_TP2_EP10 pid=381)[0;0m INFO 01-31 18:32:23 [fused_moe.py:220] [EP Rank 10/32] Expert parallelism is enabled. Local/global number of experts: 8/256. Experts local to global index map: 0->80, 1->81, 2->82, 3->83, 4->84, 5->85, 6->86, 7->87.
2026-01-31T18:32:23.5683618Z [0;36m(Worker_DP0_TP6_EP6 pid=789)[0;0m INFO 01-31 18:32:23 [fused_moe.py:427] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-01-31T18:32:23.5864332Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m INFO 01-31 18:32:23 [fused_moe.py:427] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-01-31T18:32:23.6070827Z [0;36m(Worker_DP1_TP1_EP9 pid=277)[0;0m INFO 01-31 18:32:23 [fused_moe.py:427] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-01-31T18:32:23.6081642Z [0;36m(Worker_DP1_TP0_EP8 pid=212)[0;0m INFO 01-31 18:32:23 [fused_moe.py:427] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-01-31T18:32:23.6091053Z [0;36m(Worker_DP0_TP5_EP5 pid=687)[0;0m INFO 01-31 18:32:23 [fused_moe.py:427] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-01-31T18:32:23.6262432Z [0;36m(Worker_DP1_TP4_EP12 pid=583)[0;0m INFO 01-31 18:32:23 [fused_moe.py:427] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-01-31T18:32:23.6294287Z [0;36m(Worker_DP0_TP2_EP2 pid=379)[0;0m INFO 01-31 18:32:23 [fused_moe.py:427] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-01-31T18:32:23.6342407Z [0;36m(Worker_DP1_TP5_EP13 pid=686)[0;0m INFO 01-31 18:32:23 [fused_moe.py:427] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-01-31T18:32:23.6392411Z [0;36m(Worker_DP0_TP7_EP7 pid=891)[0;0m INFO 01-31 18:32:23 [fused_moe.py:427] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-01-31T18:32:23.6494256Z [0;36m(Worker_DP1_TP7_EP15 pid=888)[0;0m INFO 01-31 18:32:23 [fused_moe.py:427] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-01-31T18:32:23.6515851Z [0;36m(Worker_DP1_TP3_EP11 pid=480)[0;0m INFO 01-31 18:32:23 [fused_moe.py:427] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-01-31T18:32:23.6841381Z [0;36m(Worker_DP0_TP4_EP4 pid=582)[0;0m INFO 01-31 18:32:23 [fused_moe.py:427] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-01-31T18:32:23.7187697Z [0;36m(Worker_DP0_TP3_EP3 pid=481)[0;0m INFO 01-31 18:32:23 [fused_moe.py:427] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-01-31T18:32:23.7211370Z [0;36m(Worker_DP1_TP2_EP10 pid=381)[0;0m INFO 01-31 18:32:23 [fused_moe.py:427] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-01-31T18:32:23.7334762Z [0;36m(Worker_DP1_TP6_EP14 pid=786)[0;0m INFO 01-31 18:32:23 [fused_moe.py:427] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-01-31T18:32:23.7494191Z [0;36m(Worker_DP0_TP1_EP1 pid=268)[0;0m INFO 01-31 18:32:23 [fused_moe.py:427] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-01-31T18:32:26.9549247Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m INFO 01-31 18:32:26 [compilation.py:862] Using OOT custom backend for compilation.
2026-01-31T18:32:27.0060614Z [0;36m(Worker_DP0_TP7_EP7 pid=891)[0;0m INFO 01-31 18:32:27 [compilation.py:862] Using OOT custom backend for compilation.
2026-01-31T18:32:27.0176349Z [0;36m(Worker_DP0_TP6_EP6 pid=789)[0;0m INFO 01-31 18:32:27 [compilation.py:862] Using OOT custom backend for compilation.
2026-01-31T18:32:27.0308794Z [0;36m(Worker_DP1_TP1_EP9 pid=277)[0;0m INFO 01-31 18:32:27 [compilation.py:862] Using OOT custom backend for compilation.
2026-01-31T18:32:27.0411759Z [0;36m(Worker_DP1_TP4_EP12 pid=583)[0;0m INFO 01-31 18:32:27 [compilation.py:862] Using OOT custom backend for compilation.
2026-01-31T18:32:27.0746830Z [0;36m(Worker_DP1_TP3_EP11 pid=480)[0;0m INFO 01-31 18:32:27 [compilation.py:862] Using OOT custom backend for compilation.
2026-01-31T18:32:27.0920755Z [0;36m(Worker_DP1_TP7_EP15 pid=888)[0;0m INFO 01-31 18:32:27 [compilation.py:862] Using OOT custom backend for compilation.
2026-01-31T18:32:27.0949511Z [0;36m(Worker_DP1_TP6_EP14 pid=786)[0;0m INFO 01-31 18:32:27 [compilation.py:862] Using OOT custom backend for compilation.
2026-01-31T18:32:27.1110089Z [0;36m(Worker_DP0_TP3_EP3 pid=481)[0;0m INFO 01-31 18:32:27 [compilation.py:862] Using OOT custom backend for compilation.
2026-01-31T18:32:27.1198578Z [0;36m(Worker_DP0_TP2_EP2 pid=379)[0;0m INFO 01-31 18:32:27 [compilation.py:862] Using OOT custom backend for compilation.
2026-01-31T18:32:27.1555522Z [0;36m(Worker_DP0_TP5_EP5 pid=687)[0;0m INFO 01-31 18:32:27 [compilation.py:862] Using OOT custom backend for compilation.
2026-01-31T18:32:27.1626521Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:32:27.1626884Z Loading safetensors checkpoint shards:   0% Completed | 0/163 [00:00<?, ?it/s]
2026-01-31T18:32:27.1743226Z [0;36m(Worker_DP1_TP0_EP8 pid=212)[0;0m INFO 01-31 18:32:27 [compilation.py:862] Using OOT custom backend for compilation.
2026-01-31T18:32:27.1764679Z [0;36m(Worker_DP0_TP4_EP4 pid=582)[0;0m INFO 01-31 18:32:27 [compilation.py:862] Using OOT custom backend for compilation.
2026-01-31T18:32:27.2035994Z [0;36m(Worker_DP1_TP5_EP13 pid=686)[0;0m INFO 01-31 18:32:27 [compilation.py:862] Using OOT custom backend for compilation.
2026-01-31T18:32:27.2062257Z [0;36m(Worker_DP0_TP1_EP1 pid=268)[0;0m INFO 01-31 18:32:27 [compilation.py:862] Using OOT custom backend for compilation.
2026-01-31T18:32:27.2516931Z [0;36m(Worker_DP1_TP2_EP10 pid=381)[0;0m INFO 01-31 18:32:27 [compilation.py:862] Using OOT custom backend for compilation.
2026-01-31T18:32:28.3298928Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:32:28.3299292Z Loading safetensors checkpoint shards:   1% Completed | 1/163 [00:01<03:08,  1.17s/it]
2026-01-31T18:32:31.7933561Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:32:31.7934425Z Loading safetensors checkpoint shards:   1% Completed | 2/163 [00:04<06:45,  2.52s/it]
2026-01-31T18:32:32.9101296Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:32:32.9101654Z Loading safetensors checkpoint shards:   2% Completed | 3/163 [00:05<05:00,  1.88s/it]
2026-01-31T18:32:34.3676377Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:32:34.3676746Z Loading safetensors checkpoint shards:   2% Completed | 4/163 [00:07<04:32,  1.71s/it]
2026-01-31T18:32:36.3833276Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:32:36.3833646Z Loading safetensors checkpoint shards:   3% Completed | 5/163 [00:09<04:47,  1.82s/it]
2026-01-31T18:32:39.2710197Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:32:39.2710563Z Loading safetensors checkpoint shards:   4% Completed | 6/163 [00:12<05:42,  2.18s/it]
2026-01-31T18:32:41.6375351Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:32:41.6375765Z Loading safetensors checkpoint shards:   4% Completed | 7/163 [00:14<05:50,  2.24s/it]
2026-01-31T18:32:43.5279023Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:32:43.5279420Z Loading safetensors checkpoint shards:   5% Completed | 8/163 [00:16<05:30,  2.13s/it]
2026-01-31T18:32:45.1988065Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:32:45.1988429Z Loading safetensors checkpoint shards:   6% Completed | 9/163 [00:18<05:06,  1.99s/it]
2026-01-31T18:32:46.9520262Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:32:46.9520654Z Loading safetensors checkpoint shards:   6% Completed | 10/163 [00:19<04:53,  1.92s/it]
2026-01-31T18:32:48.6190422Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:32:48.6190813Z Loading safetensors checkpoint shards:   7% Completed | 11/163 [00:21<04:39,  1.84s/it]
2026-01-31T18:32:50.9550137Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:32:50.9552526Z Loading safetensors checkpoint shards:   7% Completed | 12/163 [00:23<05:00,  1.99s/it]
2026-01-31T18:32:52.8809127Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:32:52.8809504Z Loading safetensors checkpoint shards:   8% Completed | 13/163 [00:25<04:55,  1.97s/it]
2026-01-31T18:32:55.0326668Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:32:55.0327064Z Loading safetensors checkpoint shards:   9% Completed | 14/163 [00:27<05:01,  2.03s/it]
2026-01-31T18:32:58.4716899Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:32:58.4717287Z Loading safetensors checkpoint shards:   9% Completed | 15/163 [00:31<06:02,  2.45s/it]
2026-01-31T18:33:00.6745189Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:33:00.6745591Z Loading safetensors checkpoint shards:  10% Completed | 16/163 [00:33<05:49,  2.38s/it]
2026-01-31T18:33:03.0163280Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:33:03.0163735Z Loading safetensors checkpoint shards:  10% Completed | 17/163 [00:35<05:45,  2.37s/it]
2026-01-31T18:33:05.4817405Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:33:05.4817821Z Loading safetensors checkpoint shards:  11% Completed | 18/163 [00:38<05:47,  2.40s/it]
2026-01-31T18:33:06.7115650Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:33:06.7116038Z Loading safetensors checkpoint shards:  12% Completed | 19/163 [00:39<04:54,  2.05s/it]
2026-01-31T18:33:08.6557145Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:33:08.6557590Z Loading safetensors checkpoint shards:  12% Completed | 20/163 [00:41<04:48,  2.02s/it]
2026-01-31T18:33:11.3807320Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:33:11.3807678Z Loading safetensors checkpoint shards:  13% Completed | 21/163 [00:44<05:16,  2.23s/it]
2026-01-31T18:33:13.2049026Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:33:13.2049420Z Loading safetensors checkpoint shards:  13% Completed | 22/163 [00:46<04:57,  2.11s/it]
2026-01-31T18:33:15.0253616Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:33:15.0254013Z Loading safetensors checkpoint shards:  14% Completed | 23/163 [00:47<04:42,  2.02s/it]
2026-01-31T18:33:16.7474917Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:33:16.7475322Z Loading safetensors checkpoint shards:  15% Completed | 24/163 [00:49<04:28,  1.93s/it]
2026-01-31T18:33:19.7416270Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:33:19.7416676Z Loading safetensors checkpoint shards:  15% Completed | 25/163 [00:52<05:10,  2.25s/it]
2026-01-31T18:33:20.3696857Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:33:20.3697399Z Loading safetensors checkpoint shards:  16% Completed | 26/163 [00:53<04:01,  1.76s/it]
2026-01-31T18:33:21.6908351Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:33:21.6908822Z Loading safetensors checkpoint shards:  17% Completed | 27/163 [00:54<03:41,  1.63s/it]
2026-01-31T18:33:24.4391320Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:33:24.4391717Z Loading safetensors checkpoint shards:  17% Completed | 28/163 [00:57<04:25,  1.97s/it]
2026-01-31T18:33:25.8583326Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:33:25.8583775Z Loading safetensors checkpoint shards:  18% Completed | 29/163 [00:58<04:01,  1.80s/it]
2026-01-31T18:33:27.2243873Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:33:27.2244271Z Loading safetensors checkpoint shards:  18% Completed | 30/163 [01:00<03:42,  1.67s/it]
2026-01-31T18:33:28.4479142Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:33:28.4479518Z Loading safetensors checkpoint shards:  19% Completed | 31/163 [01:01<03:22,  1.54s/it]
2026-01-31T18:33:30.3486370Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:33:30.3486831Z Loading safetensors checkpoint shards:  20% Completed | 32/163 [01:03<03:35,  1.65s/it]
2026-01-31T18:33:32.5892936Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:33:32.5893325Z Loading safetensors checkpoint shards:  20% Completed | 33/163 [01:05<03:57,  1.82s/it]
2026-01-31T18:33:34.7408065Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:33:34.7408510Z Loading safetensors checkpoint shards:  21% Completed | 34/163 [01:07<04:08,  1.92s/it]
2026-01-31T18:33:36.6673443Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:33:36.6673834Z Loading safetensors checkpoint shards:  21% Completed | 35/163 [01:09<04:06,  1.92s/it]
2026-01-31T18:33:41.2158594Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:33:41.2159034Z Loading safetensors checkpoint shards:  22% Completed | 36/163 [01:14<05:44,  2.71s/it]
2026-01-31T18:33:42.5133310Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:33:42.5133702Z Loading safetensors checkpoint shards:  23% Completed | 37/163 [01:15<04:48,  2.29s/it]
2026-01-31T18:33:44.1276208Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:33:44.1276604Z Loading safetensors checkpoint shards:  23% Completed | 38/163 [01:16<04:20,  2.09s/it]
2026-01-31T18:33:46.1605184Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:33:46.1605594Z Loading safetensors checkpoint shards:  24% Completed | 39/163 [01:18<04:16,  2.07s/it]
2026-01-31T18:33:50.3584257Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:33:50.3584650Z Loading safetensors checkpoint shards:  25% Completed | 40/163 [01:23<05:33,  2.71s/it]
2026-01-31T18:33:51.5272609Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:33:51.5272975Z Loading safetensors checkpoint shards:  25% Completed | 41/163 [01:24<04:34,  2.25s/it]
2026-01-31T18:33:52.5671041Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:33:52.5671437Z Loading safetensors checkpoint shards:  26% Completed | 42/163 [01:25<03:48,  1.88s/it]
2026-01-31T18:33:56.3991791Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:33:56.3992284Z Loading safetensors checkpoint shards:  26% Completed | 43/163 [01:29<04:56,  2.47s/it]
2026-01-31T18:33:57.7414356Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:33:57.7414744Z Loading safetensors checkpoint shards:  27% Completed | 44/163 [01:30<04:13,  2.13s/it]
2026-01-31T18:33:59.3672059Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:33:59.3672934Z Loading safetensors checkpoint shards:  28% Completed | 45/163 [01:32<03:53,  1.98s/it]
2026-01-31T18:34:01.0331970Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:34:01.0332479Z Loading safetensors checkpoint shards:  28% Completed | 46/163 [01:33<03:40,  1.89s/it]
2026-01-31T18:34:09.1868822Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:34:09.1869193Z Loading safetensors checkpoint shards:  29% Completed | 47/163 [01:42<07:16,  3.77s/it]
2026-01-31T18:34:11.7792893Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:34:11.7793281Z Loading safetensors checkpoint shards:  29% Completed | 48/163 [01:44<06:32,  3.41s/it]
2026-01-31T18:34:11.9518877Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:34:11.9519272Z Loading safetensors checkpoint shards:  30% Completed | 49/163 [01:44<04:38,  2.44s/it]
2026-01-31T18:34:13.8382177Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:34:13.8382677Z Loading safetensors checkpoint shards:  31% Completed | 50/163 [01:46<04:17,  2.27s/it]
2026-01-31T18:34:16.5145909Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:34:16.5146260Z Loading safetensors checkpoint shards:  31% Completed | 51/163 [01:49<04:28,  2.40s/it]
2026-01-31T18:34:18.0294132Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:34:18.0295097Z Loading safetensors checkpoint shards:  32% Completed | 52/163 [01:50<03:56,  2.13s/it]
2026-01-31T18:34:21.5367548Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:34:21.5367930Z Loading safetensors checkpoint shards:  33% Completed | 53/163 [01:54<04:39,  2.54s/it]
2026-01-31T18:34:22.7987115Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:34:22.7987484Z Loading safetensors checkpoint shards:  33% Completed | 54/163 [01:55<03:55,  2.16s/it]
2026-01-31T18:34:23.9729929Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:34:23.9730306Z Loading safetensors checkpoint shards:  34% Completed | 55/163 [01:56<03:21,  1.86s/it]
2026-01-31T18:34:25.6271461Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:34:25.6271886Z Loading safetensors checkpoint shards:  34% Completed | 56/163 [01:58<03:12,  1.80s/it]
2026-01-31T18:34:27.4413674Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:34:27.4414038Z Loading safetensors checkpoint shards:  35% Completed | 57/163 [02:00<03:11,  1.81s/it]
2026-01-31T18:34:29.5416701Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:34:29.5417147Z Loading safetensors checkpoint shards:  36% Completed | 58/163 [02:02<03:18,  1.89s/it]
2026-01-31T18:34:33.8432185Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:34:33.8432599Z Loading safetensors checkpoint shards:  36% Completed | 59/163 [02:06<04:32,  2.62s/it]
2026-01-31T18:34:34.5630565Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:34:34.5630941Z Loading safetensors checkpoint shards:  37% Completed | 60/163 [02:07<03:30,  2.05s/it]
2026-01-31T18:34:35.3211135Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:34:35.3211499Z Loading safetensors checkpoint shards:  37% Completed | 61/163 [02:08<02:49,  1.66s/it]
2026-01-31T18:34:38.4672901Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:34:38.4673276Z Loading safetensors checkpoint shards:  38% Completed | 62/163 [02:11<03:32,  2.11s/it]
2026-01-31T18:34:39.6903340Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:34:39.6903750Z Loading safetensors checkpoint shards:  39% Completed | 63/163 [02:12<03:04,  1.84s/it]
2026-01-31T18:34:41.4523495Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:34:41.4523895Z Loading safetensors checkpoint shards:  39% Completed | 64/163 [02:14<02:59,  1.82s/it]
2026-01-31T18:34:45.7722817Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:34:45.7723220Z Loading safetensors checkpoint shards:  40% Completed | 65/163 [02:18<04:11,  2.57s/it]
2026-01-31T18:34:48.1462270Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:34:48.1462670Z Loading safetensors checkpoint shards:  40% Completed | 66/163 [02:20<04:03,  2.51s/it]
2026-01-31T18:34:49.7177839Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:34:49.7178655Z Loading safetensors checkpoint shards:  41% Completed | 67/163 [02:22<03:33,  2.23s/it]
2026-01-31T18:34:52.3627754Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:34:52.3628159Z Loading safetensors checkpoint shards:  42% Completed | 68/163 [02:25<03:43,  2.35s/it]
2026-01-31T18:34:53.3899014Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:34:53.3899392Z Loading safetensors checkpoint shards:  42% Completed | 69/163 [02:26<03:03,  1.96s/it]
2026-01-31T18:34:54.3652475Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:34:54.3652968Z Loading safetensors checkpoint shards:  43% Completed | 70/163 [02:27<02:34,  1.66s/it]
2026-01-31T18:34:55.9472702Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:34:55.9473098Z Loading safetensors checkpoint shards:  44% Completed | 71/163 [02:28<02:30,  1.64s/it]
2026-01-31T18:34:58.8650799Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:34:58.8651199Z Loading safetensors checkpoint shards:  44% Completed | 72/163 [02:31<03:03,  2.02s/it]
2026-01-31T18:34:59.5575769Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:34:59.5576147Z Loading safetensors checkpoint shards:  45% Completed | 73/163 [02:32<02:26,  1.62s/it]
2026-01-31T18:35:00.9174915Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:35:00.9175337Z Loading safetensors checkpoint shards:  45% Completed | 74/163 [02:33<02:17,  1.54s/it]
2026-01-31T18:35:02.3964600Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:35:02.3964977Z Loading safetensors checkpoint shards:  46% Completed | 75/163 [02:35<02:14,  1.52s/it]
2026-01-31T18:35:03.7467276Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:35:03.7469285Z Loading safetensors checkpoint shards:  47% Completed | 76/163 [02:36<02:08,  1.47s/it]
2026-01-31T18:35:06.5062120Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:35:06.5062517Z Loading safetensors checkpoint shards:  47% Completed | 77/163 [02:39<02:39,  1.86s/it]
2026-01-31T18:35:07.6704666Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:35:07.6705067Z Loading safetensors checkpoint shards:  48% Completed | 78/163 [02:40<02:20,  1.65s/it]
2026-01-31T18:35:08.7483530Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:35:08.7484085Z Loading safetensors checkpoint shards:  48% Completed | 79/163 [02:41<02:04,  1.48s/it]
2026-01-31T18:35:10.8913390Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:35:10.8913757Z Loading safetensors checkpoint shards:  49% Completed | 80/163 [02:43<02:19,  1.68s/it]
2026-01-31T18:35:14.0911052Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:35:14.0911437Z Loading safetensors checkpoint shards:  50% Completed | 81/163 [02:46<02:55,  2.13s/it]
2026-01-31T18:35:15.3020389Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:35:15.3020778Z Loading safetensors checkpoint shards:  50% Completed | 82/163 [02:48<02:30,  1.86s/it]
2026-01-31T18:35:16.8635432Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:35:16.8635855Z Loading safetensors checkpoint shards:  51% Completed | 83/163 [02:49<02:21,  1.77s/it]
2026-01-31T18:35:18.2471349Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:35:18.2471750Z Loading safetensors checkpoint shards:  52% Completed | 84/163 [02:51<02:10,  1.65s/it]
2026-01-31T18:35:20.4693555Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:35:20.4693936Z Loading safetensors checkpoint shards:  52% Completed | 85/163 [02:53<02:22,  1.82s/it]
2026-01-31T18:35:21.6192772Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:35:21.6193157Z Loading safetensors checkpoint shards:  53% Completed | 86/163 [02:54<02:04,  1.62s/it]
2026-01-31T18:35:23.1307310Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:35:23.1307696Z Loading safetensors checkpoint shards:  53% Completed | 87/163 [02:55<02:00,  1.59s/it]
2026-01-31T18:35:26.5671176Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:35:26.5671550Z Loading safetensors checkpoint shards:  54% Completed | 88/163 [02:59<02:40,  2.14s/it]
2026-01-31T18:35:28.1803916Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:35:28.1804340Z Loading safetensors checkpoint shards:  55% Completed | 89/163 [03:01<02:26,  1.98s/it]
2026-01-31T18:35:31.8842585Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:35:31.8843002Z Loading safetensors checkpoint shards:  55% Completed | 90/163 [03:04<03:02,  2.50s/it]
2026-01-31T18:35:33.6040191Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:35:33.6040565Z Loading safetensors checkpoint shards:  56% Completed | 91/163 [03:06<02:43,  2.27s/it]
2026-01-31T18:35:37.5674722Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:35:37.5675098Z Loading safetensors checkpoint shards:  56% Completed | 92/163 [03:10<03:17,  2.78s/it]
2026-01-31T18:35:38.2628229Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:35:38.2628649Z Loading safetensors checkpoint shards:  57% Completed | 93/163 [03:11<02:30,  2.15s/it]
2026-01-31T18:35:39.2314545Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:35:39.2314967Z Loading safetensors checkpoint shards:  58% Completed | 94/163 [03:12<02:03,  1.79s/it]
2026-01-31T18:35:41.0009510Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:35:41.0010098Z Loading safetensors checkpoint shards:  58% Completed | 95/163 [03:13<02:01,  1.79s/it]
2026-01-31T18:35:43.7249601Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:35:43.7249998Z Loading safetensors checkpoint shards:  59% Completed | 96/163 [03:16<02:18,  2.07s/it]
2026-01-31T18:35:45.0549324Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:35:45.0549727Z Loading safetensors checkpoint shards:  60% Completed | 97/163 [03:17<02:02,  1.85s/it]
2026-01-31T18:35:46.4285438Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:35:46.4285844Z Loading safetensors checkpoint shards:  60% Completed | 98/163 [03:19<01:50,  1.71s/it]
2026-01-31T18:35:48.1475004Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:35:48.1475443Z Loading safetensors checkpoint shards:  61% Completed | 99/163 [03:20<01:49,  1.71s/it]
2026-01-31T18:35:49.8404754Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:35:49.8405189Z Loading safetensors checkpoint shards:  61% Completed | 100/163 [03:22<01:47,  1.70s/it]
2026-01-31T18:35:50.9156584Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:35:50.9156999Z Loading safetensors checkpoint shards:  62% Completed | 101/163 [03:23<01:33,  1.52s/it]
2026-01-31T18:35:53.8516869Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:35:53.8517278Z Loading safetensors checkpoint shards:  63% Completed | 102/163 [03:26<01:58,  1.94s/it]
2026-01-31T18:35:56.2046353Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:35:56.2046729Z Loading safetensors checkpoint shards:  63% Completed | 103/163 [03:29<02:03,  2.07s/it]
2026-01-31T18:35:59.2647675Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:35:59.2648053Z Loading safetensors checkpoint shards:  64% Completed | 104/163 [03:32<02:19,  2.36s/it]
2026-01-31T18:36:00.4478859Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:36:00.4479257Z Loading safetensors checkpoint shards:  64% Completed | 105/163 [03:33<01:56,  2.01s/it]
2026-01-31T18:36:03.1339363Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:36:03.1339763Z Loading safetensors checkpoint shards:  65% Completed | 106/163 [03:35<02:06,  2.21s/it]
2026-01-31T18:36:04.2603008Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:36:04.2603386Z Loading safetensors checkpoint shards:  66% Completed | 107/163 [03:37<01:45,  1.89s/it]
2026-01-31T18:36:07.1758147Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:36:07.1758549Z Loading safetensors checkpoint shards:  66% Completed | 108/163 [03:40<02:00,  2.20s/it]
2026-01-31T18:36:07.9421133Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:36:07.9421505Z Loading safetensors checkpoint shards:  67% Completed | 109/163 [03:40<01:35,  1.77s/it]
2026-01-31T18:36:10.2647455Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:36:10.2648273Z Loading safetensors checkpoint shards:  67% Completed | 110/163 [03:43<01:42,  1.93s/it]
2026-01-31T18:36:13.5467757Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:36:13.5468180Z Loading safetensors checkpoint shards:  68% Completed | 111/163 [03:46<02:01,  2.34s/it]
2026-01-31T18:36:15.5168476Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:36:15.5168867Z Loading safetensors checkpoint shards:  69% Completed | 112/163 [03:48<01:53,  2.23s/it]
2026-01-31T18:36:17.4119559Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:36:17.4119953Z Loading safetensors checkpoint shards:  69% Completed | 113/163 [03:50<01:46,  2.13s/it]
2026-01-31T18:36:18.4985463Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:36:18.4985835Z Loading safetensors checkpoint shards:  70% Completed | 114/163 [03:51<01:28,  1.82s/it]
2026-01-31T18:36:19.8602476Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:36:19.8602862Z Loading safetensors checkpoint shards:  71% Completed | 115/163 [03:52<01:20,  1.68s/it]
2026-01-31T18:36:23.1661675Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:36:23.1662195Z Loading safetensors checkpoint shards:  71% Completed | 116/163 [03:56<01:41,  2.17s/it]
2026-01-31T18:36:24.7166850Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:36:24.7167810Z Loading safetensors checkpoint shards:  72% Completed | 117/163 [03:57<01:31,  1.98s/it]
2026-01-31T18:36:27.7226425Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:36:27.7226821Z Loading safetensors checkpoint shards:  72% Completed | 118/163 [04:00<01:43,  2.29s/it]
2026-01-31T18:36:28.9348314Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:36:28.9348688Z Loading safetensors checkpoint shards:  73% Completed | 119/163 [04:01<01:26,  1.97s/it]
2026-01-31T18:36:30.6099912Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:36:30.6100340Z Loading safetensors checkpoint shards:  74% Completed | 120/163 [04:03<01:20,  1.88s/it]
2026-01-31T18:36:32.6738182Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:36:32.6738596Z Loading safetensors checkpoint shards:  74% Completed | 121/163 [04:05<01:21,  1.93s/it]
2026-01-31T18:36:34.0775106Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:36:34.0775484Z Loading safetensors checkpoint shards:  75% Completed | 122/163 [04:06<01:12,  1.78s/it]
2026-01-31T18:36:36.4506312Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:36:36.4506730Z Loading safetensors checkpoint shards:  75% Completed | 123/163 [04:09<01:18,  1.95s/it]
2026-01-31T18:36:37.5151820Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:36:37.5152305Z Loading safetensors checkpoint shards:  76% Completed | 124/163 [04:10<01:05,  1.69s/it]
2026-01-31T18:36:40.2538159Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:36:40.2538561Z Loading safetensors checkpoint shards:  77% Completed | 125/163 [04:13<01:16,  2.00s/it]
2026-01-31T18:36:41.5198563Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:36:41.5198971Z Loading safetensors checkpoint shards:  77% Completed | 126/163 [04:14<01:05,  1.78s/it]
2026-01-31T18:36:42.9173485Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:36:42.9173873Z Loading safetensors checkpoint shards:  78% Completed | 127/163 [04:15<00:59,  1.67s/it]
2026-01-31T18:36:45.6020992Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:36:45.6021385Z Loading safetensors checkpoint shards:  79% Completed | 128/163 [04:18<01:09,  1.97s/it]
2026-01-31T18:36:48.2993613Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:36:48.2994011Z Loading safetensors checkpoint shards:  79% Completed | 129/163 [04:21<01:14,  2.19s/it]
2026-01-31T18:36:49.3242975Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:36:49.3243371Z Loading safetensors checkpoint shards:  80% Completed | 130/163 [04:22<01:00,  1.84s/it]
2026-01-31T18:36:50.5122996Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:36:50.5123361Z Loading safetensors checkpoint shards:  80% Completed | 131/163 [04:23<00:52,  1.64s/it]
2026-01-31T18:36:52.0328859Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:36:52.0329250Z Loading safetensors checkpoint shards:  81% Completed | 132/163 [04:24<00:49,  1.61s/it]
2026-01-31T18:36:54.3926817Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:36:54.3927208Z Loading safetensors checkpoint shards:  82% Completed | 133/163 [04:27<00:55,  1.83s/it]
2026-01-31T18:36:55.9968912Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:36:55.9969301Z Loading safetensors checkpoint shards:  82% Completed | 134/163 [04:28<00:51,  1.76s/it]
2026-01-31T18:36:59.8211545Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:36:59.8211941Z Loading safetensors checkpoint shards:  83% Completed | 135/163 [04:32<01:06,  2.38s/it]
2026-01-31T18:37:01.0598595Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:37:01.0598982Z Loading safetensors checkpoint shards:  83% Completed | 136/163 [04:33<00:55,  2.04s/it]
2026-01-31T18:37:02.8410988Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:37:02.8411415Z Loading safetensors checkpoint shards:  84% Completed | 137/163 [04:35<00:51,  1.96s/it]
2026-01-31T18:37:06.8327528Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:37:06.8327953Z Loading safetensors checkpoint shards:  85% Completed | 138/163 [04:39<01:04,  2.57s/it]
2026-01-31T18:37:10.0348538Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:37:10.0348946Z Loading safetensors checkpoint shards:  85% Completed | 139/163 [04:42<01:06,  2.76s/it]
2026-01-31T18:37:11.1047550Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:37:11.1047930Z Loading safetensors checkpoint shards:  86% Completed | 140/163 [04:43<00:51,  2.25s/it]
2026-01-31T18:37:12.9111229Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:37:12.9111619Z Loading safetensors checkpoint shards:  87% Completed | 141/163 [04:45<00:46,  2.12s/it]
2026-01-31T18:37:14.5098320Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:37:14.5098690Z Loading safetensors checkpoint shards:  87% Completed | 142/163 [04:47<00:41,  1.96s/it]
2026-01-31T18:37:16.8743374Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:37:16.8743771Z Loading safetensors checkpoint shards:  88% Completed | 143/163 [04:49<00:41,  2.08s/it]
2026-01-31T18:37:19.9094481Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:37:19.9094897Z Loading safetensors checkpoint shards:  88% Completed | 144/163 [04:52<00:45,  2.37s/it]
2026-01-31T18:37:21.5772696Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:37:21.5773090Z Loading safetensors checkpoint shards:  89% Completed | 145/163 [04:54<00:38,  2.16s/it]
2026-01-31T18:37:24.1851862Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:37:24.1852351Z Loading safetensors checkpoint shards:  90% Completed | 146/163 [04:57<00:38,  2.29s/it]
2026-01-31T18:37:25.6263136Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:37:25.6263520Z Loading safetensors checkpoint shards:  90% Completed | 147/163 [04:58<00:32,  2.04s/it]
2026-01-31T18:37:27.0030973Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:37:27.0031395Z Loading safetensors checkpoint shards:  91% Completed | 148/163 [04:59<00:27,  1.84s/it]
2026-01-31T18:37:28.0986911Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:37:28.0987421Z Loading safetensors checkpoint shards:  91% Completed | 149/163 [05:00<00:22,  1.62s/it]
2026-01-31T18:37:31.1649243Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:37:31.1649641Z Loading safetensors checkpoint shards:  93% Completed | 151/163 [05:04<00:18,  1.58s/it]
2026-01-31T18:37:32.5026523Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:37:32.5026913Z Loading safetensors checkpoint shards:  93% Completed | 152/163 [05:05<00:16,  1.52s/it]
2026-01-31T18:37:33.8900195Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:37:33.8900580Z Loading safetensors checkpoint shards:  94% Completed | 153/163 [05:06<00:14,  1.48s/it]
2026-01-31T18:37:35.7106336Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:37:35.7107226Z Loading safetensors checkpoint shards:  94% Completed | 154/163 [05:08<00:14,  1.58s/it]
2026-01-31T18:37:37.8261186Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:37:37.8261574Z Loading safetensors checkpoint shards:  95% Completed | 155/163 [05:10<00:13,  1.73s/it]
2026-01-31T18:37:39.5412842Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:37:39.5413251Z Loading safetensors checkpoint shards:  96% Completed | 156/163 [05:12<00:12,  1.72s/it]
2026-01-31T18:37:40.9921626Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:37:40.9922103Z Loading safetensors checkpoint shards:  96% Completed | 157/163 [05:13<00:09,  1.64s/it]
2026-01-31T18:37:44.2373665Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:37:44.2374049Z Loading safetensors checkpoint shards:  97% Completed | 158/163 [05:17<00:10,  2.11s/it]
2026-01-31T18:37:45.6117885Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:37:45.6118261Z Loading safetensors checkpoint shards:  98% Completed | 159/163 [05:18<00:07,  1.90s/it]
2026-01-31T18:37:47.4893517Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:37:47.4893905Z Loading safetensors checkpoint shards:  98% Completed | 160/163 [05:20<00:05,  1.89s/it]
2026-01-31T18:37:48.6309798Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:37:48.6310736Z Loading safetensors checkpoint shards:  99% Completed | 161/163 [05:21<00:03,  1.67s/it]
2026-01-31T18:37:50.5527942Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:37:50.5528417Z Loading safetensors checkpoint shards:  99% Completed | 162/163 [05:23<00:01,  1.74s/it]
2026-01-31T18:37:51.9470977Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:37:51.9471348Z Loading safetensors checkpoint shards: 100% Completed | 163/163 [05:24<00:00,  1.64s/it]
2026-01-31T18:37:51.9480107Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:37:51.9480420Z Loading safetensors checkpoint shards: 100% Completed | 163/163 [05:24<00:00,  1.99s/it]
2026-01-31T18:37:51.9489159Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:37:51.9647080Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m INFO 01-31 18:37:51 [default_loader.py:308] Loading weights took 324.80 seconds
2026-01-31T18:37:52.3622507Z [0;36m(Worker_DP1_TP0_EP8 pid=212)[0;0m INFO 01-31 18:37:52 [default_loader.py:308] Loading weights took 325.13 seconds
2026-01-31T18:38:05.3442127Z INFO 01-31 18:38:05 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-01-31T18:38:05.3450558Z INFO 01-31 18:38:05 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-01-31T18:38:05.3460688Z INFO 01-31 18:38:05 [__init__.py:45] - ascend -> vllm_ascend:register
2026-01-31T18:38:05.3470804Z INFO 01-31 18:38:05 [__init__.py:45] - ascend -> vllm_ascend:register
2026-01-31T18:38:05.3480641Z INFO 01-31 18:38:05 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-01-31T18:38:05.3491111Z INFO 01-31 18:38:05 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-01-31T18:38:05.3500116Z INFO 01-31 18:38:05 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-01-31T18:38:05.3509618Z INFO 01-31 18:38:05 [__init__.py:45] - ascend -> vllm_ascend:register
2026-01-31T18:38:05.3520634Z INFO 01-31 18:38:05 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-01-31T18:38:05.3530595Z INFO 01-31 18:38:05 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-01-31T18:38:05.3540930Z INFO 01-31 18:38:05 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-01-31T18:38:05.3550539Z INFO 01-31 18:38:05 [__init__.py:45] - ascend -> vllm_ascend:register
2026-01-31T18:38:05.3560446Z INFO 01-31 18:38:05 [__init__.py:45] - ascend -> vllm_ascend:register
2026-01-31T18:38:05.3570573Z INFO 01-31 18:38:05 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-01-31T18:38:05.3581051Z INFO 01-31 18:38:05 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-01-31T18:38:05.3591199Z INFO 01-31 18:38:05 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-01-31T18:38:05.3600612Z INFO 01-31 18:38:05 [__init__.py:45] - ascend -> vllm_ascend:register
2026-01-31T18:38:05.3610869Z INFO 01-31 18:38:05 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-01-31T18:38:05.3621068Z INFO 01-31 18:38:05 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-01-31T18:38:05.3631240Z INFO 01-31 18:38:05 [__init__.py:45] - ascend -> vllm_ascend:register
2026-01-31T18:38:05.3640561Z INFO 01-31 18:38:05 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-01-31T18:38:05.3650287Z INFO 01-31 18:38:05 [__init__.py:217] Platform plugin ascend is activated
2026-01-31T18:38:05.3659928Z INFO 01-31 18:38:05 [__init__.py:217] Platform plugin ascend is activated
2026-01-31T18:38:05.3669692Z INFO 01-31 18:38:05 [__init__.py:217] Platform plugin ascend is activated
2026-01-31T18:38:05.3680484Z INFO 01-31 18:38:05 [__init__.py:217] Platform plugin ascend is activated
2026-01-31T18:38:05.3690208Z INFO 01-31 18:38:05 [__init__.py:217] Platform plugin ascend is activated
2026-01-31T18:38:05.3699747Z INFO 01-31 18:38:05 [__init__.py:217] Platform plugin ascend is activated
2026-01-31T18:38:05.3710507Z INFO 01-31 18:38:05 [__init__.py:217] Platform plugin ascend is activated
2026-01-31T18:38:05.4281707Z INFO 01-31 18:38:05 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-01-31T18:38:05.4291010Z INFO 01-31 18:38:05 [__init__.py:45] - ascend -> vllm_ascend:register
2026-01-31T18:38:05.4300592Z INFO 01-31 18:38:05 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-01-31T18:38:05.4310467Z INFO 01-31 18:38:05 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-01-31T18:38:05.4320676Z INFO 01-31 18:38:05 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-01-31T18:38:05.4330603Z INFO 01-31 18:38:05 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-01-31T18:38:05.4340521Z INFO 01-31 18:38:05 [__init__.py:45] - ascend -> vllm_ascend:register
2026-01-31T18:38:05.4348891Z INFO 01-31 18:38:05 [__init__.py:45] - ascend -> vllm_ascend:register
2026-01-31T18:38:05.4358338Z INFO 01-31 18:38:05 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-01-31T18:38:05.4367895Z INFO 01-31 18:38:05 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-01-31T18:38:05.4376702Z INFO 01-31 18:38:05 [__init__.py:45] - ascend -> vllm_ascend:register
2026-01-31T18:38:05.4386449Z INFO 01-31 18:38:05 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-01-31T18:38:05.4395942Z INFO 01-31 18:38:05 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-01-31T18:38:05.4405936Z INFO 01-31 18:38:05 [__init__.py:45] - ascend -> vllm_ascend:register
2026-01-31T18:38:05.4415578Z INFO 01-31 18:38:05 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-01-31T18:38:05.4424899Z INFO 01-31 18:38:05 [__init__.py:217] Platform plugin ascend is activated
2026-01-31T18:38:05.4433827Z INFO 01-31 18:38:05 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-01-31T18:38:05.4443846Z INFO 01-31 18:38:05 [__init__.py:45] - ascend -> vllm_ascend:register
2026-01-31T18:38:05.4455914Z INFO 01-31 18:38:05 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-01-31T18:38:05.4462355Z INFO 01-31 18:38:05 [__init__.py:217] Platform plugin ascend is activated
2026-01-31T18:38:05.4504490Z INFO 01-31 18:38:05 [__init__.py:217] Platform plugin ascend is activated
2026-01-31T18:38:05.4504821Z INFO 01-31 18:38:05 [__init__.py:217] Platform plugin ascend is activated
2026-01-31T18:38:05.4505110Z INFO 01-31 18:38:05 [__init__.py:217] Platform plugin ascend is activated
2026-01-31T18:38:05.4505502Z INFO 01-31 18:38:05 [__init__.py:217] Platform plugin ascend is activated
2026-01-31T18:38:05.4989965Z INFO 01-31 18:38:05 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-01-31T18:38:05.4999122Z INFO 01-31 18:38:05 [__init__.py:45] - ascend -> vllm_ascend:register
2026-01-31T18:38:05.5008830Z INFO 01-31 18:38:05 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-01-31T18:38:05.5017452Z INFO 01-31 18:38:05 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-01-31T18:38:05.5026943Z INFO 01-31 18:38:05 [__init__.py:45] - ascend -> vllm_ascend:register
2026-01-31T18:38:05.5037115Z INFO 01-31 18:38:05 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-01-31T18:38:05.5046895Z INFO 01-31 18:38:05 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-01-31T18:38:05.5055107Z INFO 01-31 18:38:05 [__init__.py:45] - ascend -> vllm_ascend:register
2026-01-31T18:38:05.5066710Z INFO 01-31 18:38:05 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-01-31T18:38:05.5074192Z INFO 01-31 18:38:05 [__init__.py:217] Platform plugin ascend is activated
2026-01-31T18:38:05.5083616Z INFO 01-31 18:38:05 [__init__.py:217] Platform plugin ascend is activated
2026-01-31T18:38:05.5099179Z INFO 01-31 18:38:05 [__init__.py:217] Platform plugin ascend is activated
2026-01-31T18:38:29.9595209Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m INFO 01-31 18:38:29 [fused_moe.py:500] SharedFusedMoE shared experts split computation matches the integrated computation.
2026-01-31T18:38:30.0072073Z [0;36m(Worker_DP1_TP1_EP9 pid=277)[0;0m INFO 01-31 18:38:30 [fused_moe.py:500] SharedFusedMoE shared experts split computation matches the integrated computation.
2026-01-31T18:38:30.3313357Z [0;36m(Worker_DP0_TP6_EP6 pid=789)[0;0m INFO 01-31 18:38:30 [fused_moe.py:500] SharedFusedMoE shared experts split computation matches the integrated computation.
2026-01-31T18:38:30.4373509Z [0;36m(Worker_DP0_TP7_EP7 pid=891)[0;0m INFO 01-31 18:38:30 [fused_moe.py:500] SharedFusedMoE shared experts split computation matches the integrated computation.
2026-01-31T18:38:30.5029521Z [0;36m(Worker_DP0_TP1_EP1 pid=268)[0;0m INFO 01-31 18:38:30 [fused_moe.py:500] SharedFusedMoE shared experts split computation matches the integrated computation.
2026-01-31T18:38:30.5680386Z [0;36m(Worker_DP1_TP2_EP10 pid=381)[0;0m INFO 01-31 18:38:30 [fused_moe.py:500] SharedFusedMoE shared experts split computation matches the integrated computation.
2026-01-31T18:38:30.5704366Z [0;36m(Worker_DP0_TP3_EP3 pid=481)[0;0m INFO 01-31 18:38:30 [fused_moe.py:500] SharedFusedMoE shared experts split computation matches the integrated computation.
2026-01-31T18:38:30.6332467Z [0;36m(Worker_DP1_TP0_EP8 pid=212)[0;0m INFO 01-31 18:38:30 [fused_moe.py:500] SharedFusedMoE shared experts split computation matches the integrated computation.
2026-01-31T18:38:30.6521707Z [0;36m(Worker_DP0_TP2_EP2 pid=379)[0;0m INFO 01-31 18:38:30 [fused_moe.py:500] SharedFusedMoE shared experts split computation matches the integrated computation.
2026-01-31T18:38:30.7235454Z [0;36m(Worker_DP1_TP7_EP15 pid=888)[0;0m INFO 01-31 18:38:30 [fused_moe.py:500] SharedFusedMoE shared experts split computation matches the integrated computation.
2026-01-31T18:38:30.7579148Z [0;36m(Worker_DP0_TP5_EP5 pid=687)[0;0m INFO 01-31 18:38:30 [fused_moe.py:500] SharedFusedMoE shared experts split computation matches the integrated computation.
2026-01-31T18:38:30.8092438Z [0;36m(Worker_DP1_TP3_EP11 pid=480)[0;0m INFO 01-31 18:38:30 [fused_moe.py:500] SharedFusedMoE shared experts split computation matches the integrated computation.
2026-01-31T18:38:30.9049492Z [0;36m(Worker_DP1_TP6_EP14 pid=786)[0;0m INFO 01-31 18:38:30 [fused_moe.py:500] SharedFusedMoE shared experts split computation matches the integrated computation.
2026-01-31T18:38:30.9747850Z [0;36m(Worker_DP1_TP4_EP12 pid=583)[0;0m INFO 01-31 18:38:30 [fused_moe.py:500] SharedFusedMoE shared experts split computation matches the integrated computation.
2026-01-31T18:38:31.0255914Z [0;36m(Worker_DP1_TP5_EP13 pid=686)[0;0m INFO 01-31 18:38:31 [fused_moe.py:500] SharedFusedMoE shared experts split computation matches the integrated computation.
2026-01-31T18:38:31.0755873Z [0;36m(Worker_DP0_TP4_EP4 pid=582)[0;0m INFO 01-31 18:38:31 [fused_moe.py:500] SharedFusedMoE shared experts split computation matches the integrated computation.
2026-01-31T18:38:31.7813371Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m WARNING 01-31 18:38:31 [sfa_v1.py:467] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-01-31T18:38:31.7913380Z [0;36m(Worker_DP1_TP1_EP9 pid=277)[0;0m WARNING 01-31 18:38:31 [sfa_v1.py:467] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-01-31T18:38:31.8332517Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m INFO 01-31 18:38:31 [model_runner_v1.py:2386] Loading drafter model...
2026-01-31T18:38:31.8364272Z [0;36m(Worker_DP1_TP1_EP9 pid=277)[0;0m INFO 01-31 18:38:31 [model_runner_v1.py:2386] Loading drafter model...
2026-01-31T18:38:31.9084505Z [0;36m(Worker_DP1_TP1_EP9 pid=277)[0;0m INFO 01-31 18:38:31 [compilation.py:862] Using OOT custom backend for compilation.
2026-01-31T18:38:31.9138971Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m INFO 01-31 18:38:31 [compilation.py:862] Using OOT custom backend for compilation.
2026-01-31T18:38:31.9223595Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:38:31.9223900Z Loading safetensors checkpoint shards:   0% Completed | 0/163 [00:00<?, ?it/s]
2026-01-31T18:38:32.1260366Z [0;36m(Worker_DP0_TP6_EP6 pid=789)[0;0m WARNING 01-31 18:38:32 [sfa_v1.py:467] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-01-31T18:38:32.1743209Z [0;36m(Worker_DP0_TP6_EP6 pid=789)[0;0m INFO 01-31 18:38:32 [model_runner_v1.py:2386] Loading drafter model...
2026-01-31T18:38:32.2327189Z [0;36m(Worker_DP0_TP7_EP7 pid=891)[0;0m WARNING 01-31 18:38:32 [sfa_v1.py:467] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-01-31T18:38:32.2500069Z [0;36m(Worker_DP0_TP6_EP6 pid=789)[0;0m INFO 01-31 18:38:32 [compilation.py:862] Using OOT custom backend for compilation.
2026-01-31T18:38:32.2893882Z [0;36m(Worker_DP0_TP7_EP7 pid=891)[0;0m INFO 01-31 18:38:32 [model_runner_v1.py:2386] Loading drafter model...
2026-01-31T18:38:32.3394233Z [0;36m(Worker_DP0_TP1_EP1 pid=268)[0;0m WARNING 01-31 18:38:32 [sfa_v1.py:467] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-01-31T18:38:32.3437526Z [0;36m(Worker_DP1_TP2_EP10 pid=381)[0;0m WARNING 01-31 18:38:32 [sfa_v1.py:467] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-01-31T18:38:32.3754857Z [0;36m(Worker_DP0_TP7_EP7 pid=891)[0;0m INFO 01-31 18:38:32 [compilation.py:862] Using OOT custom backend for compilation.
2026-01-31T18:38:32.3865184Z [0;36m(Worker_DP0_TP1_EP1 pid=268)[0;0m INFO 01-31 18:38:32 [model_runner_v1.py:2386] Loading drafter model...
2026-01-31T18:38:32.3893388Z [0;36m(Worker_DP1_TP2_EP10 pid=381)[0;0m INFO 01-31 18:38:32 [model_runner_v1.py:2386] Loading drafter model...
2026-01-31T18:38:32.3903020Z [0;36m(Worker_DP0_TP3_EP3 pid=481)[0;0m WARNING 01-31 18:38:32 [sfa_v1.py:467] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-01-31T18:38:32.4324814Z [0;36m(Worker_DP0_TP3_EP3 pid=481)[0;0m INFO 01-31 18:38:32 [model_runner_v1.py:2386] Loading drafter model...
2026-01-31T18:38:32.4528974Z [0;36m(Worker_DP0_TP2_EP2 pid=379)[0;0m WARNING 01-31 18:38:32 [sfa_v1.py:467] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-01-31T18:38:32.4608424Z [0;36m(Worker_DP0_TP1_EP1 pid=268)[0;0m INFO 01-31 18:38:32 [compilation.py:862] Using OOT custom backend for compilation.
2026-01-31T18:38:32.4713951Z [0;36m(Worker_DP1_TP2_EP10 pid=381)[0;0m INFO 01-31 18:38:32 [compilation.py:862] Using OOT custom backend for compilation.
2026-01-31T18:38:32.5036355Z [0;36m(Worker_DP1_TP0_EP8 pid=212)[0;0m WARNING 01-31 18:38:32 [sfa_v1.py:467] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-01-31T18:38:32.5080021Z [0;36m(Worker_DP0_TP3_EP3 pid=481)[0;0m INFO 01-31 18:38:32 [compilation.py:862] Using OOT custom backend for compilation.
2026-01-31T18:38:32.5396124Z [0;36m(Worker_DP0_TP2_EP2 pid=379)[0;0m INFO 01-31 18:38:32 [model_runner_v1.py:2386] Loading drafter model...
2026-01-31T18:38:32.5440922Z [0;36m(Worker_DP1_TP7_EP15 pid=888)[0;0m WARNING 01-31 18:38:32 [sfa_v1.py:467] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-01-31T18:38:32.5574573Z [0;36m(Worker_DP1_TP0_EP8 pid=212)[0;0m INFO 01-31 18:38:32 [model_runner_v1.py:2386] Loading drafter model...
2026-01-31T18:38:32.5714219Z [0;36m(Worker_DP0_TP5_EP5 pid=687)[0;0m WARNING 01-31 18:38:32 [sfa_v1.py:467] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-01-31T18:38:32.5960366Z [0;36m(Worker_DP1_TP7_EP15 pid=888)[0;0m INFO 01-31 18:38:32 [model_runner_v1.py:2386] Loading drafter model...
2026-01-31T18:38:32.6183920Z [0;36m(Worker_DP0_TP2_EP2 pid=379)[0;0m INFO 01-31 18:38:32 [compilation.py:862] Using OOT custom backend for compilation.
2026-01-31T18:38:32.6214927Z [0;36m(Worker_DP0_TP5_EP5 pid=687)[0;0m INFO 01-31 18:38:32 [model_runner_v1.py:2386] Loading drafter model...
2026-01-31T18:38:32.6313716Z [0;36m(Worker_DP1_TP0_EP8 pid=212)[0;0m INFO 01-31 18:38:32 [compilation.py:862] Using OOT custom backend for compilation.
2026-01-31T18:38:32.6749740Z [0;36m(Worker_DP1_TP7_EP15 pid=888)[0;0m INFO 01-31 18:38:32 [compilation.py:862] Using OOT custom backend for compilation.
2026-01-31T18:38:32.6813136Z [0;36m(Worker_DP1_TP3_EP11 pid=480)[0;0m WARNING 01-31 18:38:32 [sfa_v1.py:467] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-01-31T18:38:32.6949469Z [0;36m(Worker_DP0_TP5_EP5 pid=687)[0;0m INFO 01-31 18:38:32 [compilation.py:862] Using OOT custom backend for compilation.
2026-01-31T18:38:32.7316050Z [0;36m(Worker_DP1_TP6_EP14 pid=786)[0;0m WARNING 01-31 18:38:32 [sfa_v1.py:467] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-01-31T18:38:32.7344882Z [0;36m(Worker_DP1_TP3_EP11 pid=480)[0;0m INFO 01-31 18:38:32 [model_runner_v1.py:2386] Loading drafter model...
2026-01-31T18:38:32.7802236Z [0;36m(Worker_DP1_TP6_EP14 pid=786)[0;0m INFO 01-31 18:38:32 [model_runner_v1.py:2386] Loading drafter model...
2026-01-31T18:38:32.8017909Z [0;36m(Worker_DP1_TP4_EP12 pid=583)[0;0m WARNING 01-31 18:38:32 [sfa_v1.py:467] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-01-31T18:38:32.8142639Z [0;36m(Worker_DP1_TP3_EP11 pid=480)[0;0m INFO 01-31 18:38:32 [compilation.py:862] Using OOT custom backend for compilation.
2026-01-31T18:38:32.8430083Z [0;36m(Worker_DP1_TP5_EP13 pid=686)[0;0m WARNING 01-31 18:38:32 [sfa_v1.py:467] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-01-31T18:38:32.8525956Z [0;36m(Worker_DP1_TP4_EP12 pid=583)[0;0m INFO 01-31 18:38:32 [model_runner_v1.py:2386] Loading drafter model...
2026-01-31T18:38:32.8773492Z [0;36m(Worker_DP1_TP6_EP14 pid=786)[0;0m INFO 01-31 18:38:32 [compilation.py:862] Using OOT custom backend for compilation.
2026-01-31T18:38:32.8896432Z [0;36m(Worker_DP1_TP5_EP13 pid=686)[0;0m INFO 01-31 18:38:32 [model_runner_v1.py:2386] Loading drafter model...
2026-01-31T18:38:32.8974750Z [0;36m(Worker_DP0_TP4_EP4 pid=582)[0;0m WARNING 01-31 18:38:32 [sfa_v1.py:467] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-01-31T18:38:32.9343789Z [0;36m(Worker_DP1_TP4_EP12 pid=583)[0;0m INFO 01-31 18:38:32 [compilation.py:862] Using OOT custom backend for compilation.
2026-01-31T18:38:32.9420269Z [0;36m(Worker_DP0_TP4_EP4 pid=582)[0;0m INFO 01-31 18:38:32 [model_runner_v1.py:2386] Loading drafter model...
2026-01-31T18:38:33.0054718Z [0;36m(Worker_DP1_TP5_EP13 pid=686)[0;0m INFO 01-31 18:38:33 [compilation.py:862] Using OOT custom backend for compilation.
2026-01-31T18:38:33.0187446Z [0;36m(Worker_DP0_TP4_EP4 pid=582)[0;0m INFO 01-31 18:38:33 [compilation.py:862] Using OOT custom backend for compilation.
2026-01-31T18:38:33.0784335Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:38:33.0784677Z Loading safetensors checkpoint shards:   1% Completed | 1/163 [00:01<03:07,  1.16s/it]
2026-01-31T18:38:34.0847133Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:38:34.0847550Z Loading safetensors checkpoint shards:   1% Completed | 2/163 [00:02<02:51,  1.07s/it]
2026-01-31T18:38:35.3217097Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:38:35.3217462Z Loading safetensors checkpoint shards:   2% Completed | 3/163 [00:03<03:03,  1.14s/it]
2026-01-31T18:38:36.5910485Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:38:36.5910847Z Loading safetensors checkpoint shards:   2% Completed | 4/163 [00:04<03:09,  1.19s/it]
2026-01-31T18:38:37.7797142Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:38:37.7797517Z Loading safetensors checkpoint shards:   3% Completed | 5/163 [00:05<03:08,  1.19s/it]
2026-01-31T18:38:38.8240926Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:38:38.8241310Z Loading safetensors checkpoint shards:   4% Completed | 6/163 [00:06<02:59,  1.14s/it]
2026-01-31T18:38:39.9959112Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:38:39.9959474Z Loading safetensors checkpoint shards:   4% Completed | 7/163 [00:08<02:59,  1.15s/it]
2026-01-31T18:38:41.0666578Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:38:41.0666962Z Loading safetensors checkpoint shards:   5% Completed | 8/163 [00:09<02:54,  1.13s/it]
2026-01-31T18:38:42.0918552Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:38:42.0918970Z Loading safetensors checkpoint shards:   6% Completed | 9/163 [00:10<02:48,  1.09s/it]
2026-01-31T18:38:43.2333719Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:38:43.2334093Z Loading safetensors checkpoint shards:   6% Completed | 10/163 [00:11<02:49,  1.11s/it]
2026-01-31T18:38:44.2803104Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:38:44.2803483Z Loading safetensors checkpoint shards:   7% Completed | 11/163 [00:12<02:45,  1.09s/it]
2026-01-31T18:38:45.3727964Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:38:45.3728350Z Loading safetensors checkpoint shards:   7% Completed | 12/163 [00:13<02:44,  1.09s/it]
2026-01-31T18:38:46.5340662Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:38:46.5341022Z Loading safetensors checkpoint shards:   8% Completed | 13/163 [00:14<02:46,  1.11s/it]
2026-01-31T18:38:47.6083623Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:38:47.6084011Z Loading safetensors checkpoint shards:   9% Completed | 14/163 [00:15<02:44,  1.10s/it]
2026-01-31T18:38:48.6147740Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:38:48.6148123Z Loading safetensors checkpoint shards:   9% Completed | 15/163 [00:16<02:38,  1.07s/it]
2026-01-31T18:38:49.7263770Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:38:49.7264206Z Loading safetensors checkpoint shards:  10% Completed | 16/163 [00:17<02:39,  1.08s/it]
2026-01-31T18:38:50.8061131Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:38:50.8061528Z Loading safetensors checkpoint shards:  10% Completed | 17/163 [00:18<02:38,  1.08s/it]
2026-01-31T18:38:51.7686484Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:38:51.7686873Z Loading safetensors checkpoint shards:  11% Completed | 18/163 [00:19<02:31,  1.05s/it]
2026-01-31T18:38:52.8556023Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:38:52.8556468Z Loading safetensors checkpoint shards:  12% Completed | 19/163 [00:20<02:32,  1.06s/it]
2026-01-31T18:38:53.9390478Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:38:53.9390894Z Loading safetensors checkpoint shards:  12% Completed | 20/163 [00:22<02:32,  1.07s/it]
2026-01-31T18:38:55.0167235Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:38:55.0167591Z Loading safetensors checkpoint shards:  13% Completed | 21/163 [00:23<02:31,  1.07s/it]
2026-01-31T18:38:56.1048253Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:38:56.1048652Z Loading safetensors checkpoint shards:  13% Completed | 22/163 [00:24<02:31,  1.08s/it]
2026-01-31T18:38:57.1803000Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:38:57.1803363Z Loading safetensors checkpoint shards:  14% Completed | 23/163 [00:25<02:30,  1.08s/it]
2026-01-31T18:38:58.2830823Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:38:58.2831246Z Loading safetensors checkpoint shards:  15% Completed | 24/163 [00:26<02:30,  1.08s/it]
2026-01-31T18:38:59.3392936Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:38:59.3393318Z Loading safetensors checkpoint shards:  15% Completed | 25/163 [00:27<02:28,  1.08s/it]
2026-01-31T18:39:00.7101063Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:00.7101481Z Loading safetensors checkpoint shards:  16% Completed | 26/163 [00:28<02:39,  1.16s/it]
2026-01-31T18:39:01.9524587Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:01.9524977Z Loading safetensors checkpoint shards:  17% Completed | 27/163 [00:30<02:41,  1.19s/it]
2026-01-31T18:39:02.9772635Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:02.9773175Z Loading safetensors checkpoint shards:  17% Completed | 28/163 [00:31<02:33,  1.14s/it]
2026-01-31T18:39:03.9259018Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:03.9259539Z Loading safetensors checkpoint shards:  18% Completed | 29/163 [00:32<02:24,  1.08s/it]
2026-01-31T18:39:05.0222859Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:05.0223294Z Loading safetensors checkpoint shards:  18% Completed | 30/163 [00:33<02:24,  1.09s/it]
2026-01-31T18:39:06.1804551Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:06.1805055Z Loading safetensors checkpoint shards:  19% Completed | 31/163 [00:34<02:26,  1.11s/it]
2026-01-31T18:39:07.2537579Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:07.2538030Z Loading safetensors checkpoint shards:  20% Completed | 32/163 [00:35<02:23,  1.10s/it]
2026-01-31T18:39:08.3306621Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:08.3307066Z Loading safetensors checkpoint shards:  20% Completed | 33/163 [00:36<02:21,  1.09s/it]
2026-01-31T18:39:09.4361529Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:09.4362280Z Loading safetensors checkpoint shards:  21% Completed | 34/163 [00:37<02:21,  1.10s/it]
2026-01-31T18:39:10.4814038Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:10.4814683Z Loading safetensors checkpoint shards:  21% Completed | 35/163 [00:38<02:18,  1.08s/it]
2026-01-31T18:39:11.4815842Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:11.4816399Z Loading safetensors checkpoint shards:  22% Completed | 36/163 [00:39<02:14,  1.06s/it]
2026-01-31T18:39:12.5970055Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:12.5970589Z Loading safetensors checkpoint shards:  23% Completed | 37/163 [00:40<02:15,  1.07s/it]
2026-01-31T18:39:13.5718232Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:13.5718824Z Loading safetensors checkpoint shards:  23% Completed | 38/163 [00:41<02:10,  1.04s/it]
2026-01-31T18:39:14.7425939Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:14.7426556Z Loading safetensors checkpoint shards:  24% Completed | 39/163 [00:42<02:14,  1.08s/it]
2026-01-31T18:39:15.7660019Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:15.7660813Z Loading safetensors checkpoint shards:  25% Completed | 40/163 [00:43<02:10,  1.06s/it]
2026-01-31T18:39:16.9184818Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:16.9185283Z Loading safetensors checkpoint shards:  25% Completed | 41/163 [00:44<02:13,  1.09s/it]
2026-01-31T18:39:18.0889293Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:18.0889762Z Loading safetensors checkpoint shards:  26% Completed | 42/163 [00:46<02:14,  1.11s/it]
2026-01-31T18:39:19.0947892Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:19.0948315Z Loading safetensors checkpoint shards:  26% Completed | 43/163 [00:47<02:09,  1.08s/it]
2026-01-31T18:39:20.1140950Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:20.1141404Z Loading safetensors checkpoint shards:  27% Completed | 44/163 [00:48<02:06,  1.06s/it]
2026-01-31T18:39:21.2499449Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:21.2499935Z Loading safetensors checkpoint shards:  28% Completed | 45/163 [00:49<02:08,  1.09s/it]
2026-01-31T18:39:22.3941062Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:22.3941489Z Loading safetensors checkpoint shards:  28% Completed | 46/163 [00:50<02:09,  1.10s/it]
2026-01-31T18:39:23.1185337Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:23.1186386Z Loading safetensors checkpoint shards:  29% Completed | 47/163 [00:51<01:54,  1.01it/s]
2026-01-31T18:39:24.2469198Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:24.2469702Z Loading safetensors checkpoint shards:  30% Completed | 49/163 [00:52<01:30,  1.26it/s]
2026-01-31T18:39:25.3980509Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:25.3981034Z Loading safetensors checkpoint shards:  31% Completed | 50/163 [00:53<01:39,  1.13it/s]
2026-01-31T18:39:26.5226548Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:26.5227025Z Loading safetensors checkpoint shards:  31% Completed | 51/163 [00:54<01:45,  1.06it/s]
2026-01-31T18:39:27.6501669Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:27.6502305Z Loading safetensors checkpoint shards:  32% Completed | 52/163 [00:55<01:50,  1.01it/s]
2026-01-31T18:39:28.6747441Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:28.6748045Z Loading safetensors checkpoint shards:  33% Completed | 53/163 [00:56<01:50,  1.00s/it]
2026-01-31T18:39:29.7794622Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:29.7795094Z Loading safetensors checkpoint shards:  33% Completed | 54/163 [00:57<01:52,  1.03s/it]
2026-01-31T18:39:30.8992383Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:30.8992845Z Loading safetensors checkpoint shards:  34% Completed | 55/163 [00:58<01:54,  1.06s/it]
2026-01-31T18:39:32.0525807Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:32.0526248Z Loading safetensors checkpoint shards:  34% Completed | 56/163 [01:00<01:56,  1.09s/it]
2026-01-31T18:39:33.0812486Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:33.0812957Z Loading safetensors checkpoint shards:  35% Completed | 57/163 [01:01<01:53,  1.07s/it]
2026-01-31T18:39:34.0763407Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:34.0763888Z Loading safetensors checkpoint shards:  36% Completed | 58/163 [01:02<01:49,  1.05s/it]
2026-01-31T18:39:35.1834826Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:35.1835326Z Loading safetensors checkpoint shards:  36% Completed | 59/163 [01:03<01:50,  1.06s/it]
2026-01-31T18:39:36.2678170Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:36.2678775Z Loading safetensors checkpoint shards:  37% Completed | 60/163 [01:04<01:50,  1.07s/it]
2026-01-31T18:39:37.3893520Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:37.3893956Z Loading safetensors checkpoint shards:  37% Completed | 61/163 [01:05<01:50,  1.09s/it]
2026-01-31T18:39:38.3887800Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:38.3888229Z Loading safetensors checkpoint shards:  38% Completed | 62/163 [01:06<01:47,  1.06s/it]
2026-01-31T18:39:39.5284769Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:39.5285561Z Loading safetensors checkpoint shards:  39% Completed | 63/163 [01:07<01:48,  1.08s/it]
2026-01-31T18:39:40.7098185Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:40.7098664Z Loading safetensors checkpoint shards:  39% Completed | 64/163 [01:08<01:50,  1.11s/it]
2026-01-31T18:39:41.7648001Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:41.7648487Z Loading safetensors checkpoint shards:  40% Completed | 65/163 [01:09<01:47,  1.10s/it]
2026-01-31T18:39:42.7661716Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:42.7662376Z Loading safetensors checkpoint shards:  40% Completed | 66/163 [01:10<01:43,  1.07s/it]
2026-01-31T18:39:43.9478012Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:43.9478515Z Loading safetensors checkpoint shards:  41% Completed | 67/163 [01:12<01:45,  1.10s/it]
2026-01-31T18:39:45.0865228Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:45.0865740Z Loading safetensors checkpoint shards:  42% Completed | 68/163 [01:13<01:45,  1.11s/it]
2026-01-31T18:39:46.1895709Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:46.1896209Z Loading safetensors checkpoint shards:  42% Completed | 69/163 [01:14<01:44,  1.11s/it]
2026-01-31T18:39:47.3189552Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:47.3190204Z Loading safetensors checkpoint shards:  43% Completed | 70/163 [01:15<01:43,  1.12s/it]
2026-01-31T18:39:48.3663374Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:48.3663962Z Loading safetensors checkpoint shards:  44% Completed | 71/163 [01:16<01:40,  1.10s/it]
2026-01-31T18:39:49.4091711Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:49.4092417Z Loading safetensors checkpoint shards:  44% Completed | 72/163 [01:17<01:38,  1.08s/it]
2026-01-31T18:39:50.5081765Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:50.5082468Z Loading safetensors checkpoint shards:  45% Completed | 73/163 [01:18<01:37,  1.09s/it]
2026-01-31T18:39:51.6193110Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:51.6193582Z Loading safetensors checkpoint shards:  45% Completed | 74/163 [01:19<01:37,  1.09s/it]
2026-01-31T18:39:52.6405878Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:52.6406348Z Loading safetensors checkpoint shards:  46% Completed | 75/163 [01:20<01:34,  1.07s/it]
2026-01-31T18:39:53.7279851Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:53.7280327Z Loading safetensors checkpoint shards:  47% Completed | 76/163 [01:21<01:33,  1.08s/it]
2026-01-31T18:39:54.9138006Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:54.9138487Z Loading safetensors checkpoint shards:  47% Completed | 77/163 [01:22<01:35,  1.11s/it]
2026-01-31T18:39:56.0239939Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:56.0240390Z Loading safetensors checkpoint shards:  48% Completed | 78/163 [01:24<01:34,  1.11s/it]
2026-01-31T18:39:57.1248797Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:57.1249375Z Loading safetensors checkpoint shards:  48% Completed | 79/163 [01:25<01:32,  1.11s/it]
2026-01-31T18:39:58.1338713Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:58.1339140Z Loading safetensors checkpoint shards:  49% Completed | 80/163 [01:26<01:29,  1.08s/it]
2026-01-31T18:39:59.1169481Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:39:59.1170034Z Loading safetensors checkpoint shards:  50% Completed | 81/163 [01:27<01:26,  1.05s/it]
2026-01-31T18:40:00.1679960Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:40:00.1680431Z Loading safetensors checkpoint shards:  50% Completed | 82/163 [01:28<01:25,  1.05s/it]
2026-01-31T18:40:01.1859945Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:40:01.1860552Z Loading safetensors checkpoint shards:  51% Completed | 83/163 [01:29<01:23,  1.04s/it]
2026-01-31T18:40:02.2341625Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:40:02.2342347Z Loading safetensors checkpoint shards:  52% Completed | 84/163 [01:30<01:22,  1.04s/it]
2026-01-31T18:40:03.4036484Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:40:03.4037107Z Loading safetensors checkpoint shards:  52% Completed | 85/163 [01:31<01:24,  1.08s/it]
2026-01-31T18:40:04.5715191Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:40:04.5715800Z Loading safetensors checkpoint shards:  53% Completed | 86/163 [01:32<01:25,  1.11s/it]
2026-01-31T18:40:05.8046034Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:40:05.8046626Z Loading safetensors checkpoint shards:  53% Completed | 87/163 [01:33<01:26,  1.14s/it]
2026-01-31T18:40:06.8389964Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:40:06.8390440Z Loading safetensors checkpoint shards:  54% Completed | 88/163 [01:34<01:23,  1.11s/it]
2026-01-31T18:40:06.9654988Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:40:06.9655417Z Loading safetensors checkpoint shards:  56% Completed | 91/163 [01:35<00:36,  1.96it/s]
2026-01-31T18:40:07.0735902Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:40:07.0736553Z Loading safetensors checkpoint shards:  58% Completed | 94/163 [01:35<00:20,  3.35it/s]
2026-01-31T18:40:07.1816033Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:40:07.1816441Z Loading safetensors checkpoint shards:  60% Completed | 97/163 [01:35<00:12,  5.09it/s]
2026-01-31T18:40:07.2890055Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:40:07.2890516Z Loading safetensors checkpoint shards:  61% Completed | 100/163 [01:35<00:08,  7.18it/s]
2026-01-31T18:40:07.5082841Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:40:07.5083351Z Loading safetensors checkpoint shards:  63% Completed | 103/163 [01:35<00:06,  8.57it/s]
2026-01-31T18:40:07.6120673Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:40:07.6121163Z Loading safetensors checkpoint shards:  65% Completed | 106/163 [01:35<00:05, 11.09it/s]
2026-01-31T18:40:09.8106793Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:40:09.8107321Z Loading safetensors checkpoint shards:  67% Completed | 109/163 [01:37<00:15,  3.40it/s]
2026-01-31T18:40:09.9147415Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:40:09.9148017Z Loading safetensors checkpoint shards:  69% Completed | 112/163 [01:37<00:10,  4.69it/s]
2026-01-31T18:40:10.0205442Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:40:10.0205855Z Loading safetensors checkpoint shards:  71% Completed | 115/163 [01:38<00:07,  6.31it/s]
2026-01-31T18:40:10.1236361Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:40:10.1236749Z Loading safetensors checkpoint shards:  72% Completed | 118/163 [01:38<00:05,  8.30it/s]
2026-01-31T18:40:10.2291251Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:40:10.2291790Z Loading safetensors checkpoint shards:  74% Completed | 121/163 [01:38<00:03, 10.58it/s]
2026-01-31T18:40:10.3360026Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:40:10.3360380Z Loading safetensors checkpoint shards:  76% Completed | 124/163 [01:38<00:02, 13.04it/s]
2026-01-31T18:40:10.4428975Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:40:10.4429461Z Loading safetensors checkpoint shards:  78% Completed | 127/163 [01:38<00:02, 15.56it/s]
2026-01-31T18:40:10.5489039Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:40:10.5489470Z Loading safetensors checkpoint shards:  80% Completed | 131/163 [01:38<00:01, 19.80it/s]
2026-01-31T18:40:13.8400325Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:40:13.8400801Z Loading safetensors checkpoint shards:  83% Completed | 135/163 [01:41<00:08,  3.17it/s]
2026-01-31T18:40:17.2193405Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:40:17.2193914Z Loading safetensors checkpoint shards:  85% Completed | 138/163 [01:45<00:13,  1.88it/s]
2026-01-31T18:40:19.3714319Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:40:19.3714790Z Loading safetensors checkpoint shards:  86% Completed | 140/163 [01:47<00:14,  1.55it/s]
2026-01-31T18:40:20.7414653Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:40:20.7415928Z Loading safetensors checkpoint shards:  87% Completed | 142/163 [01:48<00:13,  1.53it/s]
2026-01-31T18:40:21.4271487Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:40:21.4272074Z Loading safetensors checkpoint shards:  88% Completed | 143/163 [01:49<00:13,  1.52it/s]
2026-01-31T18:40:22.0265653Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:40:22.0266259Z Loading safetensors checkpoint shards:  88% Completed | 144/163 [01:50<00:12,  1.54it/s]
2026-01-31T18:40:22.6798085Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:40:22.6798671Z Loading safetensors checkpoint shards:  89% Completed | 145/163 [01:50<00:11,  1.54it/s]
2026-01-31T18:40:23.4606323Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:40:23.4606980Z Loading safetensors checkpoint shards:  90% Completed | 146/163 [01:51<00:11,  1.48it/s]
2026-01-31T18:40:24.1701348Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:40:24.1702125Z Loading safetensors checkpoint shards:  90% Completed | 147/163 [01:52<00:10,  1.46it/s]
2026-01-31T18:40:24.9465801Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:40:24.9466447Z Loading safetensors checkpoint shards:  91% Completed | 148/163 [01:53<00:10,  1.41it/s]
2026-01-31T18:40:25.7537732Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:40:25.7538918Z Loading safetensors checkpoint shards:  91% Completed | 149/163 [01:53<00:10,  1.36it/s]
2026-01-31T18:40:29.7649100Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:40:29.7649589Z Loading safetensors checkpoint shards:  92% Completed | 150/163 [01:57<00:21,  1.63s/it]
2026-01-31T18:40:30.2388184Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:40:30.2388606Z Loading safetensors checkpoint shards:  93% Completed | 151/163 [01:58<00:15,  1.31s/it]
2026-01-31T18:40:30.9793140Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:40:30.9793577Z Loading safetensors checkpoint shards:  93% Completed | 152/163 [01:59<00:12,  1.14s/it]
2026-01-31T18:40:31.8228512Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:40:31.8229045Z Loading safetensors checkpoint shards:  94% Completed | 153/163 [01:59<00:10,  1.06s/it]
2026-01-31T18:40:32.6685348Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:40:32.6685865Z Loading safetensors checkpoint shards:  94% Completed | 154/163 [02:00<00:08,  1.01it/s]
2026-01-31T18:40:33.4653001Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:40:33.4653480Z Loading safetensors checkpoint shards:  95% Completed | 155/163 [02:01<00:07,  1.07it/s]
2026-01-31T18:40:34.3013202Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:40:34.3013637Z Loading safetensors checkpoint shards:  96% Completed | 156/163 [02:02<00:06,  1.10it/s]
2026-01-31T18:40:35.1052977Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:40:35.1053620Z Loading safetensors checkpoint shards:  96% Completed | 157/163 [02:03<00:05,  1.14it/s]
2026-01-31T18:40:35.7852668Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:40:35.7853294Z Loading safetensors checkpoint shards:  97% Completed | 158/163 [02:03<00:04,  1.22it/s]
2026-01-31T18:40:36.4708007Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:40:36.4708563Z Loading safetensors checkpoint shards:  98% Completed | 159/163 [02:04<00:03,  1.29it/s]
2026-01-31T18:40:37.2524142Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:40:37.2524564Z Loading safetensors checkpoint shards:  98% Completed | 160/163 [02:05<00:02,  1.28it/s]
2026-01-31T18:40:37.9555619Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:40:37.9556117Z Loading safetensors checkpoint shards:  99% Completed | 161/163 [02:06<00:01,  1.32it/s]
2026-01-31T18:40:38.6677935Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:40:38.6678411Z Loading safetensors checkpoint shards:  99% Completed | 162/163 [02:06<00:00,  1.35it/s]
2026-01-31T18:40:39.4605093Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:40:39.4605598Z Loading safetensors checkpoint shards: 100% Completed | 163/163 [02:07<00:00,  1.32it/s]
2026-01-31T18:40:39.4624157Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:40:39.4624632Z Loading safetensors checkpoint shards: 100% Completed | 163/163 [02:07<00:00,  1.28it/s]
2026-01-31T18:40:39.4636236Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:40:39.5436741Z [0;36m(Worker_DP1_TP4_EP12 pid=583)[0;0m INFO 01-31 18:40:39 [eagle_proposer.py:262] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-01-31T18:40:39.7303815Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m INFO 01-31 18:40:39 [default_loader.py:308] Loading weights took 127.81 seconds
2026-01-31T18:40:39.7658926Z [0;36m(Worker_DP0_TP7_EP7 pid=891)[0;0m INFO 01-31 18:40:39 [eagle_proposer.py:262] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-01-31T18:40:39.7686453Z [0;36m(Worker_DP1_TP6_EP14 pid=786)[0;0m INFO 01-31 18:40:39 [eagle_proposer.py:262] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-01-31T18:40:39.7708703Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m INFO 01-31 18:40:39 [eagle_proposer.py:262] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-01-31T18:40:39.7720389Z [0;36m(Worker_DP0_TP3_EP3 pid=481)[0;0m INFO 01-31 18:40:39 [eagle_proposer.py:262] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-01-31T18:40:39.7730764Z [0;36m(Worker_DP1_TP1_EP9 pid=277)[0;0m INFO 01-31 18:40:39 [eagle_proposer.py:262] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-01-31T18:40:39.7753979Z [0;36m(Worker_DP1_TP2_EP10 pid=381)[0;0m INFO 01-31 18:40:39 [eagle_proposer.py:262] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-01-31T18:40:39.7955232Z [0;36m(Worker_DP1_TP5_EP13 pid=686)[0;0m INFO 01-31 18:40:39 [eagle_proposer.py:262] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-01-31T18:40:40.5565172Z [0;36m(Worker_DP1_TP0_EP8 pid=212)[0;0m INFO 01-31 18:40:40 [default_loader.py:308] Loading weights took 127.92 seconds
2026-01-31T18:40:40.5922721Z [0;36m(Worker_DP0_TP7_EP7 pid=891)[0;0m INFO 01-31 18:40:40 [model_runner_v1.py:2396] Loading model weights took 30.7611 GB
2026-01-31T18:40:40.5970737Z [0;36m(Worker_DP0_TP6_EP6 pid=789)[0;0m INFO 01-31 18:40:40 [eagle_proposer.py:262] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-01-31T18:40:40.5980903Z [0;36m(Worker_DP1_TP0_EP8 pid=212)[0;0m INFO 01-31 18:40:40 [eagle_proposer.py:262] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-01-31T18:40:40.6018747Z [0;36m(Worker_DP0_TP2_EP2 pid=379)[0;0m INFO 01-31 18:40:40 [eagle_proposer.py:262] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-01-31T18:40:40.6044248Z [0;36m(Worker_DP1_TP3_EP11 pid=480)[0;0m INFO 01-31 18:40:40 [eagle_proposer.py:262] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-01-31T18:40:40.6124117Z [0;36m(Worker_DP1_TP7_EP15 pid=888)[0;0m INFO 01-31 18:40:40 [eagle_proposer.py:262] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-01-31T18:40:40.6133731Z [0;36m(Worker_DP0_TP4_EP4 pid=582)[0;0m INFO 01-31 18:40:40 [eagle_proposer.py:262] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-01-31T18:40:40.6143576Z [0;36m(Worker_DP0_TP5_EP5 pid=687)[0;0m INFO 01-31 18:40:40 [eagle_proposer.py:262] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-01-31T18:40:40.6154136Z [0;36m(Worker_DP0_TP1_EP1 pid=268)[0;0m INFO 01-31 18:40:40 [eagle_proposer.py:262] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-01-31T18:40:41.2120767Z [0;36m(Worker_DP1_TP1_EP9 pid=277)[0;0m INFO 01-31 18:40:41 [model_runner_v1.py:2396] Loading model weights took 30.7611 GB
2026-01-31T18:40:41.4321342Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m INFO 01-31 18:40:41 [model_runner_v1.py:2396] Loading model weights took 30.7611 GB
2026-01-31T18:40:41.6441656Z [0;36m(Worker_DP0_TP1_EP1 pid=268)[0;0m INFO 01-31 18:40:41 [model_runner_v1.py:2396] Loading model weights took 30.7611 GB
2026-01-31T18:40:41.7058766Z [0;36m(Worker_DP1_TP4_EP12 pid=583)[0;0m INFO 01-31 18:40:41 [model_runner_v1.py:2396] Loading model weights took 30.7611 GB
2026-01-31T18:40:41.8767282Z [0;36m(Worker_DP0_TP3_EP3 pid=481)[0;0m INFO 01-31 18:40:41 [model_runner_v1.py:2396] Loading model weights took 30.7611 GB
2026-01-31T18:40:41.8807814Z [0;36m(Worker_DP1_TP7_EP15 pid=888)[0;0m INFO 01-31 18:40:41 [model_runner_v1.py:2396] Loading model weights took 30.7611 GB
2026-01-31T18:40:41.9610986Z [0;36m(Worker_DP1_TP2_EP10 pid=381)[0;0m INFO 01-31 18:40:41 [model_runner_v1.py:2396] Loading model weights took 30.7611 GB
2026-01-31T18:40:42.2326614Z [0;36m(Worker_DP0_TP2_EP2 pid=379)[0;0m INFO 01-31 18:40:42 [model_runner_v1.py:2396] Loading model weights took 30.7611 GB
2026-01-31T18:40:42.3441821Z [0;36m(Worker_DP0_TP5_EP5 pid=687)[0;0m INFO 01-31 18:40:42 [model_runner_v1.py:2396] Loading model weights took 30.7611 GB
2026-01-31T18:40:42.5818276Z [0;36m(Worker_DP0_TP4_EP4 pid=582)[0;0m INFO 01-31 18:40:42 [model_runner_v1.py:2396] Loading model weights took 30.7611 GB
2026-01-31T18:40:42.7372183Z [0;36m(Worker_DP1_TP3_EP11 pid=480)[0;0m INFO 01-31 18:40:42 [model_runner_v1.py:2396] Loading model weights took 30.7611 GB
2026-01-31T18:40:42.9556268Z [0;36m(Worker_DP1_TP0_EP8 pid=212)[0;0m INFO 01-31 18:40:42 [model_runner_v1.py:2396] Loading model weights took 30.7611 GB
2026-01-31T18:40:42.9788382Z [0;36m(Worker_DP0_TP6_EP6 pid=789)[0;0m INFO 01-31 18:40:42 [model_runner_v1.py:2396] Loading model weights took 30.7611 GB
2026-01-31T18:40:43.1708528Z [0;36m(Worker_DP1_TP5_EP13 pid=686)[0;0m INFO 01-31 18:40:43 [model_runner_v1.py:2396] Loading model weights took 30.7611 GB
2026-01-31T18:40:43.2223252Z [0;36m(Worker_DP1_TP6_EP14 pid=786)[0;0m INFO 01-31 18:40:43 [model_runner_v1.py:2396] Loading model weights took 30.7611 GB
2026-01-31T18:40:48.5388351Z [0;36m(Worker_DP1_TP0_EP8 pid=212)[0;0m INFO 01-31 18:40:48 [backends.py:643] Using cache directory: /root/.cache/vllm/torch_compile_cache/fc019cffa4/rank_0_1/backbone for vLLM's torch.compile
2026-01-31T18:40:48.5410638Z [0;36m(Worker_DP1_TP0_EP8 pid=212)[0;0m INFO 01-31 18:40:48 [backends.py:703] Dynamo bytecode transform time: 4.71 s
2026-01-31T18:40:48.6530568Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m INFO 01-31 18:40:48 [backends.py:643] Using cache directory: /root/.cache/vllm/torch_compile_cache/fc019cffa4/rank_0_0/backbone for vLLM's torch.compile
2026-01-31T18:40:48.6553979Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m INFO 01-31 18:40:48 [backends.py:703] Dynamo bytecode transform time: 4.82 s
2026-01-31T18:41:01.6492669Z [0;36m(Worker_DP1_TP0_EP8 pid=212)[0;0m INFO 01-31 18:41:01 [backends.py:278] Compiling a graph for compile range (1, 4096) takes 10.79 s
2026-01-31T18:41:01.6501012Z [0;36m(Worker_DP1_TP0_EP8 pid=212)[0;0m INFO 01-31 18:41:01 [monitor.py:34] torch.compile takes 15.50 s in total
2026-01-31T18:41:02.5629749Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m INFO 01-31 18:41:02 [backends.py:278] Compiling a graph for compile range (1, 4096) takes 11.27 s
2026-01-31T18:41:02.5638786Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m INFO 01-31 18:41:02 [monitor.py:34] torch.compile takes 16.10 s in total
2026-01-31T18:41:02.8220722Z [0;36m(Worker_DP1_TP0_EP8 pid=212)[0;0m INFO 01-31 18:41:02 [backends.py:703] Dynamo bytecode transform time: 0.25 s
2026-01-31T18:41:02.8290846Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m INFO 01-31 18:41:02 [backends.py:703] Dynamo bytecode transform time: 0.26 s
2026-01-31T18:41:03.5670222Z [0;36m(Worker_DP1_TP0_EP8 pid=212)[0;0m INFO 01-31 18:41:03 [backends.py:278] Compiling a graph for compile range (1, 4096) takes 0.51 s
2026-01-31T18:41:03.5678142Z [0;36m(Worker_DP1_TP0_EP8 pid=212)[0;0m INFO 01-31 18:41:03 [monitor.py:34] torch.compile takes 16.27 s in total
2026-01-31T18:41:03.5885318Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m INFO 01-31 18:41:03 [backends.py:278] Compiling a graph for compile range (1, 4096) takes 0.53 s
2026-01-31T18:41:03.5893726Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m INFO 01-31 18:41:03 [monitor.py:34] torch.compile takes 16.89 s in total
2026-01-31T18:41:06.0787879Z [0;36m(Worker_DP0_TP1_EP1 pid=268)[0;0m INFO 01-31 18:41:06 [worker.py:302] Available memory: 18671675596, total memory: 65796046848
2026-01-31T18:41:06.1248381Z [0;36m(Worker_DP1_TP6_EP14 pid=786)[0;0m INFO 01-31 18:41:06 [worker.py:302] Available memory: 18406264832, total memory: 65787658240
2026-01-31T18:41:06.1594953Z [0;36m(Worker_DP1_TP0_EP8 pid=212)[0;0m INFO 01-31 18:41:06 [worker.py:302] Available memory: 17997317632, total memory: 65787658240
2026-01-31T18:41:06.1678519Z [0;36m(Worker_DP0_TP5_EP5 pid=687)[0;0m INFO 01-31 18:41:06 [worker.py:302] Available memory: 18672228556, total memory: 65796046848
2026-01-31T18:41:06.1702894Z [0;36m(Worker_DP1_TP2_EP10 pid=381)[0;0m INFO 01-31 18:41:06 [worker.py:302] Available memory: 18409811456, total memory: 65787658240
2026-01-31T18:41:06.1945508Z [0;36m(Worker_DP0_TP2_EP2 pid=379)[0;0m INFO 01-31 18:41:06 [worker.py:302] Available memory: 18398042112, total memory: 65787658240
2026-01-31T18:41:06.2300979Z [0;36m(Worker_DP1_TP3_EP11 pid=480)[0;0m INFO 01-31 18:41:06 [worker.py:302] Available memory: 18669482188, total memory: 65796046848
2026-01-31T18:41:06.2346507Z [0;36m(Worker_DP0_TP7_EP7 pid=891)[0;0m INFO 01-31 18:41:06 [worker.py:302] Available memory: 18685256908, total memory: 65796046848
2026-01-31T18:41:06.3128186Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m INFO 01-31 18:41:06 [worker.py:302] Available memory: 18005075968, total memory: 65787658240
2026-01-31T18:41:06.3535785Z [0;36m(Worker_DP0_TP3_EP3 pid=481)[0;0m INFO 01-31 18:41:06 [worker.py:302] Available memory: 18681528524, total memory: 65796046848
2026-01-31T18:41:06.3827157Z [0;36m(Worker_DP0_TP6_EP6 pid=789)[0;0m INFO 01-31 18:41:06 [worker.py:302] Available memory: 18387102720, total memory: 65787658240
2026-01-31T18:41:06.5293573Z [0;36m(ApiServer_1 pid=196)[0;0m Process ApiServer_1:
2026-01-31T18:41:06.5385304Z [0;36m(ApiServer_1 pid=196)[0;0m Traceback (most recent call last):
2026-01-31T18:41:06.5410855Z [0;36m(ApiServer_1 pid=196)[0;0m   File "/usr/local/python3.11.14/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
2026-01-31T18:41:06.5419075Z [0;36m(ApiServer_1 pid=196)[0;0m     self.run()
2026-01-31T18:41:06.5428769Z [0;36m(ApiServer_1 pid=196)[0;0m   File "/usr/local/python3.11.14/lib/python3.11/multiprocessing/process.py", line 108, in run
2026-01-31T18:41:06.5438606Z [0;36m(ApiServer_1 pid=196)[0;0m     self._target(*self._args, **self._kwargs)
2026-01-31T18:41:06.5448248Z [0;36m(ApiServer_1 pid=196)[0;0m   File "/vllm-workspace/vllm/vllm/entrypoints/cli/serve.py", line 247, in run_api_server_worker_proc
2026-01-31T18:41:06.5457770Z [0;36m(ApiServer_1 pid=196)[0;0m     uvloop.run(
2026-01-31T18:41:06.5468018Z [0;36m(ApiServer_1 pid=196)[0;0m   File "/usr/local/python3.11.14/lib/python3.11/site-packages/uvloop/__init__.py", line 92, in run
2026-01-31T18:41:06.5477026Z [0;36m(ApiServer_1 pid=196)[0;0m     return runner.run(wrapper())
2026-01-31T18:41:06.5486871Z [0;36m(ApiServer_1 pid=196)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
2026-01-31T18:41:06.5497595Z [0;36m(ApiServer_1 pid=196)[0;0m   File "/usr/local/python3.11.14/lib/python3.11/asyncio/runners.py", line 118, in run
2026-01-31T18:41:06.5506745Z [0;36m(ApiServer_1 pid=196)[0;0m     return self._loop.run_until_complete(task)
2026-01-31T18:41:06.5516847Z [0;36m(ApiServer_1 pid=196)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-01-31T18:41:06.5526878Z [0;36m(ApiServer_1 pid=196)[0;0m   File "uvloop/loop.pyx", line 1518, in uvloop.loop.Loop.run_until_complete
2026-01-31T18:41:06.5536663Z [0;36m(ApiServer_1 pid=196)[0;0m   File "/usr/local/python3.11.14/lib/python3.11/site-packages/uvloop/__init__.py", line 48, in wrapper
2026-01-31T18:41:06.5545907Z [0;36m(ApiServer_1 pid=196)[0;0m     return await main
2026-01-31T18:41:06.5555431Z [0;36m(ApiServer_1 pid=196)[0;0m            ^^^^^^^^^^
2026-01-31T18:41:06.5567254Z [0;36m(ApiServer_1 pid=196)[0;0m   File "/vllm-workspace/vllm/vllm/entrypoints/openai/api_server.py", line 1417, in run_server_worker
2026-01-31T18:41:06.5574976Z [0;36m(ApiServer_1 pid=196)[0;0m     async with build_async_engine_client(
2026-01-31T18:41:06.5585408Z [0;36m(ApiServer_1 pid=196)[0;0m   File "/usr/local/python3.11.14/lib/python3.11/contextlib.py", line 210, in __aenter__
2026-01-31T18:41:06.5594347Z [0;36m(ApiServer_1 pid=196)[0;0m     return await anext(self.gen)
2026-01-31T18:41:06.5604009Z [0;36m(ApiServer_1 pid=196)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
2026-01-31T18:41:06.5613945Z [0;36m(ApiServer_1 pid=196)[0;0m   File "/vllm-workspace/vllm/vllm/entrypoints/openai/api_server.py", line 172, in build_async_engine_client
2026-01-31T18:41:06.5623728Z [0;36m(ApiServer_1 pid=196)[0;0m     async with build_async_engine_client_from_engine_args(
2026-01-31T18:41:06.5633673Z [0;36m(ApiServer_1 pid=196)[0;0m   File "/usr/local/python3.11.14/lib/python3.11/contextlib.py", line 210, in __aenter__
2026-01-31T18:41:06.5643681Z [0;36m(ApiServer_1 pid=196)[0;0m     return await anext(self.gen)
2026-01-31T18:41:06.5652897Z [0;36m(ApiServer_1 pid=196)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
2026-01-31T18:41:06.5663168Z [0;36m(ApiServer_1 pid=196)[0;0m   File "/vllm-workspace/vllm/vllm/entrypoints/openai/api_server.py", line 213, in build_async_engine_client_from_engine_args
2026-01-31T18:41:06.5671781Z [0;36m(ApiServer_1 pid=196)[0;0m     async_llm = AsyncLLM.from_vllm_config(
2026-01-31T18:41:06.5681802Z [0;36m(ApiServer_1 pid=196)[0;0m                 ^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-01-31T18:41:06.5691578Z [0;36m(ApiServer_1 pid=196)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/async_llm.py", line 215, in from_vllm_config
2026-01-31T18:41:06.5701017Z [0;36m(ApiServer_1 pid=196)[0;0m     return cls(
2026-01-31T18:41:06.5710464Z [0;36m(ApiServer_1 pid=196)[0;0m            ^^^^
2026-01-31T18:41:06.5720663Z [0;36m(ApiServer_1 pid=196)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/async_llm.py", line 134, in __init__
2026-01-31T18:41:06.5730428Z [0;36m(ApiServer_1 pid=196)[0;0m     self.engine_core = EngineCoreClient.make_async_mp_client(
2026-01-31T18:41:06.5740175Z [0;36m(ApiServer_1 pid=196)[0;0m                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-01-31T18:41:06.5750314Z [0;36m(ApiServer_1 pid=196)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core_client.py", line 120, in make_async_mp_client
2026-01-31T18:41:06.5761131Z [0;36m(ApiServer_1 pid=196)[0;0m     return DPLBAsyncMPClient(*client_args)
2026-01-31T18:41:06.5770961Z [0;36m(ApiServer_1 pid=196)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-01-31T18:41:06.5781139Z [0;36m(ApiServer_1 pid=196)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core_client.py", line 1192, in __init__
2026-01-31T18:41:06.5790229Z [0;36m(ApiServer_1 pid=196)[0;0m     super().__init__(
2026-01-31T18:41:06.5800517Z [0;36m(ApiServer_1 pid=196)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core_client.py", line 1033, in __init__
2026-01-31T18:41:06.5810400Z [0;36m(ApiServer_1 pid=196)[0;0m     super().__init__(
2026-01-31T18:41:06.5820061Z [0;36m(ApiServer_1 pid=196)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core_client.py", line 820, in __init__
2026-01-31T18:41:06.5829897Z [0;36m(ApiServer_1 pid=196)[0;0m     super().__init__(
2026-01-31T18:41:06.5839940Z [0;36m(ApiServer_1 pid=196)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core_client.py", line 531, in __init__
2026-01-31T18:41:06.5849588Z [0;36m(ApiServer_1 pid=196)[0;0m     raise TimeoutError(
2026-01-31T18:41:06.5859514Z [0;36m(ApiServer_1 pid=196)[0;0m TimeoutError: Timed out waiting for engines to sendinitial message on input socket.
2026-01-31T18:41:06.6234425Z [0;36m(Worker_DP1_TP7_EP15 pid=888)[0;0m INFO 01-31 18:41:06 [worker.py:302] Available memory: 18683286732, total memory: 65796046848
2026-01-31T18:41:06.6542244Z [0;36m(Worker_DP1_TP1_EP9 pid=277)[0;0m INFO 01-31 18:41:06 [worker.py:302] Available memory: 18666671308, total memory: 65796046848
2026-01-31T18:41:06.7038182Z [0;36m(ApiServer_3 pid=198)[0;0m Process ApiServer_3:
2026-01-31T18:41:06.7056791Z [0;36m(ApiServer_3 pid=198)[0;0m Traceback (most recent call last):
2026-01-31T18:41:06.7066025Z [0;36m(ApiServer_3 pid=198)[0;0m   File "/usr/local/python3.11.14/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
2026-01-31T18:41:06.7075594Z [0;36m(ApiServer_3 pid=198)[0;0m     self.run()
2026-01-31T18:41:06.7084990Z [0;36m(ApiServer_3 pid=198)[0;0m   File "/usr/local/python3.11.14/lib/python3.11/multiprocessing/process.py", line 108, in run
2026-01-31T18:41:06.7093753Z [0;36m(ApiServer_3 pid=198)[0;0m     self._target(*self._args, **self._kwargs)
2026-01-31T18:41:06.7102885Z [0;36m(ApiServer_3 pid=198)[0;0m   File "/vllm-workspace/vllm/vllm/entrypoints/cli/serve.py", line 247, in run_api_server_worker_proc
2026-01-31T18:41:06.7112109Z [0;36m(ApiServer_3 pid=198)[0;0m     uvloop.run(
2026-01-31T18:41:06.7121937Z [0;36m(ApiServer_3 pid=198)[0;0m   File "/usr/local/python3.11.14/lib/python3.11/site-packages/uvloop/__init__.py", line 92, in run
2026-01-31T18:41:06.7130936Z [0;36m(ApiServer_3 pid=198)[0;0m     return runner.run(wrapper())
2026-01-31T18:41:06.7139814Z [0;36m(ApiServer_3 pid=198)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
2026-01-31T18:41:06.7149554Z [0;36m(ApiServer_3 pid=198)[0;0m   File "/usr/local/python3.11.14/lib/python3.11/asyncio/runners.py", line 118, in run
2026-01-31T18:41:06.7158718Z [0;36m(ApiServer_3 pid=198)[0;0m     return self._loop.run_until_complete(task)
2026-01-31T18:41:06.7169040Z [0;36m(ApiServer_3 pid=198)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-01-31T18:41:06.7178423Z [0;36m(ApiServer_3 pid=198)[0;0m   File "uvloop/loop.pyx", line 1518, in uvloop.loop.Loop.run_until_complete
2026-01-31T18:41:06.7188139Z [0;36m(ApiServer_3 pid=198)[0;0m   File "/usr/local/python3.11.14/lib/python3.11/site-packages/uvloop/__init__.py", line 48, in wrapper
2026-01-31T18:41:06.7197110Z [0;36m(ApiServer_3 pid=198)[0;0m     return await main
2026-01-31T18:41:06.7206226Z [0;36m(ApiServer_3 pid=198)[0;0m            ^^^^^^^^^^
2026-01-31T18:41:06.7215662Z [0;36m(ApiServer_3 pid=198)[0;0m   File "/vllm-workspace/vllm/vllm/entrypoints/openai/api_server.py", line 1417, in run_server_worker
2026-01-31T18:41:06.7224796Z [0;36m(ApiServer_3 pid=198)[0;0m     async with build_async_engine_client(
2026-01-31T18:41:06.7233885Z [0;36m(ApiServer_3 pid=198)[0;0m   File "/usr/local/python3.11.14/lib/python3.11/contextlib.py", line 210, in __aenter__
2026-01-31T18:41:06.7244064Z [0;36m(ApiServer_3 pid=198)[0;0m     return await anext(self.gen)
2026-01-31T18:41:06.7254214Z [0;36m(ApiServer_3 pid=198)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
2026-01-31T18:41:06.7263860Z [0;36m(ApiServer_3 pid=198)[0;0m   File "/vllm-workspace/vllm/vllm/entrypoints/openai/api_server.py", line 172, in build_async_engine_client
2026-01-31T18:41:06.7272453Z [0;36m(ApiServer_3 pid=198)[0;0m     async with build_async_engine_client_from_engine_args(
2026-01-31T18:41:06.7282810Z [0;36m(ApiServer_3 pid=198)[0;0m   File "/usr/local/python3.11.14/lib/python3.11/contextlib.py", line 210, in __aenter__
2026-01-31T18:41:06.7291572Z [0;36m(ApiServer_3 pid=198)[0;0m     return await anext(self.gen)
2026-01-31T18:41:06.7301025Z [0;36m(ApiServer_3 pid=198)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
2026-01-31T18:41:06.7310468Z [0;36m(ApiServer_3 pid=198)[0;0m   File "/vllm-workspace/vllm/vllm/entrypoints/openai/api_server.py", line 213, in build_async_engine_client_from_engine_args
2026-01-31T18:41:06.7320223Z [0;36m(ApiServer_3 pid=198)[0;0m     async_llm = AsyncLLM.from_vllm_config(
2026-01-31T18:41:06.7330141Z [0;36m(ApiServer_3 pid=198)[0;0m                 ^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-01-31T18:41:06.7340004Z [0;36m(ApiServer_3 pid=198)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/async_llm.py", line 215, in from_vllm_config
2026-01-31T18:41:06.7349935Z [0;36m(ApiServer_3 pid=198)[0;0m     return cls(
2026-01-31T18:41:06.7358780Z [0;36m(ApiServer_3 pid=198)[0;0m            ^^^^
2026-01-31T18:41:06.7368729Z [0;36m(ApiServer_3 pid=198)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/async_llm.py", line 134, in __init__
2026-01-31T18:41:06.7377996Z [0;36m(ApiServer_3 pid=198)[0;0m     self.engine_core = EngineCoreClient.make_async_mp_client(
2026-01-31T18:41:06.7387740Z [0;36m(ApiServer_3 pid=198)[0;0m                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-01-31T18:41:06.7396674Z [0;36m(ApiServer_3 pid=198)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core_client.py", line 120, in make_async_mp_client
2026-01-31T18:41:06.7405797Z [0;36m(ApiServer_3 pid=198)[0;0m     return DPLBAsyncMPClient(*client_args)
2026-01-31T18:41:06.7415427Z [0;36m(ApiServer_3 pid=198)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-01-31T18:41:06.7425107Z [0;36m(ApiServer_3 pid=198)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core_client.py", line 1192, in __init__
2026-01-31T18:41:06.7434286Z [0;36m(ApiServer_3 pid=198)[0;0m     super().__init__(
2026-01-31T18:41:06.7444485Z [0;36m(ApiServer_3 pid=198)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core_client.py", line 1033, in __init__
2026-01-31T18:41:06.7453897Z [0;36m(ApiServer_3 pid=198)[0;0m     super().__init__(
2026-01-31T18:41:06.7464028Z [0;36m(ApiServer_3 pid=198)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core_client.py", line 820, in __init__
2026-01-31T18:41:06.7473386Z [0;36m(ApiServer_3 pid=198)[0;0m     super().__init__(
2026-01-31T18:41:06.7482468Z [0;36m(ApiServer_3 pid=198)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core_client.py", line 531, in __init__
2026-01-31T18:41:06.7514711Z [0;36m(ApiServer_3 pid=198)[0;0m     raise TimeoutError(
2026-01-31T18:41:06.7517342Z [0;36m(ApiServer_3 pid=198)[0;0m TimeoutError: Timed out waiting for engines to sendinitial message on input socket.
2026-01-31T18:41:06.7518138Z [0;36m(Worker_DP1_TP5_EP13 pid=686)[0;0m INFO 01-31 18:41:06 [worker.py:302] Available memory: 18671203532, total memory: 65796046848
2026-01-31T18:41:06.7677843Z [0;36m(Worker_DP1_TP4_EP12 pid=583)[0;0m INFO 01-31 18:41:06 [worker.py:302] Available memory: 18412985344, total memory: 65787658240
2026-01-31T18:41:06.7784222Z [0;36m(EngineCore_DP1 pid=184)[0;0m INFO 01-31 18:41:06 [kv_cache_utils.py:1291] GPU KV cache size: 125,952 tokens
2026-01-31T18:41:06.7802809Z [0;36m(EngineCore_DP1 pid=184)[0;0m INFO 01-31 18:41:06 [kv_cache_utils.py:1296] Maximum concurrency for 8,192 tokens per request: 15.38x
2026-01-31T18:41:06.8578021Z [0;36m(Worker_DP0_TP4_EP4 pid=582)[0;0m INFO 01-31 18:41:06 [worker.py:302] Available memory: 18404852736, total memory: 65787658240
2026-01-31T18:41:06.8654093Z [0;36m(EngineCore_DP0 pid=165)[0;0m INFO 01-31 18:41:06 [kv_cache_utils.py:1291] GPU KV cache size: 125,952 tokens
2026-01-31T18:41:06.8673044Z [0;36m(EngineCore_DP0 pid=165)[0;0m INFO 01-31 18:41:06 [kv_cache_utils.py:1296] Maximum concurrency for 8,192 tokens per request: 15.38x
2026-01-31T18:41:06.8717944Z [0;36m(ApiServer_0 pid=195)[0;0m Process ApiServer_0:
2026-01-31T18:41:06.8738208Z [0;36m(ApiServer_0 pid=195)[0;0m Traceback (most recent call last):
2026-01-31T18:41:06.8758421Z [0;36m(ApiServer_0 pid=195)[0;0m   File "/usr/local/python3.11.14/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
2026-01-31T18:41:06.8767407Z [0;36m(ApiServer_0 pid=195)[0;0m     self.run()
2026-01-31T18:41:06.8776713Z [0;36m(ApiServer_0 pid=195)[0;0m   File "/usr/local/python3.11.14/lib/python3.11/multiprocessing/process.py", line 108, in run
2026-01-31T18:41:06.8785596Z [0;36m(ApiServer_0 pid=195)[0;0m     self._target(*self._args, **self._kwargs)
2026-01-31T18:41:06.8795877Z [0;36m(ApiServer_0 pid=195)[0;0m   File "/vllm-workspace/vllm/vllm/entrypoints/cli/serve.py", line 247, in run_api_server_worker_proc
2026-01-31T18:41:06.8804850Z [0;36m(ApiServer_0 pid=195)[0;0m     uvloop.run(
2026-01-31T18:41:06.8815460Z [0;36m(ApiServer_0 pid=195)[0;0m   File "/usr/local/python3.11.14/lib/python3.11/site-packages/uvloop/__init__.py", line 92, in run
2026-01-31T18:41:06.8823809Z [0;36m(ApiServer_0 pid=195)[0;0m     return runner.run(wrapper())
2026-01-31T18:41:06.8836205Z [0;36m(ApiServer_0 pid=195)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
2026-01-31T18:41:06.8843497Z [0;36m(ApiServer_0 pid=195)[0;0m   File "/usr/local/python3.11.14/lib/python3.11/asyncio/runners.py", line 118, in run
2026-01-31T18:41:06.8852786Z [0;36m(ApiServer_0 pid=195)[0;0m     return self._loop.run_until_complete(task)
2026-01-31T18:41:06.8862379Z [0;36m(ApiServer_0 pid=195)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-01-31T18:41:06.8871654Z [0;36m(ApiServer_0 pid=195)[0;0m   File "uvloop/loop.pyx", line 1518, in uvloop.loop.Loop.run_until_complete
2026-01-31T18:41:06.8882432Z [0;36m(ApiServer_0 pid=195)[0;0m   File "/usr/local/python3.11.14/lib/python3.11/site-packages/uvloop/__init__.py", line 48, in wrapper
2026-01-31T18:41:06.8891566Z [0;36m(ApiServer_0 pid=195)[0;0m     return await main
2026-01-31T18:41:06.8900589Z [0;36m(ApiServer_0 pid=195)[0;0m            ^^^^^^^^^^
2026-01-31T18:41:06.8910627Z [0;36m(ApiServer_0 pid=195)[0;0m   File "/vllm-workspace/vllm/vllm/entrypoints/openai/api_server.py", line 1417, in run_server_worker
2026-01-31T18:41:06.8919674Z [0;36m(ApiServer_0 pid=195)[0;0m     async with build_async_engine_client(
2026-01-31T18:41:06.8929665Z [0;36m(ApiServer_0 pid=195)[0;0m   File "/usr/local/python3.11.14/lib/python3.11/contextlib.py", line 210, in __aenter__
2026-01-31T18:41:06.8939064Z [0;36m(ApiServer_0 pid=195)[0;0m     return await anext(self.gen)
2026-01-31T18:41:06.8948046Z [0;36m(ApiServer_0 pid=195)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
2026-01-31T18:41:06.8958872Z [0;36m(ApiServer_0 pid=195)[0;0m   File "/vllm-workspace/vllm/vllm/entrypoints/openai/api_server.py", line 172, in build_async_engine_client
2026-01-31T18:41:06.8968352Z [0;36m(ApiServer_0 pid=195)[0;0m     async with build_async_engine_client_from_engine_args(
2026-01-31T18:41:06.8977614Z [0;36m(ApiServer_0 pid=195)[0;0m   File "/usr/local/python3.11.14/lib/python3.11/contextlib.py", line 210, in __aenter__
2026-01-31T18:41:06.8987449Z [0;36m(ApiServer_0 pid=195)[0;0m     return await anext(self.gen)
2026-01-31T18:41:06.8996649Z [0;36m(ApiServer_0 pid=195)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
2026-01-31T18:41:06.9007087Z [0;36m(ApiServer_0 pid=195)[0;0m   File "/vllm-workspace/vllm/vllm/entrypoints/openai/api_server.py", line 213, in build_async_engine_client_from_engine_args
2026-01-31T18:41:06.9015495Z [0;36m(ApiServer_0 pid=195)[0;0m     async_llm = AsyncLLM.from_vllm_config(
2026-01-31T18:41:06.9024470Z [0;36m(ApiServer_0 pid=195)[0;0m                 ^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-01-31T18:41:06.9033969Z [0;36m(ApiServer_0 pid=195)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/async_llm.py", line 215, in from_vllm_config
2026-01-31T18:41:06.9043604Z [0;36m(ApiServer_0 pid=195)[0;0m     return cls(
2026-01-31T18:41:06.9052907Z [0;36m(ApiServer_0 pid=195)[0;0m            ^^^^
2026-01-31T18:41:06.9063196Z [0;36m(ApiServer_0 pid=195)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/async_llm.py", line 134, in __init__
2026-01-31T18:41:06.9072448Z [0;36m(ApiServer_0 pid=195)[0;0m     self.engine_core = EngineCoreClient.make_async_mp_client(
2026-01-31T18:41:06.9082666Z [0;36m(ApiServer_0 pid=195)[0;0m                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-01-31T18:41:06.9092617Z [0;36m(ApiServer_0 pid=195)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core_client.py", line 120, in make_async_mp_client
2026-01-31T18:41:06.9100619Z [0;36m(ApiServer_0 pid=195)[0;0m     return DPLBAsyncMPClient(*client_args)
2026-01-31T18:41:06.9110228Z [0;36m(ApiServer_0 pid=195)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-01-31T18:41:06.9120452Z [0;36m(ApiServer_0 pid=195)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core_client.py", line 1192, in __init__
2026-01-31T18:41:06.9129331Z [0;36m(ApiServer_0 pid=195)[0;0m     super().__init__(
2026-01-31T18:41:06.9139182Z [0;36m(ApiServer_0 pid=195)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core_client.py", line 1033, in __init__
2026-01-31T18:41:06.9148635Z [0;36m(ApiServer_0 pid=195)[0;0m     super().__init__(
2026-01-31T18:41:06.9158332Z [0;36m(ApiServer_0 pid=195)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core_client.py", line 820, in __init__
2026-01-31T18:41:06.9167823Z [0;36m(ApiServer_0 pid=195)[0;0m     super().__init__(
2026-01-31T18:41:06.9177287Z [0;36m(ApiServer_0 pid=195)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core_client.py", line 531, in __init__
2026-01-31T18:41:06.9186059Z [0;36m(ApiServer_0 pid=195)[0;0m     raise TimeoutError(
2026-01-31T18:41:06.9195870Z [0;36m(ApiServer_0 pid=195)[0;0m TimeoutError: Timed out waiting for engines to sendinitial message on input socket.
2026-01-31T18:41:06.9357708Z [0;36m(ApiServer_2 pid=197)[0;0m Process ApiServer_2:
2026-01-31T18:41:06.9374910Z [0;36m(ApiServer_2 pid=197)[0;0m Traceback (most recent call last):
2026-01-31T18:41:06.9396460Z [0;36m(ApiServer_2 pid=197)[0;0m   File "/usr/local/python3.11.14/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
2026-01-31T18:41:06.9406402Z [0;36m(ApiServer_2 pid=197)[0;0m     self.run()
2026-01-31T18:41:06.9415241Z [0;36m(ApiServer_2 pid=197)[0;0m   File "/usr/local/python3.11.14/lib/python3.11/multiprocessing/process.py", line 108, in run
2026-01-31T18:41:06.9424557Z [0;36m(ApiServer_2 pid=197)[0;0m     self._target(*self._args, **self._kwargs)
2026-01-31T18:41:06.9434052Z [0;36m(ApiServer_2 pid=197)[0;0m   File "/vllm-workspace/vllm/vllm/entrypoints/cli/serve.py", line 247, in run_api_server_worker_proc
2026-01-31T18:41:06.9442671Z [0;36m(ApiServer_2 pid=197)[0;0m     uvloop.run(
2026-01-31T18:41:06.9452548Z [0;36m(ApiServer_2 pid=197)[0;0m   File "/usr/local/python3.11.14/lib/python3.11/site-packages/uvloop/__init__.py", line 92, in run
2026-01-31T18:41:06.9461668Z [0;36m(ApiServer_2 pid=197)[0;0m     return runner.run(wrapper())
2026-01-31T18:41:06.9470645Z [0;36m(ApiServer_2 pid=197)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
2026-01-31T18:41:06.9480989Z [0;36m(ApiServer_2 pid=197)[0;0m   File "/usr/local/python3.11.14/lib/python3.11/asyncio/runners.py", line 118, in run
2026-01-31T18:41:06.9490254Z [0;36m(ApiServer_2 pid=197)[0;0m     return self._loop.run_until_complete(task)
2026-01-31T18:41:06.9499651Z [0;36m(ApiServer_2 pid=197)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-01-31T18:41:06.9508937Z [0;36m(ApiServer_2 pid=197)[0;0m   File "uvloop/loop.pyx", line 1518, in uvloop.loop.Loop.run_until_complete
2026-01-31T18:41:06.9518506Z [0;36m(ApiServer_2 pid=197)[0;0m   File "/usr/local/python3.11.14/lib/python3.11/site-packages/uvloop/__init__.py", line 48, in wrapper
2026-01-31T18:41:06.9527470Z [0;36m(ApiServer_2 pid=197)[0;0m     return await main
2026-01-31T18:41:06.9536932Z [0;36m(ApiServer_2 pid=197)[0;0m            ^^^^^^^^^^
2026-01-31T18:41:06.9546089Z [0;36m(ApiServer_2 pid=197)[0;0m   File "/vllm-workspace/vllm/vllm/entrypoints/openai/api_server.py", line 1417, in run_server_worker
2026-01-31T18:41:06.9555522Z [0;36m(ApiServer_2 pid=197)[0;0m     async with build_async_engine_client(
2026-01-31T18:41:06.9566419Z [0;36m(ApiServer_2 pid=197)[0;0m   File "/usr/local/python3.11.14/lib/python3.11/contextlib.py", line 210, in __aenter__
2026-01-31T18:41:06.9575345Z [0;36m(ApiServer_2 pid=197)[0;0m     return await anext(self.gen)
2026-01-31T18:41:06.9586475Z [0;36m(ApiServer_2 pid=197)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
2026-01-31T18:41:06.9595798Z [0;36m(ApiServer_2 pid=197)[0;0m   File "/vllm-workspace/vllm/vllm/entrypoints/openai/api_server.py", line 172, in build_async_engine_client
2026-01-31T18:41:06.9605569Z [0;36m(ApiServer_2 pid=197)[0;0m     async with build_async_engine_client_from_engine_args(
2026-01-31T18:41:06.9615616Z [0;36m(ApiServer_2 pid=197)[0;0m   File "/usr/local/python3.11.14/lib/python3.11/contextlib.py", line 210, in __aenter__
2026-01-31T18:41:06.9625861Z [0;36m(ApiServer_2 pid=197)[0;0m     return await anext(self.gen)
2026-01-31T18:41:06.9634421Z [0;36m(ApiServer_2 pid=197)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
2026-01-31T18:41:06.9646385Z [0;36m(ApiServer_2 pid=197)[0;0m   File "/vllm-workspace/vllm/vllm/entrypoints/openai/api_server.py", line 213, in build_async_engine_client_from_engine_args
2026-01-31T18:41:06.9653588Z [0;36m(ApiServer_2 pid=197)[0;0m     async_llm = AsyncLLM.from_vllm_config(
2026-01-31T18:41:06.9662769Z [0;36m(ApiServer_2 pid=197)[0;0m                 ^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-01-31T18:41:06.9671684Z [0;36m(ApiServer_2 pid=197)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/async_llm.py", line 215, in from_vllm_config
2026-01-31T18:41:06.9680971Z [0;36m(ApiServer_2 pid=197)[0;0m     return cls(
2026-01-31T18:41:06.9690373Z [0;36m(ApiServer_2 pid=197)[0;0m            ^^^^
2026-01-31T18:41:06.9700099Z [0;36m(ApiServer_2 pid=197)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/async_llm.py", line 134, in __init__
2026-01-31T18:41:06.9709494Z [0;36m(ApiServer_2 pid=197)[0;0m     self.engine_core = EngineCoreClient.make_async_mp_client(
2026-01-31T18:41:06.9719268Z [0;36m(ApiServer_2 pid=197)[0;0m                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-01-31T18:41:06.9729559Z [0;36m(ApiServer_2 pid=197)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core_client.py", line 120, in make_async_mp_client
2026-01-31T18:41:06.9738980Z [0;36m(ApiServer_2 pid=197)[0;0m     return DPLBAsyncMPClient(*client_args)
2026-01-31T18:41:06.9747648Z [0;36m(ApiServer_2 pid=197)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-01-31T18:41:06.9757770Z [0;36m(ApiServer_2 pid=197)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core_client.py", line 1192, in __init__
2026-01-31T18:41:06.9767567Z [0;36m(ApiServer_2 pid=197)[0;0m     super().__init__(
2026-01-31T18:41:06.9777049Z [0;36m(ApiServer_2 pid=197)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core_client.py", line 1033, in __init__
2026-01-31T18:41:06.9786523Z [0;36m(ApiServer_2 pid=197)[0;0m     super().__init__(
2026-01-31T18:41:06.9796471Z [0;36m(ApiServer_2 pid=197)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core_client.py", line 820, in __init__
2026-01-31T18:41:06.9806209Z [0;36m(ApiServer_2 pid=197)[0;0m     super().__init__(
2026-01-31T18:41:06.9816272Z [0;36m(ApiServer_2 pid=197)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core_client.py", line 531, in __init__
2026-01-31T18:41:06.9826974Z [0;36m(ApiServer_2 pid=197)[0;0m     raise TimeoutError(
2026-01-31T18:41:06.9835615Z [0;36m(ApiServer_2 pid=197)[0;0m TimeoutError: Timed out waiting for engines to sendinitial message on input socket.
2026-01-31T18:41:06.9845123Z [0;36m(ApiServer_1 pid=196)[0;0m sys:1: DeprecationWarning: builtin type swigvarlink has no __module__ attribute
2026-01-31T18:41:07.0329075Z [0;36m(ApiServer_3 pid=198)[0;0m sys:1: DeprecationWarning: builtin type swigvarlink has no __module__ attribute
2026-01-31T18:41:07.2473046Z [0;36m(ApiServer_0 pid=195)[0;0m sys:1: DeprecationWarning: builtin type swigvarlink has no __module__ attribute
2026-01-31T18:41:07.7544833Z [0;36m(ApiServer_2 pid=197)[0;0m sys:1: DeprecationWarning: builtin type swigvarlink has no __module__ attribute
2026-01-31T18:41:10.1171303Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m 
2026-01-31T18:41:10.1172386Z Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s][rank6]:[W131 18:41:10.569054063 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-01-31T18:41:10.1178816Z [rank7]:[W131 18:41:10.569106003 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-01-31T18:41:10.1190355Z [rank3]:[W131 18:41:10.569165204 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-01-31T18:41:10.1199437Z [rank5]:[W131 18:41:10.569522836 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-01-31T18:41:10.1209448Z [rank0]:[W131 18:41:10.569558907 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-01-31T18:41:10.1219089Z [rank10]:[W131 18:41:10.569635117 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-01-31T18:41:10.1230012Z [rank11]:[W131 18:41:10.569702638 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-01-31T18:41:10.1240381Z [rank14]:[W131 18:41:10.569783749 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-01-31T18:41:10.1250739Z [rank2]:[W131 18:41:10.569843839 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-01-31T18:41:10.1260578Z [rank4]:[W131 18:41:10.569898459 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-01-31T18:41:10.1270413Z [rank13]:[W131 18:41:10.570174012 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-01-31T18:41:10.1281005Z [rank12]:[W131 18:41:10.570662825 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-01-31T18:41:10.1289943Z [rank15]:[W131 18:41:10.570801957 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-01-31T18:41:10.1299922Z [rank1]:[W131 18:41:10.571134899 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-01-31T18:41:10.1309762Z [rank9]:[W131 18:41:10.574207384 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-01-31T18:41:10.1319589Z [rank8]:[W131 18:41:10.575905797 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-01-31T18:41:12.0647433Z [0;36m(Worker_DP1_TP5_EP13 pid=686)[0;0m INFO 01-31 18:41:12 [acl_graph.py:194] Replaying aclgraph
2026-01-31T18:41:12.0655874Z [0;36m(Worker_DP1_TP0_EP8 pid=212)[0;0m INFO 01-31 18:41:12 [acl_graph.py:194] Replaying aclgraph
2026-01-31T18:41:12.0670361Z [0;36m(Worker_DP1_TP1_EP9 pid=277)[0;0m INFO 01-31 18:41:12 [acl_graph.py:194] Replaying aclgraph
2026-01-31T18:41:12.0682260Z [0;36m(Worker_DP1_TP2_EP10 pid=381)[0;0m INFO 01-31 18:41:12 [acl_graph.py:194] Replaying aclgraph
2026-01-31T18:41:12.0691261Z [0;36m(Worker_DP0_TP2_EP2 pid=379)[0;0m INFO 01-31 18:41:12 [acl_graph.py:194] Replaying aclgraph
2026-01-31T18:41:12.0700611Z [0;36m(Worker_DP0_TP1_EP1 pid=268)[0;0m INFO 01-31 18:41:12 [acl_graph.py:194] Replaying aclgraph
2026-01-31T18:41:12.0710907Z [0;36m(Worker_DP1_TP3_EP11 pid=480)[0;0m INFO 01-31 18:41:12 [acl_graph.py:194] Replaying aclgraph
2026-01-31T18:41:12.0720001Z [0;36m(Worker_DP1_TP6_EP14 pid=786)[0;0m INFO 01-31 18:41:12 [acl_graph.py:194] Replaying aclgraph
2026-01-31T18:41:12.0729870Z [0;36m(Worker_DP0_TP5_EP5 pid=687)[0;0m INFO 01-31 18:41:12 [acl_graph.py:194] Replaying aclgraph
2026-01-31T18:41:12.0738699Z [0;36m(Worker_DP1_TP7_EP15 pid=888)[0;0m INFO 01-31 18:41:12 [acl_graph.py:194] Replaying aclgraph
2026-01-31T18:41:12.0748124Z [0;36m(Worker_DP0_TP6_EP6 pid=789)[0;0m INFO 01-31 18:41:12 [acl_graph.py:194] Replaying aclgraph
2026-01-31T18:41:12.0758976Z [0;36m(Worker_DP0_TP7_EP7 pid=891)[0;0m INFO 01-31 18:41:12 [acl_graph.py:194] Replaying aclgraph
2026-01-31T18:41:12.0771220Z [0;36m(Worker_DP0_TP3_EP3 pid=481)[0;0m INFO 01-31 18:41:12 [acl_graph.py:194] Replaying aclgraph
2026-01-31T18:41:12.0779530Z [0;36m(Worker_DP1_TP4_EP12 pid=583)[0;0m INFO 01-31 18:41:12 [acl_graph.py:194] Replaying aclgraph
2026-01-31T18:41:12.0789719Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m INFO 01-31 18:41:12 [acl_graph.py:194] Replaying aclgraph
2026-01-31T18:41:12.0799423Z [0;36m(Worker_DP0_TP4_EP4 pid=582)[0;0m INFO 01-31 18:41:12 [acl_graph.py:194] Replaying aclgraph
2026-01-31T18:41:14.0836776Z 
2026-01-31T18:41:14.0837511Z Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:02<00:02,  2.64s/it]
2026-01-31T18:41:14.0838157Z Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.27s/it]
2026-01-31T18:41:14.0838919Z Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.32s/it]
2026-01-31T18:41:14.5547792Z [0;36m(Worker_DP1_TP0_EP8 pid=212)[0;0m INFO 01-31 18:41:14 [gpu_model_runner.py:4587] Graph capturing finished in 6 secs, took 0.14 GiB
2026-01-31T18:41:15.1513940Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m INFO 01-31 18:41:15 [gpu_model_runner.py:4587] Graph capturing finished in 6 secs, took 0.14 GiB
2026-01-31T18:41:15.5200040Z [0;36m(EngineCore_DP0 pid=165)[0;0m INFO 01-31 18:41:15 [core.py:259] init engine (profile, create kv cache, warmup model) took 32.54 seconds
2026-01-31T18:41:15.5372210Z [0;36m(EngineCore_DP1 pid=184)[0;0m INFO 01-31 18:41:15 [core.py:259] init engine (profile, create kv cache, warmup model) took 32.27 seconds
2026-01-31T18:41:16.4242600Z INFO 01-31 18:41:16 [coordinator.py:191] All engine subscriptions received by DP coordinator
2026-01-31T18:41:16.4267774Z [0;36m(EngineCore_DP0 pid=165)[0;0m INFO 01-31 18:41:16 [ascend_config.py:55] Linear layer sharding enabled with config: None. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-01-31T18:41:16.4278359Z [0;36m(EngineCore_DP1 pid=184)[0;0m INFO 01-31 18:41:16 [ascend_config.py:55] Linear layer sharding enabled with config: None. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-01-31T18:41:16.4287256Z [0;36m(EngineCore_DP1 pid=184)[0;0m INFO 01-31 18:41:16 [platform.py:254] PIECEWISE compilation enabled on NPU. use_inductor not supported - using only ACL Graph mode
2026-01-31T18:41:16.4297097Z [0;36m(EngineCore_DP0 pid=165)[0;0m INFO 01-31 18:41:16 [platform.py:254] PIECEWISE compilation enabled on NPU. use_inductor not supported - using only ACL Graph mode
2026-01-31T18:41:16.4306291Z [0;36m(EngineCore_DP0 pid=165)[0;0m INFO 01-31 18:41:16 [utils.py:498] Calculated maximum supported batch sizes for ACL graph: 2
2026-01-31T18:41:16.4316274Z [0;36m(EngineCore_DP1 pid=184)[0;0m INFO 01-31 18:41:16 [utils.py:498] Calculated maximum supported batch sizes for ACL graph: 2
2026-01-31T18:41:16.4326211Z [0;36m(EngineCore_DP0 pid=165)[0;0m INFO 01-31 18:41:16 [utils.py:554] No adjustment needed for ACL graph batch sizes: DeepseekV32ForCausalLM model (layers: 61) with 2 sizes
2026-01-31T18:41:16.4334978Z [0;36m(EngineCore_DP1 pid=184)[0;0m INFO 01-31 18:41:16 [utils.py:554] No adjustment needed for ACL graph batch sizes: DeepseekV32ForCausalLM model (layers: 61) with 2 sizes
2026-01-31T18:41:16.4343947Z INFO 01-31 18:41:16 [utils.py:247] Waiting for API servers to complete ...
2026-01-31T18:41:16.4354696Z ERROR 01-31 18:41:16 [utils.py:288] Exception occurred while running API servers: Process ApiServer_0 (PID: 195) died with exit code 1
2026-01-31T18:41:16.4364419Z ERROR 01-31 18:41:16 [utils.py:288] Traceback (most recent call last):
2026-01-31T18:41:16.4373828Z ERROR 01-31 18:41:16 [utils.py:288]   File "/vllm-workspace/vllm/vllm/v1/utils.py", line 275, in wait_for_completion_or_failure
2026-01-31T18:41:16.4383356Z ERROR 01-31 18:41:16 [utils.py:288]     raise RuntimeError(
2026-01-31T18:41:16.4392800Z ERROR 01-31 18:41:16 [utils.py:288] RuntimeError: Process ApiServer_0 (PID: 195) died with exit code 1
2026-01-31T18:41:16.4403022Z INFO 01-31 18:41:16 [utils.py:291] Terminating remaining processes ...
2026-01-31T18:41:16.7375164Z [0;36m(Worker_DP1_TP0_EP8 pid=212)[0;0m INFO 01-31 18:41:16 [multiproc_executor.py:709] Parent process exited, terminating worker
2026-01-31T18:41:16.7380974Z [0;36m(Worker_DP0_TP2_EP2 pid=379)[0;0m INFO 01-31 18:41:16 [multiproc_executor.py:709] Parent process exited, terminating worker
2026-01-31T18:41:16.7390353Z [0;36m(Worker_DP0_TP5_EP5 pid=687)[0;0m INFO 01-31 18:41:16 [multiproc_executor.py:709] Parent process exited, terminating worker
2026-01-31T18:41:16.7399181Z [0;36m(Worker_DP0_TP0_EP0 pid=213)[0;0m INFO 01-31 18:41:16 [multiproc_executor.py:709] Parent process exited, terminating worker
2026-01-31T18:41:16.7408303Z [0;36m(Worker_DP1_TP5_EP13 pid=686)[0;0m INFO 01-31 18:41:16 [multiproc_executor.py:709] Parent process exited, terminating worker
2026-01-31T18:41:16.7417251Z [0;36m(Worker_DP1_TP1_EP9 pid=277)[0;0m INFO 01-31 18:41:16 [multiproc_executor.py:709] Parent process exited, terminating worker
2026-01-31T18:41:16.7426972Z [0;36m(Worker_DP1_TP2_EP10 pid=381)[0;0m INFO 01-31 18:41:16 [multiproc_executor.py:709] Parent process exited, terminating worker
2026-01-31T18:41:16.7437301Z [0;36m(Worker_DP0_TP1_EP1 pid=268)[0;0m INFO 01-31 18:41:16 [multiproc_executor.py:709] Parent process exited, terminating worker
2026-01-31T18:41:16.7445444Z [0;36m(Worker_DP1_TP7_EP15 pid=888)[0;0m INFO 01-31 18:41:16 [multiproc_executor.py:709] Parent process exited, terminating worker
2026-01-31T18:41:16.7454612Z [0;36m(Worker_DP0_TP7_EP7 pid=891)[0;0m INFO 01-31 18:41:16 [multiproc_executor.py:709] Parent process exited, terminating worker
2026-01-31T18:41:16.7463841Z [0;36m(Worker_DP0_TP3_EP3 pid=481)[0;0m INFO 01-31 18:41:16 [multiproc_executor.py:709] Parent process exited, terminating worker
2026-01-31T18:41:16.7473713Z [0;36m(Worker_DP0_TP6_EP6 pid=789)[0;0m INFO 01-31 18:41:16 [multiproc_executor.py:709] Parent process exited, terminating worker
2026-01-31T18:41:16.7484076Z [0;36m(Worker_DP1_TP3_EP11 pid=480)[0;0m INFO 01-31 18:41:16 [multiproc_executor.py:709] Parent process exited, terminating worker
2026-01-31T18:41:16.7492253Z [0;36m(Worker_DP1_TP6_EP14 pid=786)[0;0m INFO 01-31 18:41:16 [multiproc_executor.py:709] Parent process exited, terminating worker
2026-01-31T18:41:16.7524178Z [0;36m(Worker_DP1_TP4_EP12 pid=583)[0;0m INFO 01-31 18:41:16 [multiproc_executor.py:709] Parent process exited, terminating worker
2026-01-31T18:41:16.7524847Z [0;36m(Worker_DP0_TP4_EP4 pid=582)[0;0m INFO 01-31 18:41:16 [multiproc_executor.py:709] Parent process exited, terminating worker
2026-01-31T18:41:21.7463999Z Traceback (most recent call last):
2026-01-31T18:41:21.7472709Z   File "/usr/local/python3.11.14/bin/vllm", line 7, in <module>
2026-01-31T18:41:21.7491178Z     sys.exit(main())
2026-01-31T18:41:21.7500502Z              ^^^^^^
2026-01-31T18:41:21.7509131Z   File "/vllm-workspace/vllm/vllm/entrypoints/cli/main.py", line 73, in main
2026-01-31T18:41:21.7518846Z     args.dispatch_function(args)
2026-01-31T18:41:21.7529477Z   File "/vllm-workspace/vllm/vllm/entrypoints/cli/serve.py", line 57, in cmd
2026-01-31T18:41:21.7538462Z     run_multi_api_server(args)
2026-01-31T18:41:21.7548239Z   File "/vllm-workspace/vllm/vllm/entrypoints/cli/serve.py", line 229, in run_multi_api_server
2026-01-31T18:41:21.7557440Z     wait_for_completion_or_failure(
2026-01-31T18:41:21.7567297Z   File "/vllm-workspace/vllm/vllm/v1/utils.py", line 275, in wait_for_completion_or_failure
2026-01-31T18:41:21.7576945Z     raise RuntimeError(
2026-01-31T18:41:21.7586998Z RuntimeError: Process ApiServer_0 (PID: 195) died with exit code 1
2026-01-31T18:41:21.8923756Z [ERROR] 2026-01-31-18:41:21 (PID:135, Device:-1, RankID:-1) ERR99999 UNKNOWN applicaiton exception
2026-01-31T18:41:22.2263863Z sys:1: DeprecationWarning: builtin type swigvarlink has no __module__ attribute
2026-01-31T18:41:27.4166458Z FAILED
2026-01-31T18:41:27.4175231Z 
2026-01-31T18:41:27.4184207Z =================================== FAILURES ===================================
2026-01-31T18:41:27.4195047Z _______________________________ test_multi_node ________________________________
2026-01-31T18:41:27.4203449Z 
2026-01-31T18:41:27.4213347Z     @pytest.mark.asyncio
2026-01-31T18:41:27.4222314Z     async def test_multi_node() -> None:
2026-01-31T18:41:27.4231402Z         config = MultiNodeConfigLoader.from_yaml()
2026-01-31T18:41:27.4242230Z     
2026-01-31T18:41:27.4250535Z         with ProxyLauncher(
2026-01-31T18:41:27.4260065Z                 nodes=config.nodes,
2026-01-31T18:41:27.4270019Z                 disagg_cfg=config.disagg_cfg,
2026-01-31T18:41:27.4279256Z                 envs=config.envs,
2026-01-31T18:41:27.4287986Z                 proxy_port=config.proxy_port,
2026-01-31T18:41:27.4297426Z                 cur_index=config.cur_index,
2026-01-31T18:41:27.4306546Z         ) as proxy:
2026-01-31T18:41:27.4316496Z     
2026-01-31T18:41:27.4325545Z >           with RemoteOpenAIServer(
2026-01-31T18:41:27.4382291Z                     model=config.model,
2026-01-31T18:41:27.4424051Z                     vllm_serve_args=config.server_cmd,
2026-01-31T18:41:27.4424406Z                     server_port=config.server_port,
2026-01-31T18:41:27.4424894Z                     server_host=config.master_ip,
2026-01-31T18:41:27.4425137Z                     env_dict=config.envs,
2026-01-31T18:41:27.4428642Z                     auto_port=False,
2026-01-31T18:41:27.4438461Z                     proxy_port=proxy.proxy_port,
2026-01-31T18:41:27.4446929Z                     disaggregated_prefill=config.disagg_cfg,
2026-01-31T18:41:27.4456777Z                     nodes_info=config.nodes,
2026-01-31T18:41:27.4465782Z                     max_wait_seconds=2800,
2026-01-31T18:41:27.4475622Z             ) as server:
2026-01-31T18:41:27.4484861Z 
2026-01-31T18:41:27.4494976Z tests/e2e/nightly/multi_node/scripts/test_multi_node.py:21: 
2026-01-31T18:41:27.4504142Z _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
2026-01-31T18:41:27.4514000Z tests/e2e/conftest.py:172: in __init__
2026-01-31T18:41:27.4523741Z     self._wait_for_multiple_servers(
2026-01-31T18:41:27.4532073Z _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
2026-01-31T18:41:27.4540703Z 
2026-01-31T18:41:27.4550998Z self = <tests.e2e.conftest.RemoteOpenAIServer object at 0xffff24537510>
2026-01-31T18:41:27.4561481Z targets = [('10.0.0.188', 'http://10.0.0.188:8080/health')], timeout = 2800
2026-01-31T18:41:27.4569589Z log_interval = 30.0
2026-01-31T18:41:27.4579142Z 
2026-01-31T18:41:27.4588322Z     def _wait_for_multiple_servers(self,
2026-01-31T18:41:27.4597706Z                                    targets,
2026-01-31T18:41:27.4606469Z                                    timeout: float,
2026-01-31T18:41:27.4616173Z                                    log_interval: float = 30.0):
2026-01-31T18:41:27.4624986Z         """
2026-01-31T18:41:27.4634406Z         targets: List[(node_ip, url)]
2026-01-31T18:41:27.4644389Z         log_interval
2026-01-31T18:41:27.4653810Z         """
2026-01-31T18:41:27.4662938Z         start = time.time()
2026-01-31T18:41:27.4671721Z         client = requests
2026-01-31T18:41:27.4681800Z     
2026-01-31T18:41:27.4691447Z         ready = {node_ip: False for node_ip, _ in targets}
2026-01-31T18:41:27.4700997Z     
2026-01-31T18:41:27.4710052Z         last_log_time = 0.0
2026-01-31T18:41:27.4719523Z     
2026-01-31T18:41:27.4729002Z         while True:
2026-01-31T18:41:27.4738697Z             now = time.time()
2026-01-31T18:41:27.4747873Z             all_ready = True
2026-01-31T18:41:27.4758485Z             should_log = (now - last_log_time) >= log_interval
2026-01-31T18:41:27.4767899Z     
2026-01-31T18:41:27.4777811Z             for node_ip, url in targets:
2026-01-31T18:41:27.4787383Z                 if ready[node_ip]:
2026-01-31T18:41:27.4796770Z                     continue
2026-01-31T18:41:27.4806315Z     
2026-01-31T18:41:27.4816274Z                 try:
2026-01-31T18:41:27.4825346Z                     resp = client.get(url)
2026-01-31T18:41:27.4833838Z                     if resp.status_code == 200:
2026-01-31T18:41:27.4844262Z                         ready[node_ip] = True
2026-01-31T18:41:27.4853715Z                         logger.info(f"[READY] Node {node_ip} is ready.")
2026-01-31T18:41:27.4862970Z                 except RequestException:
2026-01-31T18:41:27.4871797Z                     all_ready = False
2026-01-31T18:41:27.4881808Z                     if should_log:
2026-01-31T18:41:27.4890554Z                         logger.debug(f"[WAIT] {url}: connection failed")
2026-01-31T18:41:27.4899625Z     
2026-01-31T18:41:27.4910150Z                     # check unexpected exit
2026-01-31T18:41:27.4918668Z                     result = self._poll()
2026-01-31T18:41:27.4928126Z                     if result is not None and result != 0:
2026-01-31T18:41:27.4937560Z >                       raise RuntimeError(
2026-01-31T18:41:27.4946810Z                             f"Server at {node_ip} exited unexpectedly."
2026-01-31T18:41:27.4956401Z                         ) from None
2026-01-31T18:41:27.4966197Z E                       RuntimeError: Server at 10.0.0.188 exited unexpectedly.
2026-01-31T18:41:27.4974958Z 
2026-01-31T18:41:27.4984796Z tests/e2e/conftest.py:265: RuntimeError
2026-01-31T18:41:27.4994275Z =============================== warnings summary ===============================
2026-01-31T18:41:27.5003835Z <frozen importlib._bootstrap>:241
2026-01-31T18:41:27.5013766Z   <frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyPacked has no __module__ attribute
2026-01-31T18:41:27.5045205Z 
2026-01-31T18:41:27.5045812Z <frozen importlib._bootstrap>:241
2026-01-31T18:41:27.5046298Z   <frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyObject has no __module__ attribute
2026-01-31T18:41:27.5050246Z 
2026-01-31T18:41:27.5059650Z -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
2026-01-31T18:41:27.5068865Z =========================== short test summary info ============================
2026-01-31T18:41:27.5079501Z FAILED tests/e2e/nightly/multi_node/scripts/test_multi_node.py::test_multi_node
2026-01-31T18:41:27.5088888Z ================== 1 failed, 2 warnings in 686.39s (0:11:26) ===================
2026-01-31T18:41:29.7947507Z [0;31mFAIL_TAG_DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml âœ— ERROR: Some tests failed, please check the error stack above for details. If this is insufficient to pinpoint the error, please download and review the logs of all other nodes from the job's summary.[0m
2026-01-31T18:41:29.9321076Z Cleaning up background log streams...
2026-01-31T18:41:30.0184098Z ##[error]Error: failed to run script step: Error: command terminated with non-zero exit code: command terminated with exit code 1
2026-01-31T18:41:30.0226348Z ##[error]Process completed with exit code 1.
2026-01-31T18:41:30.0329182Z ##[error]Executing the custom container implementation failed. Please contact your self hosted runner administrator.
2026-01-31T18:41:30.0764849Z ##[group]Run actions/upload-artifact@v6
2026-01-31T18:41:30.0765139Z with:
2026-01-31T18:41:30.0765383Z   name: DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml-pod-logs
2026-01-31T18:41:30.0765721Z   path: /tmp/vllm*_logs.txt
2026-01-31T18:41:30.0765966Z   retention-days: 7
2026-01-31T18:41:30.0766177Z   if-no-files-found: warn
2026-01-31T18:41:30.0766433Z   compression-level: 6
2026-01-31T18:41:30.0766660Z   overwrite: false
2026-01-31T18:41:30.0766950Z   include-hidden-files: false
2026-01-31T18:41:30.0767196Z env:
2026-01-31T18:41:30.0767451Z   FAIL_TAG: FAIL_TAG_DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-01-31T18:41:30.0767727Z ##[endgroup]
2026-01-31T18:41:30.0798957Z ##[group]Run '/home/runner/k8s/index.js'
2026-01-31T18:41:30.0799691Z shell: /home/runner/externals/node20/bin/node {0}
2026-01-31T18:41:30.0800064Z ##[endgroup]
2026-01-31T18:41:30.4738691Z (node:11747) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-01-31T18:41:30.4739605Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-01-31T18:41:49.7053729Z With the provided path, there will be 1 file uploaded
2026-01-31T18:41:49.7057688Z Artifact name is valid!
2026-01-31T18:41:49.7058251Z Root directory input is valid!
2026-01-31T18:41:50.5912953Z Beginning upload of artifact content to blob storage
2026-01-31T18:41:51.8778478Z Uploaded bytes 10129
2026-01-31T18:41:52.1371807Z Finished uploading artifact content to blob storage!
2026-01-31T18:41:52.1372601Z SHA256 digest of uploaded artifact zip is 1c18e84c08b409f736eb76a12585acba97491c8ac80291c97e75c71c8942719b
2026-01-31T18:41:52.1373046Z Finalizing artifact upload
2026-01-31T18:41:53.0297625Z Artifact DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml-pod-logs.zip successfully finalized. Artifact ID 5329934488
2026-01-31T18:41:53.0298537Z Artifact DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml-pod-logs has been successfully uploaded! Final size is 10129 bytes. Artifact ID is 5329934488
2026-01-31T18:41:53.0299248Z Artifact download URL: https://github.com/vllm-project/vllm-ascend/actions/runs/21547211240/artifacts/5329934488
2026-01-31T18:42:11.4289811Z ##[group]Run kubectl get pods -n $NAMESPACE --ignore-not-found=true
2026-01-31T18:42:11.4290309Z [36;1mkubectl get pods -n $NAMESPACE --ignore-not-found=true[0m
2026-01-31T18:42:11.4290792Z [36;1mkubectl delete -f ./lws.yaml --ignore-not-found=true || true[0m
2026-01-31T18:42:11.4291229Z shell: bash -el {0}
2026-01-31T18:42:11.4291476Z env:
2026-01-31T18:42:11.4291881Z   FAIL_TAG: FAIL_TAG_DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-01-31T18:42:11.4292304Z ##[endgroup]
2026-01-31T18:42:11.4370113Z ##[group]Run '/home/runner/k8s/index.js'
2026-01-31T18:42:11.4370980Z shell: /home/runner/externals/node20/bin/node {0}
2026-01-31T18:42:11.4371246Z ##[endgroup]
2026-01-31T18:42:11.7953982Z (node:13399) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-01-31T18:42:11.7954868Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-01-31T18:42:30.4901036Z NAME                                             READY   STATUS    RESTARTS      AGE
2026-01-31T18:42:30.4901551Z linux-aarch64-a3-0-wgt9d-runner-dgrf2            1/1     Running   0             17m
2026-01-31T18:42:30.4902310Z linux-aarch64-a3-0-wgt9d-runner-dgrf2-workflow   1/1     Running   0             16m
2026-01-31T18:42:30.4902763Z vllm-0                                           1/1     Running   1 (61s ago)   13m
2026-01-31T18:42:30.4903085Z vllm-0-1                                         1/1     Running   0             13m
2026-01-31T18:42:30.5606943Z leaderworkerset.leaderworkerset.x-k8s.io "vllm" deleted from vllm-project namespace
2026-01-31T18:42:30.5938521Z service "vllm-leader" deleted from vllm-project namespace
2026-01-31T18:42:49.5299869Z Post job cleanup.
2026-01-31T18:42:49.5323642Z ##[group]Run '/home/runner/k8s/index.js'
2026-01-31T18:42:49.5324506Z shell: /home/runner/externals/node20/bin/node {0}
2026-01-31T18:42:49.5324796Z ##[endgroup]
2026-01-31T18:42:49.8900749Z (node:15234) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-01-31T18:42:49.8901516Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-01-31T18:43:09.0748658Z [command]/usr/bin/git version
2026-01-31T18:43:09.0984144Z git version 2.34.1
2026-01-31T18:43:09.1017097Z Copying '/root/.gitconfig' to '/__w/_temp/fc0d3fda-9d56-42f1-a6cc-6b7eafcb6d23/.gitconfig'
2026-01-31T18:43:09.1028399Z Temporarily overriding HOME='/__w/_temp/fc0d3fda-9d56-42f1-a6cc-6b7eafcb6d23' before making global git config changes
2026-01-31T18:43:09.1029076Z Adding repository directory to the temporary git global config as a safe directory
2026-01-31T18:43:09.1032679Z [command]/usr/bin/git config --global --add safe.directory /__w/vllm-ascend/vllm-ascend
2026-01-31T18:43:09.1073272Z Removing SSH command configuration
2026-01-31T18:43:09.1078478Z [command]/usr/bin/git config --local --name-only --get-regexp core\.sshCommand
2026-01-31T18:43:09.1132935Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'core\.sshCommand' && git config --local --unset-all 'core.sshCommand' || :"
2026-01-31T18:43:09.1600277Z Removing HTTP extra header
2026-01-31T18:43:09.1604031Z [command]/usr/bin/git config --local --name-only --get-regexp http\.https\:\/\/github\.com\/\.extraheader
2026-01-31T18:43:09.1629708Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'http\.https\:\/\/github\.com\/\.extraheader' && git config --local --unset-all 'http.https://github.com/.extraheader' || :"
2026-01-31T18:43:09.1810583Z Removing includeIf entries pointing to credentials config files
2026-01-31T18:43:09.1814389Z [command]/usr/bin/git config --local --name-only --get-regexp ^includeIf\.gitdir:
2026-01-31T18:43:09.1833570Z includeif.gitdir:/__w/vllm-ascend/vllm-ascend/.git.path
2026-01-31T18:43:09.1834302Z includeif.gitdir:/__w/vllm-ascend/vllm-ascend/.git/worktrees/*.path
2026-01-31T18:43:09.1834688Z includeif.gitdir:/github/workspace/.git.path
2026-01-31T18:43:09.1835088Z includeif.gitdir:/github/workspace/.git/worktrees/*.path
2026-01-31T18:43:09.1840964Z [command]/usr/bin/git config --local --get-all includeif.gitdir:/__w/vllm-ascend/vllm-ascend/.git.path
2026-01-31T18:43:09.1859117Z /__w/_temp/git-credentials-45083731-d67b-488c-a240-ba3fb1b780c0.config
2026-01-31T18:43:09.1867131Z [command]/usr/bin/git config --local --unset includeif.gitdir:/__w/vllm-ascend/vllm-ascend/.git.path /__w/_temp/git-credentials-45083731-d67b-488c-a240-ba3fb1b780c0.config
2026-01-31T18:43:09.1901572Z [command]/usr/bin/git config --local --get-all includeif.gitdir:/__w/vllm-ascend/vllm-ascend/.git/worktrees/*.path
2026-01-31T18:43:09.1924610Z /__w/_temp/git-credentials-45083731-d67b-488c-a240-ba3fb1b780c0.config
2026-01-31T18:43:09.1925935Z [command]/usr/bin/git config --local --unset includeif.gitdir:/__w/vllm-ascend/vllm-ascend/.git/worktrees/*.path /__w/_temp/git-credentials-45083731-d67b-488c-a240-ba3fb1b780c0.config
2026-01-31T18:43:09.1951793Z [command]/usr/bin/git config --local --get-all includeif.gitdir:/github/workspace/.git.path
2026-01-31T18:43:09.1972105Z /github/runner_temp/git-credentials-45083731-d67b-488c-a240-ba3fb1b780c0.config
2026-01-31T18:43:09.1980003Z [command]/usr/bin/git config --local --unset includeif.gitdir:/github/workspace/.git.path /github/runner_temp/git-credentials-45083731-d67b-488c-a240-ba3fb1b780c0.config
2026-01-31T18:43:09.2006415Z [command]/usr/bin/git config --local --get-all includeif.gitdir:/github/workspace/.git/worktrees/*.path
2026-01-31T18:43:09.2024174Z /github/runner_temp/git-credentials-45083731-d67b-488c-a240-ba3fb1b780c0.config
2026-01-31T18:43:09.2030684Z [command]/usr/bin/git config --local --unset includeif.gitdir:/github/workspace/.git/worktrees/*.path /github/runner_temp/git-credentials-45083731-d67b-488c-a240-ba3fb1b780c0.config
2026-01-31T18:43:09.2080841Z [command]/usr/bin/git submodule foreach --recursive git config --local --show-origin --name-only --get-regexp remote.origin.url
2026-01-31T18:43:09.2256140Z Removing credentials config '/__w/_temp/git-credentials-45083731-d67b-488c-a240-ba3fb1b780c0.config'
2026-01-31T18:43:27.7962817Z ##[group]Run '/home/runner/k8s/index.js'
2026-01-31T18:43:27.7963784Z shell: /home/runner/externals/node20/bin/node {0}
2026-01-31T18:43:27.7964083Z ##[endgroup]
2026-01-31T18:43:28.1896634Z Cleaning up orphan processes
