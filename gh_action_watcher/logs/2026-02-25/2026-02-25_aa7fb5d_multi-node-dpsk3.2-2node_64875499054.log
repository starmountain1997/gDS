# Run ID: 22407018984
# Commit: aa7fb5d7073b70b35445ad87bcc1fbf6aca34df1
# Job: multi-node (multi-node-dpsk3.2-2node, DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml, 2) / DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
# Date: 2026-02-25
============================================================

ï»¿2026-02-25T17:40:24.1015491Z Current runner version: '2.330.0'
2026-02-25T17:40:24.1020078Z Runner name: 'linux-aarch64-a3-0-n4cwm-runner-zbb9m'
2026-02-25T17:40:24.1020818Z Runner group name: 'Default'
2026-02-25T17:40:24.1021532Z Machine name: 'linux-aarch64-a3-0-n4cwm-runner-zbb9m'
2026-02-25T17:40:24.1025020Z ##[group]GITHUB_TOKEN Permissions
2026-02-25T17:40:24.1026972Z Actions: write
2026-02-25T17:40:24.1027412Z ArtifactMetadata: write
2026-02-25T17:40:24.1027803Z Attestations: write
2026-02-25T17:40:24.1028318Z Checks: write
2026-02-25T17:40:24.1028733Z Contents: write
2026-02-25T17:40:24.1029083Z Deployments: write
2026-02-25T17:40:24.1029480Z Discussions: write
2026-02-25T17:40:24.1029870Z Issues: write
2026-02-25T17:40:24.1030210Z Metadata: read
2026-02-25T17:40:24.1030589Z Models: read
2026-02-25T17:40:24.1030972Z Packages: write
2026-02-25T17:40:24.1031371Z Pages: write
2026-02-25T17:40:24.1031826Z PullRequests: write
2026-02-25T17:40:24.1032358Z RepositoryProjects: write
2026-02-25T17:40:24.1032941Z SecurityEvents: write
2026-02-25T17:40:24.1033381Z Statuses: write
2026-02-25T17:40:24.1033762Z ##[endgroup]
2026-02-25T17:40:24.1035440Z Secret source: Actions
2026-02-25T17:40:24.1035951Z Prepare workflow directory
2026-02-25T17:40:24.1585374Z Prepare all required actions
2026-02-25T17:40:24.1617741Z Getting action download info
2026-02-25T17:40:25.5679232Z Download action repository 'actions/checkout@v6' (SHA:de0fac2e4500dabe0009e67214ff5f5447ce83dd)
2026-02-25T17:40:30.4659087Z Download action repository 'actions/upload-artifact@v6' (SHA:b7c566a772e6b6bfb58ed0dc250532a479d7789f)
2026-02-25T17:40:37.7549162Z Uses: vllm-project/vllm-ascend/.github/workflows/_e2e_nightly_multi_node.yaml@refs/heads/main (aa7fb5d7073b70b35445ad87bcc1fbf6aca34df1)
2026-02-25T17:40:37.7552777Z ##[group] Inputs
2026-02-25T17:40:37.7553108Z   soc_version: a3
2026-02-25T17:40:37.7553366Z   runner: linux-aarch64-a3-0
2026-02-25T17:40:37.7553783Z   image: swr.cn-southwest-2.myhuaweicloud.com/base_image/ascend-ci/vllm-ascend:nightly-a3
2026-02-25T17:40:37.7554291Z   config_file_path: DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-02-25T17:40:37.7554594Z   replicas: 1
2026-02-25T17:40:37.7554810Z   size: 2
2026-02-25T17:40:37.7554983Z   vllm_version: v0.15.0
2026-02-25T17:40:37.7555354Z   vllm_ascend_remote_url: https://github.com/vllm-project/vllm-ascend.git
2026-02-25T17:40:37.7555702Z   vllm_ascend_ref: main
2026-02-25T17:40:37.7555904Z ##[endgroup]
2026-02-25T17:40:37.7556408Z Complete job name: multi-node (multi-node-dpsk3.2-2node, DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml, 2) / DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-02-25T17:40:37.8072376Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-25T17:40:37.8075112Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-25T17:40:37.8075700Z ##[endgroup]
2026-02-25T17:40:53.4046922Z (node:70) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-25T17:40:53.4047728Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-25T17:40:55.3499614Z ##[group]Run # Decode and save kubeconfig
2026-02-25T17:40:55.3500238Z [36;1m# Decode and save kubeconfig[0m
2026-02-25T17:40:55.3533961Z [36;1mecho "***" | base64 -d > "$KUBECONFIG"[0m
2026-02-25T17:40:55.3534675Z shell: bash -el {0}
2026-02-25T17:40:55.3534897Z ##[endgroup]
2026-02-25T17:40:55.3645886Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-25T17:40:55.3646954Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-25T17:40:55.3647242Z ##[endgroup]
2026-02-25T17:40:55.7156078Z (node:399) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-25T17:40:55.9949726Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-25T17:40:56.6100467Z ##[group]Run actions/checkout@v6
2026-02-25T17:40:56.6100864Z with:
2026-02-25T17:40:56.6101112Z   repository: vllm-project/vllm-ascend
2026-02-25T17:40:56.6101844Z   token: ***
2026-02-25T17:40:56.6102219Z   ssh-strict: true
2026-02-25T17:40:56.6102441Z   ssh-user: git
2026-02-25T17:40:56.6102700Z   persist-credentials: true
2026-02-25T17:40:56.6102965Z   clean: true
2026-02-25T17:40:56.6103178Z   sparse-checkout-cone-mode: true
2026-02-25T17:40:56.6103467Z   fetch-depth: 1
2026-02-25T17:40:56.6103698Z   fetch-tags: false
2026-02-25T17:40:56.6103893Z   show-progress: true
2026-02-25T17:40:56.6104134Z   lfs: false
2026-02-25T17:40:56.6104389Z   submodules: false
2026-02-25T17:40:56.6104616Z   set-safe-directory: true
2026-02-25T17:40:56.6104904Z ##[endgroup]
2026-02-25T17:40:56.6145051Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-25T17:40:56.6145880Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-25T17:40:56.6146181Z ##[endgroup]
2026-02-25T17:40:56.9667315Z (node:431) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-25T17:40:56.9668181Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-25T17:40:57.5417039Z Syncing repository: vllm-project/vllm-ascend
2026-02-25T17:40:57.5418307Z ##[group]Getting Git version info
2026-02-25T17:40:57.5418640Z Working directory is '/__w/vllm-ascend/vllm-ascend'
2026-02-25T17:40:57.5419188Z [command]/usr/bin/git version
2026-02-25T17:40:57.5619283Z git version 2.34.1
2026-02-25T17:40:57.5639253Z ##[endgroup]
2026-02-25T17:40:57.5644716Z Copying '/root/.gitconfig' to '/__w/_temp/8693dfaa-235e-4b39-a0d3-7daee32734c8/.gitconfig'
2026-02-25T17:40:57.5657235Z Temporarily overriding HOME='/__w/_temp/8693dfaa-235e-4b39-a0d3-7daee32734c8' before making global git config changes
2026-02-25T17:40:57.5657985Z Adding repository directory to the temporary git global config as a safe directory
2026-02-25T17:40:57.5660294Z [command]/usr/bin/git config --global --add safe.directory /__w/vllm-ascend/vllm-ascend
2026-02-25T17:40:57.5697260Z Deleting the contents of '/__w/vllm-ascend/vllm-ascend'
2026-02-25T17:40:57.5700206Z ##[group]Initializing the repository
2026-02-25T17:40:57.5703743Z [command]/usr/bin/git init /__w/vllm-ascend/vllm-ascend
2026-02-25T17:40:57.5828903Z hint: Using 'master' as the name for the initial branch. This default branch name
2026-02-25T17:40:57.5829437Z hint: is subject to change. To configure the initial branch name to use in all
2026-02-25T17:40:57.5829873Z hint: of your new repositories, which will suppress this warning, call:
2026-02-25T17:40:57.5830226Z hint: 
2026-02-25T17:40:57.5830489Z hint: 	git config --global init.defaultBranch <name>
2026-02-25T17:40:57.5830770Z hint: 
2026-02-25T17:40:57.5831078Z hint: Names commonly chosen instead of 'master' are 'main', 'trunk' and
2026-02-25T17:40:57.5831497Z hint: 'development'. The just-created branch can be renamed via this command:
2026-02-25T17:40:57.5831829Z hint: 
2026-02-25T17:40:57.5832178Z hint: 	git branch -m <name>
2026-02-25T17:40:57.5839547Z Initialized empty Git repository in /__w/vllm-ascend/vllm-ascend/.git/
2026-02-25T17:40:57.5848141Z [command]/usr/bin/git remote add origin https://github.com/vllm-project/vllm-ascend
2026-02-25T17:40:57.5898846Z ##[endgroup]
2026-02-25T17:40:57.5899236Z ##[group]Disabling automatic garbage collection
2026-02-25T17:40:57.5902215Z [command]/usr/bin/git config --local gc.auto 0
2026-02-25T17:40:57.5927293Z ##[endgroup]
2026-02-25T17:40:57.5927733Z ##[group]Setting up auth
2026-02-25T17:40:57.5928033Z Removing SSH command configuration
2026-02-25T17:40:57.5933164Z [command]/usr/bin/git config --local --name-only --get-regexp core\.sshCommand
2026-02-25T17:40:57.5961917Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'core\.sshCommand' && git config --local --unset-all 'core.sshCommand' || :"
2026-02-25T17:40:57.6397823Z Removing HTTP extra header
2026-02-25T17:40:57.6400856Z [command]/usr/bin/git config --local --name-only --get-regexp http\.https\:\/\/github\.com\/\.extraheader
2026-02-25T17:40:57.6425904Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'http\.https\:\/\/github\.com\/\.extraheader' && git config --local --unset-all 'http.https://github.com/.extraheader' || :"
2026-02-25T17:40:57.6608566Z Removing includeIf entries pointing to credentials config files
2026-02-25T17:40:57.6612928Z [command]/usr/bin/git config --local --name-only --get-regexp ^includeIf\.gitdir:
2026-02-25T17:40:57.6637479Z [command]/usr/bin/git submodule foreach --recursive git config --local --show-origin --name-only --get-regexp remote.origin.url
2026-02-25T17:40:57.6816864Z [command]/usr/bin/git config --file /__w/_temp/git-credentials-3ba5ebe6-40d5-4d37-871a-75aae1b32d46.config http.https://github.com/.extraheader AUTHORIZATION: basic ***
2026-02-25T17:40:57.6850922Z [command]/usr/bin/git config --local includeIf.gitdir:/__w/vllm-ascend/vllm-ascend/.git.path /__w/_temp/git-credentials-3ba5ebe6-40d5-4d37-871a-75aae1b32d46.config
2026-02-25T17:40:57.6875688Z [command]/usr/bin/git config --local includeIf.gitdir:/__w/vllm-ascend/vllm-ascend/.git/worktrees/*.path /__w/_temp/git-credentials-3ba5ebe6-40d5-4d37-871a-75aae1b32d46.config
2026-02-25T17:40:57.6905781Z [command]/usr/bin/git config --local includeIf.gitdir:/github/workspace/.git.path /github/runner_temp/git-credentials-3ba5ebe6-40d5-4d37-871a-75aae1b32d46.config
2026-02-25T17:40:57.6932139Z [command]/usr/bin/git config --local includeIf.gitdir:/github/workspace/.git/worktrees/*.path /github/runner_temp/git-credentials-3ba5ebe6-40d5-4d37-871a-75aae1b32d46.config
2026-02-25T17:40:57.6958096Z ##[endgroup]
2026-02-25T17:40:57.6958483Z ##[group]Fetching the repository
2026-02-25T17:40:57.6963652Z [command]/usr/bin/git -c protocol.version=2 fetch --no-tags --prune --no-recurse-submodules --depth=1 origin +aa7fb5d7073b70b35445ad87bcc1fbf6aca34df1:refs/remotes/origin/main
2026-02-25T17:40:59.3442310Z From https://gh-proxy.test.osinfra.cn/https://github.com/vllm-project/vllm-ascend
2026-02-25T17:40:59.3442923Z  * [new ref]         aa7fb5d7073b70b35445ad87bcc1fbf6aca34df1 -> origin/main
2026-02-25T17:40:59.3458021Z [command]/usr/bin/git branch --list --remote origin/main
2026-02-25T17:40:59.3482719Z   origin/main
2026-02-25T17:40:59.3491458Z [command]/usr/bin/git rev-parse refs/remotes/origin/main
2026-02-25T17:40:59.3509312Z aa7fb5d7073b70b35445ad87bcc1fbf6aca34df1
2026-02-25T17:40:59.3513150Z ##[endgroup]
2026-02-25T17:40:59.3513441Z ##[group]Determining the checkout info
2026-02-25T17:40:59.3515278Z ##[endgroup]
2026-02-25T17:40:59.3518468Z [command]/usr/bin/git sparse-checkout disable
2026-02-25T17:40:59.3563745Z [command]/usr/bin/git config --local --unset-all extensions.worktreeConfig
2026-02-25T17:40:59.3588116Z ##[group]Checking out the ref
2026-02-25T17:40:59.3591135Z [command]/usr/bin/git checkout --progress --force -B main refs/remotes/origin/main
2026-02-25T17:40:59.4477174Z Switched to a new branch 'main'
2026-02-25T17:40:59.4477487Z Branch 'main' set up to track remote branch 'main' from 'origin'.
2026-02-25T17:40:59.4495355Z ##[endgroup]
2026-02-25T17:40:59.4532910Z [command]/usr/bin/git log -1 --format=%H
2026-02-25T17:40:59.4554568Z aa7fb5d7073b70b35445ad87bcc1fbf6aca34df1
2026-02-25T17:40:59.8878505Z ##[group]Run # prepare for lws entrypoint scripts
2026-02-25T17:40:59.8878799Z [36;1m# prepare for lws entrypoint scripts[0m
2026-02-25T17:40:59.8879131Z [36;1minstall -D tests/e2e/nightly/multi_node/scripts/run.sh /root/.cache/tests/run.sh[0m
2026-02-25T17:40:59.8879545Z shell: bash -el {0}
2026-02-25T17:40:59.8879693Z ##[endgroup]
2026-02-25T17:40:59.8962814Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-25T17:40:59.8963577Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-25T17:40:59.8963808Z ##[endgroup]
2026-02-25T17:41:00.2529008Z (node:472) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-25T17:41:00.2529969Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-25T17:41:01.2104022Z ##[group]Run set -euo pipefail
2026-02-25T17:41:01.2104284Z [36;1mset -euo pipefail[0m
2026-02-25T17:41:01.2104453Z [36;1m[0m
2026-02-25T17:41:01.2104596Z [36;1mCRD_NAME="${CRD_NAME:-vllm}"[0m
2026-02-25T17:41:01.2104784Z [36;1mTIMEOUT=${TIMEOUT:-120}[0m
2026-02-25T17:41:01.2104965Z [36;1mSLEEP_INTERVAL=2[0m
2026-02-25T17:41:01.2105121Z [36;1m[0m
2026-02-25T17:41:01.2105346Z [36;1mecho "Deleting leaderworkerset [$CRD_NAME] in namespace [$NAMESPACE]..."[0m
2026-02-25T17:41:01.2105748Z [36;1mkubectl delete leaderworkerset "$CRD_NAME" -n "$NAMESPACE" --ignore-not-found[0m
2026-02-25T17:41:01.2106031Z [36;1m[0m
2026-02-25T17:41:01.2106236Z [36;1mecho "Waiting for all pods starting with 'vllm' to be deleted..."[0m
2026-02-25T17:41:01.2106501Z [36;1mSTART_TIME=$(date +%s)[0m
2026-02-25T17:41:01.2106663Z [36;1m[0m
2026-02-25T17:41:01.2106793Z [36;1mwhile true; do[0m
2026-02-25T17:41:01.2106955Z [36;1m  NOW=$(date +%s)[0m
2026-02-25T17:41:01.2107165Z [36;1m  ELAPSED=$((NOW - START_TIME))[0m
2026-02-25T17:41:01.2107340Z [36;1m[0m
2026-02-25T17:41:01.2107492Z [36;1m  if [[ $ELAPSED -ge $TIMEOUT ]]; then[0m
2026-02-25T17:41:01.2107765Z [36;1m    echo "Timeout reached ($TIMEOUT seconds), some pods still exist:"[0m
2026-02-25T17:41:01.2108073Z [36;1m    kubectl get pods -n "$NAMESPACE" | grep '^vllm' || true[0m
2026-02-25T17:41:01.2108384Z [36;1m    exit 1[0m
2026-02-25T17:41:01.2108531Z [36;1m  fi[0m
2026-02-25T17:41:01.2108655Z [36;1m[0m
2026-02-25T17:41:01.2109011Z [36;1m  PODS_EXIST=$(kubectl get pods -n "$NAMESPACE" -o jsonpath='{.items[*].metadata.name}' 2>/dev/null | tr ' ' '\n' | grep '^vllm' || true)[0m
2026-02-25T17:41:01.2109407Z [36;1m[0m
2026-02-25T17:41:01.2109543Z [36;1m  if [[ -z "$PODS_EXIST" ]]; then[0m
2026-02-25T17:41:01.2109748Z [36;1m    echo "All vllm pods deleted."[0m
2026-02-25T17:41:01.2109924Z [36;1m    break[0m
2026-02-25T17:41:01.2110062Z [36;1m  else[0m
2026-02-25T17:41:01.2110256Z [36;1m    echo "Waiting for pods to be deleted: $PODS_EXIST"[0m
2026-02-25T17:41:01.2110483Z [36;1m    sleep $SLEEP_INTERVAL[0m
2026-02-25T17:41:01.2110656Z [36;1m  fi[0m
2026-02-25T17:41:01.2110788Z [36;1mdone[0m
2026-02-25T17:41:01.2111036Z shell: bash -el {0}
2026-02-25T17:41:01.2111185Z ##[endgroup]
2026-02-25T17:41:01.2337443Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-25T17:41:01.2338085Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-25T17:41:01.2338366Z ##[endgroup]
2026-02-25T17:41:01.5855639Z (node:526) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-25T17:41:01.5856287Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-25T17:41:02.0740540Z Deleting leaderworkerset [vllm] in namespace [vllm-project]...
2026-02-25T17:41:02.4072263Z Waiting for all pods starting with 'vllm' to be deleted...
2026-02-25T17:41:02.4919063Z All vllm pods deleted.
2026-02-25T17:41:03.2558548Z ##[group]Run set -e
2026-02-25T17:41:03.2558893Z [36;1mset -e[0m
2026-02-25T17:41:03.2559034Z [36;1m[0m
2026-02-25T17:41:03.2559166Z [36;1msize="2"[0m
2026-02-25T17:41:03.2559299Z [36;1mreplicas="1"[0m
2026-02-25T17:41:03.2559614Z [36;1mimage="swr.cn-southwest-2.myhuaweicloud.com/base_image/ascend-ci/vllm-ascend:nightly-a3"[0m
2026-02-25T17:41:03.2560024Z [36;1mconfig_file_path="DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml"[0m
2026-02-25T17:41:03.2560324Z [36;1mfail_tag=FAIL_TAG_"DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml"[0m
2026-02-25T17:41:03.2560593Z [36;1mecho "FAIL_TAG=${fail_tag}" >> "$GITHUB_ENV"[0m
2026-02-25T17:41:03.2560785Z [36;1m[0m
2026-02-25T17:41:03.2560988Z [36;1mrequired_params=("size" "replicas" "image" "config_file_path")[0m
2026-02-25T17:41:03.2561266Z [36;1mfor param in "${required_params[@]}"; do[0m
2026-02-25T17:41:03.2561475Z [36;1m  if [ -z "${!param}" ]; then[0m
2026-02-25T17:41:03.2561894Z [36;1m    echo "Error: Parameter '$param' is required but empty"[0m
2026-02-25T17:41:03.2562253Z [36;1m    exit 1[0m
2026-02-25T17:41:03.2562400Z [36;1m  fi[0m
2026-02-25T17:41:03.2562532Z [36;1mdone[0m
2026-02-25T17:41:03.2562656Z [36;1m[0m
2026-02-25T17:41:03.2562791Z [36;1mif [ "a3" = "a3" ]; then[0m
2026-02-25T17:41:03.2562973Z [36;1m  npu_per_node=16[0m
2026-02-25T17:41:03.2563227Z [36;1m  TEMPLATE_FILE="tests/e2e/nightly/multi_node/scripts/lws.yaml.jinja2"[0m
2026-02-25T17:41:03.2563495Z [36;1melse[0m
2026-02-25T17:41:03.2563625Z [36;1m  npu_per_node=8[0m
2026-02-25T17:41:03.2563883Z [36;1m  TEMPLATE_FILE="tests/e2e/nightly/multi_node/scripts/lws-a2.yaml.jinja2"[0m
2026-02-25T17:41:03.2564159Z [36;1mfi[0m
2026-02-25T17:41:03.2564278Z [36;1m[0m
2026-02-25T17:41:03.2564414Z [36;1mjinja2 $TEMPLATE_FILE \[0m
2026-02-25T17:41:03.2564598Z [36;1m  -D size="$size" \[0m
2026-02-25T17:41:03.2564766Z [36;1m  -D replicas="$replicas" \[0m
2026-02-25T17:41:03.2564953Z [36;1m  -D image="$image" \[0m
2026-02-25T17:41:03.2565162Z [36;1m  -D config_file_path="$config_file_path" \[0m
2026-02-25T17:41:03.2565384Z [36;1m  -D npu_per_node="$npu_per_node" \[0m
2026-02-25T17:41:03.2565584Z [36;1m  -D fail_tag="$fail_tag" \[0m
2026-02-25T17:41:03.2565762Z [36;1m  --outfile lws.yaml[0m
2026-02-25T17:41:03.2565922Z [36;1m[0m
2026-02-25T17:41:03.2566060Z [36;1mkubectl apply -f ./lws.yaml[0m
2026-02-25T17:41:03.2566352Z shell: bash -el {0}
2026-02-25T17:41:03.2566581Z ##[endgroup]
2026-02-25T17:41:03.2693097Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-25T17:41:03.2693888Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-25T17:41:03.2694089Z ##[endgroup]
2026-02-25T17:41:03.6174114Z (node:592) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-25T17:41:03.6174764Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-25T17:41:04.5715539Z leaderworkerset.leaderworkerset.x-k8s.io/vllm created
2026-02-25T17:41:04.6038054Z service/vllm-leader created
2026-02-25T17:41:05.0395005Z ##[group]Run POD_PREFIX="${POD_PREFIX:-vllm-0}"
2026-02-25T17:41:05.0395324Z [36;1mPOD_PREFIX="${POD_PREFIX:-vllm-0}"[0m
2026-02-25T17:41:05.0395523Z [36;1mSIZE="2"[0m
2026-02-25T17:41:05.0395699Z [36;1mTIMEOUT=1200  # default timeout 20 minutes[0m
2026-02-25T17:41:05.0395907Z [36;1m[0m
2026-02-25T17:41:05.0396202Z [36;1mecho "Waiting for Pods in namespace [$NAMESPACE] to become Running and Ready (timeout ${TIMEOUT}s)..."[0m
2026-02-25T17:41:05.0396552Z [36;1m[0m
2026-02-25T17:41:05.0396689Z [36;1mSTART_TIME=$(date +%s)[0m
2026-02-25T17:41:05.0396852Z [36;1m[0m
2026-02-25T17:41:05.0396983Z [36;1mwhile true; do[0m
2026-02-25T17:41:05.0397136Z [36;1m  NOW=$(date +%s)[0m
2026-02-25T17:41:05.0397320Z [36;1m  ELAPSED=$((NOW - START_TIME))[0m
2026-02-25T17:41:05.0397534Z [36;1m  if [[ $ELAPSED -ge $TIMEOUT ]]; then[0m
2026-02-25T17:41:05.0397817Z [36;1m    echo "Timeout reached after ${ELAPSED}s"[0m
2026-02-25T17:41:05.0398179Z [36;1m    echo "Dumping pod status for debugging:"[0m
2026-02-25T17:41:05.0398486Z [36;1m    kubectl get pods -n "$NAMESPACE"[0m
2026-02-25T17:41:05.0398778Z [36;1m    kubectl describe pod "$LEADER_POD" -n "$NAMESPACE"[0m
2026-02-25T17:41:05.0399006Z [36;1m    exit 1[0m
2026-02-25T17:41:05.0399143Z [36;1m  fi[0m
2026-02-25T17:41:05.0399412Z [36;1m[0m
2026-02-25T17:41:05.0399654Z [36;1m  # 1) check follower pods[0m
2026-02-25T17:41:05.0399895Z [36;1m  ALL_FOLLOWERS_READY=true[0m
2026-02-25T17:41:05.0400086Z [36;1m  for ((i=1; i<SIZE; i++)); do[0m
2026-02-25T17:41:05.0400274Z [36;1m    POD="${POD_PREFIX}-${i}"[0m
2026-02-25T17:41:05.0400637Z [36;1m    PHASE=$(kubectl get pod "$POD" -n "$NAMESPACE" -o jsonpath='{.status.phase}' 2>/dev/null || echo "NotFound")[0m
2026-02-25T17:41:05.0401176Z [36;1m    READY=$(kubectl get pod "$POD" -n "$NAMESPACE" -o jsonpath='{.status.containerStatuses[*].ready}' 2>/dev/null)[0m
2026-02-25T17:41:05.0401666Z [36;1m[0m
2026-02-25T17:41:05.0401847Z [36;1m    echo "Follower [$POD] phase=$PHASE ready=$READY"[0m
2026-02-25T17:41:05.0402192Z [36;1m[0m
2026-02-25T17:41:05.0402366Z [36;1m    if [[ "$PHASE" != "Running" || "$READY" != "true" ]]; then[0m
2026-02-25T17:41:05.0402634Z [36;1m      echo "Follower [$POD] not Ready yet..."[0m
2026-02-25T17:41:05.0402860Z [36;1m      ALL_FOLLOWERS_READY=false[0m
2026-02-25T17:41:05.0403040Z [36;1m      break[0m
2026-02-25T17:41:05.0403186Z [36;1m    fi[0m
2026-02-25T17:41:05.0403320Z [36;1m  done[0m
2026-02-25T17:41:05.0403442Z [36;1m[0m
2026-02-25T17:41:05.0403574Z [36;1m  # 2) check leader pod[0m
2026-02-25T17:41:05.0403948Z [36;1m  LEADER_PHASE=$(kubectl get pod "$LEADER_POD" -n "$NAMESPACE" -o jsonpath='{.status.phase}' 2>/dev/null || echo "NotFound")[0m
2026-02-25T17:41:05.0404523Z [36;1m  LEADER_READY=$(kubectl get pod "$LEADER_POD" -n "$NAMESPACE" -o jsonpath='{.status.containerStatuses[*].ready}' 2>/dev/null)[0m
2026-02-25T17:41:05.0404903Z [36;1m[0m
2026-02-25T17:41:05.0405113Z [36;1m  echo "Leader [$LEADER_POD] phase=$LEADER_PHASE ready=$LEADER_READY"[0m
2026-02-25T17:41:05.0405364Z [36;1m[0m
2026-02-25T17:41:05.0405564Z [36;1m  if [[ "$LEADER_PHASE" != "Running" || "$LEADER_READY" != "true" ]]; then[0m
2026-02-25T17:41:05.0405837Z [36;1m    echo "Leader not Ready yet..."[0m
2026-02-25T17:41:05.0406030Z [36;1m    ALL_FOLLOWERS_READY=false[0m
2026-02-25T17:41:05.0406204Z [36;1m  fi[0m
2026-02-25T17:41:05.0406324Z [36;1m[0m
2026-02-25T17:41:05.0406483Z [36;1m  if [[ "$ALL_FOLLOWERS_READY" == "true" ]]; then[0m
2026-02-25T17:41:05.0406796Z [36;1m    echo "All follower pods and leader pod are Running and Ready â€” continuing."[0m
2026-02-25T17:41:05.0407071Z [36;1m    break[0m
2026-02-25T17:41:05.0407211Z [36;1m  fi[0m
2026-02-25T17:41:05.0407338Z [36;1m[0m
2026-02-25T17:41:05.0407454Z [36;1m  sleep 2[0m
2026-02-25T17:41:05.0407591Z [36;1mdone[0m
2026-02-25T17:41:05.0407853Z shell: bash -el {0}
2026-02-25T17:41:05.0407989Z env:
2026-02-25T17:41:05.0408324Z   FAIL_TAG: FAIL_TAG_DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-02-25T17:41:05.0408544Z ##[endgroup]
2026-02-25T17:41:05.0683061Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-25T17:41:05.0683873Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-25T17:41:05.0684147Z ##[endgroup]
2026-02-25T17:41:05.4441893Z (node:670) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-25T17:41:05.4442653Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-25T17:41:05.9650352Z Waiting for Pods in namespace [vllm-project] to become Running and Ready (timeout 1200s)...
2026-02-25T17:41:06.0795608Z Follower [vllm-0-1] phase=Pending ready=
2026-02-25T17:41:06.0795857Z Follower [vllm-0-1] not Ready yet...
2026-02-25T17:41:06.1930964Z Leader [vllm-0] phase=Pending ready=
2026-02-25T17:41:06.1931230Z Leader not Ready yet...
2026-02-25T17:41:08.3048653Z Follower [vllm-0-1] phase=Pending ready=
2026-02-25T17:41:08.3048934Z Follower [vllm-0-1] not Ready yet...
2026-02-25T17:41:08.4170370Z Leader [vllm-0] phase=Pending ready=
2026-02-25T17:41:08.4170592Z Leader not Ready yet...
2026-02-25T17:41:10.5324250Z Follower [vllm-0-1] phase=Pending ready=
2026-02-25T17:41:10.5324521Z Follower [vllm-0-1] not Ready yet...
2026-02-25T17:41:10.6509176Z Leader [vllm-0] phase=Pending ready=
2026-02-25T17:41:10.6509382Z Leader not Ready yet...
2026-02-25T17:41:12.7730269Z Follower [vllm-0-1] phase=Pending ready=
2026-02-25T17:41:12.7730546Z Follower [vllm-0-1] not Ready yet...
2026-02-25T17:41:12.8961009Z Leader [vllm-0] phase=Pending ready=
2026-02-25T17:41:12.8961220Z Leader not Ready yet...
2026-02-25T17:41:15.0061437Z Follower [vllm-0-1] phase=Pending ready=
2026-02-25T17:41:15.0061732Z Follower [vllm-0-1] not Ready yet...
2026-02-25T17:41:15.1236238Z Leader [vllm-0] phase=Pending ready=
2026-02-25T17:41:15.1236667Z Leader not Ready yet...
2026-02-25T17:41:17.2332238Z Follower [vllm-0-1] phase=Pending ready=
2026-02-25T17:41:17.2332631Z Follower [vllm-0-1] not Ready yet...
2026-02-25T17:41:17.3413498Z Leader [vllm-0] phase=Pending ready=
2026-02-25T17:41:17.3413709Z Leader not Ready yet...
2026-02-25T17:41:19.4506711Z Follower [vllm-0-1] phase=Pending ready=false
2026-02-25T17:41:19.4506986Z Follower [vllm-0-1] not Ready yet...
2026-02-25T17:41:19.5804922Z Leader [vllm-0] phase=Pending ready=false
2026-02-25T17:41:19.5805130Z Leader not Ready yet...
2026-02-25T17:41:21.6941747Z Follower [vllm-0-1] phase=Running ready=true
2026-02-25T17:41:21.8089253Z Leader [vllm-0] phase=Running ready=true
2026-02-25T17:41:21.8089852Z All follower pods and leader pod are Running and Ready â€” continuing.
2026-02-25T17:41:22.2422360Z ##[group]Run set -euo pipefail
2026-02-25T17:41:22.2422608Z [36;1mset -euo pipefail[0m
2026-02-25T17:41:22.2422767Z [36;1m[0m
2026-02-25T17:41:22.2422951Z [36;1msize="2"[0m
2026-02-25T17:41:22.2423105Z [36;1mpids=()[0m
2026-02-25T17:41:22.2423237Z [36;1m[0m
2026-02-25T17:41:22.2423371Z [36;1mcleanup() {[0m
2026-02-25T17:41:22.2423557Z [36;1m  echo "Cleaning up background log streams..."[0m
2026-02-25T17:41:22.2423792Z [36;1m  for pid in "${pids[@]}"; do[0m
2026-02-25T17:41:22.2424087Z [36;1m    kill "$pid" 2>/dev/null || true[0m
2026-02-25T17:41:22.2424272Z [36;1m  done[0m
2026-02-25T17:41:22.2424410Z [36;1m}[0m
2026-02-25T17:41:22.2424542Z [36;1mtrap cleanup EXIT[0m
2026-02-25T17:41:22.2424704Z [36;1m[0m
2026-02-25T17:41:22.2424851Z [36;1mfor i in $(seq 1 $((size - 1))); do[0m
2026-02-25T17:41:22.2425037Z [36;1m  POD="vllm-0-${i}"[0m
2026-02-25T17:41:22.2425195Z [36;1m[0m
2026-02-25T17:41:22.2425407Z [36;1m  echo "==== Collecting logs from worker pod: $POD ===="[0m
2026-02-25T17:41:22.2425683Z [36;1m  kubectl logs -f "$POD" -n "$NAMESPACE" \[0m
2026-02-25T17:41:22.2425904Z [36;1m    > "/tmp/${POD}_logs.txt" 2>&1 &[0m
2026-02-25T17:41:22.2426089Z [36;1m[0m
2026-02-25T17:41:22.2426209Z [36;1m  pids+=($!)[0m
2026-02-25T17:41:22.2426357Z [36;1mdone[0m
2026-02-25T17:41:22.2426485Z [36;1m[0m
2026-02-25T17:41:22.2426667Z [36;1mecho "==== Streaming logs from leader pod: $LEADER_POD ===="[0m
2026-02-25T17:41:22.2426940Z [36;1mecho "Looking for logs containing: $FAIL_TAG"[0m
2026-02-25T17:41:22.2427141Z [36;1m[0m
2026-02-25T17:41:22.2427362Z [36;1mkubectl logs -f "$LEADER_POD" -n "$NAMESPACE" | while IFS= read -r line; do[0m
2026-02-25T17:41:22.2427646Z [36;1m  echo "$line"[0m
2026-02-25T17:41:22.2427832Z [36;1m  if echo "$line" | grep -q "$FAIL_TAG"; then[0m
2026-02-25T17:41:22.2428030Z [36;1m    exit 1[0m
2026-02-25T17:41:22.2428170Z [36;1m  fi[0m
2026-02-25T17:41:22.2428294Z [36;1mdone[0m
2026-02-25T17:41:22.2428583Z shell: bash -el {0}
2026-02-25T17:41:22.2428726Z env:
2026-02-25T17:41:22.2428908Z   FAIL_TAG: FAIL_TAG_DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-02-25T17:41:22.2429136Z ##[endgroup]
2026-02-25T17:41:22.2531116Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-25T17:41:22.2531744Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-25T17:41:22.2531963Z ##[endgroup]
2026-02-25T17:41:22.6156764Z (node:764) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-25T17:41:22.6157433Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-25T17:41:23.1662808Z ==== Collecting logs from worker pod: vllm-0-1 ====
2026-02-25T17:41:23.1663790Z ==== Streaming logs from leader pod: vllm-0 ====
2026-02-25T17:41:23.1664140Z Looking for logs containing: FAIL_TAG_DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-02-25T17:41:23.2428322Z /usr/local/Ascend/ascend-toolkit/set_env.sh: line 31: CMAKE_PREFIX_PATH: unbound variable
2026-02-25T17:41:23.2438295Z ====> Check NPU info
2026-02-25T17:41:23.2448422Z +------------------------------------------------------------------------------------------------+
2026-02-25T17:41:23.2458702Z | npu-smi 25.5.0                   Version: 25.5.0                                               |
2026-02-25T17:41:23.2468771Z +---------------------------+---------------+----------------------------------------------------+
2026-02-25T17:41:23.2479246Z | NPU   Name                | Health        | Power(W)    Temp(C)           Hugepages-Usage(page)|
2026-02-25T17:41:23.2489477Z | Chip  Phy-ID              | Bus-Id        | AICore(%)   Memory-Usage(MB)  HBM-Usage(MB)        |
2026-02-25T17:41:23.2499968Z +===========================+===============+====================================================+
2026-02-25T17:41:23.2509872Z | 0     Ascend910           | OK            | 162.1       38                0    / 0             |
2026-02-25T17:41:23.2520088Z | 0     0                   | 0000:9D:00.0  | 0           0    / 0          3147 / 65536         |
2026-02-25T17:41:23.2530528Z +------------------------------------------------------------------------------------------------+
2026-02-25T17:41:23.2539554Z | 0     Ascend910           | OK            | -           37                0    / 0             |
2026-02-25T17:41:23.2548732Z | 1     1                   | 0000:9F:00.0  | 0           0    / 0          2890 / 65536         |
2026-02-25T17:41:23.2558531Z +===========================+===============+====================================================+
2026-02-25T17:41:23.2568855Z | 1     Ascend910           | OK            | 163.8       36                0    / 0             |
2026-02-25T17:41:23.2578915Z | 0     2                   | 0000:99:00.0  | 0           0    / 0          3157 / 65536         |
2026-02-25T17:41:23.2588796Z +------------------------------------------------------------------------------------------------+
2026-02-25T17:41:23.2598011Z | 1     Ascend910           | OK            | -           37                0    / 0             |
2026-02-25T17:41:23.2607587Z | 1     3                   | 0000:9B:00.0  | 0           0    / 0          2877 / 65536         |
2026-02-25T17:41:23.2622205Z +===========================+===============+====================================================+
2026-02-25T17:41:23.2628196Z | 2     Ascend910           | OK            | 163.4       37                0    / 0             |
2026-02-25T17:41:23.2637996Z | 0     4                   | 0000:95:00.0  | 0           0    / 0          3159 / 65536         |
2026-02-25T17:41:23.2648112Z +------------------------------------------------------------------------------------------------+
2026-02-25T17:41:23.2658193Z | 2     Ascend910           | OK            | -           37                0    / 0             |
2026-02-25T17:41:23.2669146Z | 1     5                   | 0000:97:00.0  | 0           0    / 0          2879 / 65536         |
2026-02-25T17:41:23.2678223Z +===========================+===============+====================================================+
2026-02-25T17:41:23.2688771Z | 3     Ascend910           | OK            | 168.0       37                0    / 0             |
2026-02-25T17:41:23.2699179Z | 0     6                   | 0000:91:00.0  | 0           0    / 0          3160 / 65536         |
2026-02-25T17:41:23.2708982Z +------------------------------------------------------------------------------------------------+
2026-02-25T17:41:23.2718288Z | 3     Ascend910           | OK            | -           37                0    / 0             |
2026-02-25T17:41:23.2727919Z | 1     7                   | 0000:93:00.0  | 0           0    / 0          2878 / 65536         |
2026-02-25T17:41:23.2737866Z +===========================+===============+====================================================+
2026-02-25T17:41:23.2747303Z | 4     Ascend910           | OK            | 162.3       38                0    / 0             |
2026-02-25T17:41:23.2757003Z | 0     8                   | 0000:8D:00.0  | 0           0    / 0          3157 / 65536         |
2026-02-25T17:41:23.2766810Z +------------------------------------------------------------------------------------------------+
2026-02-25T17:41:23.2777524Z | 4     Ascend910           | OK            | -           37                0    / 0             |
2026-02-25T17:41:23.2787219Z | 1     9                   | 0000:8F:00.0  | 0           0    / 0          2879 / 65536         |
2026-02-25T17:41:23.2796386Z +===========================+===============+====================================================+
2026-02-25T17:41:23.2806877Z | 5     Ascend910           | OK            | 162.6       38                0    / 0             |
2026-02-25T17:41:23.2816931Z | 0     10                  | 0000:89:00.0  | 0           0    / 0          3147 / 65536         |
2026-02-25T17:41:23.2826811Z +------------------------------------------------------------------------------------------------+
2026-02-25T17:41:23.2836218Z | 5     Ascend910           | OK            | -           38                0    / 0             |
2026-02-25T17:41:23.2845556Z | 1     11                  | 0000:8B:00.0  | 0           0    / 0          2892 / 65536         |
2026-02-25T17:41:23.5268031Z +===========================+===============+====================================================+
2026-02-25T17:41:23.5276772Z | 6     Ascend910           | OK            | 159.4       36                0    / 0             |
2026-02-25T17:41:23.5285426Z | 0     12                  | 0000:85:00.0  | 0           0    / 0          3147 / 65536         |
2026-02-25T17:41:23.5295477Z +------------------------------------------------------------------------------------------------+
2026-02-25T17:41:23.5304548Z | 6     Ascend910           | OK            | -           37                0    / 0             |
2026-02-25T17:41:23.5313819Z | 1     13                  | 0000:87:00.0  | 0           0    / 0          2893 / 65536         |
2026-02-25T17:41:23.5323134Z +===========================+===============+====================================================+
2026-02-25T17:41:23.5333517Z | 7     Ascend910           | OK            | 166.1       37                0    / 0             |
2026-02-25T17:41:23.5342818Z | 0     14                  | 0000:81:00.0  | 0           0    / 0          3152 / 65536         |
2026-02-25T17:41:23.5352252Z +------------------------------------------------------------------------------------------------+
2026-02-25T17:41:23.5361575Z | 7     Ascend910           | OK            | -           39                0    / 0             |
2026-02-25T17:41:23.5370580Z | 1     15                  | 0000:83:00.0  | 0           0    / 0          2877 / 65536         |
2026-02-25T17:41:23.5380700Z +===========================+===============+====================================================+
2026-02-25T17:41:23.5390365Z +---------------------------+---------------+----------------------------------------------------+
2026-02-25T17:41:23.5399534Z | NPU     Chip              | Process id    | Process name             | Process memory(MB)      |
2026-02-25T17:41:23.5409122Z +===========================+===============+====================================================+
2026-02-25T17:41:23.5418638Z | No running processes found in NPU 0                                                            |
2026-02-25T17:41:23.5427293Z +===========================+===============+====================================================+
2026-02-25T17:41:23.5436945Z | No running processes found in NPU 1                                                            |
2026-02-25T17:41:23.5446586Z +===========================+===============+====================================================+
2026-02-25T17:41:23.5457073Z | No running processes found in NPU 2                                                            |
2026-02-25T17:41:23.5467192Z +===========================+===============+====================================================+
2026-02-25T17:41:23.5476646Z | No running processes found in NPU 3                                                            |
2026-02-25T17:41:23.5487157Z +===========================+===============+====================================================+
2026-02-25T17:41:23.5497479Z | No running processes found in NPU 4                                                            |
2026-02-25T17:41:23.5506888Z +===========================+===============+====================================================+
2026-02-25T17:41:23.5516434Z | No running processes found in NPU 5                                                            |
2026-02-25T17:41:23.5525812Z +===========================+===============+====================================================+
2026-02-25T17:41:23.5535238Z | No running processes found in NPU 6                                                            |
2026-02-25T17:41:23.5545134Z +===========================+===============+====================================================+
2026-02-25T17:41:23.5556066Z | No running processes found in NPU 7                                                            |
2026-02-25T17:41:23.5564343Z +===========================+===============+====================================================+
2026-02-25T17:41:23.5573204Z package_name=Ascend-cann-toolkit
2026-02-25T17:41:23.5583271Z version=8.5.0
2026-02-25T17:41:23.5591949Z innerversion=V100R001C25SPC001B232
2026-02-25T17:41:23.5601840Z compatible_version=[V100R001C15],[V100R001C18],[V100R001C19],[V100R001C20],[V100R001C21],[V100R001C23]
2026-02-25T17:41:23.5610315Z arch=aarch64
2026-02-25T17:41:23.5619864Z os=linux
2026-02-25T17:41:23.5629349Z path=/usr/local/Ascend/cann-8.5.0
2026-02-25T17:41:23.5639124Z ====> Configure mirrors and git proxy
2026-02-25T17:41:23.9155610Z Writing to /root/.config/pip/pip.conf
2026-02-25T17:41:23.9500768Z Installed vLLM-related Python packages:
2026-02-25T17:41:24.9291744Z ais_bench_benchmark               3.0.20250930                /vllm-workspace/vllm-ascend/benchmark
2026-02-25T17:41:24.9299506Z vllm                              0.15.0+empty                /vllm-workspace/vllm
2026-02-25T17:41:24.9310964Z vllm_ascend                       0.14.0rc2.dev189+ge3927cc8f /vllm-workspace/vllm-ascend
2026-02-25T17:41:24.9320757Z 
2026-02-25T17:41:24.9331539Z ============================
2026-02-25T17:41:24.9341071Z vLLM Git information
2026-02-25T17:41:24.9348989Z ============================
2026-02-25T17:41:24.9398254Z Branch:      HEAD
2026-02-25T17:41:24.9485128Z Commit hash: f176443446f659dbab5315e056e605d8984fd976
2026-02-25T17:41:24.9533933Z Author:      TJian <tunjian.tan@embeddedllm.com>
2026-02-25T17:41:24.9559701Z Date:        2026-01-29 14:45:42 +0800
2026-02-25T17:41:24.9586439Z Message:     [Release] [CI] Optim release pipeline (#33156)
2026-02-25T17:41:24.9608944Z Tags:        v0.15.0
2026-02-25T17:41:24.9640844Z Remote:      origin	https://ghfast.top/https://github.com/vllm-project/vllm.git (fetch)
2026-02-25T17:41:24.9649416Z 
2026-02-25T17:41:24.9660919Z 
2026-02-25T17:41:24.9670382Z ============================
2026-02-25T17:41:24.9679357Z vLLM-Ascend Git information
2026-02-25T17:41:24.9688829Z ============================
2026-02-25T17:41:24.9705626Z Branch:      main
2026-02-25T17:41:24.9726445Z Commit hash: e3927cc8f57ee9bdc58db1d0365dfb6af9375b02
2026-02-25T17:41:24.9790547Z Author:      bowenli <125331496+Bowen-Leee@users.noreply.github.com>
2026-02-25T17:41:24.9816650Z Date:        2026-02-25 17:50:57 +0800
2026-02-25T17:41:24.9840302Z Message:     [Bugfix] fix bug for mtp (#6514)
2026-02-25T17:41:25.0130299Z Tags:        
2026-02-25T17:41:25.0139930Z Remote:      origin	https://ghfast.top/https://github.com/vllm-project/vllm-ascend (fetch)
2026-02-25T17:41:25.0148180Z 
2026-02-25T17:41:25.0158333Z ====> Check triton ascend info
2026-02-25T17:41:25.3344158Z Ubuntu clang version 15.0.7
2026-02-25T17:41:25.3351413Z Target: aarch64-unknown-linux-gnu
2026-02-25T17:41:25.3360679Z Thread model: posix
2026-02-25T17:41:25.3370131Z InstalledDir: /usr/bin
2026-02-25T17:41:25.3379054Z Found candidate GCC installation: /usr/bin/../lib/gcc/aarch64-linux-gnu/11
2026-02-25T17:41:25.3389517Z Selected GCC installation: /usr/bin/../lib/gcc/aarch64-linux-gnu/11
2026-02-25T17:41:25.3398221Z Candidate multilib: .;@m64
2026-02-25T17:41:25.3406644Z Selected multilib: .;@m64
2026-02-25T17:41:25.3466511Z /usr/local/Ascend/cann-8.5.0/tools/bishengir/bin/bishengir-compile
2026-02-25T17:41:25.9651388Z Name: triton-ascend
2026-02-25T17:41:25.9651573Z Version: 3.2.0
2026-02-25T17:41:25.9651845Z Summary: A language and compiler for custom Deep Learning operations on Ascend hardwares
2026-02-25T17:41:25.9652735Z Home-page: https://gitcode.com/Ascend/triton-ascend/
2026-02-25T17:41:25.9660206Z Author: 
2026-02-25T17:41:25.9669709Z Author-email: 
2026-02-25T17:41:25.9678986Z License: 
2026-02-25T17:41:25.9689305Z Location: /usr/local/python3.11.14/lib/python3.11/site-packages
2026-02-25T17:41:25.9699043Z Requires: 
2026-02-25T17:41:25.9709364Z Required-by: vllm_ascend
2026-02-25T17:41:43.4911295Z INFO 02-25 17:41:43 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-25T17:41:43.4920234Z INFO 02-25 17:41:43 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-25T17:41:43.4930736Z INFO 02-25 17:41:43 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-25T17:41:43.5411555Z INFO 02-25 17:41:43 [__init__.py:217] Platform plugin ascend is activated
2026-02-25T17:41:49.7020778Z ============================= test session starts ==============================
2026-02-25T17:41:49.7031650Z platform linux -- Python 3.11.14, pytest-8.4.2, pluggy-1.6.0 -- /usr/local/python3.11.14/bin/python3
2026-02-25T17:41:49.7040996Z cachedir: .pytest_cache
2026-02-25T17:41:49.7051057Z rootdir: /vllm-workspace/vllm-ascend
2026-02-25T17:41:49.7060805Z configfile: pyproject.toml
2026-02-25T17:41:49.7071606Z plugins: cov-7.0.0, mock-3.15.1, asyncio-1.3.0, anyio-4.12.1
2026-02-25T17:41:49.7081667Z asyncio: mode=Mode.STRICT, debug=False, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function
2026-02-25T17:41:50.4878669Z collecting ... collected 1 item
2026-02-25T17:41:50.4885298Z 
2026-02-25T17:41:50.4898067Z [2026-02-25 17:41:50] INFO multi_node_config.py:294: Loading config yaml: tests/e2e/nightly/multi_node/config/DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-02-25T17:41:50.4949416Z [2026-02-25 17:41:50] INFO multi_node_config.py:351: Resolving cluster IPs via DNS...
2026-02-25T17:41:50.5006155Z [2026-02-25 17:41:50] INFO multi_node_config.py:212: Node 0 envs: {'HCCL_OP_EXPANSION_MODE': 'AIV', 'VLLM_USE_MODELSCOPE': 'True', 'HCCL_BUFFSIZE': '1024', 'SERVER_PORT': '8080', 'OMP_PROC_BIND': 'False', 'OMP_NUM_THREADS': '1', 'PYTORCH_NPU_ALLOC_CONF': 'expandable_segments:True', 'VLLM_ASCEND_ENABLE_FLASHCOMM1': '1', 'ASCEND_A3_EBA_ENABLE': '1', 'HCCL_IF_IP': '10.0.0.169', 'HCCL_SOCKET_IFNAME': 'eth0', 'GLOO_SOCKET_IFNAME': 'eth0', 'TP_SOCKET_IFNAME': 'eth0', 'LOCAL_IP': '10.0.0.169', 'NIC_NAME': 'eth0', 'MASTER_IP': '10.0.0.169'}
2026-02-25T17:41:50.5026995Z [2026-02-25 17:41:50] INFO multi_node_config.py:137: Not launching proxy on non-master node
2026-02-25T17:41:50.5040807Z [2026-02-25 17:41:50] INFO conftest.py:241: Starting server with command: vllm serve vllm-ascend/DeepSeek-V3.2-W8A8 --host 0.0.0.0 --port 8080 --data-parallel-size 4 --data-parallel-size-local 2 --data-parallel-address 10.0.0.169 --data-parallel-rpc-port 13399 --tensor-parallel-size 8 --quantization ascend --seed 1024 --enable-expert-parallel --max-num-seqs 16 --max-model-len 8192 --max-num-batched-tokens 4096 --no-enable-prefix-caching --gpu-memory-utilization 0.85 --trust-remote-code --speculative-config {"num_speculative_tokens": 2, "method":"deepseek_mtp"} --compilation-config {"cudagraph_capture_sizes": [3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45, 48], "cudagraph_mode": "FULL_DECODE_ONLY"} --additional-config {"layer_sharding": ["q_b_proj", "o_proj"]} --tokenizer-mode deepseek_v32 --reasoning-parser deepseek_v3
2026-02-25T17:41:54.7161282Z tests/e2e/nightly/multi_node/scripts/test_multi_node.py::test_multi_node INFO 02-25 17:41:54 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-25T17:41:54.7165658Z INFO 02-25 17:41:54 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-25T17:41:54.7175409Z INFO 02-25 17:41:54 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-25T17:41:54.7266896Z INFO 02-25 17:41:54 [__init__.py:217] Platform plugin ascend is activated
2026-02-25T17:42:00.9983983Z 2026-02-25 17:42:00,996 - 138 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-25T17:42:01.0314035Z INFO 02-25 17:42:01 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-25T17:42:01.1748446Z INFO 02-25 17:42:01 [serve.py:100] Defaulting api_server_count to data_parallel_size (4).
2026-02-25T17:42:01.1768078Z INFO 02-25 17:42:01 [utils.py:325] 
2026-02-25T17:42:01.1778813Z INFO 02-25 17:42:01 [utils.py:325]        â–ˆ     â–ˆ     â–ˆâ–„   â–„â–ˆ
2026-02-25T17:42:01.1792111Z INFO 02-25 17:42:01 [utils.py:325]  â–„â–„ â–„â–ˆ â–ˆ     â–ˆ     â–ˆ â–€â–„â–€ â–ˆ  version 0.15.0
2026-02-25T17:42:01.1798281Z INFO 02-25 17:42:01 [utils.py:325]   â–ˆâ–„â–ˆâ–€ â–ˆ     â–ˆ     â–ˆ     â–ˆ  model   vllm-ascend/DeepSeek-V3.2-W8A8
2026-02-25T17:42:01.1807954Z INFO 02-25 17:42:01 [utils.py:325]    â–€â–€  â–€â–€â–€â–€â–€ â–€â–€â–€â–€â–€ â–€     â–€
2026-02-25T17:42:01.1818085Z INFO 02-25 17:42:01 [utils.py:325] 
2026-02-25T17:42:01.1837105Z INFO 02-25 17:42:01 [utils.py:261] non-default args: {'model_tag': 'vllm-ascend/DeepSeek-V3.2-W8A8', 'api_server_count': 4, 'host': '0.0.0.0', 'port': 8080, 'model': 'vllm-ascend/DeepSeek-V3.2-W8A8', 'tokenizer_mode': 'deepseek_v32', 'trust_remote_code': True, 'seed': 1024, 'max_model_len': 8192, 'quantization': 'ascend', 'reasoning_parser': 'deepseek_v3', 'tensor_parallel_size': 8, 'data_parallel_size': 4, 'data_parallel_size_local': 2, 'data_parallel_address': '10.0.0.169', 'data_parallel_rpc_port': 13399, 'enable_expert_parallel': True, 'gpu_memory_utilization': 0.85, 'enable_prefix_caching': False, 'max_num_batched_tokens': 4096, 'max_num_seqs': 16, 'speculative_config': {'num_speculative_tokens': 2, 'method': 'deepseek_mtp'}, 'compilation_config': {'level': None, 'mode': None, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'vllm_ascend.compilation.compiler_interface.AscendCompiler', 'custom_ops': [], 'splitting_ops': None, 'compile_mm_encoder': False, 'compile_sizes': None, 'compile_ranges_split_points': None, 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_DECODE_ONLY: (2, 0)>, 'cudagraph_num_of_warmups': 0, 'cudagraph_capture_sizes': [3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45, 48], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': None, 'pass_config': {}, 'max_cudagraph_capture_size': None, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>, 'evaluate_guards': False, 'assume_32_bit_indexing': True}, 'local_cache_dir': None}, 'additional_config': {'layer_sharding': ['q_b_proj', 'o_proj']}}
2026-02-25T17:42:01.2253719Z 2026-02-25 17:42:01,224 - modelscope - WARNING - We can not confirm the cached file is for revision: master
2026-02-25T17:42:01.2311364Z INFO 02-25 17:42:01 [arg_utils.py:602] HF_HUB_OFFLINE is True, replace model_id [vllm-ascend/DeepSeek-V3.2-W8A8] to model_path [/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8]
2026-02-25T17:42:01.2325054Z The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-25T17:42:01.2403914Z The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-25T17:42:01.2417862Z The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-25T17:42:01.2430129Z You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-25T17:42:01.2635485Z INFO 02-25 17:42:01 [model.py:541] Resolved architecture: DeepseekV32ForCausalLM
2026-02-25T17:42:01.2644555Z INFO 02-25 17:42:01 [model.py:1561] Using max model len 8192
2026-02-25T17:42:01.5346625Z WARNING 02-25 17:42:01 [speculative.py:270] method `deepseek_mtp` is deprecated and replaced with mtp.
2026-02-25T17:42:01.5382681Z The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-25T17:42:01.5391464Z The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-25T17:42:01.5400756Z You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-25T17:42:11.0692392Z INFO 02-25 17:42:11 [model.py:541] Resolved architecture: DeepSeekMTPModel
2026-02-25T17:42:11.0716541Z INFO 02-25 17:42:11 [model.py:1561] Using max model len 163840
2026-02-25T17:42:11.0726562Z WARNING 02-25 17:42:11 [speculative.py:388] Enabling num_speculative_tokens > 1 will runmultiple times of forward on same MTP layer,which may result in lower acceptance rate
2026-02-25T17:42:11.0736919Z INFO 02-25 17:42:11 [scheduler.py:226] Chunked prefill is enabled with max_num_batched_tokens=4096.
2026-02-25T17:42:11.7131497Z INFO 02-25 17:42:11 [vllm.py:624] Asynchronous scheduling is enabled.
2026-02-25T17:42:11.7139961Z INFO 02-25 17:42:11 [vllm.py:634] Disabling NCCL for DP synchronization when using async scheduling.
2026-02-25T17:42:11.7152263Z WARNING 02-25 17:42:11 [platform.py:730] Speculative quantization is set but Ascend automatically uses the main model's quantization method. Resetting to None.
2026-02-25T17:42:11.7161567Z WARNING 02-25 17:42:11 [platform.py:771] Ignored parameter 'use_trtllm_ragged_deepseek_prefill'. This is a GPU-specific feature not supported on Ascend. Resetting to False.
2026-02-25T17:42:11.7171488Z INFO 02-25 17:42:11 [ascend_config.py:412] Dynamic EPLB is False
2026-02-25T17:42:11.7180668Z INFO 02-25 17:42:11 [ascend_config.py:413] The number of redundant experts is 0
2026-02-25T17:42:11.7191033Z INFO 02-25 17:42:11 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-25T17:42:11.7201011Z WARNING 02-25 17:42:11 [vllm.py:1062] Batch sizes [3, 6, 9, 12, 15, 18, 21, 27, 30, 33, 36, 39, 42, 45] are removed because they are not multiple of tp_size 8 when sequence parallelism is enabled
2026-02-25T17:42:11.7211348Z INFO 02-25 17:42:11 [platform.py:318] FULL_DECODE_ONLY compilation enabled on NPU. use_inductor not supported - using only ACL Graph mode
2026-02-25T17:42:11.7221499Z WARNING 02-25 17:42:11 [platform.py:335] [91m
2026-02-25T17:42:11.7230481Z WARNING 02-25 17:42:11 [platform.py:335]             **********************************************************************************
2026-02-25T17:42:11.7240281Z WARNING 02-25 17:42:11 [platform.py:335]             * WARNING: You have enabled the *full graph* feature.
2026-02-25T17:42:11.7251034Z WARNING 02-25 17:42:11 [platform.py:335]             * This is an early experimental stage and may involve various unknown issues.
2026-02-25T17:42:11.7260780Z WARNING 02-25 17:42:11 [platform.py:335]             * A known problem is that capturing too many batch sizes can lead to OOM
2026-02-25T17:42:11.7270394Z WARNING 02-25 17:42:11 [platform.py:335]             * (Out of Memory) errors or inference hangs. If you encounter such issues,
2026-02-25T17:42:11.7280122Z WARNING 02-25 17:42:11 [platform.py:335]             * consider reducing `gpu_memory_utilization` or manually specifying a smaller
2026-02-25T17:42:11.7290545Z WARNING 02-25 17:42:11 [platform.py:335]             * batch size for graph capture.
2026-02-25T17:42:11.7300268Z WARNING 02-25 17:42:11 [platform.py:335]             * For more details, please refer to:
2026-02-25T17:42:11.7309657Z WARNING 02-25 17:42:11 [platform.py:335]             * https://docs.vllm.ai/en/stable/configuration/conserving_memory.html#reduce-cuda-graphs
2026-02-25T17:42:11.7319389Z WARNING 02-25 17:42:11 [platform.py:335]             **********************************************************************************[0m
2026-02-25T17:42:11.7330309Z WARNING 02-25 17:42:11 [platform.py:335]             
2026-02-25T17:42:11.7338795Z INFO 02-25 17:42:11 [platform.py:443] Set PYTORCH_NPU_ALLOC_CONF=expandable_segments:True
2026-02-25T17:42:11.7348438Z INFO 02-25 17:42:11 [utils.py:851] Started DP Coordinator process (PID: 158)
2026-02-25T17:42:16.0855103Z INFO 02-25 17:42:16 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-25T17:42:16.0866470Z INFO 02-25 17:42:16 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-25T17:42:16.0876524Z INFO 02-25 17:42:16 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-25T17:42:16.0923467Z INFO 02-25 17:42:16 [__init__.py:217] Platform plugin ascend is activated
2026-02-25T17:42:16.3036962Z INFO 02-25 17:42:16 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-25T17:42:16.3045179Z INFO 02-25 17:42:16 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-25T17:42:16.3055378Z INFO 02-25 17:42:16 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-25T17:42:16.3136549Z INFO 02-25 17:42:16 [__init__.py:217] Platform plugin ascend is activated
2026-02-25T17:42:25.5156898Z INFO 02-25 17:42:25 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-25T17:42:25.5168751Z INFO 02-25 17:42:25 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-25T17:42:25.5179057Z INFO 02-25 17:42:25 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-25T17:42:25.5222354Z INFO 02-25 17:42:25 [__init__.py:217] Platform plugin ascend is activated
2026-02-25T17:42:30.7500482Z INFO 02-25 17:42:30 [utils.py:218] Started 4 API server processes
2026-02-25T17:42:30.9384163Z [0;36m(EngineCore_DP1 pid=180)[0;0m 2026-02-25 17:42:30,935 - 180 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-25T17:42:30.9401447Z [0;36m(EngineCore_DP1 pid=180)[0;0m INFO 02-25 17:42:30 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-25T17:42:30.9612799Z [0;36m(EngineCore_DP0 pid=161)[0;0m 2026-02-25 17:42:30,960 - 161 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-25T17:42:30.9696566Z [0;36m(EngineCore_DP0 pid=161)[0;0m INFO 02-25 17:42:30 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-25T17:42:30.9721697Z [0;36m(EngineCore_DP0 pid=161)[0;0m INFO 02-25 17:42:30 [core.py:96] Initializing a V1 LLM engine (v0.15.0) with config: model='/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8', speculative_config=SpeculativeConfig(method='mtp', model='/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8', num_spec_tokens=2), tokenizer='/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8', skip_tokenizer_init=False, tokenizer_mode=deepseek_v32, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=8, pipeline_parallel_size=1, data_parallel_size=4, disable_custom_all_reduce=True, quantization=ascend, enforce_eager=False, enable_return_routed_experts=False, kv_cache_dtype=bfloat16, device_config=npu, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='deepseek_v3', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01, cudagraph_metrics=False, enable_layerwise_nvtx_tracing=False, enable_mfu_metrics=False, enable_mm_processor_stats=False, enable_logging_iteration_details=False), seed=1024, served_model_name=/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'vllm_ascend.compilation.compiler_interface.AscendCompiler', 'custom_ops': ['all'], 'splitting_ops': [], 'compile_mm_encoder': False, 'compile_sizes': [], 'compile_ranges_split_points': [4096], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_DECODE_ONLY: (2, 0)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [24, 48], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': True, 'fuse_act_quant': True, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 48, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>, 'evaluate_guards': False, 'assume_32_bit_indexing': True}, 'local_cache_dir': None}
2026-02-25T17:42:35.9395978Z INFO 02-25 17:42:35 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-25T17:42:35.9407010Z INFO 02-25 17:42:35 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-25T17:42:35.9417638Z INFO 02-25 17:42:35 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-25T17:42:35.9491154Z INFO 02-25 17:42:35 [__init__.py:217] Platform plugin ascend is activated
2026-02-25T17:42:36.0253621Z INFO 02-25 17:42:36 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-25T17:42:36.0262244Z INFO 02-25 17:42:36 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-25T17:42:36.0271493Z INFO 02-25 17:42:36 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-25T17:42:36.0327387Z INFO 02-25 17:42:36 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-25T17:42:36.0342768Z INFO 02-25 17:42:36 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-25T17:42:36.0355031Z INFO 02-25 17:42:36 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-25T17:42:36.0364867Z INFO 02-25 17:42:36 [__init__.py:217] Platform plugin ascend is activated
2026-02-25T17:42:36.0430358Z INFO 02-25 17:42:36 [__init__.py:217] Platform plugin ascend is activated
2026-02-25T17:42:36.0475291Z INFO 02-25 17:42:36 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-25T17:42:36.0486564Z INFO 02-25 17:42:36 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-25T17:42:36.0496795Z INFO 02-25 17:42:36 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-25T17:42:36.0590619Z INFO 02-25 17:42:36 [__init__.py:217] Platform plugin ascend is activated
2026-02-25T17:42:36.3088180Z INFO 02-25 17:42:36 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-25T17:42:36.3096241Z INFO 02-25 17:42:36 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-25T17:42:36.3105712Z INFO 02-25 17:42:36 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-25T17:42:36.3160891Z INFO 02-25 17:42:36 [__init__.py:217] Platform plugin ascend is activated
2026-02-25T17:42:36.3969306Z INFO 02-25 17:42:36 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-25T17:42:36.3978201Z INFO 02-25 17:42:36 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-25T17:42:36.3987345Z INFO 02-25 17:42:36 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-25T17:42:36.4052720Z INFO 02-25 17:42:36 [__init__.py:217] Platform plugin ascend is activated
2026-02-25T17:42:41.7241828Z 2026-02-25 17:42:41,722 - 209 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-25T17:42:41.7333605Z INFO 02-25 17:42:41 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-25T17:42:41.8754700Z 2026-02-25 17:42:41,874 - 208 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-25T17:42:41.8815017Z INFO 02-25 17:42:41 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-25T17:42:42.3333241Z [0;36m(ApiServer_0 pid=191)[0;0m 2026-02-25 17:42:42,331 - 191 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-25T17:42:42.3481331Z [0;36m(ApiServer_0 pid=191)[0;0m INFO 02-25 17:42:42 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-25T17:42:42.3741284Z [0;36m(ApiServer_0 pid=191)[0;0m 2026-02-25 17:42:42,372 - modelscope - WARNING - We can not confirm the cached file is for revision: master
2026-02-25T17:42:42.3796842Z [0;36m(ApiServer_0 pid=191)[0;0m INFO 02-25 17:42:42 [arg_utils.py:602] HF_HUB_OFFLINE is True, replace model_id [vllm-ascend/DeepSeek-V3.2-W8A8] to model_path [/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8]
2026-02-25T17:42:42.3878985Z [0;36m(ApiServer_3 pid=194)[0;0m 2026-02-25 17:42:42,386 - 194 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-25T17:42:42.4028824Z [0;36m(ApiServer_3 pid=194)[0;0m INFO 02-25 17:42:42 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-25T17:42:42.4184021Z [0;36m(ApiServer_3 pid=194)[0;0m 2026-02-25 17:42:42,417 - modelscope - WARNING - We can not confirm the cached file is for revision: master
2026-02-25T17:42:42.4242396Z [0;36m(ApiServer_3 pid=194)[0;0m INFO 02-25 17:42:42 [arg_utils.py:602] HF_HUB_OFFLINE is True, replace model_id [vllm-ascend/DeepSeek-V3.2-W8A8] to model_path [/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8]
2026-02-25T17:42:42.4792107Z [0;36m(ApiServer_0 pid=191)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-25T17:42:42.4813085Z [0;36m(ApiServer_0 pid=191)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-25T17:42:42.4835260Z [0;36m(ApiServer_0 pid=191)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-25T17:42:42.4845459Z [0;36m(ApiServer_0 pid=191)[0;0m You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-25T17:42:42.4925046Z [0;36m(ApiServer_0 pid=191)[0;0m INFO 02-25 17:42:42 [model.py:541] Resolved architecture: DeepseekV32ForCausalLM
2026-02-25T17:42:42.4939959Z [0;36m(ApiServer_0 pid=191)[0;0m INFO 02-25 17:42:42 [model.py:1561] Using max model len 8192
2026-02-25T17:42:42.5225657Z [0;36m(ApiServer_3 pid=194)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-25T17:42:42.5247029Z [0;36m(ApiServer_3 pid=194)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-25T17:42:42.5257309Z [0;36m(ApiServer_3 pid=194)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-25T17:42:42.5270379Z [0;36m(ApiServer_3 pid=194)[0;0m You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-25T17:42:42.5318361Z [0;36m(ApiServer_3 pid=194)[0;0m INFO 02-25 17:42:42 [model.py:541] Resolved architecture: DeepseekV32ForCausalLM
2026-02-25T17:42:42.5338583Z [0;36m(ApiServer_3 pid=194)[0;0m INFO 02-25 17:42:42 [model.py:1561] Using max model len 8192
2026-02-25T17:42:42.5694725Z [0;36m(ApiServer_1 pid=192)[0;0m 2026-02-25 17:42:42,568 - 192 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-25T17:42:42.5856365Z [0;36m(ApiServer_1 pid=192)[0;0m INFO 02-25 17:42:42 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-25T17:42:42.6011536Z [0;36m(ApiServer_1 pid=192)[0;0m 2026-02-25 17:42:42,600 - modelscope - WARNING - We can not confirm the cached file is for revision: master
2026-02-25T17:42:42.6020684Z [0;36m(ApiServer_0 pid=191)[0;0m WARNING 02-25 17:42:42 [speculative.py:270] method `deepseek_mtp` is deprecated and replaced with mtp.
2026-02-25T17:42:42.6035755Z [0;36m(ApiServer_0 pid=191)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-25T17:42:42.6045134Z [0;36m(ApiServer_0 pid=191)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-25T17:42:42.6056349Z [0;36m(ApiServer_0 pid=191)[0;0m You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-25T17:42:42.6136636Z [0;36m(ApiServer_0 pid=191)[0;0m INFO 02-25 17:42:42 [model.py:541] Resolved architecture: DeepSeekMTPModel
2026-02-25T17:42:42.6146533Z [0;36m(ApiServer_0 pid=191)[0;0m INFO 02-25 17:42:42 [model.py:1561] Using max model len 163840
2026-02-25T17:42:42.6156374Z [0;36m(ApiServer_0 pid=191)[0;0m WARNING 02-25 17:42:42 [speculative.py:388] Enabling num_speculative_tokens > 1 will runmultiple times of forward on same MTP layer,which may result in lower acceptance rate
2026-02-25T17:42:42.6165462Z [0;36m(ApiServer_0 pid=191)[0;0m INFO 02-25 17:42:42 [scheduler.py:226] Chunked prefill is enabled with max_num_batched_tokens=4096.
2026-02-25T17:42:42.6176162Z [0;36m(ApiServer_1 pid=192)[0;0m INFO 02-25 17:42:42 [arg_utils.py:602] HF_HUB_OFFLINE is True, replace model_id [vllm-ascend/DeepSeek-V3.2-W8A8] to model_path [/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8]
2026-02-25T17:42:42.6384791Z [0;36m(ApiServer_3 pid=194)[0;0m WARNING 02-25 17:42:42 [speculative.py:270] method `deepseek_mtp` is deprecated and replaced with mtp.
2026-02-25T17:42:42.6410441Z [0;36m(ApiServer_3 pid=194)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-25T17:42:42.6419934Z [0;36m(ApiServer_3 pid=194)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-25T17:42:42.6429673Z [0;36m(ApiServer_3 pid=194)[0;0m You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-25T17:42:42.6486439Z [0;36m(ApiServer_3 pid=194)[0;0m INFO 02-25 17:42:42 [model.py:541] Resolved architecture: DeepSeekMTPModel
2026-02-25T17:42:42.6496429Z [0;36m(ApiServer_3 pid=194)[0;0m INFO 02-25 17:42:42 [model.py:1561] Using max model len 163840
2026-02-25T17:42:42.6506429Z [0;36m(ApiServer_3 pid=194)[0;0m WARNING 02-25 17:42:42 [speculative.py:388] Enabling num_speculative_tokens > 1 will runmultiple times of forward on same MTP layer,which may result in lower acceptance rate
2026-02-25T17:42:42.6515462Z [0;36m(ApiServer_3 pid=194)[0;0m INFO 02-25 17:42:42 [scheduler.py:226] Chunked prefill is enabled with max_num_batched_tokens=4096.
2026-02-25T17:42:42.7151880Z [0;36m(ApiServer_1 pid=192)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-25T17:42:42.7173782Z [0;36m(ApiServer_1 pid=192)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-25T17:42:42.7184900Z [0;36m(ApiServer_1 pid=192)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-25T17:42:42.7197485Z [0;36m(ApiServer_1 pid=192)[0;0m You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-25T17:42:42.7271246Z [0;36m(ApiServer_1 pid=192)[0;0m INFO 02-25 17:42:42 [model.py:541] Resolved architecture: DeepseekV32ForCausalLM
2026-02-25T17:42:42.7280510Z [0;36m(ApiServer_1 pid=192)[0;0m INFO 02-25 17:42:42 [model.py:1561] Using max model len 8192
2026-02-25T17:42:42.7318203Z [0;36m(ApiServer_0 pid=191)[0;0m INFO 02-25 17:42:42 [vllm.py:624] Asynchronous scheduling is enabled.
2026-02-25T17:42:42.7329909Z [0;36m(ApiServer_0 pid=191)[0;0m INFO 02-25 17:42:42 [vllm.py:634] Disabling NCCL for DP synchronization when using async scheduling.
2026-02-25T17:42:42.7350510Z [0;36m(ApiServer_0 pid=191)[0;0m WARNING 02-25 17:42:42 [platform.py:730] Speculative quantization is set but Ascend automatically uses the main model's quantization method. Resetting to None.
2026-02-25T17:42:42.7360923Z [0;36m(ApiServer_0 pid=191)[0;0m WARNING 02-25 17:42:42 [platform.py:771] Ignored parameter 'use_trtllm_ragged_deepseek_prefill'. This is a GPU-specific feature not supported on Ascend. Resetting to False.
2026-02-25T17:42:42.7372351Z [0;36m(ApiServer_0 pid=191)[0;0m INFO 02-25 17:42:42 [ascend_config.py:412] Dynamic EPLB is False
2026-02-25T17:42:42.7384832Z [0;36m(ApiServer_0 pid=191)[0;0m INFO 02-25 17:42:42 [ascend_config.py:413] The number of redundant experts is 0
2026-02-25T17:42:42.7392277Z [0;36m(ApiServer_0 pid=191)[0;0m INFO 02-25 17:42:42 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-25T17:42:42.7402306Z [0;36m(ApiServer_0 pid=191)[0;0m WARNING 02-25 17:42:42 [vllm.py:1062] Batch sizes [3, 6, 9, 12, 15, 18, 21, 27, 30, 33, 36, 39, 42, 45] are removed because they are not multiple of tp_size 8 when sequence parallelism is enabled
2026-02-25T17:42:42.7412300Z [0;36m(ApiServer_0 pid=191)[0;0m INFO 02-25 17:42:42 [platform.py:318] FULL_DECODE_ONLY compilation enabled on NPU. use_inductor not supported - using only ACL Graph mode
2026-02-25T17:42:42.7421611Z [0;36m(ApiServer_0 pid=191)[0;0m WARNING 02-25 17:42:42 [platform.py:335] [91m
2026-02-25T17:42:42.7431889Z [0;36m(ApiServer_0 pid=191)[0;0m WARNING 02-25 17:42:42 [platform.py:335]             **********************************************************************************
2026-02-25T17:42:42.7441355Z [0;36m(ApiServer_0 pid=191)[0;0m WARNING 02-25 17:42:42 [platform.py:335]             * WARNING: You have enabled the *full graph* feature.
2026-02-25T17:42:42.7452216Z [0;36m(ApiServer_0 pid=191)[0;0m WARNING 02-25 17:42:42 [platform.py:335]             * This is an early experimental stage and may involve various unknown issues.
2026-02-25T17:42:42.7463350Z [0;36m(ApiServer_0 pid=191)[0;0m WARNING 02-25 17:42:42 [platform.py:335]             * A known problem is that capturing too many batch sizes can lead to OOM
2026-02-25T17:42:42.7474311Z [0;36m(ApiServer_0 pid=191)[0;0m WARNING 02-25 17:42:42 [platform.py:335]             * (Out of Memory) errors or inference hangs. If you encounter such issues,
2026-02-25T17:42:42.7484997Z [0;36m(ApiServer_0 pid=191)[0;0m WARNING 02-25 17:42:42 [platform.py:335]             * consider reducing `gpu_memory_utilization` or manually specifying a smaller
2026-02-25T17:42:42.7495105Z [0;36m(ApiServer_0 pid=191)[0;0m WARNING 02-25 17:42:42 [platform.py:335]             * batch size for graph capture.
2026-02-25T17:42:42.7506800Z [0;36m(ApiServer_0 pid=191)[0;0m WARNING 02-25 17:42:42 [platform.py:335]             * For more details, please refer to:
2026-02-25T17:42:42.7519393Z [0;36m(ApiServer_0 pid=191)[0;0m WARNING 02-25 17:42:42 [platform.py:335]             * https://docs.vllm.ai/en/stable/configuration/conserving_memory.html#reduce-cuda-graphs
2026-02-25T17:42:42.7530677Z [0;36m(ApiServer_0 pid=191)[0;0m WARNING 02-25 17:42:42 [platform.py:335]             **********************************************************************************[0m
2026-02-25T17:42:42.7540872Z [0;36m(ApiServer_0 pid=191)[0;0m WARNING 02-25 17:42:42 [platform.py:335]             
2026-02-25T17:42:42.7551358Z [0;36m(ApiServer_0 pid=191)[0;0m INFO 02-25 17:42:42 [platform.py:443] Set PYTORCH_NPU_ALLOC_CONF=expandable_segments:True
2026-02-25T17:42:42.7647314Z [0;36m(ApiServer_3 pid=194)[0;0m INFO 02-25 17:42:42 [vllm.py:624] Asynchronous scheduling is enabled.
2026-02-25T17:42:42.7659159Z [0;36m(ApiServer_3 pid=194)[0;0m INFO 02-25 17:42:42 [vllm.py:634] Disabling NCCL for DP synchronization when using async scheduling.
2026-02-25T17:42:42.7669674Z [0;36m(ApiServer_3 pid=194)[0;0m WARNING 02-25 17:42:42 [platform.py:730] Speculative quantization is set but Ascend automatically uses the main model's quantization method. Resetting to None.
2026-02-25T17:42:42.7680373Z [0;36m(ApiServer_3 pid=194)[0;0m WARNING 02-25 17:42:42 [platform.py:771] Ignored parameter 'use_trtllm_ragged_deepseek_prefill'. This is a GPU-specific feature not supported on Ascend. Resetting to False.
2026-02-25T17:42:42.7689113Z [0;36m(ApiServer_3 pid=194)[0;0m INFO 02-25 17:42:42 [ascend_config.py:412] Dynamic EPLB is False
2026-02-25T17:42:42.7699486Z [0;36m(ApiServer_3 pid=194)[0;0m INFO 02-25 17:42:42 [ascend_config.py:413] The number of redundant experts is 0
2026-02-25T17:42:42.7710405Z [0;36m(ApiServer_3 pid=194)[0;0m INFO 02-25 17:42:42 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-25T17:42:42.7720482Z [0;36m(ApiServer_3 pid=194)[0;0m WARNING 02-25 17:42:42 [vllm.py:1062] Batch sizes [3, 6, 9, 12, 15, 18, 21, 27, 30, 33, 36, 39, 42, 45] are removed because they are not multiple of tp_size 8 when sequence parallelism is enabled
2026-02-25T17:42:42.7730970Z [0;36m(ApiServer_3 pid=194)[0;0m INFO 02-25 17:42:42 [platform.py:318] FULL_DECODE_ONLY compilation enabled on NPU. use_inductor not supported - using only ACL Graph mode
2026-02-25T17:42:42.7740647Z [0;36m(ApiServer_3 pid=194)[0;0m WARNING 02-25 17:42:42 [platform.py:335] [91m
2026-02-25T17:42:42.7751074Z [0;36m(ApiServer_3 pid=194)[0;0m WARNING 02-25 17:42:42 [platform.py:335]             **********************************************************************************
2026-02-25T17:42:42.7760221Z [0;36m(ApiServer_3 pid=194)[0;0m WARNING 02-25 17:42:42 [platform.py:335]             * WARNING: You have enabled the *full graph* feature.
2026-02-25T17:42:42.7770762Z [0;36m(ApiServer_3 pid=194)[0;0m WARNING 02-25 17:42:42 [platform.py:335]             * This is an early experimental stage and may involve various unknown issues.
2026-02-25T17:42:42.7780872Z [0;36m(ApiServer_3 pid=194)[0;0m WARNING 02-25 17:42:42 [platform.py:335]             * A known problem is that capturing too many batch sizes can lead to OOM
2026-02-25T17:42:42.7791740Z [0;36m(ApiServer_3 pid=194)[0;0m WARNING 02-25 17:42:42 [platform.py:335]             * (Out of Memory) errors or inference hangs. If you encounter such issues,
2026-02-25T17:42:42.7803158Z [0;36m(ApiServer_3 pid=194)[0;0m WARNING 02-25 17:42:42 [platform.py:335]             * consider reducing `gpu_memory_utilization` or manually specifying a smaller
2026-02-25T17:42:42.7811089Z [0;36m(ApiServer_3 pid=194)[0;0m WARNING 02-25 17:42:42 [platform.py:335]             * batch size for graph capture.
2026-02-25T17:42:42.7821051Z [0;36m(ApiServer_3 pid=194)[0;0m WARNING 02-25 17:42:42 [platform.py:335]             * For more details, please refer to:
2026-02-25T17:42:42.7831071Z [0;36m(ApiServer_3 pid=194)[0;0m WARNING 02-25 17:42:42 [platform.py:335]             * https://docs.vllm.ai/en/stable/configuration/conserving_memory.html#reduce-cuda-graphs
2026-02-25T17:42:42.7840510Z [0;36m(ApiServer_3 pid=194)[0;0m WARNING 02-25 17:42:42 [platform.py:335]             **********************************************************************************[0m
2026-02-25T17:42:42.7850071Z [0;36m(ApiServer_3 pid=194)[0;0m WARNING 02-25 17:42:42 [platform.py:335]             
2026-02-25T17:42:42.7860339Z [0;36m(ApiServer_3 pid=194)[0;0m INFO 02-25 17:42:42 [platform.py:443] Set PYTORCH_NPU_ALLOC_CONF=expandable_segments:True
2026-02-25T17:42:42.7982542Z [0;36m(ApiServer_2 pid=193)[0;0m 2026-02-25 17:42:42,797 - 193 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-25T17:42:42.8133626Z [0;36m(ApiServer_2 pid=193)[0;0m INFO 02-25 17:42:42 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-25T17:42:42.8286263Z [0;36m(ApiServer_2 pid=193)[0;0m 2026-02-25 17:42:42,827 - modelscope - WARNING - We can not confirm the cached file is for revision: master
2026-02-25T17:42:42.8330208Z [0;36m(ApiServer_1 pid=192)[0;0m WARNING 02-25 17:42:42 [speculative.py:270] method `deepseek_mtp` is deprecated and replaced with mtp.
2026-02-25T17:42:42.8352245Z [0;36m(ApiServer_1 pid=192)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-25T17:42:42.8372568Z [0;36m(ApiServer_1 pid=192)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-25T17:42:42.8392310Z [0;36m(ApiServer_2 pid=193)[0;0m INFO 02-25 17:42:42 [arg_utils.py:602] HF_HUB_OFFLINE is True, replace model_id [vllm-ascend/DeepSeek-V3.2-W8A8] to model_path [/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8]
2026-02-25T17:42:42.8402433Z [0;36m(ApiServer_1 pid=192)[0;0m You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-25T17:42:42.8412420Z [0;36m(ApiServer_1 pid=192)[0;0m INFO 02-25 17:42:42 [model.py:541] Resolved architecture: DeepSeekMTPModel
2026-02-25T17:42:42.8429841Z [0;36m(ApiServer_1 pid=192)[0;0m INFO 02-25 17:42:42 [model.py:1561] Using max model len 163840
2026-02-25T17:42:42.8440221Z [0;36m(ApiServer_1 pid=192)[0;0m WARNING 02-25 17:42:42 [speculative.py:388] Enabling num_speculative_tokens > 1 will runmultiple times of forward on same MTP layer,which may result in lower acceptance rate
2026-02-25T17:42:42.8449338Z [0;36m(ApiServer_1 pid=192)[0;0m INFO 02-25 17:42:42 [scheduler.py:226] Chunked prefill is enabled with max_num_batched_tokens=4096.
2026-02-25T17:42:42.9354201Z [0;36m(ApiServer_2 pid=193)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-25T17:42:42.9377858Z [0;36m(ApiServer_2 pid=193)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-25T17:42:42.9387149Z [0;36m(ApiServer_2 pid=193)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-25T17:42:42.9406969Z [0;36m(ApiServer_2 pid=193)[0;0m You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-25T17:42:42.9473537Z [0;36m(ApiServer_2 pid=193)[0;0m INFO 02-25 17:42:42 [model.py:541] Resolved architecture: DeepseekV32ForCausalLM
2026-02-25T17:42:42.9493652Z [0;36m(ApiServer_2 pid=193)[0;0m INFO 02-25 17:42:42 [model.py:1561] Using max model len 8192
2026-02-25T17:42:42.9589770Z [0;36m(ApiServer_1 pid=192)[0;0m INFO 02-25 17:42:42 [vllm.py:624] Asynchronous scheduling is enabled.
2026-02-25T17:42:42.9601348Z [0;36m(ApiServer_1 pid=192)[0;0m INFO 02-25 17:42:42 [vllm.py:634] Disabling NCCL for DP synchronization when using async scheduling.
2026-02-25T17:42:42.9613800Z [0;36m(ApiServer_1 pid=192)[0;0m WARNING 02-25 17:42:42 [platform.py:730] Speculative quantization is set but Ascend automatically uses the main model's quantization method. Resetting to None.
2026-02-25T17:42:42.9623609Z [0;36m(ApiServer_1 pid=192)[0;0m WARNING 02-25 17:42:42 [platform.py:771] Ignored parameter 'use_trtllm_ragged_deepseek_prefill'. This is a GPU-specific feature not supported on Ascend. Resetting to False.
2026-02-25T17:42:42.9634480Z [0;36m(ApiServer_1 pid=192)[0;0m INFO 02-25 17:42:42 [ascend_config.py:412] Dynamic EPLB is False
2026-02-25T17:42:42.9644311Z [0;36m(ApiServer_1 pid=192)[0;0m INFO 02-25 17:42:42 [ascend_config.py:413] The number of redundant experts is 0
2026-02-25T17:42:42.9656052Z [0;36m(ApiServer_1 pid=192)[0;0m INFO 02-25 17:42:42 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-25T17:42:42.9667104Z [0;36m(ApiServer_1 pid=192)[0;0m WARNING 02-25 17:42:42 [vllm.py:1062] Batch sizes [3, 6, 9, 12, 15, 18, 21, 27, 30, 33, 36, 39, 42, 45] are removed because they are not multiple of tp_size 8 when sequence parallelism is enabled
2026-02-25T17:42:42.9677971Z [0;36m(ApiServer_1 pid=192)[0;0m INFO 02-25 17:42:42 [platform.py:318] FULL_DECODE_ONLY compilation enabled on NPU. use_inductor not supported - using only ACL Graph mode
2026-02-25T17:42:42.9687989Z [0;36m(ApiServer_1 pid=192)[0;0m WARNING 02-25 17:42:42 [platform.py:335] [91m
2026-02-25T17:42:42.9698747Z [0;36m(ApiServer_1 pid=192)[0;0m WARNING 02-25 17:42:42 [platform.py:335]             **********************************************************************************
2026-02-25T17:42:42.9708707Z [0;36m(ApiServer_1 pid=192)[0;0m WARNING 02-25 17:42:42 [platform.py:335]             * WARNING: You have enabled the *full graph* feature.
2026-02-25T17:42:42.9718526Z [0;36m(ApiServer_1 pid=192)[0;0m WARNING 02-25 17:42:42 [platform.py:335]             * This is an early experimental stage and may involve various unknown issues.
2026-02-25T17:42:42.9729305Z [0;36m(ApiServer_1 pid=192)[0;0m WARNING 02-25 17:42:42 [platform.py:335]             * A known problem is that capturing too many batch sizes can lead to OOM
2026-02-25T17:42:42.9740454Z [0;36m(ApiServer_1 pid=192)[0;0m WARNING 02-25 17:42:42 [platform.py:335]             * (Out of Memory) errors or inference hangs. If you encounter such issues,
2026-02-25T17:42:42.9750688Z [0;36m(ApiServer_1 pid=192)[0;0m WARNING 02-25 17:42:42 [platform.py:335]             * consider reducing `gpu_memory_utilization` or manually specifying a smaller
2026-02-25T17:42:42.9760784Z [0;36m(ApiServer_1 pid=192)[0;0m WARNING 02-25 17:42:42 [platform.py:335]             * batch size for graph capture.
2026-02-25T17:42:42.9771520Z [0;36m(ApiServer_1 pid=192)[0;0m WARNING 02-25 17:42:42 [platform.py:335]             * For more details, please refer to:
2026-02-25T17:42:42.9782168Z [0;36m(ApiServer_1 pid=192)[0;0m WARNING 02-25 17:42:42 [platform.py:335]             * https://docs.vllm.ai/en/stable/configuration/conserving_memory.html#reduce-cuda-graphs
2026-02-25T17:42:42.9791803Z [0;36m(ApiServer_1 pid=192)[0;0m WARNING 02-25 17:42:42 [platform.py:335]             **********************************************************************************[0m
2026-02-25T17:42:42.9801435Z [0;36m(ApiServer_1 pid=192)[0;0m WARNING 02-25 17:42:42 [platform.py:335]             
2026-02-25T17:42:42.9812101Z [0;36m(ApiServer_1 pid=192)[0;0m INFO 02-25 17:42:42 [platform.py:443] Set PYTORCH_NPU_ALLOC_CONF=expandable_segments:True
2026-02-25T17:42:43.0553899Z [0;36m(ApiServer_2 pid=193)[0;0m WARNING 02-25 17:42:43 [speculative.py:270] method `deepseek_mtp` is deprecated and replaced with mtp.
2026-02-25T17:42:43.0574969Z [0;36m(ApiServer_2 pid=193)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-25T17:42:43.0584254Z [0;36m(ApiServer_2 pid=193)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-25T17:42:43.0593723Z [0;36m(ApiServer_2 pid=193)[0;0m You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-25T17:42:43.0646097Z [0;36m(ApiServer_2 pid=193)[0;0m INFO 02-25 17:42:43 [model.py:541] Resolved architecture: DeepSeekMTPModel
2026-02-25T17:42:43.0679410Z [0;36m(ApiServer_2 pid=193)[0;0m INFO 02-25 17:42:43 [model.py:1561] Using max model len 163840
2026-02-25T17:42:43.0690229Z [0;36m(ApiServer_2 pid=193)[0;0m WARNING 02-25 17:42:43 [speculative.py:388] Enabling num_speculative_tokens > 1 will runmultiple times of forward on same MTP layer,which may result in lower acceptance rate
2026-02-25T17:42:43.0699363Z [0;36m(ApiServer_2 pid=193)[0;0m INFO 02-25 17:42:43 [scheduler.py:226] Chunked prefill is enabled with max_num_batched_tokens=4096.
2026-02-25T17:42:43.1850763Z [0;36m(ApiServer_2 pid=193)[0;0m INFO 02-25 17:42:43 [vllm.py:624] Asynchronous scheduling is enabled.
2026-02-25T17:42:43.1859217Z [0;36m(ApiServer_2 pid=193)[0;0m INFO 02-25 17:42:43 [vllm.py:634] Disabling NCCL for DP synchronization when using async scheduling.
2026-02-25T17:42:43.1877328Z [0;36m(ApiServer_2 pid=193)[0;0m WARNING 02-25 17:42:43 [platform.py:730] Speculative quantization is set but Ascend automatically uses the main model's quantization method. Resetting to None.
2026-02-25T17:42:43.1885733Z [0;36m(ApiServer_2 pid=193)[0;0m WARNING 02-25 17:42:43 [platform.py:771] Ignored parameter 'use_trtllm_ragged_deepseek_prefill'. This is a GPU-specific feature not supported on Ascend. Resetting to False.
2026-02-25T17:42:43.1894632Z [0;36m(ApiServer_2 pid=193)[0;0m INFO 02-25 17:42:43 [ascend_config.py:412] Dynamic EPLB is False
2026-02-25T17:42:43.1904220Z [0;36m(ApiServer_2 pid=193)[0;0m INFO 02-25 17:42:43 [ascend_config.py:413] The number of redundant experts is 0
2026-02-25T17:42:43.1915370Z [0;36m(ApiServer_2 pid=193)[0;0m INFO 02-25 17:42:43 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-25T17:42:43.1924668Z [0;36m(ApiServer_2 pid=193)[0;0m WARNING 02-25 17:42:43 [vllm.py:1062] Batch sizes [3, 6, 9, 12, 15, 18, 21, 27, 30, 33, 36, 39, 42, 45] are removed because they are not multiple of tp_size 8 when sequence parallelism is enabled
2026-02-25T17:42:43.1934548Z [0;36m(ApiServer_2 pid=193)[0;0m INFO 02-25 17:42:43 [platform.py:318] FULL_DECODE_ONLY compilation enabled on NPU. use_inductor not supported - using only ACL Graph mode
2026-02-25T17:42:43.1943291Z [0;36m(ApiServer_2 pid=193)[0;0m WARNING 02-25 17:42:43 [platform.py:335] [91m
2026-02-25T17:42:43.1953326Z [0;36m(ApiServer_2 pid=193)[0;0m WARNING 02-25 17:42:43 [platform.py:335]             **********************************************************************************
2026-02-25T17:42:43.1962932Z [0;36m(ApiServer_2 pid=193)[0;0m WARNING 02-25 17:42:43 [platform.py:335]             * WARNING: You have enabled the *full graph* feature.
2026-02-25T17:42:43.1973045Z [0;36m(ApiServer_2 pid=193)[0;0m WARNING 02-25 17:42:43 [platform.py:335]             * This is an early experimental stage and may involve various unknown issues.
2026-02-25T17:42:43.1983240Z [0;36m(ApiServer_2 pid=193)[0;0m WARNING 02-25 17:42:43 [platform.py:335]             * A known problem is that capturing too many batch sizes can lead to OOM
2026-02-25T17:42:43.1992386Z [0;36m(ApiServer_2 pid=193)[0;0m WARNING 02-25 17:42:43 [platform.py:335]             * (Out of Memory) errors or inference hangs. If you encounter such issues,
2026-02-25T17:42:43.2001902Z [0;36m(ApiServer_2 pid=193)[0;0m WARNING 02-25 17:42:43 [platform.py:335]             * consider reducing `gpu_memory_utilization` or manually specifying a smaller
2026-02-25T17:42:43.2012221Z [0;36m(ApiServer_2 pid=193)[0;0m WARNING 02-25 17:42:43 [platform.py:335]             * batch size for graph capture.
2026-02-25T17:42:43.2021512Z [0;36m(ApiServer_2 pid=193)[0;0m WARNING 02-25 17:42:43 [platform.py:335]             * For more details, please refer to:
2026-02-25T17:42:43.2031458Z [0;36m(ApiServer_2 pid=193)[0;0m WARNING 02-25 17:42:43 [platform.py:335]             * https://docs.vllm.ai/en/stable/configuration/conserving_memory.html#reduce-cuda-graphs
2026-02-25T17:42:43.2041052Z [0;36m(ApiServer_2 pid=193)[0;0m WARNING 02-25 17:42:43 [platform.py:335]             **********************************************************************************[0m
2026-02-25T17:42:43.2050242Z [0;36m(ApiServer_2 pid=193)[0;0m WARNING 02-25 17:42:43 [platform.py:335]             
2026-02-25T17:42:43.2060403Z [0;36m(ApiServer_2 pid=193)[0;0m INFO 02-25 17:42:43 [platform.py:443] Set PYTORCH_NPU_ALLOC_CONF=expandable_segments:True
2026-02-25T17:42:43.5931867Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-25T17:42:43.5940075Z   warnings.warn(
2026-02-25T17:42:43.6091141Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-25T17:42:43.6100829Z   warnings.warn(
2026-02-25T17:42:46.2145026Z INFO 02-25 17:42:46 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-25T17:42:46.2153044Z INFO 02-25 17:42:46 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-25T17:42:46.2164393Z INFO 02-25 17:42:46 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-25T17:42:46.2217290Z INFO 02-25 17:42:46 [__init__.py:217] Platform plugin ascend is activated
2026-02-25T17:42:46.4566262Z INFO 02-25 17:42:46 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-25T17:42:46.4574281Z INFO 02-25 17:42:46 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-25T17:42:46.4585082Z INFO 02-25 17:42:46 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-25T17:42:46.4643193Z INFO 02-25 17:42:46 [__init__.py:217] Platform plugin ascend is activated
2026-02-25T17:42:47.0236513Z INFO 02-25 17:42:47 [ascend_config.py:412] Dynamic EPLB is False
2026-02-25T17:42:47.0243848Z INFO 02-25 17:42:47 [ascend_config.py:413] The number of redundant experts is 0
2026-02-25T17:42:47.0254868Z INFO 02-25 17:42:47 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-25T17:42:47.0263660Z INFO 02-25 17:42:47 [ascend_config.py:412] Dynamic EPLB is False
2026-02-25T17:42:47.0272894Z INFO 02-25 17:42:47 [ascend_config.py:413] The number of redundant experts is 0
2026-02-25T17:42:47.0283651Z INFO 02-25 17:42:47 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-25T17:42:47.3980780Z INFO 02-25 17:42:47 [parallel_state.py:1212] world_size=32 rank=8 local_rank=0 distributed_init_method=tcp://10.0.0.169:32979 backend=hccl
2026-02-25T17:42:47.4206268Z INFO 02-25 17:42:47 [parallel_state.py:1212] world_size=32 rank=0 local_rank=0 distributed_init_method=tcp://10.0.0.169:32979 backend=hccl
2026-02-25T17:42:51.2271457Z 2026-02-25 17:42:51,225 - 258 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-25T17:42:51.2328517Z INFO 02-25 17:42:51 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-25T17:42:51.4736239Z 2026-02-25 17:42:51,472 - 260 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-25T17:42:51.4807165Z INFO 02-25 17:42:51 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-25T17:42:52.6182813Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-25T17:42:52.6190927Z   warnings.warn(
2026-02-25T17:42:52.8838940Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-25T17:42:52.8844678Z   warnings.warn(
2026-02-25T17:42:54.7174359Z INFO 02-25 17:42:54 [ascend_config.py:412] Dynamic EPLB is False
2026-02-25T17:42:54.7182874Z INFO 02-25 17:42:54 [ascend_config.py:413] The number of redundant experts is 0
2026-02-25T17:42:54.7195885Z INFO 02-25 17:42:54 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-25T17:42:54.9589841Z INFO 02-25 17:42:54 [ascend_config.py:412] Dynamic EPLB is False
2026-02-25T17:42:54.9597707Z INFO 02-25 17:42:54 [ascend_config.py:413] The number of redundant experts is 0
2026-02-25T17:42:54.9607989Z INFO 02-25 17:42:54 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-25T17:42:55.5266743Z INFO 02-25 17:42:55 [parallel_state.py:1212] world_size=32 rank=1 local_rank=1 distributed_init_method=tcp://10.0.0.169:32979 backend=hccl
2026-02-25T17:42:55.7362127Z INFO 02-25 17:42:55 [parallel_state.py:1212] world_size=32 rank=9 local_rank=1 distributed_init_method=tcp://10.0.0.169:32979 backend=hccl
2026-02-25T17:42:55.9572365Z INFO 02-25 17:42:55 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-25T17:42:55.9579449Z INFO 02-25 17:42:55 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-25T17:42:55.9589068Z INFO 02-25 17:42:55 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-25T17:42:55.9645506Z INFO 02-25 17:42:55 [__init__.py:217] Platform plugin ascend is activated
2026-02-25T17:42:56.0678124Z INFO 02-25 17:42:56 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-25T17:42:56.0686943Z INFO 02-25 17:42:56 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-25T17:42:56.0696384Z INFO 02-25 17:42:56 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-25T17:42:56.0751806Z INFO 02-25 17:42:56 [__init__.py:217] Platform plugin ascend is activated
2026-02-25T17:43:00.9810867Z 2026-02-25 17:43:00,979 - 376 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-25T17:43:00.9866782Z INFO 02-25 17:43:00 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-25T17:43:01.1425203Z 2026-02-25 17:43:01,141 - 379 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-25T17:43:01.1487807Z INFO 02-25 17:43:01 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-25T17:43:02.2999759Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-25T17:43:02.3006478Z   warnings.warn(
2026-02-25T17:43:02.4547563Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-25T17:43:02.4548497Z   warnings.warn(
2026-02-25T17:43:04.4813764Z INFO 02-25 17:43:04 [ascend_config.py:412] Dynamic EPLB is False
2026-02-25T17:43:04.4823370Z INFO 02-25 17:43:04 [ascend_config.py:413] The number of redundant experts is 0
2026-02-25T17:43:04.4836442Z INFO 02-25 17:43:04 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-25T17:43:04.6563620Z INFO 02-25 17:43:04 [ascend_config.py:412] Dynamic EPLB is False
2026-02-25T17:43:04.6572947Z INFO 02-25 17:43:04 [ascend_config.py:413] The number of redundant experts is 0
2026-02-25T17:43:04.6585305Z INFO 02-25 17:43:04 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-25T17:43:05.2751948Z INFO 02-25 17:43:05 [parallel_state.py:1212] world_size=32 rank=2 local_rank=2 distributed_init_method=tcp://10.0.0.169:32979 backend=hccl
2026-02-25T17:43:05.4261826Z INFO 02-25 17:43:05 [parallel_state.py:1212] world_size=32 rank=10 local_rank=2 distributed_init_method=tcp://10.0.0.169:32979 backend=hccl
2026-02-25T17:43:05.5232050Z INFO 02-25 17:43:05 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-25T17:43:05.5239608Z INFO 02-25 17:43:05 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-25T17:43:05.5249926Z INFO 02-25 17:43:05 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-25T17:43:05.5306536Z INFO 02-25 17:43:05 [__init__.py:217] Platform plugin ascend is activated
2026-02-25T17:43:05.7514327Z INFO 02-25 17:43:05 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-25T17:43:05.7522916Z INFO 02-25 17:43:05 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-25T17:43:05.7532653Z INFO 02-25 17:43:05 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-25T17:43:05.7604804Z INFO 02-25 17:43:05 [__init__.py:217] Platform plugin ascend is activated
2026-02-25T17:43:10.4923347Z 2026-02-25 17:43:10,490 - 480 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-25T17:43:10.4975115Z INFO 02-25 17:43:10 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-25T17:43:10.8117876Z 2026-02-25 17:43:10,810 - 483 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-25T17:43:10.8155300Z INFO 02-25 17:43:10 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-25T17:43:11.9194203Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-25T17:43:11.9199400Z   warnings.warn(
2026-02-25T17:43:12.1160600Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-25T17:43:12.1166388Z   warnings.warn(
2026-02-25T17:43:13.9655020Z INFO 02-25 17:43:13 [ascend_config.py:412] Dynamic EPLB is False
2026-02-25T17:43:13.9662420Z INFO 02-25 17:43:13 [ascend_config.py:413] The number of redundant experts is 0
2026-02-25T17:43:13.9673482Z INFO 02-25 17:43:13 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-25T17:43:14.3143621Z INFO 02-25 17:43:14 [ascend_config.py:412] Dynamic EPLB is False
2026-02-25T17:43:14.3152772Z INFO 02-25 17:43:14 [ascend_config.py:413] The number of redundant experts is 0
2026-02-25T17:43:14.3165882Z INFO 02-25 17:43:14 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-25T17:43:14.6825433Z INFO 02-25 17:43:14 [parallel_state.py:1212] world_size=32 rank=3 local_rank=3 distributed_init_method=tcp://10.0.0.169:32979 backend=hccl
2026-02-25T17:43:15.0177046Z INFO 02-25 17:43:15 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-25T17:43:15.0184300Z INFO 02-25 17:43:15 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-25T17:43:15.0193477Z INFO 02-25 17:43:15 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-25T17:43:15.0249863Z INFO 02-25 17:43:15 [__init__.py:217] Platform plugin ascend is activated
2026-02-25T17:43:15.0854846Z INFO 02-25 17:43:15 [parallel_state.py:1212] world_size=32 rank=11 local_rank=3 distributed_init_method=tcp://10.0.0.169:32979 backend=hccl
2026-02-25T17:43:15.2884763Z INFO 02-25 17:43:15 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-25T17:43:15.2892118Z INFO 02-25 17:43:15 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-25T17:43:15.2901757Z INFO 02-25 17:43:15 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-25T17:43:15.2961555Z INFO 02-25 17:43:15 [__init__.py:217] Platform plugin ascend is activated
2026-02-25T17:43:20.0331621Z 2026-02-25 17:43:20,031 - 584 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-25T17:43:20.0386972Z INFO 02-25 17:43:20 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-25T17:43:20.2913290Z 2026-02-25 17:43:20,289 - 587 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-25T17:43:20.2971508Z INFO 02-25 17:43:20 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-25T17:43:21.3637359Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-25T17:43:21.3643663Z   warnings.warn(
2026-02-25T17:43:21.6503618Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-25T17:43:21.6509706Z   warnings.warn(
2026-02-25T17:43:23.5548114Z INFO 02-25 17:43:23 [ascend_config.py:412] Dynamic EPLB is False
2026-02-25T17:43:23.5561228Z INFO 02-25 17:43:23 [ascend_config.py:413] The number of redundant experts is 0
2026-02-25T17:43:23.5574824Z INFO 02-25 17:43:23 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-25T17:43:23.7839818Z INFO 02-25 17:43:23 [ascend_config.py:412] Dynamic EPLB is False
2026-02-25T17:43:23.7841419Z INFO 02-25 17:43:23 [ascend_config.py:413] The number of redundant experts is 0
2026-02-25T17:43:23.7854298Z INFO 02-25 17:43:23 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-25T17:43:24.4215622Z INFO 02-25 17:43:24 [parallel_state.py:1212] world_size=32 rank=4 local_rank=4 distributed_init_method=tcp://10.0.0.169:32979 backend=hccl
2026-02-25T17:43:24.5426373Z INFO 02-25 17:43:24 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-25T17:43:24.5435408Z INFO 02-25 17:43:24 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-25T17:43:24.5445387Z INFO 02-25 17:43:24 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-25T17:43:24.5455190Z INFO 02-25 17:43:24 [parallel_state.py:1212] world_size=32 rank=12 local_rank=4 distributed_init_method=tcp://10.0.0.169:32979 backend=hccl
2026-02-25T17:43:24.5501331Z INFO 02-25 17:43:24 [__init__.py:217] Platform plugin ascend is activated
2026-02-25T17:43:24.7252992Z INFO 02-25 17:43:24 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-25T17:43:24.7259696Z INFO 02-25 17:43:24 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-25T17:43:24.7269471Z INFO 02-25 17:43:24 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-25T17:43:24.7294255Z INFO 02-25 17:43:24 [__init__.py:217] Platform plugin ascend is activated
2026-02-25T17:43:29.5661691Z 2026-02-25 17:43:29,564 - 688 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-25T17:43:29.5723156Z INFO 02-25 17:43:29 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-25T17:43:29.8140096Z 2026-02-25 17:43:29,812 - 691 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-25T17:43:29.8197706Z INFO 02-25 17:43:29 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-25T17:43:30.8978042Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-25T17:43:30.8982324Z   warnings.warn(
2026-02-25T17:43:31.2327734Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-25T17:43:31.2334025Z   warnings.warn(
2026-02-25T17:43:33.0096596Z INFO 02-25 17:43:33 [ascend_config.py:412] Dynamic EPLB is False
2026-02-25T17:43:33.0105573Z INFO 02-25 17:43:33 [ascend_config.py:413] The number of redundant experts is 0
2026-02-25T17:43:33.0117088Z INFO 02-25 17:43:33 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-25T17:43:33.3302410Z INFO 02-25 17:43:33 [ascend_config.py:412] Dynamic EPLB is False
2026-02-25T17:43:33.3309933Z INFO 02-25 17:43:33 [ascend_config.py:413] The number of redundant experts is 0
2026-02-25T17:43:33.3320382Z INFO 02-25 17:43:33 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-25T17:43:33.7783406Z INFO 02-25 17:43:33 [parallel_state.py:1212] world_size=32 rank=5 local_rank=5 distributed_init_method=tcp://10.0.0.169:32979 backend=hccl
2026-02-25T17:43:34.1198550Z INFO 02-25 17:43:34 [parallel_state.py:1212] world_size=32 rank=13 local_rank=5 distributed_init_method=tcp://10.0.0.169:32979 backend=hccl
2026-02-25T17:43:34.1218567Z INFO 02-25 17:43:34 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-25T17:43:34.1228953Z INFO 02-25 17:43:34 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-25T17:43:34.1238343Z INFO 02-25 17:43:34 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-25T17:43:34.1278555Z INFO 02-25 17:43:34 [__init__.py:217] Platform plugin ascend is activated
2026-02-25T17:43:34.3285199Z INFO 02-25 17:43:34 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-25T17:43:34.3294862Z INFO 02-25 17:43:34 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-25T17:43:34.3306495Z INFO 02-25 17:43:34 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-25T17:43:34.3360611Z INFO 02-25 17:43:34 [__init__.py:217] Platform plugin ascend is activated
2026-02-25T17:43:39.0860360Z 2026-02-25 17:43:39,084 - 792 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-25T17:43:39.0893116Z INFO 02-25 17:43:39 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-25T17:43:39.4710259Z 2026-02-25 17:43:39,469 - 795 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-25T17:43:39.4771366Z INFO 02-25 17:43:39 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-25T17:43:40.5294711Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-25T17:43:40.5299693Z   warnings.warn(
2026-02-25T17:43:40.8062249Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-25T17:43:40.8068137Z   warnings.warn(
2026-02-25T17:43:42.6961532Z INFO 02-25 17:43:42 [ascend_config.py:412] Dynamic EPLB is False
2026-02-25T17:43:42.6972691Z INFO 02-25 17:43:42 [ascend_config.py:413] The number of redundant experts is 0
2026-02-25T17:43:42.6984588Z INFO 02-25 17:43:42 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-25T17:43:42.8946040Z INFO 02-25 17:43:42 [ascend_config.py:412] Dynamic EPLB is False
2026-02-25T17:43:42.8956308Z INFO 02-25 17:43:42 [ascend_config.py:413] The number of redundant experts is 0
2026-02-25T17:43:42.8965515Z INFO 02-25 17:43:42 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-25T17:43:43.4514119Z INFO 02-25 17:43:43 [parallel_state.py:1212] world_size=32 rank=6 local_rank=6 distributed_init_method=tcp://10.0.0.169:32979 backend=hccl
2026-02-25T17:43:43.5937727Z INFO 02-25 17:43:43 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-25T17:43:43.5945732Z INFO 02-25 17:43:43 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-25T17:43:43.5955480Z INFO 02-25 17:43:43 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-25T17:43:43.6012545Z INFO 02-25 17:43:43 [__init__.py:217] Platform plugin ascend is activated
2026-02-25T17:43:43.9097628Z INFO 02-25 17:43:43 [parallel_state.py:1212] world_size=32 rank=14 local_rank=6 distributed_init_method=tcp://10.0.0.169:32979 backend=hccl
2026-02-25T17:43:44.0616623Z INFO 02-25 17:43:44 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-25T17:43:44.0624719Z INFO 02-25 17:43:44 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-25T17:43:44.0634358Z INFO 02-25 17:43:44 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-25T17:43:44.0720353Z INFO 02-25 17:43:44 [__init__.py:217] Platform plugin ascend is activated
2026-02-25T17:43:48.5592576Z 2026-02-25 17:43:48,557 - 896 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-25T17:43:48.5649055Z INFO 02-25 17:43:48 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-25T17:43:49.0694338Z 2026-02-25 17:43:49,067 - 899 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-25T17:43:49.0751319Z INFO 02-25 17:43:49 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-25T17:43:49.8485688Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-25T17:43:49.8491758Z   warnings.warn(
2026-02-25T17:43:50.3883783Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-25T17:43:50.3890662Z   warnings.warn(
2026-02-25T17:43:51.8735271Z INFO 02-25 17:43:51 [ascend_config.py:412] Dynamic EPLB is False
2026-02-25T17:43:51.8742682Z INFO 02-25 17:43:51 [ascend_config.py:413] The number of redundant experts is 0
2026-02-25T17:43:51.8753353Z INFO 02-25 17:43:51 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-25T17:43:52.4428957Z INFO 02-25 17:43:52 [ascend_config.py:412] Dynamic EPLB is False
2026-02-25T17:43:52.4438137Z INFO 02-25 17:43:52 [ascend_config.py:413] The number of redundant experts is 0
2026-02-25T17:43:52.4449723Z INFO 02-25 17:43:52 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-25T17:43:52.6482554Z INFO 02-25 17:43:52 [parallel_state.py:1212] world_size=32 rank=7 local_rank=7 distributed_init_method=tcp://10.0.0.169:32979 backend=hccl
2026-02-25T17:43:53.2145431Z INFO 02-25 17:43:53 [parallel_state.py:1212] world_size=32 rank=15 local_rank=7 distributed_init_method=tcp://10.0.0.169:32979 backend=hccl
2026-02-25T17:43:53.2551929Z [Gloo] Rank 4 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-25T17:43:53.2578706Z [Gloo] Rank 0 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-25T17:43:53.2587745Z [Gloo] Rank 2 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-25T17:43:53.2599881Z [Gloo] Rank 7 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-25T17:43:53.2608248Z [Gloo] Rank 3 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-25T17:43:53.2618976Z [Gloo] Rank 6 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-25T17:43:53.2627623Z [Gloo] Rank 5 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-25T17:43:53.3347106Z [Gloo] Rank 11 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-25T17:43:53.3366348Z [Gloo] Rank 10 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-25T17:43:53.3375606Z [Gloo] Rank 1 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-25T17:43:53.3386195Z [Gloo] Rank 8 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-25T17:43:53.3395849Z [Gloo] Rank 9 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-25T17:43:53.3461826Z [Gloo] Rank 12 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-25T17:43:53.3488638Z [Gloo] Rank 13 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-25T17:43:53.3499736Z [Gloo] Rank 15 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-25T17:43:53.3507782Z [Gloo] Rank 14 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-25T17:43:53.4959777Z [Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-25T17:43:53.4973055Z [Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-25T17:43:53.4983541Z [Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-25T17:43:53.4994018Z [Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-25T17:43:53.5003778Z [Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-25T17:43:53.5014340Z [Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-25T17:43:53.5024214Z [Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-25T17:43:53.5034040Z [Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-25T17:43:53.5044250Z [Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-25T17:43:53.5054888Z [Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-25T17:43:53.5065165Z [Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-25T17:43:53.5075123Z [Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-25T17:43:53.5085242Z [Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-25T17:43:53.5124620Z [Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-25T17:43:53.5126813Z [Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-25T17:43:53.5127846Z [Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-25T17:43:53.5128692Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-25T17:43:53.5136051Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-25T17:43:53.5145309Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-25T17:43:53.5155313Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-25T17:43:53.5165084Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-25T17:43:53.5176199Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-25T17:43:53.5185607Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-25T17:43:53.5195501Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-25T17:43:53.5204756Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-25T17:43:53.5214511Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-25T17:43:53.5224516Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-25T17:43:53.5234629Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-25T17:43:53.5244178Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-25T17:43:53.5254139Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-25T17:43:53.5264010Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-25T17:43:53.5274170Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-25T17:43:53.5283565Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-25T17:43:53.5294024Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-25T17:43:53.5303259Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-25T17:43:53.5312840Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-25T17:43:53.5323011Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-25T17:43:53.5333190Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-25T17:43:53.5343082Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-25T17:43:53.5352587Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-25T17:43:53.5670746Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-25T17:43:53.5681853Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-25T17:43:53.5690918Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-25T17:43:53.5700136Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-25T17:43:53.5709035Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-25T17:43:53.5718627Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-25T17:43:53.5728092Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-25T17:43:53.5737876Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-25T17:43:53.5747971Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-25T17:43:53.5757683Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-25T17:43:53.5767461Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-25T17:43:53.5778518Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-25T17:43:53.5788328Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-25T17:43:53.5798337Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-25T17:43:53.5808784Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-25T17:43:53.5819037Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-25T17:43:53.5828203Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-25T17:43:53.5838307Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-25T17:43:53.5848773Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-25T17:43:53.5858376Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-25T17:43:53.5867696Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-25T17:43:53.5876768Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-25T17:43:53.5886830Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-25T17:43:53.5896938Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-25T17:43:53.5906264Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-25T17:43:53.5915967Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-25T17:43:53.5926495Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-25T17:43:53.5936957Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-25T17:43:53.5945861Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-25T17:43:53.5956310Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-25T17:43:53.5965065Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-25T17:43:53.5975487Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-25T17:43:53.5985306Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-25T17:43:53.5995511Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-25T17:43:53.6005524Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-25T17:43:53.6015154Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-25T17:43:53.6025898Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-25T17:43:53.6035217Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-25T17:43:53.6044511Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-25T17:43:53.6054871Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-25T17:43:53.6159011Z [Gloo] Rank 0 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-25T17:43:53.6179410Z INFO 02-25 17:43:53 [parallel_state.py:1423] rank 0 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
2026-02-25T17:43:53.6799355Z [Gloo] Rank 8 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-25T17:43:53.6821563Z INFO 02-25 17:43:53 [parallel_state.py:1423] rank 8 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 0, EP rank 8
2026-02-25T17:43:53.6838843Z [Gloo] Rank 1 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-25T17:43:53.6848646Z INFO 02-25 17:43:53 [parallel_state.py:1423] rank 1 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 1, EP rank 1
2026-02-25T17:43:53.6914156Z [Gloo] Rank 2 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-25T17:43:53.6934667Z INFO 02-25 17:43:53 [parallel_state.py:1423] rank 2 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 2, EP rank 2
2026-02-25T17:43:53.7509304Z [Gloo] Rank 5 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-25T17:43:53.7625710Z [Gloo] Rank 4 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-25T17:43:53.7634247Z [Gloo] Rank 6 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-25T17:43:53.7643616Z INFO 02-25 17:43:53 [parallel_state.py:1423] rank 5 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 5, EP rank 5
2026-02-25T17:43:53.7654427Z INFO 02-25 17:43:53 [parallel_state.py:1423] rank 4 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 4, EP rank 4
2026-02-25T17:43:53.7662336Z [Gloo] Rank 3 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-25T17:43:53.7672486Z [Gloo] Rank 15 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-25T17:43:53.7681200Z [Gloo] Rank 7 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-25T17:43:53.7691297Z [Gloo] Rank 11 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-25T17:43:53.7700139Z [Gloo] Rank 10 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-25T17:43:53.7709626Z [Gloo] Rank 12 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-25T17:43:53.7719212Z [Gloo] Rank 9 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-25T17:43:53.7730368Z [Gloo] Rank 14 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-25T17:43:53.7739240Z [Gloo] Rank 13 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-25T17:43:53.7748482Z INFO 02-25 17:43:53 [parallel_state.py:1423] rank 15 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 7, EP rank 15
2026-02-25T17:43:53.7758266Z INFO 02-25 17:43:53 [parallel_state.py:1423] rank 6 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 6, EP rank 6
2026-02-25T17:43:53.7768804Z INFO 02-25 17:43:53 [parallel_state.py:1423] rank 3 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 3, EP rank 3
2026-02-25T17:43:53.7779376Z INFO 02-25 17:43:53 [parallel_state.py:1423] rank 7 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 7, EP rank 7
2026-02-25T17:43:53.7791276Z INFO 02-25 17:43:53 [parallel_state.py:1423] rank 11 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 3, EP rank 11
2026-02-25T17:43:53.7800676Z INFO 02-25 17:43:53 [parallel_state.py:1423] rank 14 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 6, EP rank 14
2026-02-25T17:43:53.7810855Z INFO 02-25 17:43:53 [parallel_state.py:1423] rank 10 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 2, EP rank 10
2026-02-25T17:43:53.7821161Z INFO 02-25 17:43:53 [parallel_state.py:1423] rank 12 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 4, EP rank 12
2026-02-25T17:43:53.7831661Z INFO 02-25 17:43:53 [parallel_state.py:1423] rank 9 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 1, EP rank 9
2026-02-25T17:43:53.7841471Z INFO 02-25 17:43:53 [parallel_state.py:1423] rank 13 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 5, EP rank 13
2026-02-25T17:43:53.7892237Z [Gloo] Rank 3 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-25T17:43:53.7900514Z [Gloo] Rank 9 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-25T17:43:53.7924085Z [Gloo] Rank 7 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-25T17:43:53.7930148Z [Gloo] Rank 10 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-25T17:43:53.7939835Z [Gloo] Rank 0 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-25T17:43:53.7949166Z [Gloo] Rank 1 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-25T17:43:53.7959405Z [Gloo] Rank 4 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-25T17:43:53.7967887Z [Gloo] Rank 11 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-25T17:43:53.7978123Z [Gloo] Rank 13 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-25T17:43:53.7987520Z [Gloo] Rank 6 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-25T17:43:53.7996398Z [Gloo] Rank 12 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-25T17:43:53.8006381Z [Gloo] Rank 15 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-25T17:43:53.8016016Z [Gloo] Rank 5 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-25T17:43:53.8025118Z [Gloo] Rank 2 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-25T17:43:53.8034815Z [Gloo] Rank 14 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-25T17:43:53.8044490Z [Gloo] Rank 8 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-25T17:43:53.8053597Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-25T17:43:53.8063506Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-25T17:43:53.8073038Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-25T17:43:53.8082951Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-25T17:43:53.8092326Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-25T17:43:53.8102372Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-25T17:43:53.8111334Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-25T17:43:53.8121065Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-25T17:43:53.8131670Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-25T17:43:53.8140649Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-25T17:43:53.8150495Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-25T17:43:53.8160033Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-25T17:43:53.8170091Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-25T17:43:53.8180178Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-25T17:43:53.8190323Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-25T17:43:53.8199810Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-25T17:44:02.6119759Z INFO 02-25 17:44:02 [cpu_binding.py:285] The CPU allocation plan is as follows:
2026-02-25T17:44:02.6129562Z INFO 02-25 17:44:02 [cpu_binding.py:290] NPU8: main=[0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37]  acl=[38]  release=[[39]]
2026-02-25T17:44:02.7197332Z WARNING 02-25 17:44:02 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-25T17:44:02.7695853Z WARNING 02-25 17:44:02 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-25T17:44:02.7721718Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m INFO 02-25 17:44:02 [model_runner_v1.py:2319] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-25T17:44:03.0638516Z INFO 02-25 17:44:03 [cpu_binding.py:285] The CPU allocation plan is as follows:
2026-02-25T17:44:03.0646249Z INFO 02-25 17:44:03 [cpu_binding.py:290] NPU12: main=[160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197]  acl=[198]  release=[[199]]
2026-02-25T17:44:03.0664577Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m [2026-02-25 17:44:03] INFO modelslim_config.py:290: Using the vLLM Ascend modelslim Quantization now!
2026-02-25T17:44:03.0849116Z INFO 02-25 17:44:03 [cpu_binding.py:285] The CPU allocation plan is as follows:
2026-02-25T17:44:03.0858881Z INFO 02-25 17:44:03 [cpu_binding.py:290] NPU6: main=[240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277]  acl=[278]  release=[[279]]
2026-02-25T17:44:03.1608576Z WARNING 02-25 17:44:03 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-25T17:44:03.1841658Z WARNING 02-25 17:44:03 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-25T17:44:03.1875884Z WARNING 02-25 17:44:03 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-25T17:44:03.1902578Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m INFO 02-25 17:44:03 [model_runner_v1.py:2319] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-25T17:44:03.2090780Z WARNING 02-25 17:44:03 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-25T17:44:03.2125466Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m INFO 02-25 17:44:03 [model_runner_v1.py:2319] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-25T17:44:03.2741925Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m INFO 02-25 17:44:03 [layer.py:475] [EP Rank 8/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->64, 1->65, 2->66, 3->67, 4->68, 5->69, 6->70, 7->71.
2026-02-25T17:44:03.3548045Z INFO 02-25 17:44:03 [cpu_binding.py:285] The CPU allocation plan is as follows:
2026-02-25T17:44:03.3560232Z INFO 02-25 17:44:03 [cpu_binding.py:290] NPU7: main=[280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317]  acl=[318]  release=[[319]]
2026-02-25T17:44:03.4261568Z INFO 02-25 17:44:03 [cpu_binding.py:285] The CPU allocation plan is as follows:
2026-02-25T17:44:03.4270244Z INFO 02-25 17:44:03 [cpu_binding.py:290] NPU0: main=[0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37]  acl=[38]  release=[[39]]
2026-02-25T17:44:03.4881823Z WARNING 02-25 17:44:03 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-25T17:44:03.5127650Z WARNING 02-25 17:44:03 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-25T17:44:03.5137573Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m INFO 02-25 17:44:03 [model_runner_v1.py:2319] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-25T17:44:03.5294662Z WARNING 02-25 17:44:03 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-25T17:44:03.5543834Z WARNING 02-25 17:44:03 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-25T17:44:03.5644976Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m [2026-02-25 17:44:03] INFO modelslim_config.py:290: Using the vLLM Ascend modelslim Quantization now!
2026-02-25T17:44:03.6351841Z INFO 02-25 17:44:03 [cpu_binding.py:285] The CPU allocation plan is as follows:
2026-02-25T17:44:03.6361383Z INFO 02-25 17:44:03 [cpu_binding.py:290] NPU10: main=[80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117]  acl=[118]  release=[[119]]
2026-02-25T17:44:03.6379158Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m INFO 02-25 17:44:03 [model_runner_v1.py:2319] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-25T17:44:03.6724606Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m INFO 02-25 17:44:03 [layer.py:475] [EP Rank 6/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->48, 1->49, 2->50, 3->51, 4->52, 5->53, 6->54, 7->55.
2026-02-25T17:44:03.7012224Z INFO 02-25 17:44:03 [cpu_binding.py:285] The CPU allocation plan is as follows:
2026-02-25T17:44:03.7021325Z INFO 02-25 17:44:03 [cpu_binding.py:290] NPU15: main=[280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317]  acl=[318]  release=[[319]]
2026-02-25T17:44:03.7343900Z WARNING 02-25 17:44:03 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-25T17:44:03.7572386Z WARNING 02-25 17:44:03 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-25T17:44:03.7607206Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m INFO 02-25 17:44:03 [model_runner_v1.py:2319] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-25T17:44:03.7630019Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m [2026-02-25 17:44:03] INFO modelslim_config.py:290: Using the vLLM Ascend modelslim Quantization now!
2026-02-25T17:44:03.8135603Z WARNING 02-25 17:44:03 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-25T17:44:03.8234420Z INFO 02-25 17:44:03 [cpu_binding.py:285] The CPU allocation plan is as follows:
2026-02-25T17:44:03.8244322Z INFO 02-25 17:44:03 [cpu_binding.py:290] NPU14: main=[240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277]  acl=[278]  release=[[279]]
2026-02-25T17:44:03.8380903Z WARNING 02-25 17:44:03 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-25T17:44:03.8422903Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m INFO 02-25 17:44:03 [model_runner_v1.py:2319] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-25T17:44:03.8733404Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m INFO 02-25 17:44:03 [layer.py:475] [EP Rank 12/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->96, 1->97, 2->98, 3->99, 4->100, 5->101, 6->102, 7->103.
2026-02-25T17:44:03.8775580Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m [2026-02-25 17:44:03] INFO modelslim_config.py:290: Using the vLLM Ascend modelslim Quantization now!
2026-02-25T17:44:03.9442592Z WARNING 02-25 17:44:03 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-25T17:44:03.9686129Z WARNING 02-25 17:44:03 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-25T17:44:03.9723430Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m INFO 02-25 17:44:03 [model_runner_v1.py:2319] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-25T17:44:03.9852672Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m INFO 02-25 17:44:03 [layer.py:475] [EP Rank 7/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->56, 1->57, 2->58, 3->59, 4->60, 5->61, 6->62, 7->63.
2026-02-25T17:44:03.9997924Z INFO 02-25 17:44:03 [cpu_binding.py:285] The CPU allocation plan is as follows:
2026-02-25T17:44:04.0009718Z INFO 02-25 17:44:03 [cpu_binding.py:290] NPU5: main=[200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237]  acl=[238]  release=[[239]]
2026-02-25T17:44:04.0714256Z INFO 02-25 17:44:04 [cpu_binding.py:285] The CPU allocation plan is as follows:
2026-02-25T17:44:04.0723181Z INFO 02-25 17:44:04 [cpu_binding.py:290] NPU13: main=[200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237]  acl=[238]  release=[[239]]
2026-02-25T17:44:04.1003297Z WARNING 02-25 17:44:04 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-25T17:44:04.1250953Z WARNING 02-25 17:44:04 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-25T17:44:04.1294083Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m INFO 02-25 17:44:04 [model_runner_v1.py:2319] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-25T17:44:04.1705904Z WARNING 02-25 17:44:04 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-25T17:44:04.1953858Z WARNING 02-25 17:44:04 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-25T17:44:04.1994543Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m INFO 02-25 17:44:04 [model_runner_v1.py:2319] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-25T17:44:04.2410595Z INFO 02-25 17:44:04 [cpu_binding.py:285] The CPU allocation plan is as follows:
2026-02-25T17:44:04.2420752Z INFO 02-25 17:44:04 [cpu_binding.py:290] NPU1: main=[40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77]  acl=[78]  release=[[79]]
2026-02-25T17:44:04.3056335Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m [2026-02-25 17:44:04] INFO modelslim_config.py:290: Using the vLLM Ascend modelslim Quantization now!
2026-02-25T17:44:04.3626481Z WARNING 02-25 17:44:04 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-25T17:44:04.3690987Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m [2026-02-25 17:44:04] INFO modelslim_config.py:290: Using the vLLM Ascend modelslim Quantization now!
2026-02-25T17:44:04.3901735Z WARNING 02-25 17:44:04 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-25T17:44:04.3948374Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m INFO 02-25 17:44:04 [model_runner_v1.py:2319] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-25T17:44:04.4185487Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m INFO 02-25 17:44:04 [layer.py:475] [EP Rank 10/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->80, 1->81, 2->82, 3->83, 4->84, 5->85, 6->86, 7->87.
2026-02-25T17:44:04.5101922Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m [2026-02-25 17:44:04] INFO modelslim_config.py:290: Using the vLLM Ascend modelslim Quantization now!
2026-02-25T17:44:04.5307593Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m INFO 02-25 17:44:04 [layer.py:475] [EP Rank 0/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->0, 1->1, 2->2, 3->3, 4->4, 5->5, 6->6, 7->7.
2026-02-25T17:44:04.6244852Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m INFO 02-25 17:44:04 [layer.py:475] [EP Rank 15/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->120, 1->121, 2->122, 3->123, 4->124, 5->125, 6->126, 7->127.
2026-02-25T17:44:04.6276104Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m [2026-02-25 17:44:04] INFO modelslim_config.py:290: Using the vLLM Ascend modelslim Quantization now!
2026-02-25T17:44:04.6713158Z INFO 02-25 17:44:04 [cpu_binding.py:285] The CPU allocation plan is as follows:
2026-02-25T17:44:04.6724597Z INFO 02-25 17:44:04 [cpu_binding.py:290] NPU2: main=[80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117]  acl=[118]  release=[[119]]
2026-02-25T17:44:04.7419036Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m INFO 02-25 17:44:04 [layer.py:475] [EP Rank 14/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->112, 1->113, 2->114, 3->115, 4->116, 5->117, 6->118, 7->119.
2026-02-25T17:44:04.7444786Z INFO 02-25 17:44:04 [cpu_binding.py:285] The CPU allocation plan is as follows:
2026-02-25T17:44:04.7455741Z INFO 02-25 17:44:04 [cpu_binding.py:290] NPU9: main=[40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77]  acl=[78]  release=[[79]]
2026-02-25T17:44:04.8300113Z WARNING 02-25 17:44:04 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-25T17:44:04.8491203Z WARNING 02-25 17:44:04 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-25T17:44:04.8600208Z WARNING 02-25 17:44:04 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-25T17:44:04.8669509Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m INFO 02-25 17:44:04 [model_runner_v1.py:2319] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-25T17:44:04.8702565Z WARNING 02-25 17:44:04 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-25T17:44:04.8734378Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m [2026-02-25 17:44:04] INFO modelslim_config.py:290: Using the vLLM Ascend modelslim Quantization now!
2026-02-25T17:44:04.8744303Z INFO 02-25 17:44:04 [cpu_binding.py:285] The CPU allocation plan is as follows:
2026-02-25T17:44:04.8754952Z INFO 02-25 17:44:04 [cpu_binding.py:290] NPU3: main=[120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157]  acl=[158]  release=[[159]]
2026-02-25T17:44:04.8765381Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m INFO 02-25 17:44:04 [model_runner_v1.py:2319] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-25T17:44:04.9073447Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m [2026-02-25 17:44:04] INFO modelslim_config.py:290: Using the vLLM Ascend modelslim Quantization now!
2026-02-25T17:44:04.9842152Z WARNING 02-25 17:44:04 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-25T17:44:04.9948958Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m INFO 02-25 17:44:04 [layer.py:475] [EP Rank 5/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->40, 1->41, 2->42, 3->43, 4->44, 5->45, 6->46, 7->47.
2026-02-25T17:44:05.0129563Z WARNING 02-25 17:44:05 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-25T17:44:05.0198171Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m INFO 02-25 17:44:05 [model_runner_v1.py:2319] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-25T17:44:05.0326856Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m INFO 02-25 17:44:05 [layer.py:475] [EP Rank 13/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->104, 1->105, 2->106, 3->107, 4->108, 5->109, 6->110, 7->111.
2026-02-25T17:44:05.1034167Z INFO 02-25 17:44:05 [cpu_binding.py:285] The CPU allocation plan is as follows:
2026-02-25T17:44:05.1044104Z INFO 02-25 17:44:05 [cpu_binding.py:290] NPU11: main=[120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157]  acl=[158]  release=[[159]]
2026-02-25T17:44:05.1813282Z INFO 02-25 17:44:05 [cpu_binding.py:285] The CPU allocation plan is as follows:
2026-02-25T17:44:05.1821253Z INFO 02-25 17:44:05 [cpu_binding.py:290] NPU4: main=[160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197]  acl=[198]  release=[[199]]
2026-02-25T17:44:05.2021845Z WARNING 02-25 17:44:05 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-25T17:44:05.2267055Z WARNING 02-25 17:44:05 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-25T17:44:05.2310391Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m INFO 02-25 17:44:05 [model_runner_v1.py:2319] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-25T17:44:05.2361563Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m [2026-02-25 17:44:05] INFO modelslim_config.py:290: Using the vLLM Ascend modelslim Quantization now!
2026-02-25T17:44:05.3005560Z WARNING 02-25 17:44:05 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-25T17:44:05.3228354Z WARNING 02-25 17:44:05 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-25T17:44:05.3264254Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m INFO 02-25 17:44:05 [model_runner_v1.py:2319] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-25T17:44:05.3471958Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m INFO 02-25 17:44:05 [layer.py:475] [EP Rank 9/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->72, 1->73, 2->74, 3->75, 4->76, 5->77, 6->78, 7->79.
2026-02-25T17:44:05.8947436Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m [2026-02-25 17:44:05] INFO modelslim_config.py:290: Using the vLLM Ascend modelslim Quantization now!
2026-02-25T17:44:05.9552172Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m [2026-02-25 17:44:05] INFO modelslim_config.py:290: Using the vLLM Ascend modelslim Quantization now!
2026-02-25T17:44:06.0097688Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m INFO 02-25 17:44:06 [layer.py:475] [EP Rank 11/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->88, 1->89, 2->90, 3->91, 4->92, 5->93, 6->94, 7->95.
2026-02-25T17:44:06.0752768Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m INFO 02-25 17:44:06 [layer.py:475] [EP Rank 4/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->32, 1->33, 2->34, 3->35, 4->36, 5->37, 6->38, 7->39.
2026-02-25T17:44:06.1931011Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m [2026-02-25 17:44:06] INFO modelslim_config.py:290: Using the vLLM Ascend modelslim Quantization now!
2026-02-25T17:44:06.3226845Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m INFO 02-25 17:44:06 [layer.py:475] [EP Rank 1/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->8, 1->9, 2->10, 3->11, 4->12, 5->13, 6->14, 7->15.
2026-02-25T17:44:06.6351099Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m [2026-02-25 17:44:06] INFO modelslim_config.py:290: Using the vLLM Ascend modelslim Quantization now!
2026-02-25T17:44:06.6524392Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m [2026-02-25 17:44:06] INFO modelslim_config.py:290: Using the vLLM Ascend modelslim Quantization now!
2026-02-25T17:44:06.7636019Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m INFO 02-25 17:44:06 [layer.py:475] [EP Rank 2/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->16, 1->17, 2->18, 3->19, 4->20, 5->21, 6->22, 7->23.
2026-02-25T17:44:06.7663165Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m INFO 02-25 17:44:06 [layer.py:475] [EP Rank 3/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->24, 1->25, 2->26, 3->27, 4->28, 5->29, 6->30, 7->31.
2026-02-25T17:44:08.3727590Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-25T17:44:08.3735931Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-25T17:44:08.3748015Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-25T17:44:08.3759064Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-25T17:44:08.3769667Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.3781456Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-25T17:44:08.3790905Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-25T17:44:08.3801615Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 429, in load_model
2026-02-25T17:44:08.3813485Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-25T17:44:08.3823356Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2322, in load_model
2026-02-25T17:44:08.3834158Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-25T17:44:08.3844493Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.3854829Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-25T17:44:08.3864205Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     return loader.load_model(
2026-02-25T17:44:08.3874043Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.3885403Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-25T17:44:08.3894881Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     model = initialize_model(
2026-02-25T17:44:08.3904725Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.3914677Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-25T17:44:08.3925240Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-25T17:44:08.3935064Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.3945715Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-25T17:44:08.3955450Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-25T17:44:08.3964723Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-25T17:44:08.3974898Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-25T17:44:08.3985252Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-25T17:44:08.3995435Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-25T17:44:08.4005295Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-25T17:44:08.4014851Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-25T17:44:08.4025171Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-25T17:44:08.4038824Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     + [
2026-02-25T17:44:08.4049368Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]       ^
2026-02-25T17:44:08.4059938Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-25T17:44:08.4069690Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-25T17:44:08.4079904Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.4090424Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-25T17:44:08.4099925Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-25T17:44:08.4109685Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.4119382Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-25T17:44:08.4129885Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-25T17:44:08.4139435Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-25T17:44:08.4149648Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-25T17:44:08.4159199Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-25T17:44:08.4169130Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-25T17:44:08.4179300Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 512, in __init__
2026-02-25T17:44:08.4188430Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-25T17:44:08.4198904Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 240, in __init__
2026-02-25T17:44:08.4209245Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-25T17:44:08.4219782Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-25T17:44:08.4228961Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-25T17:44:08.4238553Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.4247995Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-25T17:44:08.4261251Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-25T17:44:08.4268856Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.4278597Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 424, in get_quant_method
2026-02-25T17:44:08.4288226Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-25T17:44:08.4298379Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.4308029Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 299, in create_scheme_for_layer
2026-02-25T17:44:08.4317848Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     return scheme_cls()
2026-02-25T17:44:08.4326741Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-25T17:44:08.4337501Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-25T17:44:08.4347208Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-25T17:44:08.4356921Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.4367742Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-25T17:44:08.4377618Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] [ERROR] 2026-02-25-17:44:07 (PID:896, Device:7, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-25T17:44:08.4387325Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] 
2026-02-25T17:44:08.4396959Z [0;36m(Worker_DP0_TP7_EP7 pid=896)[0;0m INFO 02-25 17:44:08 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-25T17:44:08.4406589Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-25T17:44:08.4416811Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-25T17:44:08.4426707Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-25T17:44:08.4436646Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-25T17:44:08.4446765Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.4457012Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-25T17:44:08.4466774Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-25T17:44:08.4476928Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 429, in load_model
2026-02-25T17:44:08.4486349Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-25T17:44:08.4496596Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2322, in load_model
2026-02-25T17:44:08.4506367Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-25T17:44:08.4516245Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.4526179Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-25T17:44:08.4536298Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     return loader.load_model(
2026-02-25T17:44:08.4545770Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.4555948Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-25T17:44:08.4564814Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     model = initialize_model(
2026-02-25T17:44:08.4574960Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.4585036Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-25T17:44:08.4595197Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-25T17:44:08.4605013Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.4614799Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-25T17:44:08.4624761Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-25T17:44:08.4633597Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-25T17:44:08.4643497Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-25T17:44:08.4653462Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-25T17:44:08.4663081Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-25T17:44:08.4673491Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-25T17:44:08.4682718Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-25T17:44:08.4692923Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-25T17:44:08.4701858Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     + [
2026-02-25T17:44:08.4711275Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]       ^
2026-02-25T17:44:08.4721719Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-25T17:44:08.4731767Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-25T17:44:08.4770507Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.4781813Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-25T17:44:08.4790452Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-25T17:44:08.4799614Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.4809884Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-25T17:44:08.4819755Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-25T17:44:08.4829176Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-25T17:44:08.4839398Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-25T17:44:08.4849268Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-25T17:44:08.4859108Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-25T17:44:08.4868948Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 512, in __init__
2026-02-25T17:44:08.4878481Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-25T17:44:08.4889018Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 240, in __init__
2026-02-25T17:44:08.4898389Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-25T17:44:08.4908508Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-25T17:44:08.4918034Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-25T17:44:08.4927456Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.4938054Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-25T17:44:08.4947705Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-25T17:44:08.4957843Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.4969041Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 424, in get_quant_method
2026-02-25T17:44:08.4980688Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-25T17:44:08.4990263Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.4999963Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 299, in create_scheme_for_layer
2026-02-25T17:44:08.5009807Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     return scheme_cls()
2026-02-25T17:44:08.5019470Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-25T17:44:08.5029451Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-25T17:44:08.5039662Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-25T17:44:08.5049412Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.5060082Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-25T17:44:08.5069339Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] [ERROR] 2026-02-25-17:44:07 (PID:208, Device:0, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-25T17:44:08.5078589Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] 
2026-02-25T17:44:08.5088392Z [0;36m(Worker_DP1_TP0_EP8 pid=208)[0;0m INFO 02-25 17:44:08 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-25T17:44:08.5098803Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-25T17:44:08.5108420Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-25T17:44:08.5118309Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-25T17:44:08.5127471Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-25T17:44:08.5137370Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.5147152Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-25T17:44:08.5157461Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-25T17:44:08.5166718Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 429, in load_model
2026-02-25T17:44:08.5177462Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-25T17:44:08.5187127Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2322, in load_model
2026-02-25T17:44:08.5197492Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-25T17:44:08.5206296Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.5216323Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-25T17:44:08.5225893Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     return loader.load_model(
2026-02-25T17:44:08.5234804Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.5244713Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-25T17:44:08.5254869Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     model = initialize_model(
2026-02-25T17:44:08.5264952Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.5274396Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-25T17:44:08.5283363Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-25T17:44:08.5293597Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.5303584Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-25T17:44:08.5312941Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-25T17:44:08.5323375Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-25T17:44:08.5333581Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-25T17:44:08.5343370Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-25T17:44:08.5352575Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-25T17:44:08.5363373Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-25T17:44:08.5371654Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-25T17:44:08.5382236Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-25T17:44:08.5391092Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     + [
2026-02-25T17:44:08.5405130Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]       ^
2026-02-25T17:44:08.5414958Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-25T17:44:08.5425007Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-25T17:44:08.5434319Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.5444465Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-25T17:44:08.5454827Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-25T17:44:08.5463871Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.5473334Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-25T17:44:08.5483047Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-25T17:44:08.5493102Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-25T17:44:08.5503105Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-25T17:44:08.5511809Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-25T17:44:08.5521410Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-25T17:44:08.5531291Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 512, in __init__
2026-02-25T17:44:08.5540931Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-25T17:44:08.5551595Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 240, in __init__
2026-02-25T17:44:08.5560255Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-25T17:44:08.5570956Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-25T17:44:08.5580336Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-25T17:44:08.5589521Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.5599826Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-25T17:44:08.5609582Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-25T17:44:08.5620037Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.5629198Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 424, in get_quant_method
2026-02-25T17:44:08.5638986Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-25T17:44:08.5648406Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.5659323Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 299, in create_scheme_for_layer
2026-02-25T17:44:08.5668522Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     return scheme_cls()
2026-02-25T17:44:08.5677605Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-25T17:44:08.5687599Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-25T17:44:08.5697553Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-25T17:44:08.5707728Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.5718048Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-25T17:44:08.5728971Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] [ERROR] 2026-02-25-17:44:07 (PID:376, Device:2, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-25T17:44:08.5737575Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] 
2026-02-25T17:44:08.5747391Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m INFO 02-25 17:44:08 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-25T17:44:08.5756293Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m INFO 02-25 17:44:08 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-25T17:44:08.5765749Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m INFO 02-25 17:44:08 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-25T17:44:08.5775252Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-25T17:44:08.5785212Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-25T17:44:08.5794813Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-25T17:44:08.5804223Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-25T17:44:08.5814139Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.5824131Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-25T17:44:08.5833417Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-25T17:44:08.5843390Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 429, in load_model
2026-02-25T17:44:08.5853703Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-25T17:44:08.5863362Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2322, in load_model
2026-02-25T17:44:08.5873005Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-25T17:44:08.5882961Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.5893797Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-25T17:44:08.5903348Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     return loader.load_model(
2026-02-25T17:44:08.5912957Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.5922723Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-25T17:44:08.5932280Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     model = initialize_model(
2026-02-25T17:44:08.5942232Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.5952220Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-25T17:44:08.5961662Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-25T17:44:08.5971276Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.5981760Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-25T17:44:08.5991447Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-25T17:44:08.6006488Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-25T17:44:08.6023886Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-25T17:44:08.6034872Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-25T17:44:08.6045937Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-25T17:44:08.6057291Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-25T17:44:08.6068559Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-25T17:44:08.6079643Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-25T17:44:08.6090777Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     + [
2026-02-25T17:44:08.6101411Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]       ^
2026-02-25T17:44:08.6112208Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-25T17:44:08.6122661Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-25T17:44:08.6132990Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.6143769Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-25T17:44:08.6153356Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-25T17:44:08.6162696Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.6173329Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-25T17:44:08.6183186Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-25T17:44:08.6193020Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-25T17:44:08.6203206Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-25T17:44:08.6214220Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-25T17:44:08.6223980Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-25T17:44:08.6234034Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 512, in __init__
2026-02-25T17:44:08.6243830Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-25T17:44:08.6254308Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 240, in __init__
2026-02-25T17:44:08.6263522Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-25T17:44:08.6273890Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-25T17:44:08.6283392Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-25T17:44:08.6293536Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.6304310Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-25T17:44:08.6314302Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-25T17:44:08.6324774Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.6335097Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 424, in get_quant_method
2026-02-25T17:44:08.6345198Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-25T17:44:08.6355209Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.6365793Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 299, in create_scheme_for_layer
2026-02-25T17:44:08.6375093Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     return scheme_cls()
2026-02-25T17:44:08.6384615Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-25T17:44:08.6395040Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-25T17:44:08.6404605Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-25T17:44:08.6415125Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.6426172Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-25T17:44:08.6436161Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] [ERROR] 2026-02-25-17:44:07 (PID:260, Device:1, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-25T17:44:08.6445145Z [0;36m(Worker_DP1_TP1_EP9 pid=260)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] 
2026-02-25T17:44:08.6456350Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m INFO 02-25 17:44:08 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-25T17:44:08.6467226Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m INFO 02-25 17:44:08 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-25T17:44:08.6495937Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-25T17:44:08.6509535Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-25T17:44:08.6520359Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-25T17:44:08.6531389Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-25T17:44:08.6541916Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.6552175Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-25T17:44:08.6562546Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-25T17:44:08.6572808Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 429, in load_model
2026-02-25T17:44:08.6582464Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-25T17:44:08.6592584Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2322, in load_model
2026-02-25T17:44:08.6602533Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-25T17:44:08.6612469Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.6622742Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-25T17:44:08.6633021Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     return loader.load_model(
2026-02-25T17:44:08.6655795Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.6656590Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-25T17:44:08.6664353Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     model = initialize_model(
2026-02-25T17:44:08.6673700Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.6684688Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-25T17:44:08.6694840Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-25T17:44:08.6704728Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.6714394Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-25T17:44:08.6724445Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-25T17:44:08.6735671Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-25T17:44:08.6746642Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-25T17:44:08.6756747Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-25T17:44:08.6767318Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-25T17:44:08.6778074Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-25T17:44:08.6787908Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-25T17:44:08.6797353Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-25T17:44:08.6807227Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     + [
2026-02-25T17:44:08.6817637Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]       ^
2026-02-25T17:44:08.6830008Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-25T17:44:08.6840323Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-25T17:44:08.6852298Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.6862166Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-25T17:44:08.6871812Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-25T17:44:08.6881216Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.6891551Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-25T17:44:08.6901343Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-25T17:44:08.6910473Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-25T17:44:08.6920539Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-25T17:44:08.6979472Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-25T17:44:08.6980245Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-25T17:44:08.6981027Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 512, in __init__
2026-02-25T17:44:08.6981878Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-25T17:44:08.6982827Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 240, in __init__
2026-02-25T17:44:08.6983770Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-25T17:44:08.6989131Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-25T17:44:08.6999143Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-25T17:44:08.7009326Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.7019345Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-25T17:44:08.7029143Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-25T17:44:08.7038986Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.7052079Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 424, in get_quant_method
2026-02-25T17:44:08.7059208Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-25T17:44:08.7068992Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.7078053Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 299, in create_scheme_for_layer
2026-02-25T17:44:08.7086902Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     return scheme_cls()
2026-02-25T17:44:08.7098051Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-25T17:44:08.7107795Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-25T17:44:08.7117416Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-25T17:44:08.7126934Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.7137982Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-25T17:44:08.7148714Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] [ERROR] 2026-02-25-17:44:07 (PID:379, Device:2, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-25T17:44:08.7157814Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] 
2026-02-25T17:44:08.7167777Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m INFO 02-25 17:44:08 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-25T17:44:08.7177998Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-25T17:44:08.7187054Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-25T17:44:08.7197400Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-25T17:44:08.7207223Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-25T17:44:08.7217451Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.7227418Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-25T17:44:08.7236422Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-25T17:44:08.7246771Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 429, in load_model
2026-02-25T17:44:08.7256469Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-25T17:44:08.7267247Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2322, in load_model
2026-02-25T17:44:08.7275925Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-25T17:44:08.7285214Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.7295670Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-25T17:44:08.7306190Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     return loader.load_model(
2026-02-25T17:44:08.7314969Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.7326189Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-25T17:44:08.7335222Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     model = initialize_model(
2026-02-25T17:44:08.7344830Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.7355085Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-25T17:44:08.7364950Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-25T17:44:08.7374915Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.7384942Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-25T17:44:08.7394699Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-25T17:44:08.7404722Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-25T17:44:08.7414225Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-25T17:44:08.7423278Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-25T17:44:08.7432701Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-25T17:44:08.7442656Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-25T17:44:08.7452381Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-25T17:44:08.7462721Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-25T17:44:08.7472562Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     + [
2026-02-25T17:44:08.7482781Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]       ^
2026-02-25T17:44:08.7494188Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-25T17:44:08.7504368Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-25T17:44:08.7514038Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.7523739Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-25T17:44:08.7533230Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-25T17:44:08.7543022Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.7552677Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-25T17:44:08.7562348Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-25T17:44:08.7571430Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-25T17:44:08.7581929Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-25T17:44:08.7591452Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-25T17:44:08.7600944Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-25T17:44:08.7611329Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 512, in __init__
2026-02-25T17:44:08.7620705Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-25T17:44:08.7630855Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 240, in __init__
2026-02-25T17:44:08.7640152Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-25T17:44:08.7695801Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-25T17:44:08.7696638Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-25T17:44:08.7697457Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.7698308Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-25T17:44:08.7699374Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-25T17:44:08.7700256Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.7710172Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 424, in get_quant_method
2026-02-25T17:44:08.7719693Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-25T17:44:08.7731111Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.7741021Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 299, in create_scheme_for_layer
2026-02-25T17:44:08.7750097Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     return scheme_cls()
2026-02-25T17:44:08.7759745Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-25T17:44:08.7770273Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-25T17:44:08.7780133Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-25T17:44:08.7789916Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.7799861Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-25T17:44:08.7810044Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] [ERROR] 2026-02-25-17:44:07 (PID:792, Device:6, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-25T17:44:08.7819447Z [0;36m(Worker_DP0_TP6_EP6 pid=792)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] 
2026-02-25T17:44:08.7828627Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m INFO 02-25 17:44:08 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-25T17:44:08.7838420Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-25T17:44:08.7848087Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-25T17:44:08.7858344Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-25T17:44:08.7868209Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-25T17:44:08.7877531Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.7886901Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-25T17:44:08.7896375Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-25T17:44:08.7905977Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 429, in load_model
2026-02-25T17:44:08.7915171Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-25T17:44:08.7924703Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2322, in load_model
2026-02-25T17:44:08.7934729Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-25T17:44:08.7944670Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.7954421Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-25T17:44:08.7964042Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     return loader.load_model(
2026-02-25T17:44:08.7973317Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.7983651Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-25T17:44:08.7992192Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     model = initialize_model(
2026-02-25T17:44:08.8001856Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.8012506Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-25T17:44:08.8021542Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-25T17:44:08.8031512Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.8041604Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-25T17:44:08.8052291Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-25T17:44:08.8063176Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-25T17:44:08.8073601Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-25T17:44:08.8083929Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-25T17:44:08.8093499Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-25T17:44:08.8151867Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-25T17:44:08.8153059Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-25T17:44:08.8154356Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-25T17:44:08.8155572Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     + [
2026-02-25T17:44:08.8156361Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]       ^
2026-02-25T17:44:08.8157481Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-25T17:44:08.8162651Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-25T17:44:08.8173332Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.8182728Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-25T17:44:08.8192099Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-25T17:44:08.8201678Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.8212491Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-25T17:44:08.8221193Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-25T17:44:08.8231507Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-25T17:44:08.8241584Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-25T17:44:08.8251249Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-25T17:44:08.8261079Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-25T17:44:08.8270904Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 512, in __init__
2026-02-25T17:44:08.8281052Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-25T17:44:08.8291167Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 240, in __init__
2026-02-25T17:44:08.8300737Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-25T17:44:08.8310425Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-25T17:44:08.8320419Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-25T17:44:08.8331510Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.8342405Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-25T17:44:08.8352859Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-25T17:44:08.8362581Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.8373638Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 424, in get_quant_method
2026-02-25T17:44:08.8384345Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-25T17:44:08.8394162Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.8404535Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 299, in create_scheme_for_layer
2026-02-25T17:44:08.8413958Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     return scheme_cls()
2026-02-25T17:44:08.8422962Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-25T17:44:08.8433180Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-25T17:44:08.8442276Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-25T17:44:08.8452602Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.8463269Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-25T17:44:08.8472870Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] [ERROR] 2026-02-25-17:44:07 (PID:258, Device:1, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-25T17:44:08.8482690Z [0;36m(Worker_DP0_TP1_EP1 pid=258)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] 
2026-02-25T17:44:08.8493712Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m INFO 02-25 17:44:08 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-25T17:44:08.8601024Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m INFO 02-25 17:44:08 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-25T17:44:08.8638207Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-25T17:44:08.8667054Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-25T17:44:08.8667971Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-25T17:44:08.8668766Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-25T17:44:08.8677657Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.8687470Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-25T17:44:08.8697896Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-25T17:44:08.8707974Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 429, in load_model
2026-02-25T17:44:08.8717772Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-25T17:44:08.8727072Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2322, in load_model
2026-02-25T17:44:08.8737528Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-25T17:44:08.8747181Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.8756620Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-25T17:44:08.8766554Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     return loader.load_model(
2026-02-25T17:44:08.8776613Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.8787113Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-25T17:44:08.8797153Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     model = initialize_model(
2026-02-25T17:44:08.8806248Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.8816297Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-25T17:44:08.8826052Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-25T17:44:08.8835288Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.8845861Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-25T17:44:08.8854954Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-25T17:44:08.8864863Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-25T17:44:08.8874792Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-25T17:44:08.8884945Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-25T17:44:08.8895568Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-25T17:44:08.8904774Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-25T17:44:08.8913475Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-25T17:44:08.8923455Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-25T17:44:08.8933390Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     + [
2026-02-25T17:44:08.8943269Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]       ^
2026-02-25T17:44:08.8953149Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-25T17:44:08.8965154Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-25T17:44:08.8975650Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.8986274Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-25T17:44:08.8996305Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-25T17:44:08.9006692Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.9017039Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-25T17:44:08.9026665Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-25T17:44:08.9036002Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-25T17:44:08.9046397Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-25T17:44:08.9056140Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-25T17:44:08.9065768Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-25T17:44:08.9075175Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 512, in __init__
2026-02-25T17:44:08.9087079Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-25T17:44:08.9098980Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 240, in __init__
2026-02-25T17:44:08.9108788Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-25T17:44:08.9119399Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-25T17:44:08.9130024Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-25T17:44:08.9140254Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.9149960Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-25T17:44:08.9159738Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-25T17:44:08.9169830Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.9179541Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 424, in get_quant_method
2026-02-25T17:44:08.9189549Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-25T17:44:08.9198585Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.9208212Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 299, in create_scheme_for_layer
2026-02-25T17:44:08.9217913Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     return scheme_cls()
2026-02-25T17:44:08.9226895Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-25T17:44:08.9236584Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-25T17:44:08.9246041Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-25T17:44:08.9256171Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.9266331Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-25T17:44:08.9275628Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] [ERROR] 2026-02-25-17:44:07 (PID:584, Device:4, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-25T17:44:08.9284814Z [0;36m(Worker_DP0_TP4_EP4 pid=584)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] 
2026-02-25T17:44:08.9296380Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m INFO 02-25 17:44:08 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-25T17:44:08.9304615Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m INFO 02-25 17:44:08 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-25T17:44:08.9313709Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-25T17:44:08.9323760Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-25T17:44:08.9333812Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-25T17:44:08.9343356Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-25T17:44:08.9352348Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.9362185Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-25T17:44:08.9374802Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-25T17:44:08.9381651Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 429, in load_model
2026-02-25T17:44:08.9391073Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-25T17:44:08.9401071Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2322, in load_model
2026-02-25T17:44:08.9410938Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-25T17:44:08.9421038Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.9430692Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-25T17:44:08.9439670Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     return loader.load_model(
2026-02-25T17:44:08.9449080Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.9459945Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-25T17:44:08.9468774Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     model = initialize_model(
2026-02-25T17:44:08.9477988Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.9487660Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-25T17:44:08.9497683Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-25T17:44:08.9507439Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.9517428Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-25T17:44:08.9526813Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-25T17:44:08.9536551Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-25T17:44:08.9545895Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-25T17:44:08.9555945Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-25T17:44:08.9565377Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-25T17:44:08.9575318Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-25T17:44:08.9585099Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-25T17:44:08.9594960Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-25T17:44:08.9604713Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     + [
2026-02-25T17:44:08.9614425Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]       ^
2026-02-25T17:44:08.9624564Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-25T17:44:08.9633564Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-25T17:44:08.9643042Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.9653220Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-25T17:44:08.9662776Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-25T17:44:08.9671965Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.9681838Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-25T17:44:08.9691485Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-25T17:44:08.9701370Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-25T17:44:08.9711000Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-25T17:44:08.9720236Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-25T17:44:08.9730253Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-25T17:44:08.9740575Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 512, in __init__
2026-02-25T17:44:08.9750078Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-25T17:44:08.9759984Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 240, in __init__
2026-02-25T17:44:08.9769438Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-25T17:44:08.9782932Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-25T17:44:08.9794228Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-25T17:44:08.9803785Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.9814633Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-25T17:44:08.9824184Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-25T17:44:08.9833335Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.9843706Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 424, in get_quant_method
2026-02-25T17:44:08.9854092Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-25T17:44:08.9863707Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.9873662Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 299, in create_scheme_for_layer
2026-02-25T17:44:08.9882413Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     return scheme_cls()
2026-02-25T17:44:08.9892628Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-25T17:44:08.9906962Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-25T17:44:08.9916516Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-25T17:44:08.9926571Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:08.9937899Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-25T17:44:08.9947252Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] [ERROR] 2026-02-25-17:44:07 (PID:795, Device:6, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-25T17:44:08.9957296Z [0;36m(Worker_DP1_TP6_EP14 pid=795)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] 
2026-02-25T17:44:08.9967450Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m INFO 02-25 17:44:08 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-25T17:44:08.9977345Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m INFO 02-25 17:44:08 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-25T17:44:08.9987253Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-25T17:44:08.9996494Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-25T17:44:09.0006675Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-25T17:44:09.0016143Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-25T17:44:09.0025726Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.0035597Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-25T17:44:09.0044832Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-25T17:44:09.0055474Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 429, in load_model
2026-02-25T17:44:09.0065104Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-25T17:44:09.0074774Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2322, in load_model
2026-02-25T17:44:09.0084305Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-25T17:44:09.0094316Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.0105029Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-25T17:44:09.0113848Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     return loader.load_model(
2026-02-25T17:44:09.0123388Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.0133122Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-25T17:44:09.0142894Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     model = initialize_model(
2026-02-25T17:44:09.0152439Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.0162111Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-25T17:44:09.0171558Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-25T17:44:09.0181587Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.0191430Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-25T17:44:09.0200650Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-25T17:44:09.0210704Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-25T17:44:09.0220754Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-25T17:44:09.0230042Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-25T17:44:09.0239516Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-25T17:44:09.0249450Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-25T17:44:09.0260032Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-25T17:44:09.0270182Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-25T17:44:09.0279160Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     + [
2026-02-25T17:44:09.0288955Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]       ^
2026-02-25T17:44:09.0299523Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-25T17:44:09.0308978Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-25T17:44:09.0318713Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.0328608Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-25T17:44:09.0338382Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-25T17:44:09.0348202Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.0358195Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-25T17:44:09.0367508Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-25T17:44:09.0379330Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-25T17:44:09.0388304Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-25T17:44:09.0397665Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-25T17:44:09.0408016Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-25T17:44:09.0418562Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 512, in __init__
2026-02-25T17:44:09.0428270Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-25T17:44:09.0438231Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 240, in __init__
2026-02-25T17:44:09.0447919Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-25T17:44:09.0458976Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-25T17:44:09.0468747Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-25T17:44:09.0477896Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.0488254Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-25T17:44:09.0498707Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-25T17:44:09.0508900Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.0518533Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 424, in get_quant_method
2026-02-25T17:44:09.0528383Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-25T17:44:09.0538513Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.0548355Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 299, in create_scheme_for_layer
2026-02-25T17:44:09.0556988Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     return scheme_cls()
2026-02-25T17:44:09.0566491Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-25T17:44:09.0576716Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-25T17:44:09.0585888Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-25T17:44:09.0596138Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.0606779Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-25T17:44:09.0616375Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] [ERROR] 2026-02-25-17:44:07 (PID:688, Device:5, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-25T17:44:09.0625149Z [0;36m(Worker_DP0_TP5_EP5 pid=688)[0;0m ERROR 02-25 17:44:08 [multiproc_executor.py:772] 
2026-02-25T17:44:09.0634946Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m INFO 02-25 17:44:09 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-25T17:44:09.0644980Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-25T17:44:09.0654328Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-25T17:44:09.0664278Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-25T17:44:09.0673496Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-25T17:44:09.0682980Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.0693540Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-25T17:44:09.0703148Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-25T17:44:09.0712637Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 429, in load_model
2026-02-25T17:44:09.0722189Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-25T17:44:09.0732300Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2322, in load_model
2026-02-25T17:44:09.0742184Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-25T17:44:09.0751411Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.0761146Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-25T17:44:09.0771012Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     return loader.load_model(
2026-02-25T17:44:09.0780564Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.0790306Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-25T17:44:09.0799586Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     model = initialize_model(
2026-02-25T17:44:09.0809439Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.0870878Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-25T17:44:09.0871816Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-25T17:44:09.0872639Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.0873505Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-25T17:44:09.0874329Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-25T17:44:09.0874979Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-25T17:44:09.0878070Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-25T17:44:09.0887808Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-25T17:44:09.0898096Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-25T17:44:09.0907499Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-25T17:44:09.0917387Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-25T17:44:09.0927553Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-25T17:44:09.0937197Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     + [
2026-02-25T17:44:09.0946696Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]       ^
2026-02-25T17:44:09.0957549Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-25T17:44:09.0966463Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-25T17:44:09.0976603Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.0986742Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-25T17:44:09.0995857Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-25T17:44:09.1006327Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.1014841Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-25T17:44:09.1024993Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-25T17:44:09.1034115Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-25T17:44:09.1044354Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-25T17:44:09.1053513Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-25T17:44:09.1063539Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-25T17:44:09.1073373Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 512, in __init__
2026-02-25T17:44:09.1082948Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-25T17:44:09.1093176Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 240, in __init__
2026-02-25T17:44:09.1102926Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-25T17:44:09.1112364Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-25T17:44:09.1122284Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-25T17:44:09.1132300Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.1143219Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-25T17:44:09.1152500Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-25T17:44:09.1162282Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.1172806Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 424, in get_quant_method
2026-02-25T17:44:09.1182780Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-25T17:44:09.1192464Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.1202255Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 299, in create_scheme_for_layer
2026-02-25T17:44:09.1212168Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     return scheme_cls()
2026-02-25T17:44:09.1221677Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-25T17:44:09.1231680Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-25T17:44:09.1241095Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-25T17:44:09.1251464Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.1262567Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-25T17:44:09.1271898Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772] [ERROR] 2026-02-25-17:44:07 (PID:899, Device:7, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-25T17:44:09.1280592Z [0;36m(Worker_DP1_TP7_EP15 pid=899)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772] 
2026-02-25T17:44:09.1290590Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-25T17:44:09.1300452Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-25T17:44:09.1310027Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-25T17:44:09.1319363Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-25T17:44:09.1328838Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.1339418Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-25T17:44:09.1348904Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-25T17:44:09.1358094Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 429, in load_model
2026-02-25T17:44:09.1367454Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-25T17:44:09.1377854Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2322, in load_model
2026-02-25T17:44:09.1387375Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-25T17:44:09.1396857Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.1406290Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-25T17:44:09.1416184Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     return loader.load_model(
2026-02-25T17:44:09.1425872Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.1435516Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-25T17:44:09.1444947Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     model = initialize_model(
2026-02-25T17:44:09.1454606Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.1464961Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-25T17:44:09.1474128Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-25T17:44:09.1484458Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.1494790Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-25T17:44:09.1504269Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-25T17:44:09.1513718Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-25T17:44:09.1524376Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-25T17:44:09.1533585Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-25T17:44:09.1544232Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-25T17:44:09.1553951Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-25T17:44:09.1563701Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-25T17:44:09.1573845Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-25T17:44:09.1584022Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     + [
2026-02-25T17:44:09.1593521Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]       ^
2026-02-25T17:44:09.1603890Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-25T17:44:09.1613561Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-25T17:44:09.1630065Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.1633643Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-25T17:44:09.1643071Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-25T17:44:09.1659929Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.1670431Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-25T17:44:09.1680638Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-25T17:44:09.1691022Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-25T17:44:09.1701367Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-25T17:44:09.1715550Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-25T17:44:09.1724026Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-25T17:44:09.1735195Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 512, in __init__
2026-02-25T17:44:09.1745479Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-25T17:44:09.1755334Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 240, in __init__
2026-02-25T17:44:09.1764826Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-25T17:44:09.1775839Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-25T17:44:09.1786382Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-25T17:44:09.1796009Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.1806269Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-25T17:44:09.1816854Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-25T17:44:09.1826980Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.1837878Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 424, in get_quant_method
2026-02-25T17:44:09.1847653Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-25T17:44:09.1858520Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.1868954Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 299, in create_scheme_for_layer
2026-02-25T17:44:09.1877950Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     return scheme_cls()
2026-02-25T17:44:09.1887097Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-25T17:44:09.1897581Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-25T17:44:09.1907798Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-25T17:44:09.1916911Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.1927142Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-25T17:44:09.1937471Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772] [ERROR] 2026-02-25-17:44:07 (PID:483, Device:3, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-25T17:44:09.1946280Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772] 
2026-02-25T17:44:09.1956174Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-25T17:44:09.1965622Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-25T17:44:09.1975785Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-25T17:44:09.1985091Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-25T17:44:09.1995897Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.2008419Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-25T17:44:09.2018422Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-25T17:44:09.2028550Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 429, in load_model
2026-02-25T17:44:09.2039462Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-25T17:44:09.2051240Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2322, in load_model
2026-02-25T17:44:09.2063452Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-25T17:44:09.2074001Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.2083865Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-25T17:44:09.2094897Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     return loader.load_model(
2026-02-25T17:44:09.2105262Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.2115044Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-25T17:44:09.2124493Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     model = initialize_model(
2026-02-25T17:44:09.2134102Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.2143551Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-25T17:44:09.2153551Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-25T17:44:09.2164172Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.2177955Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-25T17:44:09.2187972Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-25T17:44:09.2197357Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-25T17:44:09.2207268Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-25T17:44:09.2217219Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-25T17:44:09.2225932Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-25T17:44:09.2235476Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-25T17:44:09.2245336Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-25T17:44:09.2255082Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-25T17:44:09.2264584Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     + [
2026-02-25T17:44:09.2274584Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]       ^
2026-02-25T17:44:09.2284817Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-25T17:44:09.2294525Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-25T17:44:09.2304571Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.2314408Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-25T17:44:09.2323679Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-25T17:44:09.2334012Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.2344879Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-25T17:44:09.2353123Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-25T17:44:09.2362278Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-25T17:44:09.2372778Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-25T17:44:09.2382325Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-25T17:44:09.2391703Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-25T17:44:09.2401758Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 512, in __init__
2026-02-25T17:44:09.2411787Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-25T17:44:09.2421690Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 240, in __init__
2026-02-25T17:44:09.2431033Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-25T17:44:09.2441549Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-25T17:44:09.2464187Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-25T17:44:09.2465015Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.2471029Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-25T17:44:09.2480357Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-25T17:44:09.2490193Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.2500531Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 424, in get_quant_method
2026-02-25T17:44:09.2509980Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-25T17:44:09.2519213Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.2529163Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 299, in create_scheme_for_layer
2026-02-25T17:44:09.2565011Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     return scheme_cls()
2026-02-25T17:44:09.2565733Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-25T17:44:09.2566535Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-25T17:44:09.2585689Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-25T17:44:09.2586538Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.2588483Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-25T17:44:09.2598174Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772] [ERROR] 2026-02-25-17:44:08 (PID:480, Device:3, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-25T17:44:09.2607450Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772] 
2026-02-25T17:44:09.2617311Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-25T17:44:09.2627117Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-25T17:44:09.2639050Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-25T17:44:09.2646179Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-25T17:44:09.2656513Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.2667229Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-25T17:44:09.2676489Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-25T17:44:09.2685859Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 429, in load_model
2026-02-25T17:44:09.2695640Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-25T17:44:09.2705862Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2322, in load_model
2026-02-25T17:44:09.2715358Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-25T17:44:09.2725022Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.2734907Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-25T17:44:09.2744552Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     return loader.load_model(
2026-02-25T17:44:09.2753933Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.2763572Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-25T17:44:09.2772516Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     model = initialize_model(
2026-02-25T17:44:09.2782392Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.2792316Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-25T17:44:09.2801870Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-25T17:44:09.2811392Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.2821355Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-25T17:44:09.2830959Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-25T17:44:09.2840368Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-25T17:44:09.2850447Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-25T17:44:09.2860083Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-25T17:44:09.2870054Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-25T17:44:09.2879586Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-25T17:44:09.2889160Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-25T17:44:09.2900049Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-25T17:44:09.2909078Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     + [
2026-02-25T17:44:09.2918433Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]       ^
2026-02-25T17:44:09.2928181Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-25T17:44:09.2938556Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-25T17:44:09.2947851Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.2957920Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-25T17:44:09.2970906Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-25T17:44:09.2981265Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.2991451Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-25T17:44:09.3001455Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-25T17:44:09.3011439Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-25T17:44:09.3022201Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-25T17:44:09.3031630Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-25T17:44:09.3041253Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-25T17:44:09.3051524Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 512, in __init__
2026-02-25T17:44:09.3061629Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-25T17:44:09.3071574Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 240, in __init__
2026-02-25T17:44:09.3080705Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-25T17:44:09.3090834Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-25T17:44:09.3100694Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-25T17:44:09.3110318Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.3120417Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-25T17:44:09.3130480Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-25T17:44:09.3140623Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.3150343Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 424, in get_quant_method
2026-02-25T17:44:09.3160193Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-25T17:44:09.3169803Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.3180565Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 299, in create_scheme_for_layer
2026-02-25T17:44:09.3189480Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     return scheme_cls()
2026-02-25T17:44:09.3198830Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-25T17:44:09.3209297Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-25T17:44:09.3218852Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-25T17:44:09.3228497Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.3238270Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-25T17:44:09.3248188Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772] [ERROR] 2026-02-25-17:44:07 (PID:587, Device:4, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-25T17:44:09.3257993Z [0;36m(Worker_DP1_TP4_EP12 pid=587)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772] 
2026-02-25T17:44:09.4378208Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-25T17:44:09.4387046Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-25T17:44:09.4395945Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-25T17:44:09.4404853Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-25T17:44:09.4414683Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.4424423Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-25T17:44:09.4433660Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-25T17:44:09.4444071Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 429, in load_model
2026-02-25T17:44:09.4452872Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-25T17:44:09.4462581Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2322, in load_model
2026-02-25T17:44:09.4471621Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-25T17:44:09.4481230Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.4490744Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-25T17:44:09.4499789Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     return loader.load_model(
2026-02-25T17:44:09.4509073Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.4519095Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-25T17:44:09.4527872Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     model = initialize_model(
2026-02-25T17:44:09.4537502Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.4547649Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-25T17:44:09.4557548Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-25T17:44:09.4566825Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.4576739Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-25T17:44:09.4586537Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-25T17:44:09.4595795Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-25T17:44:09.4605389Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-25T17:44:09.4614651Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-25T17:44:09.4624534Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-25T17:44:09.4633793Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-25T17:44:09.4643216Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-25T17:44:09.4653819Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-25T17:44:09.4663093Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     + [
2026-02-25T17:44:09.4672549Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]       ^
2026-02-25T17:44:09.4682699Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-25T17:44:09.4692550Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-25T17:44:09.4701876Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.4711483Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-25T17:44:09.4770685Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-25T17:44:09.4771475Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.4772378Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-25T17:44:09.4773195Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-25T17:44:09.4773768Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-25T17:44:09.4774588Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-25T17:44:09.4778675Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-25T17:44:09.4787995Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-25T17:44:09.4797688Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 512, in __init__
2026-02-25T17:44:09.4807216Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-25T17:44:09.4817769Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 240, in __init__
2026-02-25T17:44:09.4827040Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-25T17:44:09.4837098Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-25T17:44:09.4871725Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-25T17:44:09.4872721Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.4873620Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-25T17:44:09.4876786Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-25T17:44:09.4886717Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.4897384Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 424, in get_quant_method
2026-02-25T17:44:09.4906792Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-25T17:44:09.4916217Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.4925805Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 299, in create_scheme_for_layer
2026-02-25T17:44:09.4935095Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     return scheme_cls()
2026-02-25T17:44:09.4944889Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-25T17:44:09.4955192Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-25T17:44:09.4964688Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-25T17:44:09.4974977Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.4985064Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-25T17:44:09.4994674Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772] [ERROR] 2026-02-25-17:44:07 (PID:209, Device:0, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-25T17:44:09.5003902Z [0;36m(Worker_DP0_TP0_EP0 pid=209)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772] 
2026-02-25T17:44:09.5355578Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-25T17:44:09.5364918Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-25T17:44:09.5374780Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-25T17:44:09.5384874Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-25T17:44:09.5393721Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.5402908Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-25T17:44:09.5412046Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-25T17:44:09.5421901Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 429, in load_model
2026-02-25T17:44:09.5431238Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-25T17:44:09.5443859Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2322, in load_model
2026-02-25T17:44:09.5450812Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-25T17:44:09.5460750Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.5470835Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-25T17:44:09.5480432Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     return loader.load_model(
2026-02-25T17:44:09.5490589Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.5500944Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-25T17:44:09.5510578Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     model = initialize_model(
2026-02-25T17:44:09.5520306Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.5531411Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-25T17:44:09.5541039Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-25T17:44:09.5550492Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.5560513Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-25T17:44:09.5570437Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-25T17:44:09.5579422Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-25T17:44:09.5589884Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-25T17:44:09.5598406Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-25T17:44:09.5608536Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-25T17:44:09.5618291Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-25T17:44:09.5628130Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-25T17:44:09.5637933Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-25T17:44:09.5647500Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     + [
2026-02-25T17:44:09.5657317Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]       ^
2026-02-25T17:44:09.5667449Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-25T17:44:09.5677370Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-25T17:44:09.5686407Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.5696827Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-25T17:44:09.5706360Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-25T17:44:09.5716849Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.5725854Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-25T17:44:09.5735392Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-25T17:44:09.5744817Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-25T17:44:09.5755019Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-25T17:44:09.5764530Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-25T17:44:09.5774101Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-25T17:44:09.5784683Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 512, in __init__
2026-02-25T17:44:09.5793667Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-25T17:44:09.5803304Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 240, in __init__
2026-02-25T17:44:09.5813037Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-25T17:44:09.5823261Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-25T17:44:09.5833007Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-25T17:44:09.5842518Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.5852739Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-25T17:44:09.5862499Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-25T17:44:09.5871794Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.5881928Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 424, in get_quant_method
2026-02-25T17:44:09.5892074Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-25T17:44:09.5902506Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.5912076Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 299, in create_scheme_for_layer
2026-02-25T17:44:09.5921531Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     return scheme_cls()
2026-02-25T17:44:09.5930713Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-25T17:44:09.5940577Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-25T17:44:09.5950308Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-25T17:44:09.5960080Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:09.5970646Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-25T17:44:09.5980372Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772] [ERROR] 2026-02-25-17:44:07 (PID:691, Device:5, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-25T17:44:09.5989739Z [0;36m(Worker_DP1_TP5_EP13 pid=691)[0;0m ERROR 02-25 17:44:09 [multiproc_executor.py:772] 
2026-02-25T17:44:13.1869265Z [0;36m(EngineCore_DP0 pid=161)[0;0m ERROR 02-25 17:44:13 [core.py:946] EngineCore failed to start.
2026-02-25T17:44:13.1878003Z [0;36m(EngineCore_DP0 pid=161)[0;0m ERROR 02-25 17:44:13 [core.py:946] Traceback (most recent call last):
2026-02-25T17:44:13.1889025Z [0;36m(EngineCore_DP0 pid=161)[0;0m ERROR 02-25 17:44:13 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 929, in run_engine_core
2026-02-25T17:44:13.1898961Z [0;36m(EngineCore_DP0 pid=161)[0;0m ERROR 02-25 17:44:13 [core.py:946]     engine_core = DPEngineCoreProc(*args, **kwargs)
2026-02-25T17:44:13.1908288Z [0;36m(EngineCore_DP0 pid=161)[0;0m ERROR 02-25 17:44:13 [core.py:946]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:13.1918898Z [0;36m(EngineCore_DP0 pid=161)[0;0m ERROR 02-25 17:44:13 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 1279, in __init__
2026-02-25T17:44:13.1928219Z [0;36m(EngineCore_DP0 pid=161)[0;0m ERROR 02-25 17:44:13 [core.py:946]     super().__init__(
2026-02-25T17:44:13.1938244Z [0;36m(EngineCore_DP0 pid=161)[0;0m ERROR 02-25 17:44:13 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 691, in __init__
2026-02-25T17:44:13.1947804Z [0;36m(EngineCore_DP0 pid=161)[0;0m ERROR 02-25 17:44:13 [core.py:946]     super().__init__(
2026-02-25T17:44:13.1957213Z [0;36m(EngineCore_DP0 pid=161)[0;0m ERROR 02-25 17:44:13 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 105, in __init__
2026-02-25T17:44:13.1972434Z [0;36m(EngineCore_DP0 pid=161)[0;0m ERROR 02-25 17:44:13 [core.py:946]     self.model_executor = executor_class(vllm_config)
2026-02-25T17:44:13.1977599Z [0;36m(EngineCore_DP0 pid=161)[0;0m ERROR 02-25 17:44:13 [core.py:946]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:13.1987586Z [0;36m(EngineCore_DP0 pid=161)[0;0m ERROR 02-25 17:44:13 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 97, in __init__
2026-02-25T17:44:13.1998359Z [0;36m(EngineCore_DP0 pid=161)[0;0m ERROR 02-25 17:44:13 [core.py:946]     super().__init__(vllm_config)
2026-02-25T17:44:13.2007561Z [0;36m(EngineCore_DP0 pid=161)[0;0m ERROR 02-25 17:44:13 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/executor/abstract.py", line 101, in __init__
2026-02-25T17:44:13.2018122Z [0;36m(EngineCore_DP0 pid=161)[0;0m ERROR 02-25 17:44:13 [core.py:946]     self._init_executor()
2026-02-25T17:44:13.2028070Z [0;36m(EngineCore_DP0 pid=161)[0;0m ERROR 02-25 17:44:13 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 165, in _init_executor
2026-02-25T17:44:13.2037674Z [0;36m(EngineCore_DP0 pid=161)[0;0m ERROR 02-25 17:44:13 [core.py:946]     self.workers = WorkerProc.wait_for_ready(unready_workers)
2026-02-25T17:44:13.2047412Z [0;36m(EngineCore_DP0 pid=161)[0;0m ERROR 02-25 17:44:13 [core.py:946]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:13.2058312Z [0;36m(EngineCore_DP0 pid=161)[0;0m ERROR 02-25 17:44:13 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 678, in wait_for_ready
2026-02-25T17:44:13.2067930Z [0;36m(EngineCore_DP0 pid=161)[0;0m ERROR 02-25 17:44:13 [core.py:946]     raise e from None
2026-02-25T17:44:13.2078298Z [0;36m(EngineCore_DP0 pid=161)[0;0m ERROR 02-25 17:44:13 [core.py:946] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
2026-02-25T17:44:13.2087103Z [0;36m(EngineCore_DP0 pid=161)[0;0m Process EngineCore_DP0:
2026-02-25T17:44:13.2098014Z [0;36m(EngineCore_DP0 pid=161)[0;0m Traceback (most recent call last):
2026-02-25T17:44:13.2107924Z [0;36m(EngineCore_DP0 pid=161)[0;0m   File "/usr/local/python3.11.14/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
2026-02-25T17:44:13.2117109Z [0;36m(EngineCore_DP0 pid=161)[0;0m     self.run()
2026-02-25T17:44:13.2126364Z [0;36m(EngineCore_DP0 pid=161)[0;0m   File "/usr/local/python3.11.14/lib/python3.11/multiprocessing/process.py", line 108, in run
2026-02-25T17:44:13.2136237Z [0;36m(EngineCore_DP0 pid=161)[0;0m     self._target(*self._args, **self._kwargs)
2026-02-25T17:44:13.2145998Z [0;36m(EngineCore_DP0 pid=161)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 950, in run_engine_core
2026-02-25T17:44:13.2155215Z [0;36m(EngineCore_DP0 pid=161)[0;0m     raise e
2026-02-25T17:44:13.2164641Z [0;36m(EngineCore_DP0 pid=161)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 929, in run_engine_core
2026-02-25T17:44:13.2174818Z [0;36m(EngineCore_DP0 pid=161)[0;0m     engine_core = DPEngineCoreProc(*args, **kwargs)
2026-02-25T17:44:13.2184555Z [0;36m(EngineCore_DP0 pid=161)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:13.2194639Z [0;36m(EngineCore_DP0 pid=161)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 1279, in __init__
2026-02-25T17:44:13.2204104Z [0;36m(EngineCore_DP0 pid=161)[0;0m     super().__init__(
2026-02-25T17:44:13.2214194Z [0;36m(EngineCore_DP0 pid=161)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 691, in __init__
2026-02-25T17:44:13.2223514Z [0;36m(EngineCore_DP0 pid=161)[0;0m     super().__init__(
2026-02-25T17:44:13.2233173Z [0;36m(EngineCore_DP0 pid=161)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 105, in __init__
2026-02-25T17:44:13.2242844Z [0;36m(EngineCore_DP0 pid=161)[0;0m     self.model_executor = executor_class(vllm_config)
2026-02-25T17:44:13.2253896Z [0;36m(EngineCore_DP0 pid=161)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:13.2263215Z [0;36m(EngineCore_DP0 pid=161)[0;0m   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 97, in __init__
2026-02-25T17:44:13.2271833Z [0;36m(EngineCore_DP0 pid=161)[0;0m     super().__init__(vllm_config)
2026-02-25T17:44:13.2281157Z [0;36m(EngineCore_DP0 pid=161)[0;0m   File "/vllm-workspace/vllm/vllm/v1/executor/abstract.py", line 101, in __init__
2026-02-25T17:44:13.2291392Z [0;36m(EngineCore_DP0 pid=161)[0;0m     self._init_executor()
2026-02-25T17:44:13.2301231Z [0;36m(EngineCore_DP0 pid=161)[0;0m   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 165, in _init_executor
2026-02-25T17:44:13.2310663Z [0;36m(EngineCore_DP0 pid=161)[0;0m     self.workers = WorkerProc.wait_for_ready(unready_workers)
2026-02-25T17:44:13.2319567Z [0;36m(EngineCore_DP0 pid=161)[0;0m                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:13.2329875Z [0;36m(EngineCore_DP0 pid=161)[0;0m   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 678, in wait_for_ready
2026-02-25T17:44:13.2339236Z [0;36m(EngineCore_DP0 pid=161)[0;0m     raise e from None
2026-02-25T17:44:13.2349491Z [0;36m(EngineCore_DP0 pid=161)[0;0m Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
2026-02-25T17:44:13.2359154Z [0;36m(EngineCore_DP1 pid=180)[0;0m ERROR 02-25 17:44:13 [core.py:946] EngineCore failed to start.
2026-02-25T17:44:13.2368786Z [0;36m(EngineCore_DP1 pid=180)[0;0m ERROR 02-25 17:44:13 [core.py:946] Traceback (most recent call last):
2026-02-25T17:44:13.2378573Z [0;36m(EngineCore_DP1 pid=180)[0;0m ERROR 02-25 17:44:13 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 929, in run_engine_core
2026-02-25T17:44:13.2388380Z [0;36m(EngineCore_DP1 pid=180)[0;0m ERROR 02-25 17:44:13 [core.py:946]     engine_core = DPEngineCoreProc(*args, **kwargs)
2026-02-25T17:44:13.2397449Z [0;36m(EngineCore_DP1 pid=180)[0;0m ERROR 02-25 17:44:13 [core.py:946]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:13.2407574Z [0;36m(EngineCore_DP1 pid=180)[0;0m ERROR 02-25 17:44:13 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 1279, in __init__
2026-02-25T17:44:13.2417196Z [0;36m(EngineCore_DP1 pid=180)[0;0m ERROR 02-25 17:44:13 [core.py:946]     super().__init__(
2026-02-25T17:44:13.2428255Z [0;36m(EngineCore_DP1 pid=180)[0;0m ERROR 02-25 17:44:13 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 691, in __init__
2026-02-25T17:44:13.2437439Z [0;36m(EngineCore_DP1 pid=180)[0;0m ERROR 02-25 17:44:13 [core.py:946]     super().__init__(
2026-02-25T17:44:13.2446636Z [0;36m(EngineCore_DP1 pid=180)[0;0m ERROR 02-25 17:44:13 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 105, in __init__
2026-02-25T17:44:13.2457075Z [0;36m(EngineCore_DP1 pid=180)[0;0m ERROR 02-25 17:44:13 [core.py:946]     self.model_executor = executor_class(vllm_config)
2026-02-25T17:44:13.2467290Z [0;36m(EngineCore_DP1 pid=180)[0;0m ERROR 02-25 17:44:13 [core.py:946]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:13.2477787Z [0;36m(EngineCore_DP1 pid=180)[0;0m ERROR 02-25 17:44:13 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 97, in __init__
2026-02-25T17:44:13.2487033Z [0;36m(EngineCore_DP1 pid=180)[0;0m ERROR 02-25 17:44:13 [core.py:946]     super().__init__(vllm_config)
2026-02-25T17:44:13.2497056Z [0;36m(EngineCore_DP1 pid=180)[0;0m ERROR 02-25 17:44:13 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/executor/abstract.py", line 101, in __init__
2026-02-25T17:44:13.2506607Z [0;36m(EngineCore_DP1 pid=180)[0;0m ERROR 02-25 17:44:13 [core.py:946]     self._init_executor()
2026-02-25T17:44:13.2518106Z [0;36m(EngineCore_DP1 pid=180)[0;0m ERROR 02-25 17:44:13 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 165, in _init_executor
2026-02-25T17:44:13.2525927Z [0;36m(EngineCore_DP1 pid=180)[0;0m ERROR 02-25 17:44:13 [core.py:946]     self.workers = WorkerProc.wait_for_ready(unready_workers)
2026-02-25T17:44:13.2536100Z [0;36m(EngineCore_DP1 pid=180)[0;0m ERROR 02-25 17:44:13 [core.py:946]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:13.2546294Z [0;36m(EngineCore_DP1 pid=180)[0;0m ERROR 02-25 17:44:13 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 678, in wait_for_ready
2026-02-25T17:44:13.2555406Z [0;36m(EngineCore_DP1 pid=180)[0;0m ERROR 02-25 17:44:13 [core.py:946]     raise e from None
2026-02-25T17:44:13.2565464Z [0;36m(EngineCore_DP1 pid=180)[0;0m ERROR 02-25 17:44:13 [core.py:946] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
2026-02-25T17:44:13.2575047Z [0;36m(EngineCore_DP1 pid=180)[0;0m Process EngineCore_DP1:
2026-02-25T17:44:13.2584978Z [0;36m(EngineCore_DP1 pid=180)[0;0m Traceback (most recent call last):
2026-02-25T17:44:13.2594650Z [0;36m(EngineCore_DP1 pid=180)[0;0m   File "/usr/local/python3.11.14/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
2026-02-25T17:44:13.2603065Z [0;36m(EngineCore_DP1 pid=180)[0;0m     self.run()
2026-02-25T17:44:13.2613183Z [0;36m(EngineCore_DP1 pid=180)[0;0m   File "/usr/local/python3.11.14/lib/python3.11/multiprocessing/process.py", line 108, in run
2026-02-25T17:44:13.2622699Z [0;36m(EngineCore_DP1 pid=180)[0;0m     self._target(*self._args, **self._kwargs)
2026-02-25T17:44:13.2632653Z [0;36m(EngineCore_DP1 pid=180)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 950, in run_engine_core
2026-02-25T17:44:13.2641856Z [0;36m(EngineCore_DP1 pid=180)[0;0m     raise e
2026-02-25T17:44:13.2651886Z [0;36m(EngineCore_DP1 pid=180)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 929, in run_engine_core
2026-02-25T17:44:13.2661766Z [0;36m(EngineCore_DP1 pid=180)[0;0m     engine_core = DPEngineCoreProc(*args, **kwargs)
2026-02-25T17:44:13.2671126Z [0;36m(EngineCore_DP1 pid=180)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:13.2680451Z [0;36m(EngineCore_DP1 pid=180)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 1279, in __init__
2026-02-25T17:44:13.2690402Z [0;36m(EngineCore_DP1 pid=180)[0;0m     super().__init__(
2026-02-25T17:44:13.2700552Z [0;36m(EngineCore_DP1 pid=180)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 691, in __init__
2026-02-25T17:44:13.2709323Z [0;36m(EngineCore_DP1 pid=180)[0;0m     super().__init__(
2026-02-25T17:44:13.2718892Z [0;36m(EngineCore_DP1 pid=180)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 105, in __init__
2026-02-25T17:44:13.2730697Z [0;36m(EngineCore_DP1 pid=180)[0;0m     self.model_executor = executor_class(vllm_config)
2026-02-25T17:44:13.2739198Z [0;36m(EngineCore_DP1 pid=180)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:13.2747748Z [0;36m(EngineCore_DP1 pid=180)[0;0m   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 97, in __init__
2026-02-25T17:44:13.2756886Z [0;36m(EngineCore_DP1 pid=180)[0;0m     super().__init__(vllm_config)
2026-02-25T17:44:13.2766769Z [0;36m(EngineCore_DP1 pid=180)[0;0m   File "/vllm-workspace/vllm/vllm/v1/executor/abstract.py", line 101, in __init__
2026-02-25T17:44:13.2776391Z [0;36m(EngineCore_DP1 pid=180)[0;0m     self._init_executor()
2026-02-25T17:44:13.2786253Z [0;36m(EngineCore_DP1 pid=180)[0;0m   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 165, in _init_executor
2026-02-25T17:44:13.2795832Z [0;36m(EngineCore_DP1 pid=180)[0;0m     self.workers = WorkerProc.wait_for_ready(unready_workers)
2026-02-25T17:44:13.2805299Z [0;36m(EngineCore_DP1 pid=180)[0;0m                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-25T17:44:13.2815140Z [0;36m(EngineCore_DP1 pid=180)[0;0m   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 678, in wait_for_ready
2026-02-25T17:44:13.2824432Z [0;36m(EngineCore_DP1 pid=180)[0;0m     raise e from None
2026-02-25T17:44:13.2834569Z [0;36m(EngineCore_DP1 pid=180)[0;0m Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
2026-02-25T17:44:14.8804108Z Traceback (most recent call last):
2026-02-25T17:44:14.8810745Z   File "/usr/local/python3.11.14/bin/vllm", line 7, in <module>
2026-02-25T17:44:14.8820722Z     sys.exit(main())
2026-02-25T17:44:14.8830032Z              ^^^^^^
2026-02-25T17:44:14.8841482Z   File "/vllm-workspace/vllm/vllm/entrypoints/cli/main.py", line 73, in main
2026-02-25T17:44:14.8849270Z     args.dispatch_function(args)
2026-02-25T17:44:14.8858301Z   File "/vllm-workspace/vllm/vllm/entrypoints/cli/serve.py", line 108, in cmd
2026-02-25T17:44:14.8867844Z     run_multi_api_server(args)
2026-02-25T17:44:14.8876979Z   File "/vllm-workspace/vllm/vllm/entrypoints/cli/serve.py", line 248, in run_multi_api_server
2026-02-25T17:44:14.8886750Z     with launch_core_engines(
2026-02-25T17:44:14.8896641Z   File "/usr/local/python3.11.14/lib/python3.11/contextlib.py", line 144, in __exit__
2026-02-25T17:44:14.8905654Z     next(self.gen)
2026-02-25T17:44:14.8915603Z   File "/vllm-workspace/vllm/vllm/v1/engine/utils.py", line 933, in launch_core_engines
2026-02-25T17:44:14.8925041Z     wait_for_engine_startup(
2026-02-25T17:44:14.8934607Z   File "/vllm-workspace/vllm/vllm/v1/engine/utils.py", line 992, in wait_for_engine_startup
2026-02-25T17:44:14.8944006Z     raise RuntimeError(
2026-02-25T17:44:14.8953503Z RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}
2026-02-25T17:44:15.7106979Z [ERROR] 2026-02-25-17:44:14 (PID:138, Device:-1, RankID:-1) ERR99999 UNKNOWN applicaiton exception
2026-02-25T17:44:16.0063486Z sys:1: DeprecationWarning: builtin type swigvarlink has no __module__ attribute
2026-02-25T17:44:17.4018324Z /usr/local/python3.11.14/lib/python3.11/multiprocessing/resource_tracker.py:254: UserWarning: resource_tracker: There appear to be 18 leaked shared_memory objects to clean up at shutdown
2026-02-25T17:44:17.4024767Z   warnings.warn('resource_tracker: There appear to be %d '
2026-02-25T17:44:22.0439253Z FAILED
2026-02-25T17:44:22.0448165Z 
2026-02-25T17:44:22.0458641Z =================================== FAILURES ===================================
2026-02-25T17:44:22.0473247Z _______________________________ test_multi_node ________________________________
2026-02-25T17:44:22.0482961Z 
2026-02-25T17:44:22.0493370Z     @pytest.mark.asyncio
2026-02-25T17:44:22.0501662Z     async def test_multi_node() -> None:
2026-02-25T17:44:22.0512291Z         config = MultiNodeConfigLoader.from_yaml()
2026-02-25T17:44:22.0520847Z     
2026-02-25T17:44:22.0531278Z         with ProxyLauncher(
2026-02-25T17:44:22.0541012Z                 nodes=config.nodes,
2026-02-25T17:44:22.0551760Z                 disagg_cfg=config.disagg_cfg,
2026-02-25T17:44:22.0561438Z                 envs=config.envs,
2026-02-25T17:44:22.0571225Z                 proxy_port=config.proxy_port,
2026-02-25T17:44:22.0580979Z                 cur_index=config.cur_index,
2026-02-25T17:44:22.0592274Z         ) as proxy:
2026-02-25T17:44:22.0600219Z     
2026-02-25T17:44:22.0610900Z >           with RemoteOpenAIServer(
2026-02-25T17:44:22.0620098Z                     model=config.model,
2026-02-25T17:44:22.0630496Z                     vllm_serve_args=config.server_cmd,
2026-02-25T17:44:22.0640347Z                     server_port=config.server_port,
2026-02-25T17:44:22.0650455Z                     server_host=config.master_ip,
2026-02-25T17:44:22.0660327Z                     env_dict=config.envs,
2026-02-25T17:44:22.0670572Z                     auto_port=False,
2026-02-25T17:44:22.0679995Z                     proxy_port=proxy.proxy_port,
2026-02-25T17:44:22.0690518Z                     disaggregated_prefill=config.disagg_cfg,
2026-02-25T17:44:22.0700383Z                     nodes_info=config.nodes,
2026-02-25T17:44:22.0710318Z                     max_wait_seconds=2800,
2026-02-25T17:44:22.0721213Z             ) as server:
2026-02-25T17:44:22.0730655Z 
2026-02-25T17:44:22.0741554Z tests/e2e/nightly/multi_node/scripts/test_multi_node.py:21: 
2026-02-25T17:44:22.0751020Z _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
2026-02-25T17:44:22.0760831Z tests/e2e/conftest.py:306: in __init__
2026-02-25T17:44:22.0770771Z     self._wait_for_multiple_servers(
2026-02-25T17:44:22.0780336Z _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
2026-02-25T17:44:22.0790487Z 
2026-02-25T17:44:22.0800224Z self = <tests.e2e.conftest.RemoteOpenAIServer object at 0xffff265e2ed0>
2026-02-25T17:44:22.0810833Z targets = [('10.0.0.169', 'http://10.0.0.169:8080/health')], timeout = 2800
2026-02-25T17:44:22.0820132Z log_interval = 30.0
2026-02-25T17:44:22.0829907Z 
2026-02-25T17:44:22.0840246Z     def _wait_for_multiple_servers(self,
2026-02-25T17:44:22.0854829Z                                    targets,
2026-02-25T17:44:22.0863143Z                                    timeout: float,
2026-02-25T17:44:22.0873228Z                                    log_interval: float = 30.0):
2026-02-25T17:44:22.0883333Z         """
2026-02-25T17:44:22.0894204Z         targets: List[(node_ip, url)]
2026-02-25T17:44:22.0904152Z         log_interval
2026-02-25T17:44:22.0913095Z         """
2026-02-25T17:44:22.0922703Z         start = time.time()
2026-02-25T17:44:22.0933158Z         client = requests
2026-02-25T17:44:22.0942647Z     
2026-02-25T17:44:22.0951576Z         ready = {node_ip: False for node_ip, _ in targets}
2026-02-25T17:44:22.0961088Z     
2026-02-25T17:44:22.0970575Z         last_log_time = 0.0
2026-02-25T17:44:22.0980384Z     
2026-02-25T17:44:22.0990210Z         while True:
2026-02-25T17:44:22.1013616Z             now = time.time()
2026-02-25T17:44:22.1030499Z             all_ready = True
2026-02-25T17:44:22.1040680Z             should_log = (now - last_log_time) >= log_interval
2026-02-25T17:44:22.1050354Z     
2026-02-25T17:44:22.1059384Z             for node_ip, url in targets:
2026-02-25T17:44:22.1068933Z                 if ready[node_ip]:
2026-02-25T17:44:22.1078621Z                     continue
2026-02-25T17:44:22.1087095Z     
2026-02-25T17:44:22.1098006Z                 try:
2026-02-25T17:44:22.1106038Z                     resp = client.get(url)
2026-02-25T17:44:22.1115639Z                     if resp.status_code == 200:
2026-02-25T17:44:22.1125214Z                         ready[node_ip] = True
2026-02-25T17:44:22.1134989Z                         logger.info(f"[READY] Node {node_ip} is ready.")
2026-02-25T17:44:22.1144263Z                 except RequestException:
2026-02-25T17:44:22.1154085Z                     all_ready = False
2026-02-25T17:44:22.1163818Z                     if should_log:
2026-02-25T17:44:22.1173699Z                         logger.debug(f"[WAIT] {url}: connection failed")
2026-02-25T17:44:22.1182316Z     
2026-02-25T17:44:22.1191377Z                     # check unexpected exit
2026-02-25T17:44:22.1200948Z                     result = self._poll()
2026-02-25T17:44:22.1210457Z                     if result is not None and result != 0:
2026-02-25T17:44:22.1219599Z >                       raise RuntimeError(
2026-02-25T17:44:22.1229376Z                             f"Server at {node_ip} exited unexpectedly."
2026-02-25T17:44:22.1238435Z                         ) from None
2026-02-25T17:44:22.1247810Z E                       RuntimeError: Server at 10.0.0.169 exited unexpectedly.
2026-02-25T17:44:22.1257904Z 
2026-02-25T17:44:22.1266496Z tests/e2e/conftest.py:399: RuntimeError
2026-02-25T17:44:22.1275888Z =============================== warnings summary ===============================
2026-02-25T17:44:22.1284646Z <frozen importlib._bootstrap>:241
2026-02-25T17:44:22.1295208Z   <frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyPacked has no __module__ attribute
2026-02-25T17:44:22.1304222Z 
2026-02-25T17:44:22.1314226Z <frozen importlib._bootstrap>:241
2026-02-25T17:44:22.1324468Z   <frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyObject has no __module__ attribute
2026-02-25T17:44:22.1333815Z 
2026-02-25T17:44:22.1344453Z ../../usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647
2026-02-25T17:44:22.1356072Z   /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-25T17:44:22.1367510Z     warnings.warn(
2026-02-25T17:44:22.1389689Z 
2026-02-25T17:44:22.1389993Z ../../usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/__init__.py:8
2026-02-25T17:44:22.1398082Z   /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/__init__.py:8: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html
2026-02-25T17:44:22.1407339Z     import pkg_resources
2026-02-25T17:44:22.1417315Z 
2026-02-25T17:44:22.1427312Z -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
2026-02-25T17:44:22.1437146Z =========================== short test summary info ============================
2026-02-25T17:44:22.1447026Z FAILED tests/e2e/nightly/multi_node/scripts/test_multi_node.py::test_multi_node
2026-02-25T17:44:22.1459048Z ================== 1 failed, 4 warnings in 151.03s (0:02:31) ===================
2026-02-25T17:44:23.7015842Z [0;31mFAIL_TAG_DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml âœ— ERROR: Some tests failed, please check the error stack above for details. If this is insufficient to pinpoint the error, please download and review the logs of all other nodes from the job's summary.[0m
2026-02-25T17:44:23.9306593Z Cleaning up background log streams...
2026-02-25T17:44:23.9969245Z ##[error]Error: failed to run script step: Error: command terminated with non-zero exit code: command terminated with exit code 1
2026-02-25T17:44:24.0007703Z ##[error]Process completed with exit code 1.
2026-02-25T17:44:24.0103780Z ##[error]Executing the custom container implementation failed. Please contact your self hosted runner administrator.
2026-02-25T17:44:24.0504231Z ##[group]Run actions/upload-artifact@v6
2026-02-25T17:44:24.0504537Z with:
2026-02-25T17:44:24.0504802Z   name: DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml-pod-logs
2026-02-25T17:44:24.0505080Z   path: /tmp/vllm*_logs.txt
2026-02-25T17:44:24.0505326Z   retention-days: 7
2026-02-25T17:44:24.0505519Z   if-no-files-found: warn
2026-02-25T17:44:24.0505761Z   compression-level: 6
2026-02-25T17:44:24.0505991Z   overwrite: false
2026-02-25T17:44:24.0506184Z   include-hidden-files: false
2026-02-25T17:44:24.0506467Z env:
2026-02-25T17:44:24.0506727Z   FAIL_TAG: FAIL_TAG_DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-02-25T17:44:24.0506988Z ##[endgroup]
2026-02-25T17:44:24.0531887Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-25T17:44:24.0532758Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-25T17:44:24.0533186Z ##[endgroup]
2026-02-25T17:44:24.4285213Z (node:867) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-25T17:44:24.4285958Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-25T17:44:25.2258208Z With the provided path, there will be 1 file uploaded
2026-02-25T17:44:25.2262332Z Artifact name is valid!
2026-02-25T17:44:25.2262602Z Root directory input is valid!
2026-02-25T17:44:26.2029833Z Beginning upload of artifact content to blob storage
2026-02-25T17:44:27.8008359Z Uploaded bytes 17778
2026-02-25T17:44:28.0598166Z Finished uploading artifact content to blob storage!
2026-02-25T17:44:28.0598761Z SHA256 digest of uploaded artifact zip is 8ac87b6df0c571c371743a6489b9b83a00e9ff1d2f4a13bfa9393155dd0c22e3
2026-02-25T17:44:28.0599380Z Finalizing artifact upload
2026-02-25T17:44:29.0417800Z Artifact DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml-pod-logs.zip successfully finalized. Artifact ID 5658630785
2026-02-25T17:44:29.0418544Z Artifact DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml-pod-logs has been successfully uploaded! Final size is 17778 bytes. Artifact ID is 5658630785
2026-02-25T17:44:29.0423109Z Artifact download URL: https://github.com/vllm-project/vllm-ascend/actions/runs/22407018984/artifacts/5658630785
2026-02-25T17:44:29.5351811Z ##[group]Run kubectl get pods -n "$NAMESPACE" --ignore-not-found=true
2026-02-25T17:44:29.5352381Z [36;1mkubectl get pods -n "$NAMESPACE" --ignore-not-found=true[0m
2026-02-25T17:44:29.5352778Z [36;1mkubectl delete -f ./lws.yaml --ignore-not-found=true || true[0m
2026-02-25T17:44:29.5353217Z shell: bash -el {0}
2026-02-25T17:44:29.5353578Z env:
2026-02-25T17:44:29.5353884Z   FAIL_TAG: FAIL_TAG_DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-02-25T17:44:29.5354163Z ##[endgroup]
2026-02-25T17:44:29.5442539Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-25T17:44:29.5443558Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-25T17:44:29.5443972Z ##[endgroup]
2026-02-25T17:44:29.8974737Z (node:979) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-25T17:44:29.8975483Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-25T17:44:30.6043647Z NAME                                             READY   STATUS    RESTARTS     AGE
2026-02-25T17:44:30.6044143Z linux-aarch64-a3-0-n4cwm-runner-zbb9m            1/1     Running   0            4m29s
2026-02-25T17:44:30.6044662Z linux-aarch64-a3-0-n4cwm-runner-zbb9m-workflow   1/1     Running   0            3m52s
2026-02-25T17:44:30.6045269Z linux-aarch64-a3-4-lxnt7-runner-5nvg4            1/1     Running   0            134m
2026-02-25T17:44:30.6045770Z linux-aarch64-a3-4-lxnt7-runner-5nvg4-workflow   1/1     Running   0            133m
2026-02-25T17:44:30.6046281Z linux-aarch64-a3-4-lxnt7-runner-9zxw6            1/1     Running   0            134m
2026-02-25T17:44:30.6046726Z linux-aarch64-a3-4-lxnt7-runner-9zxw6-workflow   1/1     Running   0            133m
2026-02-25T17:44:30.6047156Z vllm-0                                           1/1     Running   1 (7s ago)   3m26s
2026-02-25T17:44:30.6047517Z vllm-0-1                                         1/1     Running   0            3m26s
2026-02-25T17:44:30.6633510Z leaderworkerset.leaderworkerset.x-k8s.io "vllm" deleted from vllm-project namespace
2026-02-25T17:44:30.6897931Z service "vllm-leader" deleted from vllm-project namespace
2026-02-25T17:44:31.1923846Z Post job cleanup.
2026-02-25T17:44:31.1949521Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-25T17:44:31.1950369Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-25T17:44:31.1950643Z ##[endgroup]
2026-02-25T17:44:31.5476281Z (node:1105) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-25T17:44:31.5477053Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-25T17:44:32.1957158Z [command]/usr/bin/git version
2026-02-25T17:44:32.1990834Z git version 2.34.1
2026-02-25T17:44:32.2019938Z Copying '/root/.gitconfig' to '/__w/_temp/f482c620-29a0-473f-b85f-140b3770a01b/.gitconfig'
2026-02-25T17:44:32.2035257Z Temporarily overriding HOME='/__w/_temp/f482c620-29a0-473f-b85f-140b3770a01b' before making global git config changes
2026-02-25T17:44:32.2036050Z Adding repository directory to the temporary git global config as a safe directory
2026-02-25T17:44:32.2039448Z [command]/usr/bin/git config --global --add safe.directory /__w/vllm-ascend/vllm-ascend
2026-02-25T17:44:32.2071018Z Removing SSH command configuration
2026-02-25T17:44:32.2075523Z [command]/usr/bin/git config --local --name-only --get-regexp core\.sshCommand
2026-02-25T17:44:32.2105606Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'core\.sshCommand' && git config --local --unset-all 'core.sshCommand' || :"
2026-02-25T17:44:32.2295212Z Removing HTTP extra header
2026-02-25T17:44:32.2298361Z [command]/usr/bin/git config --local --name-only --get-regexp http\.https\:\/\/github\.com\/\.extraheader
2026-02-25T17:44:32.2324619Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'http\.https\:\/\/github\.com\/\.extraheader' && git config --local --unset-all 'http.https://github.com/.extraheader' || :"
2026-02-25T17:44:32.2527661Z Removing includeIf entries pointing to credentials config files
2026-02-25T17:44:32.2528061Z [command]/usr/bin/git config --local --name-only --get-regexp ^includeIf\.gitdir:
2026-02-25T17:44:32.2534491Z includeif.gitdir:/__w/vllm-ascend/vllm-ascend/.git.path
2026-02-25T17:44:32.2534822Z includeif.gitdir:/__w/vllm-ascend/vllm-ascend/.git/worktrees/*.path
2026-02-25T17:44:32.2535173Z includeif.gitdir:/github/workspace/.git.path
2026-02-25T17:44:32.2535459Z includeif.gitdir:/github/workspace/.git/worktrees/*.path
2026-02-25T17:44:32.2542419Z [command]/usr/bin/git config --local --get-all includeif.gitdir:/__w/vllm-ascend/vllm-ascend/.git.path
2026-02-25T17:44:32.2560074Z /__w/_temp/git-credentials-3ba5ebe6-40d5-4d37-871a-75aae1b32d46.config
2026-02-25T17:44:32.2568359Z [command]/usr/bin/git config --local --unset includeif.gitdir:/__w/vllm-ascend/vllm-ascend/.git.path /__w/_temp/git-credentials-3ba5ebe6-40d5-4d37-871a-75aae1b32d46.config
2026-02-25T17:44:32.2596867Z [command]/usr/bin/git config --local --get-all includeif.gitdir:/__w/vllm-ascend/vllm-ascend/.git/worktrees/*.path
2026-02-25T17:44:32.2615623Z /__w/_temp/git-credentials-3ba5ebe6-40d5-4d37-871a-75aae1b32d46.config
2026-02-25T17:44:32.2622356Z [command]/usr/bin/git config --local --unset includeif.gitdir:/__w/vllm-ascend/vllm-ascend/.git/worktrees/*.path /__w/_temp/git-credentials-3ba5ebe6-40d5-4d37-871a-75aae1b32d46.config
2026-02-25T17:44:32.2648872Z [command]/usr/bin/git config --local --get-all includeif.gitdir:/github/workspace/.git.path
2026-02-25T17:44:32.2667327Z /github/runner_temp/git-credentials-3ba5ebe6-40d5-4d37-871a-75aae1b32d46.config
2026-02-25T17:44:32.2674289Z [command]/usr/bin/git config --local --unset includeif.gitdir:/github/workspace/.git.path /github/runner_temp/git-credentials-3ba5ebe6-40d5-4d37-871a-75aae1b32d46.config
2026-02-25T17:44:32.2701679Z [command]/usr/bin/git config --local --get-all includeif.gitdir:/github/workspace/.git/worktrees/*.path
2026-02-25T17:44:32.2720646Z /github/runner_temp/git-credentials-3ba5ebe6-40d5-4d37-871a-75aae1b32d46.config
2026-02-25T17:44:32.2726693Z [command]/usr/bin/git config --local --unset includeif.gitdir:/github/workspace/.git/worktrees/*.path /github/runner_temp/git-credentials-3ba5ebe6-40d5-4d37-871a-75aae1b32d46.config
2026-02-25T17:44:32.2753993Z [command]/usr/bin/git submodule foreach --recursive git config --local --show-origin --name-only --get-regexp remote.origin.url
2026-02-25T17:44:32.2927092Z Removing credentials config '/__w/_temp/git-credentials-3ba5ebe6-40d5-4d37-871a-75aae1b32d46.config'
2026-02-25T17:44:50.7807626Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-25T17:44:50.7808309Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-25T17:44:50.7808534Z ##[endgroup]
2026-02-25T17:44:51.2903800Z Cleaning up orphan processes
