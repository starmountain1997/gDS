# Run ID: 21914310156
# Commit: ff3a50d011dcbea08f87ebed69ff1bf156dbb01e
# Job: multi-node (multi-node-dpsk3.2-2node, DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml, 2) / DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
# Date: 2026-02-11
============================================================

ï»¿2026-02-11T19:16:15.5757297Z Current runner version: '2.330.0'
2026-02-11T19:16:15.5762531Z Runner name: 'linux-aarch64-a3-0-n4cwm-runner-8vlf4'
2026-02-11T19:16:15.5763256Z Runner group name: 'Default'
2026-02-11T19:16:15.5764025Z Machine name: 'linux-aarch64-a3-0-n4cwm-runner-8vlf4'
2026-02-11T19:16:15.5767668Z ##[group]GITHUB_TOKEN Permissions
2026-02-11T19:16:15.5769606Z Actions: write
2026-02-11T19:16:15.5770216Z ArtifactMetadata: write
2026-02-11T19:16:15.5770676Z Attestations: write
2026-02-11T19:16:15.5771048Z Checks: write
2026-02-11T19:16:15.5771416Z Contents: write
2026-02-11T19:16:15.5771781Z Deployments: write
2026-02-11T19:16:15.5772320Z Discussions: write
2026-02-11T19:16:15.5772706Z Issues: write
2026-02-11T19:16:15.5773054Z Metadata: read
2026-02-11T19:16:15.5773518Z Models: read
2026-02-11T19:16:15.5773873Z Packages: write
2026-02-11T19:16:15.5774237Z Pages: write
2026-02-11T19:16:15.5774609Z PullRequests: write
2026-02-11T19:16:15.5774967Z RepositoryProjects: write
2026-02-11T19:16:15.5775598Z SecurityEvents: write
2026-02-11T19:16:15.5776031Z Statuses: write
2026-02-11T19:16:15.5776423Z ##[endgroup]
2026-02-11T19:16:15.5778190Z Secret source: Actions
2026-02-11T19:16:15.5778666Z Prepare workflow directory
2026-02-11T19:16:15.6499473Z Prepare all required actions
2026-02-11T19:16:15.6530557Z Getting action download info
2026-02-11T19:16:16.7658813Z Download action repository 'actions/checkout@v6' (SHA:de0fac2e4500dabe0009e67214ff5f5447ce83dd)
2026-02-11T19:16:21.3290483Z Download action repository 'actions/upload-artifact@v6' (SHA:b7c566a772e6b6bfb58ed0dc250532a479d7789f)
2026-02-11T19:16:28.9785495Z Uses: vllm-project/vllm-ascend/.github/workflows/_e2e_nightly_multi_node.yaml@refs/heads/main (ff3a50d011dcbea08f87ebed69ff1bf156dbb01e)
2026-02-11T19:16:28.9788702Z ##[group] Inputs
2026-02-11T19:16:28.9788967Z   soc_version: a3
2026-02-11T19:16:28.9789216Z   runner: linux-aarch64-a3-0
2026-02-11T19:16:28.9789627Z   image: swr.cn-southwest-2.myhuaweicloud.com/base_image/ascend-ci/vllm-ascend:nightly-a3
2026-02-11T19:16:28.9790104Z   config_file_path: DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-02-11T19:16:28.9790463Z   replicas: 1
2026-02-11T19:16:28.9790638Z   size: 2
2026-02-11T19:16:28.9790874Z   vllm_version: v0.15.0
2026-02-11T19:16:28.9791241Z   vllm_ascend_remote_url: https://github.com/vllm-project/vllm-ascend.git
2026-02-11T19:16:28.9791554Z   vllm_ascend_ref: main
2026-02-11T19:16:28.9791819Z ##[endgroup]
2026-02-11T19:16:28.9792498Z Complete job name: multi-node (multi-node-dpsk3.2-2node, DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml, 2) / DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-02-11T19:16:29.0285034Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-11T19:16:29.0287439Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-11T19:16:29.0287930Z ##[endgroup]
2026-02-11T19:16:44.5083945Z (node:68) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-11T19:16:46.2026183Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-11T19:16:46.4774956Z ##[group]Run # Decode and save kubeconfig
2026-02-11T19:16:46.4775377Z [36;1m# Decode and save kubeconfig[0m
2026-02-11T19:16:46.4807728Z [36;1mecho "***" | base64 -d > "$KUBECONFIG"[0m
2026-02-11T19:16:46.4808349Z shell: bash -el {0}
2026-02-11T19:16:46.4808615Z ##[endgroup]
2026-02-11T19:16:46.4941087Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-11T19:16:46.4942158Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-11T19:16:46.4942447Z ##[endgroup]
2026-02-11T19:16:46.8449168Z (node:399) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-11T19:16:46.8449960Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-11T19:16:47.7226158Z ##[group]Run actions/checkout@v6
2026-02-11T19:16:47.7226573Z with:
2026-02-11T19:16:47.7226821Z   repository: vllm-project/vllm-ascend
2026-02-11T19:16:47.7227524Z   token: ***
2026-02-11T19:16:47.7227794Z   ssh-strict: true
2026-02-11T19:16:47.7228002Z   ssh-user: git
2026-02-11T19:16:47.7228239Z   persist-credentials: true
2026-02-11T19:16:47.7228519Z   clean: true
2026-02-11T19:16:47.7228859Z   sparse-checkout-cone-mode: true
2026-02-11T19:16:47.7229136Z   fetch-depth: 1
2026-02-11T19:16:47.7229461Z   fetch-tags: false
2026-02-11T19:16:47.7229659Z   show-progress: true
2026-02-11T19:16:47.7229877Z   lfs: false
2026-02-11T19:16:47.7230111Z   submodules: false
2026-02-11T19:16:47.7230308Z   set-safe-directory: true
2026-02-11T19:16:47.7230536Z ##[endgroup]
2026-02-11T19:16:47.7271872Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-11T19:16:47.7272996Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-11T19:16:47.7273303Z ##[endgroup]
2026-02-11T19:16:48.1243415Z (node:430) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-11T19:16:48.1244221Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-11T19:16:48.6842444Z Syncing repository: vllm-project/vllm-ascend
2026-02-11T19:16:48.6843639Z ##[group]Getting Git version info
2026-02-11T19:16:48.6843947Z Working directory is '/__w/vllm-ascend/vllm-ascend'
2026-02-11T19:16:48.6844424Z [command]/usr/bin/git version
2026-02-11T19:16:48.6844689Z git version 2.34.1
2026-02-11T19:16:48.6845996Z ##[endgroup]
2026-02-11T19:16:48.6848800Z Copying '/root/.gitconfig' to '/__w/_temp/cd2293c6-d29b-432a-a5e6-614a55ece798/.gitconfig'
2026-02-11T19:16:48.6859377Z Temporarily overriding HOME='/__w/_temp/cd2293c6-d29b-432a-a5e6-614a55ece798' before making global git config changes
2026-02-11T19:16:48.6859948Z Adding repository directory to the temporary git global config as a safe directory
2026-02-11T19:16:48.6862862Z [command]/usr/bin/git config --global --add safe.directory /__w/vllm-ascend/vllm-ascend
2026-02-11T19:16:48.6892964Z Deleting the contents of '/__w/vllm-ascend/vllm-ascend'
2026-02-11T19:16:48.6895377Z ##[group]Initializing the repository
2026-02-11T19:16:48.6898916Z [command]/usr/bin/git init /__w/vllm-ascend/vllm-ascend
2026-02-11T19:16:48.7015306Z hint: Using 'master' as the name for the initial branch. This default branch name
2026-02-11T19:16:48.7015833Z hint: is subject to change. To configure the initial branch name to use in all
2026-02-11T19:16:48.7016264Z hint: of your new repositories, which will suppress this warning, call:
2026-02-11T19:16:48.7016563Z hint: 
2026-02-11T19:16:48.7016908Z hint: 	git config --global init.defaultBranch <name>
2026-02-11T19:16:48.7017203Z hint: 
2026-02-11T19:16:48.7017451Z hint: Names commonly chosen instead of 'master' are 'main', 'trunk' and
2026-02-11T19:16:48.7017915Z hint: 'development'. The just-created branch can be renamed via this command:
2026-02-11T19:16:48.7018261Z hint: 
2026-02-11T19:16:48.7018498Z hint: 	git branch -m <name>
2026-02-11T19:16:48.7027108Z Initialized empty Git repository in /__w/vllm-ascend/vllm-ascend/.git/
2026-02-11T19:16:48.7036031Z [command]/usr/bin/git remote add origin https://github.com/vllm-project/vllm-ascend
2026-02-11T19:16:48.7074098Z ##[endgroup]
2026-02-11T19:16:48.7074519Z ##[group]Disabling automatic garbage collection
2026-02-11T19:16:48.7078014Z [command]/usr/bin/git config --local gc.auto 0
2026-02-11T19:16:48.7101925Z ##[endgroup]
2026-02-11T19:16:48.7102421Z ##[group]Setting up auth
2026-02-11T19:16:48.7103114Z Removing SSH command configuration
2026-02-11T19:16:48.7108275Z [command]/usr/bin/git config --local --name-only --get-regexp core\.sshCommand
2026-02-11T19:16:48.7135067Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'core\.sshCommand' && git config --local --unset-all 'core.sshCommand' || :"
2026-02-11T19:16:48.7318239Z Removing HTTP extra header
2026-02-11T19:16:48.7321106Z [command]/usr/bin/git config --local --name-only --get-regexp http\.https\:\/\/github\.com\/\.extraheader
2026-02-11T19:16:48.7346382Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'http\.https\:\/\/github\.com\/\.extraheader' && git config --local --unset-all 'http.https://github.com/.extraheader' || :"
2026-02-11T19:16:48.7522267Z Removing includeIf entries pointing to credentials config files
2026-02-11T19:16:48.7526881Z [command]/usr/bin/git config --local --name-only --get-regexp ^includeIf\.gitdir:
2026-02-11T19:16:48.7552382Z [command]/usr/bin/git submodule foreach --recursive git config --local --show-origin --name-only --get-regexp remote.origin.url
2026-02-11T19:16:48.7729408Z [command]/usr/bin/git config --file /__w/_temp/git-credentials-3dcfa604-4b42-4181-a805-dea57f72262e.config http.https://github.com/.extraheader AUTHORIZATION: basic ***
2026-02-11T19:16:48.7761309Z [command]/usr/bin/git config --local includeIf.gitdir:/__w/vllm-ascend/vllm-ascend/.git.path /__w/_temp/git-credentials-3dcfa604-4b42-4181-a805-dea57f72262e.config
2026-02-11T19:16:48.7786838Z [command]/usr/bin/git config --local includeIf.gitdir:/__w/vllm-ascend/vllm-ascend/.git/worktrees/*.path /__w/_temp/git-credentials-3dcfa604-4b42-4181-a805-dea57f72262e.config
2026-02-11T19:16:48.7814717Z [command]/usr/bin/git config --local includeIf.gitdir:/github/workspace/.git.path /github/runner_temp/git-credentials-3dcfa604-4b42-4181-a805-dea57f72262e.config
2026-02-11T19:16:48.7844383Z [command]/usr/bin/git config --local includeIf.gitdir:/github/workspace/.git/worktrees/*.path /github/runner_temp/git-credentials-3dcfa604-4b42-4181-a805-dea57f72262e.config
2026-02-11T19:16:48.7866758Z ##[endgroup]
2026-02-11T19:16:48.7867137Z ##[group]Fetching the repository
2026-02-11T19:16:48.7874087Z [command]/usr/bin/git -c protocol.version=2 fetch --no-tags --prune --no-recurse-submodules --depth=1 origin +ff3a50d011dcbea08f87ebed69ff1bf156dbb01e:refs/remotes/origin/main
2026-02-11T19:16:51.6232454Z From https://gh-proxy.test.osinfra.cn/https://github.com/vllm-project/vllm-ascend
2026-02-11T19:16:51.6233237Z  * [new ref]         ff3a50d011dcbea08f87ebed69ff1bf156dbb01e -> origin/main
2026-02-11T19:16:51.6254392Z [command]/usr/bin/git branch --list --remote origin/main
2026-02-11T19:16:51.6278729Z   origin/main
2026-02-11T19:16:51.6285659Z [command]/usr/bin/git rev-parse refs/remotes/origin/main
2026-02-11T19:16:51.6304122Z ff3a50d011dcbea08f87ebed69ff1bf156dbb01e
2026-02-11T19:16:51.6308255Z ##[endgroup]
2026-02-11T19:16:51.6308584Z ##[group]Determining the checkout info
2026-02-11T19:16:51.6309148Z ##[endgroup]
2026-02-11T19:16:51.6313027Z [command]/usr/bin/git sparse-checkout disable
2026-02-11T19:16:51.6354141Z [command]/usr/bin/git config --local --unset-all extensions.worktreeConfig
2026-02-11T19:16:51.6382481Z ##[group]Checking out the ref
2026-02-11T19:16:51.6386015Z [command]/usr/bin/git checkout --progress --force -B main refs/remotes/origin/main
2026-02-11T19:16:51.7233694Z Switched to a new branch 'main'
2026-02-11T19:16:51.7234013Z Branch 'main' set up to track remote branch 'main' from 'origin'.
2026-02-11T19:16:51.7244774Z ##[endgroup]
2026-02-11T19:16:51.7281664Z [command]/usr/bin/git log -1 --format=%H
2026-02-11T19:16:51.7302347Z ff3a50d011dcbea08f87ebed69ff1bf156dbb01e
2026-02-11T19:16:52.1789051Z ##[group]Run # prepare for lws entrypoint scripts
2026-02-11T19:16:52.1789400Z [36;1m# prepare for lws entrypoint scripts[0m
2026-02-11T19:16:52.1789911Z [36;1minstall -D tests/e2e/nightly/multi_node/scripts/run.sh /root/.cache/tests/run.sh[0m
2026-02-11T19:16:52.1790467Z shell: bash -el {0}
2026-02-11T19:16:52.1790668Z ##[endgroup]
2026-02-11T19:16:52.1878135Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-11T19:16:52.1879065Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-11T19:16:52.1879320Z ##[endgroup]
2026-02-11T19:16:52.5387428Z (node:471) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-11T19:16:52.5388153Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-11T19:16:53.4701026Z ##[group]Run set -euo pipefail
2026-02-11T19:16:53.4701271Z [36;1mset -euo pipefail[0m
2026-02-11T19:16:53.4701441Z [36;1m[0m
2026-02-11T19:16:53.4701621Z [36;1mCRD_NAME="${CRD_NAME:-vllm}"[0m
2026-02-11T19:16:53.4701817Z [36;1mTIMEOUT=${TIMEOUT:-120}[0m
2026-02-11T19:16:53.4702127Z [36;1mSLEEP_INTERVAL=2[0m
2026-02-11T19:16:53.4702300Z [36;1m[0m
2026-02-11T19:16:53.4702529Z [36;1mecho "Deleting leaderworkerset [$CRD_NAME] in namespace [$NAMESPACE]..."[0m
2026-02-11T19:16:53.4702973Z [36;1mkubectl delete leaderworkerset "$CRD_NAME" -n "$NAMESPACE" --ignore-not-found[0m
2026-02-11T19:16:53.4703313Z [36;1m[0m
2026-02-11T19:16:53.4703534Z [36;1mecho "Waiting for all pods starting with 'vllm' to be deleted..."[0m
2026-02-11T19:16:53.4703839Z [36;1mSTART_TIME=$(date +%s)[0m
2026-02-11T19:16:53.4704005Z [36;1m[0m
2026-02-11T19:16:53.4704265Z [36;1mwhile true; do[0m
2026-02-11T19:16:53.4704486Z [36;1m  NOW=$(date +%s)[0m
2026-02-11T19:16:53.4704709Z [36;1m  ELAPSED=$((NOW - START_TIME))[0m
2026-02-11T19:16:53.4704893Z [36;1m[0m
2026-02-11T19:16:53.4705066Z [36;1m  if [[ $ELAPSED -ge $TIMEOUT ]]; then[0m
2026-02-11T19:16:53.4705359Z [36;1m    echo "Timeout reached ($TIMEOUT seconds), some pods still exist:"[0m
2026-02-11T19:16:53.4705682Z [36;1m    kubectl get pods -n "$NAMESPACE" | grep '^vllm' || true[0m
2026-02-11T19:16:53.4705958Z [36;1m    exit 1[0m
2026-02-11T19:16:53.4706098Z [36;1m  fi[0m
2026-02-11T19:16:53.4706240Z [36;1m[0m
2026-02-11T19:16:53.4706641Z [36;1m  PODS_EXIST=$(kubectl get pods -n "$NAMESPACE" -o jsonpath='{.items[*].metadata.name}' 2>/dev/null | tr ' ' '\n' | grep '^vllm' || true)[0m
2026-02-11T19:16:53.4707038Z [36;1m[0m
2026-02-11T19:16:53.4707191Z [36;1m  if [[ -z "$PODS_EXIST" ]]; then[0m
2026-02-11T19:16:53.4707437Z [36;1m    echo "All vllm pods deleted."[0m
2026-02-11T19:16:53.4707622Z [36;1m    break[0m
2026-02-11T19:16:53.4707770Z [36;1m  else[0m
2026-02-11T19:16:53.4707977Z [36;1m    echo "Waiting for pods to be deleted: $PODS_EXIST"[0m
2026-02-11T19:16:53.4708253Z [36;1m    sleep $SLEEP_INTERVAL[0m
2026-02-11T19:16:53.4708432Z [36;1m  fi[0m
2026-02-11T19:16:53.4708563Z [36;1mdone[0m
2026-02-11T19:16:53.4708864Z shell: bash -el {0}
2026-02-11T19:16:53.4709030Z ##[endgroup]
2026-02-11T19:16:53.4799228Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-11T19:16:53.4799862Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-11T19:16:53.4800201Z ##[endgroup]
2026-02-11T19:16:53.8264928Z (node:525) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-11T19:16:53.8265607Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-11T19:16:54.3346016Z Deleting leaderworkerset [vllm] in namespace [vllm-project]...
2026-02-11T19:16:54.4233165Z Waiting for all pods starting with 'vllm' to be deleted...
2026-02-11T19:16:54.4874632Z All vllm pods deleted.
2026-02-11T19:16:54.9398105Z ##[group]Run set -e
2026-02-11T19:16:54.9398322Z [36;1mset -e[0m
2026-02-11T19:16:54.9398467Z [36;1m[0m
2026-02-11T19:16:54.9398592Z [36;1msize="2"[0m
2026-02-11T19:16:54.9398737Z [36;1mreplicas="1"[0m
2026-02-11T19:16:54.9399054Z [36;1mimage="swr.cn-southwest-2.myhuaweicloud.com/base_image/ascend-ci/vllm-ascend:nightly-a3"[0m
2026-02-11T19:16:54.9399455Z [36;1mconfig_file_path="DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml"[0m
2026-02-11T19:16:54.9399761Z [36;1mfail_tag=FAIL_TAG_"DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml"[0m
2026-02-11T19:16:54.9400034Z [36;1mecho "FAIL_TAG=${fail_tag}" >> "$GITHUB_ENV"[0m
2026-02-11T19:16:54.9400224Z [36;1m[0m
2026-02-11T19:16:54.9400432Z [36;1mrequired_params=("size" "replicas" "image" "config_file_path")[0m
2026-02-11T19:16:54.9400816Z [36;1mfor param in "${required_params[@]}"; do[0m
2026-02-11T19:16:54.9401030Z [36;1m  if [ -z "${!param}" ]; then[0m
2026-02-11T19:16:54.9401482Z [36;1m    echo "Error: Parameter '$param' is required but empty"[0m
2026-02-11T19:16:54.9401710Z [36;1m    exit 1[0m
2026-02-11T19:16:54.9401856Z [36;1m  fi[0m
2026-02-11T19:16:54.9402086Z [36;1mdone[0m
2026-02-11T19:16:54.9402226Z [36;1m[0m
2026-02-11T19:16:54.9402365Z [36;1mif [ "a3" = "a3" ]; then[0m
2026-02-11T19:16:54.9402542Z [36;1m  npu_per_node=16[0m
2026-02-11T19:16:54.9402806Z [36;1m  TEMPLATE_FILE="tests/e2e/nightly/multi_node/scripts/lws.yaml.jinja2"[0m
2026-02-11T19:16:54.9403076Z [36;1melse[0m
2026-02-11T19:16:54.9403215Z [36;1m  npu_per_node=8[0m
2026-02-11T19:16:54.9403475Z [36;1m  TEMPLATE_FILE="tests/e2e/nightly/multi_node/scripts/lws-a2.yaml.jinja2"[0m
2026-02-11T19:16:54.9403750Z [36;1mfi[0m
2026-02-11T19:16:54.9403872Z [36;1m[0m
2026-02-11T19:16:54.9404015Z [36;1mjinja2 $TEMPLATE_FILE \[0m
2026-02-11T19:16:54.9404203Z [36;1m  -D size="$size" \[0m
2026-02-11T19:16:54.9404376Z [36;1m  -D replicas="$replicas" \[0m
2026-02-11T19:16:54.9404565Z [36;1m  -D image="$image" \[0m
2026-02-11T19:16:54.9404768Z [36;1m  -D config_file_path="$config_file_path" \[0m
2026-02-11T19:16:54.9404998Z [36;1m  -D npu_per_node="$npu_per_node" \[0m
2026-02-11T19:16:54.9405201Z [36;1m  -D fail_tag="$fail_tag" \[0m
2026-02-11T19:16:54.9405380Z [36;1m  --outfile lws.yaml[0m
2026-02-11T19:16:54.9405541Z [36;1m[0m
2026-02-11T19:16:54.9405681Z [36;1mkubectl apply -f ./lws.yaml[0m
2026-02-11T19:16:54.9406004Z shell: bash -el {0}
2026-02-11T19:16:54.9406162Z ##[endgroup]
2026-02-11T19:16:54.9489404Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-11T19:16:54.9490066Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-11T19:16:54.9490279Z ##[endgroup]
2026-02-11T19:16:55.3006835Z (node:591) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-11T19:16:55.3007489Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-11T19:16:56.2677930Z leaderworkerset.leaderworkerset.x-k8s.io/vllm created
2026-02-11T19:16:56.2899171Z service/vllm-leader created
2026-02-11T19:16:56.8048532Z ##[group]Run POD_PREFIX="${POD_PREFIX:-vllm-0}"
2026-02-11T19:16:56.8048933Z [36;1mPOD_PREFIX="${POD_PREFIX:-vllm-0}"[0m
2026-02-11T19:16:56.8049245Z [36;1mSIZE="2"[0m
2026-02-11T19:16:56.8049504Z [36;1mTIMEOUT=1200  # default timeout 20 minutes[0m
2026-02-11T19:16:56.8049757Z [36;1m[0m
2026-02-11T19:16:56.8050147Z [36;1mecho "Waiting for Pods in namespace [$NAMESPACE] to become Running and Ready (timeout ${TIMEOUT}s)..."[0m
2026-02-11T19:16:56.8050556Z [36;1m[0m
2026-02-11T19:16:56.8050742Z [36;1mSTART_TIME=$(date +%s)[0m
2026-02-11T19:16:56.8051165Z [36;1m[0m
2026-02-11T19:16:56.8051443Z [36;1mwhile true; do[0m
2026-02-11T19:16:56.8051650Z [36;1m  NOW=$(date +%s)[0m
2026-02-11T19:16:56.8051924Z [36;1m  ELAPSED=$((NOW - START_TIME))[0m
2026-02-11T19:16:56.8052316Z [36;1m  if [[ $ELAPSED -ge $TIMEOUT ]]; then[0m
2026-02-11T19:16:56.8052645Z [36;1m    echo "Timeout reached after ${ELAPSED}s"[0m
2026-02-11T19:16:56.8053046Z [36;1m    echo "Dumping pod status for debugging:"[0m
2026-02-11T19:16:56.8053320Z [36;1m    kubectl get pods -n "$NAMESPACE"[0m
2026-02-11T19:16:56.8053633Z [36;1m    kubectl describe pod "$LEADER_POD" -n "$NAMESPACE"[0m
2026-02-11T19:16:56.8053951Z [36;1m    exit 1[0m
2026-02-11T19:16:56.8054137Z [36;1m  fi[0m
2026-02-11T19:16:56.8054353Z [36;1m[0m
2026-02-11T19:16:56.8054617Z [36;1m  # 1) check follower pods[0m
2026-02-11T19:16:56.8054887Z [36;1m  ALL_FOLLOWERS_READY=true[0m
2026-02-11T19:16:56.8055155Z [36;1m  for ((i=1; i<SIZE; i++)); do[0m
2026-02-11T19:16:56.8055410Z [36;1m    POD="${POD_PREFIX}-${i}"[0m
2026-02-11T19:16:56.8055869Z [36;1m    PHASE=$(kubectl get pod "$POD" -n "$NAMESPACE" -o jsonpath='{.status.phase}' 2>/dev/null || echo "NotFound")[0m
2026-02-11T19:16:56.8056475Z [36;1m    READY=$(kubectl get pod "$POD" -n "$NAMESPACE" -o jsonpath='{.status.containerStatuses[*].ready}' 2>/dev/null)[0m
2026-02-11T19:16:56.8057061Z [36;1m[0m
2026-02-11T19:16:56.8057337Z [36;1m    echo "Follower [$POD] phase=$PHASE ready=$READY"[0m
2026-02-11T19:16:56.8057629Z [36;1m[0m
2026-02-11T19:16:56.8057875Z [36;1m    if [[ "$PHASE" != "Running" || "$READY" != "true" ]]; then[0m
2026-02-11T19:16:56.8058237Z [36;1m      echo "Follower [$POD] not Ready yet..."[0m
2026-02-11T19:16:56.8058540Z [36;1m      ALL_FOLLOWERS_READY=false[0m
2026-02-11T19:16:56.8058895Z [36;1m      break[0m
2026-02-11T19:16:56.8059124Z [36;1m    fi[0m
2026-02-11T19:16:56.8059301Z [36;1m  done[0m
2026-02-11T19:16:56.8059436Z [36;1m[0m
2026-02-11T19:16:56.8059564Z [36;1m  # 2) check leader pod[0m
2026-02-11T19:16:56.8059942Z [36;1m  LEADER_PHASE=$(kubectl get pod "$LEADER_POD" -n "$NAMESPACE" -o jsonpath='{.status.phase}' 2>/dev/null || echo "NotFound")[0m
2026-02-11T19:16:56.8060531Z [36;1m  LEADER_READY=$(kubectl get pod "$LEADER_POD" -n "$NAMESPACE" -o jsonpath='{.status.containerStatuses[*].ready}' 2>/dev/null)[0m
2026-02-11T19:16:56.8060920Z [36;1m[0m
2026-02-11T19:16:56.8061211Z [36;1m  echo "Leader [$LEADER_POD] phase=$LEADER_PHASE ready=$LEADER_READY"[0m
2026-02-11T19:16:56.8061474Z [36;1m[0m
2026-02-11T19:16:56.8061670Z [36;1m  if [[ "$LEADER_PHASE" != "Running" || "$LEADER_READY" != "true" ]]; then[0m
2026-02-11T19:16:56.8061942Z [36;1m    echo "Leader not Ready yet..."[0m
2026-02-11T19:16:56.8062252Z [36;1m    ALL_FOLLOWERS_READY=false[0m
2026-02-11T19:16:56.8062424Z [36;1m  fi[0m
2026-02-11T19:16:56.8062556Z [36;1m[0m
2026-02-11T19:16:56.8062717Z [36;1m  if [[ "$ALL_FOLLOWERS_READY" == "true" ]]; then[0m
2026-02-11T19:16:56.8063028Z [36;1m    echo "All follower pods and leader pod are Running and Ready â€” continuing."[0m
2026-02-11T19:16:56.8063313Z [36;1m    break[0m
2026-02-11T19:16:56.8063454Z [36;1m  fi[0m
2026-02-11T19:16:56.8063575Z [36;1m[0m
2026-02-11T19:16:56.8063698Z [36;1m  sleep 2[0m
2026-02-11T19:16:56.8063831Z [36;1mdone[0m
2026-02-11T19:16:56.8064117Z shell: bash -el {0}
2026-02-11T19:16:56.8064262Z env:
2026-02-11T19:16:56.8064582Z   FAIL_TAG: FAIL_TAG_DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-02-11T19:16:56.8064806Z ##[endgroup]
2026-02-11T19:16:56.8234000Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-11T19:16:56.8234796Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-11T19:16:56.8235090Z ##[endgroup]
2026-02-11T19:16:57.1968755Z (node:669) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-11T19:16:57.1969415Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-11T19:16:57.8054550Z Waiting for Pods in namespace [vllm-project] to become Running and Ready (timeout 1200s)...
2026-02-11T19:16:57.9261795Z Follower [vllm-0-1] phase=Pending ready=
2026-02-11T19:16:57.9262146Z Follower [vllm-0-1] not Ready yet...
2026-02-11T19:16:58.0307142Z Leader [vllm-0] phase=Pending ready=
2026-02-11T19:16:58.0307407Z Leader not Ready yet...
2026-02-11T19:17:00.1499219Z Follower [vllm-0-1] phase=Pending ready=
2026-02-11T19:17:00.1499539Z Follower [vllm-0-1] not Ready yet...
2026-02-11T19:17:00.2620836Z Leader [vllm-0] phase=Pending ready=
2026-02-11T19:17:00.2621105Z Leader not Ready yet...
2026-02-11T19:17:02.3728668Z Follower [vllm-0-1] phase=Pending ready=
2026-02-11T19:17:02.3728993Z Follower [vllm-0-1] not Ready yet...
2026-02-11T19:17:02.4850408Z Leader [vllm-0] phase=Pending ready=
2026-02-11T19:17:02.4850719Z Leader not Ready yet...
2026-02-11T19:17:04.6000498Z Follower [vllm-0-1] phase=Pending ready=
2026-02-11T19:17:04.6000789Z Follower [vllm-0-1] not Ready yet...
2026-02-11T19:17:04.7128299Z Leader [vllm-0] phase=Pending ready=
2026-02-11T19:17:04.7128593Z Leader not Ready yet...
2026-02-11T19:17:06.8275906Z Follower [vllm-0-1] phase=Pending ready=
2026-02-11T19:17:06.8276200Z Follower [vllm-0-1] not Ready yet...
2026-02-11T19:17:06.9415557Z Leader [vllm-0] phase=Pending ready=
2026-02-11T19:17:06.9416295Z Leader not Ready yet...
2026-02-11T19:17:09.0538954Z Follower [vllm-0-1] phase=Pending ready=
2026-02-11T19:17:09.0539276Z Follower [vllm-0-1] not Ready yet...
2026-02-11T19:17:09.1769838Z Leader [vllm-0] phase=Pending ready=false
2026-02-11T19:17:09.1770134Z Leader not Ready yet...
2026-02-11T19:17:11.2869136Z Follower [vllm-0-1] phase=Pending ready=false
2026-02-11T19:17:11.2869421Z Follower [vllm-0-1] not Ready yet...
2026-02-11T19:17:11.3958583Z Leader [vllm-0] phase=Pending ready=false
2026-02-11T19:17:11.3958872Z Leader not Ready yet...
2026-02-11T19:17:13.5203580Z Follower [vllm-0-1] phase=Running ready=true
2026-02-11T19:17:13.6302878Z Leader [vllm-0] phase=Running ready=true
2026-02-11T19:17:13.6303507Z All follower pods and leader pod are Running and Ready â€” continuing.
2026-02-11T19:17:14.1597963Z ##[group]Run set -euo pipefail
2026-02-11T19:17:14.1598236Z [36;1mset -euo pipefail[0m
2026-02-11T19:17:14.1598401Z [36;1m[0m
2026-02-11T19:17:14.1598542Z [36;1msize="2"[0m
2026-02-11T19:17:14.1598704Z [36;1mpids=()[0m
2026-02-11T19:17:14.1598834Z [36;1m[0m
2026-02-11T19:17:14.1598968Z [36;1mcleanup() {[0m
2026-02-11T19:17:14.1599159Z [36;1m  echo "Cleaning up background log streams..."[0m
2026-02-11T19:17:14.1599393Z [36;1m  for pid in "${pids[@]}"; do[0m
2026-02-11T19:17:14.1599617Z [36;1m    kill "$pid" 2>/dev/null || true[0m
2026-02-11T19:17:14.1599805Z [36;1m  done[0m
2026-02-11T19:17:14.1599937Z [36;1m}[0m
2026-02-11T19:17:14.1600076Z [36;1mtrap cleanup EXIT[0m
2026-02-11T19:17:14.1600227Z [36;1m[0m
2026-02-11T19:17:14.1600377Z [36;1mfor i in $(seq 1 $((size - 1))); do[0m
2026-02-11T19:17:14.1600572Z [36;1m  POD="vllm-0-${i}"[0m
2026-02-11T19:17:14.1600724Z [36;1m[0m
2026-02-11T19:17:14.1600940Z [36;1m  echo "==== Collecting logs from worker pod: $POD ===="[0m
2026-02-11T19:17:14.1601203Z [36;1m  kubectl logs -f "$POD" -n "$NAMESPACE" \[0m
2026-02-11T19:17:14.1601430Z [36;1m    > "/tmp/${POD}_logs.txt" 2>&1 &[0m
2026-02-11T19:17:14.1601622Z [36;1m[0m
2026-02-11T19:17:14.1601748Z [36;1m  pids+=($!)[0m
2026-02-11T19:17:14.1601900Z [36;1mdone[0m
2026-02-11T19:17:14.1602139Z [36;1m[0m
2026-02-11T19:17:14.1602332Z [36;1mecho "==== Streaming logs from leader pod: $LEADER_POD ===="[0m
2026-02-11T19:17:14.1602612Z [36;1mecho "Looking for logs containing: $FAIL_TAG"[0m
2026-02-11T19:17:14.1602810Z [36;1m[0m
2026-02-11T19:17:14.1603038Z [36;1mkubectl logs -f "$LEADER_POD" -n "$NAMESPACE" | while IFS= read -r line; do[0m
2026-02-11T19:17:14.1603328Z [36;1m  echo "$line"[0m
2026-02-11T19:17:14.1603512Z [36;1m  if echo "$line" | grep -q "$FAIL_TAG"; then[0m
2026-02-11T19:17:14.1603713Z [36;1m    exit 1[0m
2026-02-11T19:17:14.1603853Z [36;1m  fi[0m
2026-02-11T19:17:14.1603980Z [36;1mdone[0m
2026-02-11T19:17:14.1604292Z shell: bash -el {0}
2026-02-11T19:17:14.1604431Z env:
2026-02-11T19:17:14.1604626Z   FAIL_TAG: FAIL_TAG_DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-02-11T19:17:14.1604853Z ##[endgroup]
2026-02-11T19:17:14.1703827Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-11T19:17:14.1704500Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-11T19:17:14.1704715Z ##[endgroup]
2026-02-11T19:17:14.5215952Z (node:763) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-11T19:17:14.5216626Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-11T19:17:15.0791104Z ==== Collecting logs from worker pod: vllm-0-1 ====
2026-02-11T19:17:15.0791723Z ==== Streaming logs from leader pod: vllm-0 ====
2026-02-11T19:17:15.0792181Z Looking for logs containing: FAIL_TAG_DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-02-11T19:17:15.1619613Z /usr/local/Ascend/ascend-toolkit/set_env.sh: line 31: CMAKE_PREFIX_PATH: unbound variable
2026-02-11T19:17:15.1629077Z ====> Check NPU info
2026-02-11T19:17:15.1639136Z +------------------------------------------------------------------------------------------------+
2026-02-11T19:17:15.1649722Z | npu-smi 25.5.0                   Version: 25.5.0                                               |
2026-02-11T19:17:15.1660380Z +---------------------------+---------------+----------------------------------------------------+
2026-02-11T19:17:15.1669316Z | NPU   Name                | Health        | Power(W)    Temp(C)           Hugepages-Usage(page)|
2026-02-11T19:17:15.1678852Z | Chip  Phy-ID              | Bus-Id        | AICore(%)   Memory-Usage(MB)  HBM-Usage(MB)        |
2026-02-11T19:17:15.1688569Z +===========================+===============+====================================================+
2026-02-11T19:17:15.1697577Z | 0     Ascend910           | OK            | 161.8       36                0    / 0             |
2026-02-11T19:17:15.1707192Z | 0     0                   | 0000:9D:00.0  | 0           0    / 0          3146 / 65536         |
2026-02-11T19:17:15.1716430Z +------------------------------------------------------------------------------------------------+
2026-02-11T19:17:15.1726895Z | 0     Ascend910           | OK            | -           36                0    / 0             |
2026-02-11T19:17:15.1735074Z | 1     1                   | 0000:9F:00.0  | 0           0    / 0          2891 / 65536         |
2026-02-11T19:17:15.1771406Z +===========================+===============+====================================================+
2026-02-11T19:17:15.1771811Z | 1     Ascend910           | OK            | 163.6       34                0    / 0             |
2026-02-11T19:17:15.1772244Z | 0     2                   | 0000:99:00.0  | 0           0    / 0          3159 / 65536         |
2026-02-11T19:17:15.1774326Z +------------------------------------------------------------------------------------------------+
2026-02-11T19:17:15.1784969Z | 1     Ascend910           | OK            | -           36                0    / 0             |
2026-02-11T19:17:15.1795337Z | 1     3                   | 0000:9B:00.0  | 0           0    / 0          2880 / 65536         |
2026-02-11T19:17:15.1805653Z +===========================+===============+====================================================+
2026-02-11T19:17:15.1815544Z | 2     Ascend910           | OK            | 162.6       37                0    / 0             |
2026-02-11T19:17:15.1826274Z | 0     4                   | 0000:95:00.0  | 0           0    / 0          3161 / 65536         |
2026-02-11T19:17:15.1836066Z +------------------------------------------------------------------------------------------------+
2026-02-11T19:17:15.1846880Z | 2     Ascend910           | OK            | -           36                0    / 0             |
2026-02-11T19:17:15.1857312Z | 1     5                   | 0000:97:00.0  | 0           0    / 0          2880 / 65536         |
2026-02-11T19:17:15.1866779Z +===========================+===============+====================================================+
2026-02-11T19:17:15.1876402Z | 3     Ascend910           | OK            | 167.6       36                0    / 0             |
2026-02-11T19:17:15.1887019Z | 0     6                   | 0000:91:00.0  | 0           0    / 0          3161 / 65536         |
2026-02-11T19:17:15.1897211Z +------------------------------------------------------------------------------------------------+
2026-02-11T19:17:15.1907020Z | 3     Ascend910           | OK            | -           36                0    / 0             |
2026-02-11T19:17:15.1917529Z | 1     7                   | 0000:93:00.0  | 0           0    / 0          2879 / 65536         |
2026-02-11T19:17:15.1928434Z +===========================+===============+====================================================+
2026-02-11T19:17:15.1938344Z | 4     Ascend910           | OK            | 161.9       37                0    / 0             |
2026-02-11T19:17:15.1948198Z | 0     8                   | 0000:8D:00.0  | 0           0    / 0          3159 / 65536         |
2026-02-11T19:17:15.1958320Z +------------------------------------------------------------------------------------------------+
2026-02-11T19:17:15.1968329Z | 4     Ascend910           | OK            | -           36                0    / 0             |
2026-02-11T19:17:15.1977927Z | 1     9                   | 0000:8F:00.0  | 0           0    / 0          2881 / 65536         |
2026-02-11T19:17:15.1987023Z +===========================+===============+====================================================+
2026-02-11T19:17:15.1996391Z | 5     Ascend910           | OK            | 162.2       37                0    / 0             |
2026-02-11T19:17:15.2005492Z | 0     10                  | 0000:89:00.0  | 0           0    / 0          3145 / 65536         |
2026-02-11T19:17:15.2015169Z +------------------------------------------------------------------------------------------------+
2026-02-11T19:17:15.2024476Z | 5     Ascend910           | OK            | -           37                0    / 0             |
2026-02-11T19:17:15.2033453Z | 1     11                  | 0000:8B:00.0  | 0           0    / 0          2892 / 65536         |
2026-02-11T19:17:15.2043056Z +===========================+===============+====================================================+
2026-02-11T19:17:15.2052817Z | 6     Ascend910           | OK            | 159.4       36                0    / 0             |
2026-02-11T19:17:15.2061891Z | 0     12                  | 0000:85:00.0  | 0           0    / 0          3148 / 65536         |
2026-02-11T19:17:15.2071047Z +------------------------------------------------------------------------------------------------+
2026-02-11T19:17:15.2081020Z | 6     Ascend910           | OK            | -           35                0    / 0             |
2026-02-11T19:17:15.2090164Z | 1     13                  | 0000:87:00.0  | 0           0    / 0          2891 / 65536         |
2026-02-11T19:17:15.2099475Z +===========================+===============+====================================================+
2026-02-11T19:17:15.2108740Z | 7     Ascend910           | OK            | 164.7       37                0    / 0             |
2026-02-11T19:17:15.2118078Z | 0     14                  | 0000:81:00.0  | 0           0    / 0          3153 / 65536         |
2026-02-11T19:17:15.2127671Z +------------------------------------------------------------------------------------------------+
2026-02-11T19:17:15.2137026Z | 7     Ascend910           | OK            | -           36                0    / 0             |
2026-02-11T19:17:15.2146392Z | 1     15                  | 0000:83:00.0  | 0           0    / 0          2876 / 65536         |
2026-02-11T19:17:15.2155731Z +===========================+===============+====================================================+
2026-02-11T19:17:15.2165601Z +---------------------------+---------------+----------------------------------------------------+
2026-02-11T19:17:15.2175280Z | NPU     Chip              | Process id    | Process name             | Process memory(MB)      |
2026-02-11T19:17:15.2184178Z +===========================+===============+====================================================+
2026-02-11T19:17:15.2193592Z | No running processes found in NPU 0                                                            |
2026-02-11T19:17:15.2202752Z +===========================+===============+====================================================+
2026-02-11T19:17:15.2212289Z | No running processes found in NPU 1                                                            |
2026-02-11T19:17:15.2221503Z +===========================+===============+====================================================+
2026-02-11T19:17:15.2231038Z | No running processes found in NPU 2                                                            |
2026-02-11T19:17:15.2241034Z +===========================+===============+====================================================+
2026-02-11T19:17:15.2251015Z | No running processes found in NPU 3                                                            |
2026-02-11T19:17:15.2259885Z +===========================+===============+====================================================+
2026-02-11T19:17:15.2269557Z | No running processes found in NPU 4                                                            |
2026-02-11T19:17:15.2279004Z +===========================+===============+====================================================+
2026-02-11T19:17:15.2288473Z | No running processes found in NPU 5                                                            |
2026-02-11T19:17:15.2297782Z +===========================+===============+====================================================+
2026-02-11T19:17:15.2307352Z | No running processes found in NPU 6                                                            |
2026-02-11T19:17:15.2316332Z +===========================+===============+====================================================+
2026-02-11T19:17:15.2326336Z | No running processes found in NPU 7                                                            |
2026-02-11T19:17:15.2335240Z +===========================+===============+====================================================+
2026-02-11T19:17:15.2344324Z package_name=Ascend-cann-toolkit
2026-02-11T19:17:15.2352994Z version=8.5.0
2026-02-11T19:17:15.2362430Z innerversion=V100R001C25SPC001B232
2026-02-11T19:17:15.2372302Z compatible_version=[V100R001C15],[V100R001C18],[V100R001C19],[V100R001C20],[V100R001C21],[V100R001C23]
2026-02-11T19:17:15.2380950Z arch=aarch64
2026-02-11T19:17:15.2390025Z os=linux
2026-02-11T19:17:15.2399315Z path=/usr/local/Ascend/cann-8.5.0
2026-02-11T19:17:15.2408704Z ====> Configure mirrors and git proxy
2026-02-11T19:17:15.2417995Z Writing to /root/.config/pip/pip.conf
2026-02-11T19:17:15.2426799Z Installed vLLM-related Python packages:
2026-02-11T19:17:15.2436385Z ais_bench_benchmark               3.0.20250930                /vllm-workspace/vllm-ascend/benchmark
2026-02-11T19:17:15.2486595Z vllm                              0.15.0+empty                /vllm-workspace/vllm
2026-02-11T19:17:15.2487120Z vllm_ascend                       0.14.0rc2.dev145+g53b494b1e /vllm-workspace/vllm-ascend
2026-02-11T19:17:15.2487346Z 
2026-02-11T19:17:15.2487416Z ============================
2026-02-11T19:17:15.2487581Z vLLM Git information
2026-02-11T19:17:15.2493024Z ============================
2026-02-11T19:17:15.2502449Z Branch:      HEAD
2026-02-11T19:17:15.2536875Z Commit hash: f176443446f659dbab5315e056e605d8984fd976
2026-02-11T19:17:15.2537273Z Author:      TJian <tunjian.tan@embeddedllm.com>
2026-02-11T19:17:15.2537508Z Date:        2026-01-29 14:45:42 +0800
2026-02-11T19:17:15.2547890Z Message:     [Release] [CI] Optim release pipeline (#33156)
2026-02-11T19:17:15.2548550Z Tags:        v0.15.0
2026-02-11T19:17:15.2561114Z Remote:      origin	https://ghfast.top/https://github.com/vllm-project/vllm.git (fetch)
2026-02-11T19:17:15.2569334Z 
2026-02-11T19:17:15.2576629Z 
2026-02-11T19:17:15.2585897Z ============================
2026-02-11T19:17:15.2595071Z vLLM-Ascend Git information
2026-02-11T19:17:15.2604526Z ============================
2026-02-11T19:17:15.2613746Z Branch:      main
2026-02-11T19:17:15.2622475Z Commit hash: 53b494b1e413eb583d393d878f3c7c88f28c6769
2026-02-11T19:17:15.2631688Z Author:      Cao Yi <slightwindsec@gmail.com>
2026-02-11T19:17:15.2641068Z Date:        2026-02-11 16:38:45 +0800
2026-02-11T19:17:15.2651127Z Message:     [main][Quant] Remove unused rotation functions and parameters from W4A4 LAOS quantization (#6648)
2026-02-11T19:17:15.2659613Z Tags:        
2026-02-11T19:17:15.2668917Z Remote:      origin	https://ghfast.top/https://github.com/vllm-project/vllm-ascend (fetch)
2026-02-11T19:17:15.2677433Z 
2026-02-11T19:17:15.2687009Z ====> Check triton ascend info
2026-02-11T19:17:15.4923418Z Ubuntu clang version 15.0.7
2026-02-11T19:17:15.4933107Z Target: aarch64-unknown-linux-gnu
2026-02-11T19:17:15.4941837Z Thread model: posix
2026-02-11T19:17:15.4951504Z InstalledDir: /usr/bin
2026-02-11T19:17:15.4961369Z Found candidate GCC installation: /usr/bin/../lib/gcc/aarch64-linux-gnu/11
2026-02-11T19:17:15.4971565Z Selected GCC installation: /usr/bin/../lib/gcc/aarch64-linux-gnu/11
2026-02-11T19:17:15.4980697Z Candidate multilib: .;@m64
2026-02-11T19:17:15.4989379Z Selected multilib: .;@m64
2026-02-11T19:17:15.5043367Z /usr/local/Ascend/cann-8.5.0/tools/bishengir/bin/bishengir-compile
2026-02-11T19:17:16.1189725Z Name: triton-ascend
2026-02-11T19:17:16.1197917Z Version: 3.2.0
2026-02-11T19:17:16.1208760Z Summary: A language and compiler for custom Deep Learning operations on Ascend hardwares
2026-02-11T19:17:16.1219377Z Home-page: https://gitcode.com/Ascend/triton-ascend/
2026-02-11T19:17:16.1227346Z Author: 
2026-02-11T19:17:16.1237270Z Author-email: 
2026-02-11T19:17:16.1246679Z License: 
2026-02-11T19:17:16.1256312Z Location: /usr/local/python3.11.14/lib/python3.11/site-packages
2026-02-11T19:17:16.1265657Z Requires: 
2026-02-11T19:17:16.1275980Z Required-by: vllm_ascend
2026-02-11T19:17:33.7834248Z INFO 02-11 19:17:33 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-11T19:17:33.7844224Z INFO 02-11 19:17:33 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-11T19:17:33.7854330Z INFO 02-11 19:17:33 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-11T19:17:34.0051800Z INFO 02-11 19:17:33 [__init__.py:217] Platform plugin ascend is activated
2026-02-11T19:17:39.3753858Z ============================= test session starts ==============================
2026-02-11T19:17:39.3754284Z platform linux -- Python 3.11.14, pytest-8.4.2, pluggy-1.6.0 -- /usr/local/python3.11.14/bin/python3
2026-02-11T19:17:39.3757834Z cachedir: .pytest_cache
2026-02-11T19:17:39.3768931Z rootdir: /vllm-workspace/vllm-ascend
2026-02-11T19:17:39.3782956Z configfile: pyproject.toml
2026-02-11T19:17:39.3793710Z plugins: cov-7.0.0, mock-3.15.1, asyncio-1.3.0, anyio-4.12.1
2026-02-11T19:17:39.3804129Z asyncio: mode=Mode.STRICT, debug=False, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function
2026-02-11T19:17:40.1259992Z collecting ... collected 1 item
2026-02-11T19:17:40.1267922Z 
2026-02-11T19:17:40.1284393Z [2026-02-11 19:17:40] INFO multi_node_config.py:294: Loading config yaml: tests/e2e/nightly/multi_node/config/DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-02-11T19:17:40.1312619Z [2026-02-11 19:17:40] INFO multi_node_config.py:351: Resolving cluster IPs via DNS...
2026-02-11T19:17:40.1365771Z [2026-02-11 19:17:40] INFO multi_node_config.py:212: Node 0 envs: {'HCCL_OP_EXPANSION_MODE': 'AIV', 'VLLM_USE_MODELSCOPE': 'True', 'HCCL_BUFFSIZE': '1024', 'SERVER_PORT': '8080', 'OMP_PROC_BIND': 'False', 'OMP_NUM_THREADS': '1', 'PYTORCH_NPU_ALLOC_CONF': 'expandable_segments:True', 'VLLM_ASCEND_ENABLE_FLASHCOMM1': '1', 'ASCEND_A3_EBA_ENABLE': '1', 'HCCL_IF_IP': '10.0.0.163', 'HCCL_SOCKET_IFNAME': 'eth0', 'GLOO_SOCKET_IFNAME': 'eth0', 'TP_SOCKET_IFNAME': 'eth0', 'LOCAL_IP': '10.0.0.163', 'NIC_NAME': 'eth0', 'MASTER_IP': '10.0.0.163'}
2026-02-11T19:17:40.1383045Z [2026-02-11 19:17:40] INFO multi_node_config.py:137: Not launching proxy on non-master node
2026-02-11T19:17:40.1396144Z [2026-02-11 19:17:40] INFO conftest.py:241: Starting server with command: vllm serve vllm-ascend/DeepSeek-V3.2-W8A8 --host 0.0.0.0 --port 8080 --data-parallel-size 4 --data-parallel-size-local 2 --data-parallel-address 10.0.0.163 --data-parallel-rpc-port 13399 --tensor-parallel-size 8 --quantization ascend --seed 1024 --enable-expert-parallel --max-num-seqs 16 --max-model-len 8192 --max-num-batched-tokens 4096 --no-enable-prefix-caching --gpu-memory-utilization 0.85 --trust-remote-code --speculative-config {"num_speculative_tokens": 2, "method":"deepseek_mtp"} --compilation-config {"cudagraph_capture_sizes": [3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45, 48], "cudagraph_mode": "FULL_DECODE_ONLY"} --additional-config {"layer_sharding": ["q_b_proj", "o_proj"]} --tokenizer-mode deepseek_v32 --reasoning-parser deepseek_v3
2026-02-11T19:17:44.6314032Z tests/e2e/nightly/multi_node/scripts/test_multi_node.py::test_multi_node INFO 02-11 19:17:44 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-11T19:17:44.6319581Z INFO 02-11 19:17:44 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-11T19:17:44.6329240Z INFO 02-11 19:17:44 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-11T19:17:44.6387554Z INFO 02-11 19:17:44 [__init__.py:217] Platform plugin ascend is activated
2026-02-11T19:17:50.9698083Z 2026-02-11 19:17:50,967 - 138 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-11T19:17:51.0014384Z INFO 02-11 19:17:50 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-11T19:17:51.1407377Z INFO 02-11 19:17:51 [serve.py:100] Defaulting api_server_count to data_parallel_size (4).
2026-02-11T19:17:51.1429861Z INFO 02-11 19:17:51 [utils.py:325] 
2026-02-11T19:17:51.1439915Z INFO 02-11 19:17:51 [utils.py:325]        â–ˆ     â–ˆ     â–ˆâ–„   â–„â–ˆ
2026-02-11T19:17:51.1449381Z INFO 02-11 19:17:51 [utils.py:325]  â–„â–„ â–„â–ˆ â–ˆ     â–ˆ     â–ˆ â–€â–„â–€ â–ˆ  version 0.15.0
2026-02-11T19:17:51.1458889Z INFO 02-11 19:17:51 [utils.py:325]   â–ˆâ–„â–ˆâ–€ â–ˆ     â–ˆ     â–ˆ     â–ˆ  model   vllm-ascend/DeepSeek-V3.2-W8A8
2026-02-11T19:17:51.1469270Z INFO 02-11 19:17:51 [utils.py:325]    â–€â–€  â–€â–€â–€â–€â–€ â–€â–€â–€â–€â–€ â–€     â–€
2026-02-11T19:17:51.1478358Z INFO 02-11 19:17:51 [utils.py:325] 
2026-02-11T19:17:51.1512873Z INFO 02-11 19:17:51 [utils.py:261] non-default args: {'model_tag': 'vllm-ascend/DeepSeek-V3.2-W8A8', 'api_server_count': 4, 'host': '0.0.0.0', 'port': 8080, 'model': 'vllm-ascend/DeepSeek-V3.2-W8A8', 'tokenizer_mode': 'deepseek_v32', 'trust_remote_code': True, 'seed': 1024, 'max_model_len': 8192, 'quantization': 'ascend', 'reasoning_parser': 'deepseek_v3', 'tensor_parallel_size': 8, 'data_parallel_size': 4, 'data_parallel_size_local': 2, 'data_parallel_address': '10.0.0.163', 'data_parallel_rpc_port': 13399, 'enable_expert_parallel': True, 'gpu_memory_utilization': 0.85, 'enable_prefix_caching': False, 'max_num_batched_tokens': 4096, 'max_num_seqs': 16, 'speculative_config': {'num_speculative_tokens': 2, 'method': 'deepseek_mtp'}, 'compilation_config': {'level': None, 'mode': None, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'vllm_ascend.compilation.compiler_interface.AscendCompiler', 'custom_ops': [], 'splitting_ops': None, 'compile_mm_encoder': False, 'compile_sizes': None, 'compile_ranges_split_points': None, 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_DECODE_ONLY: (2, 0)>, 'cudagraph_num_of_warmups': 0, 'cudagraph_capture_sizes': [3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45, 48], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': None, 'pass_config': {}, 'max_cudagraph_capture_size': None, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>, 'evaluate_guards': False, 'assume_32_bit_indexing': True}, 'local_cache_dir': None}, 'additional_config': {'layer_sharding': ['q_b_proj', 'o_proj']}}
2026-02-11T19:17:51.1976492Z 2026-02-11 19:17:51,195 - modelscope - WARNING - We can not confirm the cached file is for revision: master
2026-02-11T19:17:51.1988120Z INFO 02-11 19:17:51 [arg_utils.py:602] HF_HUB_OFFLINE is True, replace model_id [vllm-ascend/DeepSeek-V3.2-W8A8] to model_path [/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8]
2026-02-11T19:17:51.2010908Z The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-11T19:17:51.2049941Z The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-11T19:17:51.2070878Z The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-11T19:17:51.2081249Z You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-11T19:17:51.2302515Z INFO 02-11 19:17:51 [model.py:541] Resolved architecture: DeepseekV32ForCausalLM
2026-02-11T19:17:51.2309473Z INFO 02-11 19:17:51 [model.py:1561] Using max model len 8192
2026-02-11T19:17:51.4917827Z WARNING 02-11 19:17:51 [speculative.py:270] method `deepseek_mtp` is deprecated and replaced with mtp.
2026-02-11T19:17:51.4939452Z The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-11T19:17:51.4949508Z The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-11T19:17:51.4959203Z You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-11T19:18:00.9626155Z INFO 02-11 19:18:00 [model.py:541] Resolved architecture: DeepSeekMTPModel
2026-02-11T19:18:00.9637232Z INFO 02-11 19:18:00 [model.py:1561] Using max model len 163840
2026-02-11T19:18:00.9646974Z WARNING 02-11 19:18:00 [speculative.py:388] Enabling num_speculative_tokens > 1 will runmultiple times of forward on same MTP layer,which may result in lower acceptance rate
2026-02-11T19:18:00.9657299Z INFO 02-11 19:18:00 [scheduler.py:226] Chunked prefill is enabled with max_num_batched_tokens=4096.
2026-02-11T19:18:01.3270256Z INFO 02-11 19:18:01 [vllm.py:624] Asynchronous scheduling is enabled.
2026-02-11T19:18:01.3278806Z INFO 02-11 19:18:01 [vllm.py:634] Disabling NCCL for DP synchronization when using async scheduling.
2026-02-11T19:18:01.3294436Z WARNING 02-11 19:18:01 [platform.py:722] Speculative quantization is set but Ascend automatically uses the main model's quantization method. Resetting to None.
2026-02-11T19:18:01.3304018Z WARNING 02-11 19:18:01 [platform.py:763] Ignored parameter 'use_trtllm_ragged_deepseek_prefill'. This is a GPU-specific feature not supported on Ascend. Resetting to False.
2026-02-11T19:18:01.3313636Z INFO 02-11 19:18:01 [ascend_config.py:412] Dynamic EPLB is False
2026-02-11T19:18:01.3324090Z INFO 02-11 19:18:01 [ascend_config.py:413] The number of redundant experts is 0
2026-02-11T19:18:01.3334634Z INFO 02-11 19:18:01 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-11T19:18:01.3343829Z WARNING 02-11 19:18:01 [vllm.py:1062] Batch sizes [3, 6, 9, 12, 15, 18, 21, 27, 30, 33, 36, 39, 42, 45] are removed because they are not multiple of tp_size 8 when sequence parallelism is enabled
2026-02-11T19:18:01.3352717Z INFO 02-11 19:18:01 [platform.py:310] FULL_DECODE_ONLY compilation enabled on NPU. use_inductor not supported - using only ACL Graph mode
2026-02-11T19:18:01.3363037Z WARNING 02-11 19:18:01 [platform.py:327] [91m
2026-02-11T19:18:01.3372353Z WARNING 02-11 19:18:01 [platform.py:327]             **********************************************************************************
2026-02-11T19:18:01.3382439Z WARNING 02-11 19:18:01 [platform.py:327]             * WARNING: You have enabled the *full graph* feature.
2026-02-11T19:18:01.3392440Z WARNING 02-11 19:18:01 [platform.py:327]             * This is an early experimental stage and may involve various unknown issues.
2026-02-11T19:18:01.3402947Z WARNING 02-11 19:18:01 [platform.py:327]             * A known problem is that capturing too many batch sizes can lead to OOM
2026-02-11T19:18:01.3412487Z WARNING 02-11 19:18:01 [platform.py:327]             * (Out of Memory) errors or inference hangs. If you encounter such issues,
2026-02-11T19:18:01.3421699Z WARNING 02-11 19:18:01 [platform.py:327]             * consider reducing `gpu_memory_utilization` or manually specifying a smaller
2026-02-11T19:18:01.3430796Z WARNING 02-11 19:18:01 [platform.py:327]             * batch size for graph capture.
2026-02-11T19:18:01.3440723Z WARNING 02-11 19:18:01 [platform.py:327]             * For more details, please refer to:
2026-02-11T19:18:01.3450279Z WARNING 02-11 19:18:01 [platform.py:327]             * https://docs.vllm.ai/en/stable/configuration/conserving_memory.html#reduce-cuda-graphs
2026-02-11T19:18:01.3459577Z WARNING 02-11 19:18:01 [platform.py:327]             **********************************************************************************[0m
2026-02-11T19:18:01.3468712Z WARNING 02-11 19:18:01 [platform.py:327]             
2026-02-11T19:18:01.3478688Z INFO 02-11 19:18:01 [platform.py:435] Set PYTORCH_NPU_ALLOC_CONF=expandable_segments:True
2026-02-11T19:18:01.3487787Z INFO 02-11 19:18:01 [utils.py:851] Started DP Coordinator process (PID: 158)
2026-02-11T19:18:05.7055894Z INFO 02-11 19:18:05 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-11T19:18:05.7064767Z INFO 02-11 19:18:05 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-11T19:18:05.7074763Z INFO 02-11 19:18:05 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-11T19:18:05.7125943Z INFO 02-11 19:18:05 [__init__.py:217] Platform plugin ascend is activated
2026-02-11T19:18:05.9265940Z INFO 02-11 19:18:05 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-11T19:18:05.9273475Z INFO 02-11 19:18:05 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-11T19:18:05.9283445Z INFO 02-11 19:18:05 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-11T19:18:05.9344418Z INFO 02-11 19:18:05 [__init__.py:217] Platform plugin ascend is activated
2026-02-11T19:18:15.1450794Z INFO 02-11 19:18:15 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-11T19:18:15.1461500Z INFO 02-11 19:18:15 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-11T19:18:15.1471566Z INFO 02-11 19:18:15 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-11T19:18:15.1518163Z INFO 02-11 19:18:15 [__init__.py:217] Platform plugin ascend is activated
2026-02-11T19:18:20.3317954Z INFO 02-11 19:18:20 [utils.py:218] Started 4 API server processes
2026-02-11T19:18:22.1511703Z [0;36m(EngineCore_DP1 pid=180)[0;0m 2026-02-11 19:18:22,148 - 180 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-11T19:18:22.1531199Z [0;36m(EngineCore_DP0 pid=161)[0;0m 2026-02-11 19:18:22,150 - 161 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-11T19:18:22.1557607Z [0;36m(EngineCore_DP1 pid=180)[0;0m INFO 02-11 19:18:22 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-11T19:18:22.1580905Z [0;36m(EngineCore_DP0 pid=161)[0;0m INFO 02-11 19:18:22 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-11T19:18:22.1605841Z [0;36m(EngineCore_DP0 pid=161)[0;0m INFO 02-11 19:18:22 [core.py:96] Initializing a V1 LLM engine (v0.15.0) with config: model='/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8', speculative_config=SpeculativeConfig(method='mtp', model='/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8', num_spec_tokens=2), tokenizer='/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8', skip_tokenizer_init=False, tokenizer_mode=deepseek_v32, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=8, pipeline_parallel_size=1, data_parallel_size=4, disable_custom_all_reduce=True, quantization=ascend, enforce_eager=False, enable_return_routed_experts=False, kv_cache_dtype=auto, device_config=npu, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='deepseek_v3', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01, cudagraph_metrics=False, enable_layerwise_nvtx_tracing=False, enable_mfu_metrics=False, enable_mm_processor_stats=False, enable_logging_iteration_details=False), seed=1024, served_model_name=/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'vllm_ascend.compilation.compiler_interface.AscendCompiler', 'custom_ops': ['all'], 'splitting_ops': [], 'compile_mm_encoder': False, 'compile_sizes': [], 'compile_ranges_split_points': [4096], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_DECODE_ONLY: (2, 0)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [24, 48], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': True, 'fuse_act_quant': True, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 48, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>, 'evaluate_guards': False, 'assume_32_bit_indexing': True}, 'local_cache_dir': None}
2026-02-11T19:18:24.9600576Z INFO 02-11 19:18:24 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-11T19:18:24.9608692Z INFO 02-11 19:18:24 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-11T19:18:24.9618313Z INFO 02-11 19:18:24 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-11T19:18:24.9673396Z INFO 02-11 19:18:24 [__init__.py:217] Platform plugin ascend is activated
2026-02-11T19:18:25.2611621Z INFO 02-11 19:18:25 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-11T19:18:25.2620022Z INFO 02-11 19:18:25 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-11T19:18:25.2629133Z INFO 02-11 19:18:25 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-11T19:18:25.2685983Z INFO 02-11 19:18:25 [__init__.py:217] Platform plugin ascend is activated
2026-02-11T19:18:25.2985244Z INFO 02-11 19:18:25 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-11T19:18:25.2993911Z INFO 02-11 19:18:25 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-11T19:18:25.3003639Z INFO 02-11 19:18:25 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-11T19:18:25.3030780Z INFO 02-11 19:18:25 [__init__.py:217] Platform plugin ascend is activated
2026-02-11T19:18:25.3721042Z INFO 02-11 19:18:25 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-11T19:18:25.3728446Z INFO 02-11 19:18:25 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-11T19:18:25.3737923Z INFO 02-11 19:18:25 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-11T19:18:25.3794986Z INFO 02-11 19:18:25 [__init__.py:217] Platform plugin ascend is activated
2026-02-11T19:18:27.6242520Z INFO 02-11 19:18:27 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-11T19:18:27.6250166Z INFO 02-11 19:18:27 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-11T19:18:27.6261085Z INFO 02-11 19:18:27 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-11T19:18:27.6350011Z INFO 02-11 19:18:27 [__init__.py:217] Platform plugin ascend is activated
2026-02-11T19:18:27.6403211Z INFO 02-11 19:18:27 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-11T19:18:27.6417732Z INFO 02-11 19:18:27 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-11T19:18:27.6429351Z INFO 02-11 19:18:27 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-11T19:18:27.6506999Z INFO 02-11 19:18:27 [__init__.py:217] Platform plugin ascend is activated
2026-02-11T19:18:31.0205864Z [0;36m(ApiServer_3 pid=194)[0;0m 2026-02-11 19:18:31,018 - 194 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-11T19:18:31.0364951Z [0;36m(ApiServer_3 pid=194)[0;0m INFO 02-11 19:18:31 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-11T19:18:31.0676567Z [0;36m(ApiServer_3 pid=194)[0;0m 2026-02-11 19:18:31,065 - modelscope - WARNING - We can not confirm the cached file is for revision: master
2026-02-11T19:18:31.0721308Z [0;36m(ApiServer_3 pid=194)[0;0m INFO 02-11 19:18:31 [arg_utils.py:602] HF_HUB_OFFLINE is True, replace model_id [vllm-ascend/DeepSeek-V3.2-W8A8] to model_path [/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8]
2026-02-11T19:18:31.1668713Z [0;36m(ApiServer_3 pid=194)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-11T19:18:31.1689785Z [0;36m(ApiServer_3 pid=194)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-11T19:18:31.1718600Z [0;36m(ApiServer_3 pid=194)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-11T19:18:31.1729604Z [0;36m(ApiServer_3 pid=194)[0;0m You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-11T19:18:31.1821758Z [0;36m(ApiServer_3 pid=194)[0;0m INFO 02-11 19:18:31 [model.py:541] Resolved architecture: DeepseekV32ForCausalLM
2026-02-11T19:18:31.1842322Z [0;36m(ApiServer_3 pid=194)[0;0m INFO 02-11 19:18:31 [model.py:1561] Using max model len 8192
2026-02-11T19:18:31.2909938Z [0;36m(ApiServer_3 pid=194)[0;0m WARNING 02-11 19:18:31 [speculative.py:270] method `deepseek_mtp` is deprecated and replaced with mtp.
2026-02-11T19:18:31.2929748Z [0;36m(ApiServer_3 pid=194)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-11T19:18:31.2939604Z [0;36m(ApiServer_3 pid=194)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-11T19:18:31.2950399Z [0;36m(ApiServer_3 pid=194)[0;0m You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-11T19:18:31.3038666Z [0;36m(ApiServer_3 pid=194)[0;0m INFO 02-11 19:18:31 [model.py:541] Resolved architecture: DeepSeekMTPModel
2026-02-11T19:18:31.3047860Z [0;36m(ApiServer_3 pid=194)[0;0m INFO 02-11 19:18:31 [model.py:1561] Using max model len 163840
2026-02-11T19:18:31.3058373Z [0;36m(ApiServer_3 pid=194)[0;0m WARNING 02-11 19:18:31 [speculative.py:388] Enabling num_speculative_tokens > 1 will runmultiple times of forward on same MTP layer,which may result in lower acceptance rate
2026-02-11T19:18:31.3067682Z [0;36m(ApiServer_3 pid=194)[0;0m INFO 02-11 19:18:31 [scheduler.py:226] Chunked prefill is enabled with max_num_batched_tokens=4096.
2026-02-11T19:18:31.4219539Z [0;36m(ApiServer_3 pid=194)[0;0m INFO 02-11 19:18:31 [vllm.py:624] Asynchronous scheduling is enabled.
2026-02-11T19:18:31.4228056Z [0;36m(ApiServer_3 pid=194)[0;0m INFO 02-11 19:18:31 [vllm.py:634] Disabling NCCL for DP synchronization when using async scheduling.
2026-02-11T19:18:31.4239666Z [0;36m(ApiServer_3 pid=194)[0;0m WARNING 02-11 19:18:31 [platform.py:722] Speculative quantization is set but Ascend automatically uses the main model's quantization method. Resetting to None.
2026-02-11T19:18:31.4249975Z [0;36m(ApiServer_3 pid=194)[0;0m WARNING 02-11 19:18:31 [platform.py:763] Ignored parameter 'use_trtllm_ragged_deepseek_prefill'. This is a GPU-specific feature not supported on Ascend. Resetting to False.
2026-02-11T19:18:31.4259266Z [0;36m(ApiServer_3 pid=194)[0;0m INFO 02-11 19:18:31 [ascend_config.py:412] Dynamic EPLB is False
2026-02-11T19:18:31.4268307Z [0;36m(ApiServer_3 pid=194)[0;0m INFO 02-11 19:18:31 [ascend_config.py:413] The number of redundant experts is 0
2026-02-11T19:18:31.4279799Z [0;36m(ApiServer_3 pid=194)[0;0m INFO 02-11 19:18:31 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-11T19:18:31.4289435Z [0;36m(ApiServer_3 pid=194)[0;0m WARNING 02-11 19:18:31 [vllm.py:1062] Batch sizes [3, 6, 9, 12, 15, 18, 21, 27, 30, 33, 36, 39, 42, 45] are removed because they are not multiple of tp_size 8 when sequence parallelism is enabled
2026-02-11T19:18:31.4298963Z [0;36m(ApiServer_3 pid=194)[0;0m INFO 02-11 19:18:31 [platform.py:310] FULL_DECODE_ONLY compilation enabled on NPU. use_inductor not supported - using only ACL Graph mode
2026-02-11T19:18:31.4308846Z [0;36m(ApiServer_3 pid=194)[0;0m WARNING 02-11 19:18:31 [platform.py:327] [91m
2026-02-11T19:18:31.4318627Z [0;36m(ApiServer_3 pid=194)[0;0m WARNING 02-11 19:18:31 [platform.py:327]             **********************************************************************************
2026-02-11T19:18:31.4328878Z [0;36m(ApiServer_3 pid=194)[0;0m WARNING 02-11 19:18:31 [platform.py:327]             * WARNING: You have enabled the *full graph* feature.
2026-02-11T19:18:31.4339366Z [0;36m(ApiServer_3 pid=194)[0;0m WARNING 02-11 19:18:31 [platform.py:327]             * This is an early experimental stage and may involve various unknown issues.
2026-02-11T19:18:31.4349014Z [0;36m(ApiServer_3 pid=194)[0;0m WARNING 02-11 19:18:31 [platform.py:327]             * A known problem is that capturing too many batch sizes can lead to OOM
2026-02-11T19:18:31.4359122Z [0;36m(ApiServer_3 pid=194)[0;0m WARNING 02-11 19:18:31 [platform.py:327]             * (Out of Memory) errors or inference hangs. If you encounter such issues,
2026-02-11T19:18:31.4369577Z [0;36m(ApiServer_3 pid=194)[0;0m WARNING 02-11 19:18:31 [platform.py:327]             * consider reducing `gpu_memory_utilization` or manually specifying a smaller
2026-02-11T19:18:31.4379230Z [0;36m(ApiServer_3 pid=194)[0;0m WARNING 02-11 19:18:31 [platform.py:327]             * batch size for graph capture.
2026-02-11T19:18:31.4388895Z [0;36m(ApiServer_3 pid=194)[0;0m WARNING 02-11 19:18:31 [platform.py:327]             * For more details, please refer to:
2026-02-11T19:18:31.4398948Z [0;36m(ApiServer_3 pid=194)[0;0m WARNING 02-11 19:18:31 [platform.py:327]             * https://docs.vllm.ai/en/stable/configuration/conserving_memory.html#reduce-cuda-graphs
2026-02-11T19:18:31.4408530Z [0;36m(ApiServer_3 pid=194)[0;0m WARNING 02-11 19:18:31 [platform.py:327]             **********************************************************************************[0m
2026-02-11T19:18:31.4417733Z [0;36m(ApiServer_3 pid=194)[0;0m WARNING 02-11 19:18:31 [platform.py:327]             
2026-02-11T19:18:31.4427381Z [0;36m(ApiServer_3 pid=194)[0;0m INFO 02-11 19:18:31 [platform.py:435] Set PYTORCH_NPU_ALLOC_CONF=expandable_segments:True
2026-02-11T19:18:31.5049267Z [0;36m(ApiServer_0 pid=191)[0;0m 2026-02-11 19:18:31,503 - 191 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-11T19:18:31.5210587Z [0;36m(ApiServer_0 pid=191)[0;0m INFO 02-11 19:18:31 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-11T19:18:31.5373945Z [0;36m(ApiServer_0 pid=191)[0;0m 2026-02-11 19:18:31,535 - modelscope - WARNING - We can not confirm the cached file is for revision: master
2026-02-11T19:18:31.5392449Z [0;36m(ApiServer_0 pid=191)[0;0m INFO 02-11 19:18:31 [arg_utils.py:602] HF_HUB_OFFLINE is True, replace model_id [vllm-ascend/DeepSeek-V3.2-W8A8] to model_path [/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8]
2026-02-11T19:18:31.6341839Z [0;36m(ApiServer_0 pid=191)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-11T19:18:31.6360070Z [0;36m(ApiServer_0 pid=191)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-11T19:18:31.6379133Z [0;36m(ApiServer_0 pid=191)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-11T19:18:31.6389116Z [0;36m(ApiServer_0 pid=191)[0;0m You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-11T19:18:31.6447076Z [0;36m(ApiServer_0 pid=191)[0;0m INFO 02-11 19:18:31 [model.py:541] Resolved architecture: DeepseekV32ForCausalLM
2026-02-11T19:18:31.6465584Z [0;36m(ApiServer_0 pid=191)[0;0m INFO 02-11 19:18:31 [model.py:1561] Using max model len 8192
2026-02-11T19:18:31.6559821Z [0;36m(ApiServer_2 pid=193)[0;0m 2026-02-11 19:18:31,654 - 193 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-11T19:18:31.6722811Z [0;36m(ApiServer_2 pid=193)[0;0m INFO 02-11 19:18:31 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-11T19:18:31.6915163Z [0;36m(ApiServer_2 pid=193)[0;0m 2026-02-11 19:18:31,689 - modelscope - WARNING - We can not confirm the cached file is for revision: master
2026-02-11T19:18:31.6938238Z [0;36m(ApiServer_2 pid=193)[0;0m INFO 02-11 19:18:31 [arg_utils.py:602] HF_HUB_OFFLINE is True, replace model_id [vllm-ascend/DeepSeek-V3.2-W8A8] to model_path [/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8]
2026-02-11T19:18:31.7564642Z [0;36m(ApiServer_1 pid=192)[0;0m 2026-02-11 19:18:31,754 - 192 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-11T19:18:31.7594174Z [0;36m(ApiServer_0 pid=191)[0;0m WARNING 02-11 19:18:31 [speculative.py:270] method `deepseek_mtp` is deprecated and replaced with mtp.
2026-02-11T19:18:31.7616179Z [0;36m(ApiServer_0 pid=191)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-11T19:18:31.7626088Z [0;36m(ApiServer_0 pid=191)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-11T19:18:31.7635497Z [0;36m(ApiServer_0 pid=191)[0;0m You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-11T19:18:31.7673476Z [0;36m(ApiServer_0 pid=191)[0;0m INFO 02-11 19:18:31 [model.py:541] Resolved architecture: DeepSeekMTPModel
2026-02-11T19:18:31.7691614Z [0;36m(ApiServer_0 pid=191)[0;0m INFO 02-11 19:18:31 [model.py:1561] Using max model len 163840
2026-02-11T19:18:31.7702356Z [0;36m(ApiServer_0 pid=191)[0;0m WARNING 02-11 19:18:31 [speculative.py:388] Enabling num_speculative_tokens > 1 will runmultiple times of forward on same MTP layer,which may result in lower acceptance rate
2026-02-11T19:18:31.7711926Z [0;36m(ApiServer_0 pid=191)[0;0m INFO 02-11 19:18:31 [scheduler.py:226] Chunked prefill is enabled with max_num_batched_tokens=4096.
2026-02-11T19:18:31.7728125Z [0;36m(ApiServer_1 pid=192)[0;0m INFO 02-11 19:18:31 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-11T19:18:31.7908308Z [0;36m(ApiServer_2 pid=193)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-11T19:18:31.7924049Z [0;36m(ApiServer_2 pid=193)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-11T19:18:31.7942743Z [0;36m(ApiServer_2 pid=193)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-11T19:18:31.7952286Z [0;36m(ApiServer_2 pid=193)[0;0m You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-11T19:18:31.7961579Z [0;36m(ApiServer_1 pid=192)[0;0m 2026-02-11 19:18:31,793 - modelscope - WARNING - We can not confirm the cached file is for revision: master
2026-02-11T19:18:31.7971948Z [0;36m(ApiServer_1 pid=192)[0;0m INFO 02-11 19:18:31 [arg_utils.py:602] HF_HUB_OFFLINE is True, replace model_id [vllm-ascend/DeepSeek-V3.2-W8A8] to model_path [/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8]
2026-02-11T19:18:31.8020080Z [0;36m(ApiServer_2 pid=193)[0;0m INFO 02-11 19:18:31 [model.py:541] Resolved architecture: DeepseekV32ForCausalLM
2026-02-11T19:18:31.8040751Z [0;36m(ApiServer_2 pid=193)[0;0m INFO 02-11 19:18:31 [model.py:1561] Using max model len 8192
2026-02-11T19:18:31.8904640Z [0;36m(ApiServer_0 pid=191)[0;0m INFO 02-11 19:18:31 [vllm.py:624] Asynchronous scheduling is enabled.
2026-02-11T19:18:31.8913877Z [0;36m(ApiServer_0 pid=191)[0;0m INFO 02-11 19:18:31 [vllm.py:634] Disabling NCCL for DP synchronization when using async scheduling.
2026-02-11T19:18:31.8923217Z [0;36m(ApiServer_0 pid=191)[0;0m WARNING 02-11 19:18:31 [platform.py:722] Speculative quantization is set but Ascend automatically uses the main model's quantization method. Resetting to None.
2026-02-11T19:18:31.8932703Z [0;36m(ApiServer_0 pid=191)[0;0m WARNING 02-11 19:18:31 [platform.py:763] Ignored parameter 'use_trtllm_ragged_deepseek_prefill'. This is a GPU-specific feature not supported on Ascend. Resetting to False.
2026-02-11T19:18:31.8941355Z [0;36m(ApiServer_0 pid=191)[0;0m INFO 02-11 19:18:31 [ascend_config.py:412] Dynamic EPLB is False
2026-02-11T19:18:31.8951130Z [0;36m(ApiServer_0 pid=191)[0;0m INFO 02-11 19:18:31 [ascend_config.py:413] The number of redundant experts is 0
2026-02-11T19:18:31.8961059Z [0;36m(ApiServer_0 pid=191)[0;0m INFO 02-11 19:18:31 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-11T19:18:31.8970727Z [0;36m(ApiServer_0 pid=191)[0;0m WARNING 02-11 19:18:31 [vllm.py:1062] Batch sizes [3, 6, 9, 12, 15, 18, 21, 27, 30, 33, 36, 39, 42, 45] are removed because they are not multiple of tp_size 8 when sequence parallelism is enabled
2026-02-11T19:18:31.8979879Z [0;36m(ApiServer_0 pid=191)[0;0m INFO 02-11 19:18:31 [platform.py:310] FULL_DECODE_ONLY compilation enabled on NPU. use_inductor not supported - using only ACL Graph mode
2026-02-11T19:18:31.8989085Z [0;36m(ApiServer_0 pid=191)[0;0m WARNING 02-11 19:18:31 [platform.py:327] [91m
2026-02-11T19:18:31.8998175Z [0;36m(ApiServer_0 pid=191)[0;0m WARNING 02-11 19:18:31 [platform.py:327]             **********************************************************************************
2026-02-11T19:18:31.9007978Z [0;36m(ApiServer_0 pid=191)[0;0m WARNING 02-11 19:18:31 [platform.py:327]             * WARNING: You have enabled the *full graph* feature.
2026-02-11T19:18:31.9017641Z [0;36m(ApiServer_0 pid=191)[0;0m WARNING 02-11 19:18:31 [platform.py:327]             * This is an early experimental stage and may involve various unknown issues.
2026-02-11T19:18:31.9027112Z [0;36m(ApiServer_0 pid=191)[0;0m WARNING 02-11 19:18:31 [platform.py:327]             * A known problem is that capturing too many batch sizes can lead to OOM
2026-02-11T19:18:31.9036871Z [0;36m(ApiServer_0 pid=191)[0;0m WARNING 02-11 19:18:31 [platform.py:327]             * (Out of Memory) errors or inference hangs. If you encounter such issues,
2026-02-11T19:18:31.9046906Z [0;36m(ApiServer_0 pid=191)[0;0m WARNING 02-11 19:18:31 [platform.py:327]             * consider reducing `gpu_memory_utilization` or manually specifying a smaller
2026-02-11T19:18:31.9056115Z [0;36m(ApiServer_0 pid=191)[0;0m WARNING 02-11 19:18:31 [platform.py:327]             * batch size for graph capture.
2026-02-11T19:18:31.9065310Z [0;36m(ApiServer_0 pid=191)[0;0m WARNING 02-11 19:18:31 [platform.py:327]             * For more details, please refer to:
2026-02-11T19:18:31.9075476Z [0;36m(ApiServer_0 pid=191)[0;0m WARNING 02-11 19:18:31 [platform.py:327]             * https://docs.vllm.ai/en/stable/configuration/conserving_memory.html#reduce-cuda-graphs
2026-02-11T19:18:31.9086695Z [0;36m(ApiServer_0 pid=191)[0;0m WARNING 02-11 19:18:31 [platform.py:327]             **********************************************************************************[0m
2026-02-11T19:18:31.9095625Z [0;36m(ApiServer_0 pid=191)[0;0m WARNING 02-11 19:18:31 [platform.py:327]             
2026-02-11T19:18:31.9105162Z [0;36m(ApiServer_0 pid=191)[0;0m INFO 02-11 19:18:31 [platform.py:435] Set PYTORCH_NPU_ALLOC_CONF=expandable_segments:True
2026-02-11T19:18:31.9115625Z [0;36m(ApiServer_1 pid=192)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-11T19:18:31.9124667Z [0;36m(ApiServer_1 pid=192)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-11T19:18:31.9134322Z [0;36m(ApiServer_1 pid=192)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-11T19:18:31.9144198Z [0;36m(ApiServer_1 pid=192)[0;0m You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-11T19:18:31.9153380Z [0;36m(ApiServer_1 pid=192)[0;0m INFO 02-11 19:18:31 [model.py:541] Resolved architecture: DeepseekV32ForCausalLM
2026-02-11T19:18:31.9163920Z [0;36m(ApiServer_1 pid=192)[0;0m INFO 02-11 19:18:31 [model.py:1561] Using max model len 8192
2026-02-11T19:18:31.9173618Z [0;36m(ApiServer_2 pid=193)[0;0m WARNING 02-11 19:18:31 [speculative.py:270] method `deepseek_mtp` is deprecated and replaced with mtp.
2026-02-11T19:18:31.9183048Z [0;36m(ApiServer_2 pid=193)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-11T19:18:31.9192532Z [0;36m(ApiServer_2 pid=193)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-11T19:18:31.9202695Z [0;36m(ApiServer_2 pid=193)[0;0m You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-11T19:18:31.9239383Z [0;36m(ApiServer_2 pid=193)[0;0m INFO 02-11 19:18:31 [model.py:541] Resolved architecture: DeepSeekMTPModel
2026-02-11T19:18:31.9279294Z [0;36m(ApiServer_2 pid=193)[0;0m INFO 02-11 19:18:31 [model.py:1561] Using max model len 163840
2026-02-11T19:18:31.9290529Z [0;36m(ApiServer_2 pid=193)[0;0m WARNING 02-11 19:18:31 [speculative.py:388] Enabling num_speculative_tokens > 1 will runmultiple times of forward on same MTP layer,which may result in lower acceptance rate
2026-02-11T19:18:31.9301125Z [0;36m(ApiServer_2 pid=193)[0;0m INFO 02-11 19:18:31 [scheduler.py:226] Chunked prefill is enabled with max_num_batched_tokens=4096.
2026-02-11T19:18:32.0154348Z [0;36m(ApiServer_1 pid=192)[0;0m WARNING 02-11 19:18:32 [speculative.py:270] method `deepseek_mtp` is deprecated and replaced with mtp.
2026-02-11T19:18:32.0185492Z [0;36m(ApiServer_1 pid=192)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-11T19:18:32.0197830Z [0;36m(ApiServer_1 pid=192)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-11T19:18:32.0208014Z [0;36m(ApiServer_1 pid=192)[0;0m You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-11T19:18:32.0296306Z [0;36m(ApiServer_1 pid=192)[0;0m INFO 02-11 19:18:32 [model.py:541] Resolved architecture: DeepSeekMTPModel
2026-02-11T19:18:32.0316854Z [0;36m(ApiServer_1 pid=192)[0;0m INFO 02-11 19:18:32 [model.py:1561] Using max model len 163840
2026-02-11T19:18:32.0327391Z [0;36m(ApiServer_1 pid=192)[0;0m WARNING 02-11 19:18:32 [speculative.py:388] Enabling num_speculative_tokens > 1 will runmultiple times of forward on same MTP layer,which may result in lower acceptance rate
2026-02-11T19:18:32.0336041Z [0;36m(ApiServer_1 pid=192)[0;0m INFO 02-11 19:18:32 [scheduler.py:226] Chunked prefill is enabled with max_num_batched_tokens=4096.
2026-02-11T19:18:32.0451347Z [0;36m(ApiServer_2 pid=193)[0;0m INFO 02-11 19:18:32 [vllm.py:624] Asynchronous scheduling is enabled.
2026-02-11T19:18:32.0462818Z [0;36m(ApiServer_2 pid=193)[0;0m INFO 02-11 19:18:32 [vllm.py:634] Disabling NCCL for DP synchronization when using async scheduling.
2026-02-11T19:18:32.0475521Z [0;36m(ApiServer_2 pid=193)[0;0m WARNING 02-11 19:18:32 [platform.py:722] Speculative quantization is set but Ascend automatically uses the main model's quantization method. Resetting to None.
2026-02-11T19:18:32.0486156Z [0;36m(ApiServer_2 pid=193)[0;0m WARNING 02-11 19:18:32 [platform.py:763] Ignored parameter 'use_trtllm_ragged_deepseek_prefill'. This is a GPU-specific feature not supported on Ascend. Resetting to False.
2026-02-11T19:18:32.0495679Z [0;36m(ApiServer_2 pid=193)[0;0m INFO 02-11 19:18:32 [ascend_config.py:412] Dynamic EPLB is False
2026-02-11T19:18:32.0505122Z [0;36m(ApiServer_2 pid=193)[0;0m INFO 02-11 19:18:32 [ascend_config.py:413] The number of redundant experts is 0
2026-02-11T19:18:32.0515982Z [0;36m(ApiServer_2 pid=193)[0;0m INFO 02-11 19:18:32 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-11T19:18:32.0525676Z [0;36m(ApiServer_2 pid=193)[0;0m WARNING 02-11 19:18:32 [vllm.py:1062] Batch sizes [3, 6, 9, 12, 15, 18, 21, 27, 30, 33, 36, 39, 42, 45] are removed because they are not multiple of tp_size 8 when sequence parallelism is enabled
2026-02-11T19:18:32.0535533Z [0;36m(ApiServer_2 pid=193)[0;0m INFO 02-11 19:18:32 [platform.py:310] FULL_DECODE_ONLY compilation enabled on NPU. use_inductor not supported - using only ACL Graph mode
2026-02-11T19:18:32.0545227Z [0;36m(ApiServer_2 pid=193)[0;0m WARNING 02-11 19:18:32 [platform.py:327] [91m
2026-02-11T19:18:32.0554572Z [0;36m(ApiServer_2 pid=193)[0;0m WARNING 02-11 19:18:32 [platform.py:327]             **********************************************************************************
2026-02-11T19:18:32.0565176Z [0;36m(ApiServer_2 pid=193)[0;0m WARNING 02-11 19:18:32 [platform.py:327]             * WARNING: You have enabled the *full graph* feature.
2026-02-11T19:18:32.0574610Z [0;36m(ApiServer_2 pid=193)[0;0m WARNING 02-11 19:18:32 [platform.py:327]             * This is an early experimental stage and may involve various unknown issues.
2026-02-11T19:18:32.0583505Z [0;36m(ApiServer_2 pid=193)[0;0m WARNING 02-11 19:18:32 [platform.py:327]             * A known problem is that capturing too many batch sizes can lead to OOM
2026-02-11T19:18:32.0593993Z [0;36m(ApiServer_2 pid=193)[0;0m WARNING 02-11 19:18:32 [platform.py:327]             * (Out of Memory) errors or inference hangs. If you encounter such issues,
2026-02-11T19:18:32.0604189Z [0;36m(ApiServer_2 pid=193)[0;0m WARNING 02-11 19:18:32 [platform.py:327]             * consider reducing `gpu_memory_utilization` or manually specifying a smaller
2026-02-11T19:18:32.0613497Z [0;36m(ApiServer_2 pid=193)[0;0m WARNING 02-11 19:18:32 [platform.py:327]             * batch size for graph capture.
2026-02-11T19:18:32.0622710Z [0;36m(ApiServer_2 pid=193)[0;0m WARNING 02-11 19:18:32 [platform.py:327]             * For more details, please refer to:
2026-02-11T19:18:32.0633214Z [0;36m(ApiServer_2 pid=193)[0;0m WARNING 02-11 19:18:32 [platform.py:327]             * https://docs.vllm.ai/en/stable/configuration/conserving_memory.html#reduce-cuda-graphs
2026-02-11T19:18:32.0643071Z [0;36m(ApiServer_2 pid=193)[0;0m WARNING 02-11 19:18:32 [platform.py:327]             **********************************************************************************[0m
2026-02-11T19:18:32.0652424Z [0;36m(ApiServer_2 pid=193)[0;0m WARNING 02-11 19:18:32 [platform.py:327]             
2026-02-11T19:18:32.0661515Z [0;36m(ApiServer_2 pid=193)[0;0m INFO 02-11 19:18:32 [platform.py:435] Set PYTORCH_NPU_ALLOC_CONF=expandable_segments:True
2026-02-11T19:18:32.1516387Z [0;36m(ApiServer_1 pid=192)[0;0m INFO 02-11 19:18:32 [vllm.py:624] Asynchronous scheduling is enabled.
2026-02-11T19:18:32.1525429Z [0;36m(ApiServer_1 pid=192)[0;0m INFO 02-11 19:18:32 [vllm.py:634] Disabling NCCL for DP synchronization when using async scheduling.
2026-02-11T19:18:32.1537351Z [0;36m(ApiServer_1 pid=192)[0;0m WARNING 02-11 19:18:32 [platform.py:722] Speculative quantization is set but Ascend automatically uses the main model's quantization method. Resetting to None.
2026-02-11T19:18:32.1544891Z [0;36m(ApiServer_1 pid=192)[0;0m WARNING 02-11 19:18:32 [platform.py:763] Ignored parameter 'use_trtllm_ragged_deepseek_prefill'. This is a GPU-specific feature not supported on Ascend. Resetting to False.
2026-02-11T19:18:32.1554781Z [0;36m(ApiServer_1 pid=192)[0;0m INFO 02-11 19:18:32 [ascend_config.py:412] Dynamic EPLB is False
2026-02-11T19:18:32.1563728Z [0;36m(ApiServer_1 pid=192)[0;0m INFO 02-11 19:18:32 [ascend_config.py:413] The number of redundant experts is 0
2026-02-11T19:18:32.1574415Z [0;36m(ApiServer_1 pid=192)[0;0m INFO 02-11 19:18:32 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-11T19:18:32.1584251Z [0;36m(ApiServer_1 pid=192)[0;0m WARNING 02-11 19:18:32 [vllm.py:1062] Batch sizes [3, 6, 9, 12, 15, 18, 21, 27, 30, 33, 36, 39, 42, 45] are removed because they are not multiple of tp_size 8 when sequence parallelism is enabled
2026-02-11T19:18:32.1593916Z [0;36m(ApiServer_1 pid=192)[0;0m INFO 02-11 19:18:32 [platform.py:310] FULL_DECODE_ONLY compilation enabled on NPU. use_inductor not supported - using only ACL Graph mode
2026-02-11T19:18:32.1602928Z [0;36m(ApiServer_1 pid=192)[0;0m WARNING 02-11 19:18:32 [platform.py:327] [91m
2026-02-11T19:18:32.1612796Z [0;36m(ApiServer_1 pid=192)[0;0m WARNING 02-11 19:18:32 [platform.py:327]             **********************************************************************************
2026-02-11T19:18:32.1622227Z [0;36m(ApiServer_1 pid=192)[0;0m WARNING 02-11 19:18:32 [platform.py:327]             * WARNING: You have enabled the *full graph* feature.
2026-02-11T19:18:32.1631458Z [0;36m(ApiServer_1 pid=192)[0;0m WARNING 02-11 19:18:32 [platform.py:327]             * This is an early experimental stage and may involve various unknown issues.
2026-02-11T19:18:32.1641031Z [0;36m(ApiServer_1 pid=192)[0;0m WARNING 02-11 19:18:32 [platform.py:327]             * A known problem is that capturing too many batch sizes can lead to OOM
2026-02-11T19:18:32.1649936Z [0;36m(ApiServer_1 pid=192)[0;0m WARNING 02-11 19:18:32 [platform.py:327]             * (Out of Memory) errors or inference hangs. If you encounter such issues,
2026-02-11T19:18:32.1659286Z [0;36m(ApiServer_1 pid=192)[0;0m WARNING 02-11 19:18:32 [platform.py:327]             * consider reducing `gpu_memory_utilization` or manually specifying a smaller
2026-02-11T19:18:32.1668655Z [0;36m(ApiServer_1 pid=192)[0;0m WARNING 02-11 19:18:32 [platform.py:327]             * batch size for graph capture.
2026-02-11T19:18:32.1678592Z [0;36m(ApiServer_1 pid=192)[0;0m WARNING 02-11 19:18:32 [platform.py:327]             * For more details, please refer to:
2026-02-11T19:18:32.1688593Z [0;36m(ApiServer_1 pid=192)[0;0m WARNING 02-11 19:18:32 [platform.py:327]             * https://docs.vllm.ai/en/stable/configuration/conserving_memory.html#reduce-cuda-graphs
2026-02-11T19:18:32.1698172Z [0;36m(ApiServer_1 pid=192)[0;0m WARNING 02-11 19:18:32 [platform.py:327]             **********************************************************************************[0m
2026-02-11T19:18:32.1706672Z [0;36m(ApiServer_1 pid=192)[0;0m WARNING 02-11 19:18:32 [platform.py:327]             
2026-02-11T19:18:32.1716215Z [0;36m(ApiServer_1 pid=192)[0;0m INFO 02-11 19:18:32 [platform.py:435] Set PYTORCH_NPU_ALLOC_CONF=expandable_segments:True
2026-02-11T19:18:33.2103511Z 2026-02-11 19:18:33,208 - 221 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-11T19:18:33.2141689Z INFO 02-11 19:18:33 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-11T19:18:33.3319786Z 2026-02-11 19:18:33,330 - 220 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-11T19:18:33.3356546Z INFO 02-11 19:18:33 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-11T19:18:35.1279003Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-11T19:18:35.1286274Z   warnings.warn(
2026-02-11T19:18:35.1298149Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-11T19:18:35.1306698Z   warnings.warn(
2026-02-11T19:18:37.4424502Z INFO 02-11 19:18:37 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-11T19:18:37.4433358Z INFO 02-11 19:18:37 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-11T19:18:37.4443531Z INFO 02-11 19:18:37 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-11T19:18:37.4533338Z INFO 02-11 19:18:37 [__init__.py:217] Platform plugin ascend is activated
2026-02-11T19:18:37.8913076Z INFO 02-11 19:18:37 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-11T19:18:37.8921289Z INFO 02-11 19:18:37 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-11T19:18:37.8930871Z INFO 02-11 19:18:37 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-11T19:18:37.8994488Z INFO 02-11 19:18:37 [__init__.py:217] Platform plugin ascend is activated
2026-02-11T19:18:38.2050276Z INFO 02-11 19:18:38 [ascend_config.py:412] Dynamic EPLB is False
2026-02-11T19:18:38.2057967Z INFO 02-11 19:18:38 [ascend_config.py:413] The number of redundant experts is 0
2026-02-11T19:18:38.2068297Z INFO 02-11 19:18:38 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-11T19:18:38.2076603Z INFO 02-11 19:18:38 [ascend_config.py:412] Dynamic EPLB is False
2026-02-11T19:18:38.2086760Z INFO 02-11 19:18:38 [ascend_config.py:413] The number of redundant experts is 0
2026-02-11T19:18:38.2097697Z INFO 02-11 19:18:38 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-11T19:18:38.2688265Z INFO 02-11 19:18:38 [parallel_state.py:1212] world_size=32 rank=0 local_rank=0 distributed_init_method=tcp://10.0.0.163:49785 backend=hccl
2026-02-11T19:18:38.2708745Z INFO 02-11 19:18:38 [parallel_state.py:1212] world_size=32 rank=8 local_rank=0 distributed_init_method=tcp://10.0.0.163:49785 backend=hccl
2026-02-11T19:18:42.3083255Z 2026-02-11 19:18:42,305 - 282 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-11T19:18:42.3113201Z INFO 02-11 19:18:42 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-11T19:18:43.0921584Z 2026-02-11 19:18:43,089 - 284 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-11T19:18:43.0957395Z INFO 02-11 19:18:43 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-11T19:18:43.6827906Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-11T19:18:43.6835389Z   warnings.warn(
2026-02-11T19:18:44.4536887Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-11T19:18:44.4543618Z   warnings.warn(
2026-02-11T19:18:45.4348926Z INFO 02-11 19:18:45 [ascend_config.py:412] Dynamic EPLB is False
2026-02-11T19:18:45.4356505Z INFO 02-11 19:18:45 [ascend_config.py:413] The number of redundant experts is 0
2026-02-11T19:18:45.4368231Z INFO 02-11 19:18:45 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-11T19:18:45.8748243Z INFO 02-11 19:18:45 [parallel_state.py:1212] world_size=32 rank=1 local_rank=1 distributed_init_method=tcp://10.0.0.163:49785 backend=hccl
2026-02-11T19:18:46.1816819Z INFO 02-11 19:18:46 [ascend_config.py:412] Dynamic EPLB is False
2026-02-11T19:18:46.1825359Z INFO 02-11 19:18:46 [ascend_config.py:413] The number of redundant experts is 0
2026-02-11T19:18:46.1835511Z INFO 02-11 19:18:46 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-11T19:18:46.6184403Z INFO 02-11 19:18:46 [parallel_state.py:1212] world_size=32 rank=9 local_rank=1 distributed_init_method=tcp://10.0.0.163:49785 backend=hccl
2026-02-11T19:18:47.0820130Z INFO 02-11 19:18:47 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-11T19:18:47.0829043Z INFO 02-11 19:18:47 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-11T19:18:47.0837240Z INFO 02-11 19:18:47 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-11T19:18:47.0893683Z INFO 02-11 19:18:47 [__init__.py:217] Platform plugin ascend is activated
2026-02-11T19:18:47.4660644Z INFO 02-11 19:18:47 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-11T19:18:47.4668535Z INFO 02-11 19:18:47 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-11T19:18:47.4677350Z INFO 02-11 19:18:47 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-11T19:18:47.4732664Z INFO 02-11 19:18:47 [__init__.py:217] Platform plugin ascend is activated
2026-02-11T19:18:52.1118851Z 2026-02-11 19:18:52,109 - 376 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-11T19:18:52.1151901Z INFO 02-11 19:18:52 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-11T19:18:52.4081391Z 2026-02-11 19:18:52,406 - 379 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-11T19:18:52.4117450Z INFO 02-11 19:18:52 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-11T19:18:53.4755207Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-11T19:18:53.4762599Z   warnings.warn(
2026-02-11T19:18:53.6936899Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-11T19:18:53.6943697Z   warnings.warn(
2026-02-11T19:18:55.4836159Z INFO 02-11 19:18:55 [ascend_config.py:412] Dynamic EPLB is False
2026-02-11T19:18:55.4844214Z INFO 02-11 19:18:55 [ascend_config.py:413] The number of redundant experts is 0
2026-02-11T19:18:55.4854610Z INFO 02-11 19:18:55 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-11T19:18:55.6072900Z INFO 02-11 19:18:55 [ascend_config.py:412] Dynamic EPLB is False
2026-02-11T19:18:55.6081651Z INFO 02-11 19:18:55 [ascend_config.py:413] The number of redundant experts is 0
2026-02-11T19:18:55.6093524Z INFO 02-11 19:18:55 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-11T19:18:55.9134720Z INFO 02-11 19:18:55 [parallel_state.py:1212] world_size=32 rank=10 local_rank=2 distributed_init_method=tcp://10.0.0.163:49785 backend=hccl
2026-02-11T19:18:56.0360612Z INFO 02-11 19:18:56 [parallel_state.py:1212] world_size=32 rank=2 local_rank=2 distributed_init_method=tcp://10.0.0.163:49785 backend=hccl
2026-02-11T19:18:56.6852537Z INFO 02-11 19:18:56 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-11T19:18:56.6860327Z INFO 02-11 19:18:56 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-11T19:18:56.6869583Z INFO 02-11 19:18:56 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-11T19:18:56.6927423Z INFO 02-11 19:18:56 [__init__.py:217] Platform plugin ascend is activated
2026-02-11T19:18:56.7082806Z INFO 02-11 19:18:56 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-11T19:18:56.7092327Z INFO 02-11 19:18:56 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-11T19:18:56.7101950Z INFO 02-11 19:18:56 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-11T19:18:56.7200239Z INFO 02-11 19:18:56 [__init__.py:217] Platform plugin ascend is activated
2026-02-11T19:19:01.7514447Z 2026-02-11 19:19:01,749 - 483 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-11T19:19:01.7566191Z INFO 02-11 19:19:01 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-11T19:19:01.8875505Z 2026-02-11 19:19:01,885 - 480 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-11T19:19:01.8935263Z INFO 02-11 19:19:01 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-11T19:19:03.1557795Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-11T19:19:03.1565665Z   warnings.warn(
2026-02-11T19:19:03.3825238Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-11T19:19:03.3832257Z   warnings.warn(
2026-02-11T19:19:04.9044107Z INFO 02-11 19:19:04 [ascend_config.py:412] Dynamic EPLB is False
2026-02-11T19:19:04.9051850Z INFO 02-11 19:19:04 [ascend_config.py:413] The number of redundant experts is 0
2026-02-11T19:19:04.9062551Z INFO 02-11 19:19:04 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-11T19:19:05.1380271Z INFO 02-11 19:19:05 [ascend_config.py:412] Dynamic EPLB is False
2026-02-11T19:19:05.1406553Z INFO 02-11 19:19:05 [ascend_config.py:413] The number of redundant experts is 0
2026-02-11T19:19:05.1417300Z INFO 02-11 19:19:05 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-11T19:19:05.3419529Z INFO 02-11 19:19:05 [parallel_state.py:1212] world_size=32 rank=11 local_rank=3 distributed_init_method=tcp://10.0.0.163:49785 backend=hccl
2026-02-11T19:19:05.5967605Z INFO 02-11 19:19:05 [parallel_state.py:1212] world_size=32 rank=3 local_rank=3 distributed_init_method=tcp://10.0.0.163:49785 backend=hccl
2026-02-11T19:19:06.2471673Z INFO 02-11 19:19:06 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-11T19:19:06.2479584Z INFO 02-11 19:19:06 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-11T19:19:06.2489462Z INFO 02-11 19:19:06 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-11T19:19:06.2604066Z INFO 02-11 19:19:06 [__init__.py:217] Platform plugin ascend is activated
2026-02-11T19:19:06.5351360Z INFO 02-11 19:19:06 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-11T19:19:06.5359383Z INFO 02-11 19:19:06 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-11T19:19:06.5370983Z INFO 02-11 19:19:06 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-11T19:19:06.5434574Z INFO 02-11 19:19:06 [__init__.py:217] Platform plugin ascend is activated
2026-02-11T19:19:11.2790786Z 2026-02-11 19:19:11,276 - 584 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-11T19:19:11.2823129Z INFO 02-11 19:19:11 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-11T19:19:11.7324978Z 2026-02-11 19:19:11,730 - 586 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-11T19:19:11.7358655Z INFO 02-11 19:19:11 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-11T19:19:12.6349487Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-11T19:19:12.6356139Z   warnings.warn(
2026-02-11T19:19:13.0451310Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-11T19:19:13.0457913Z   warnings.warn(
2026-02-11T19:19:14.3971499Z INFO 02-11 19:19:14 [ascend_config.py:412] Dynamic EPLB is False
2026-02-11T19:19:14.3979473Z INFO 02-11 19:19:14 [ascend_config.py:413] The number of redundant experts is 0
2026-02-11T19:19:14.3990292Z INFO 02-11 19:19:14 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-11T19:19:14.7943789Z INFO 02-11 19:19:14 [ascend_config.py:412] Dynamic EPLB is False
2026-02-11T19:19:14.7951909Z INFO 02-11 19:19:14 [ascend_config.py:413] The number of redundant experts is 0
2026-02-11T19:19:14.7962084Z INFO 02-11 19:19:14 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-11T19:19:14.8410147Z INFO 02-11 19:19:14 [parallel_state.py:1212] world_size=32 rank=12 local_rank=4 distributed_init_method=tcp://10.0.0.163:49785 backend=hccl
2026-02-11T19:19:15.2188149Z INFO 02-11 19:19:15 [parallel_state.py:1212] world_size=32 rank=4 local_rank=4 distributed_init_method=tcp://10.0.0.163:49785 backend=hccl
2026-02-11T19:19:15.8545231Z INFO 02-11 19:19:15 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-11T19:19:15.8553064Z INFO 02-11 19:19:15 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-11T19:19:15.8563606Z INFO 02-11 19:19:15 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-11T19:19:15.8614893Z INFO 02-11 19:19:15 [__init__.py:217] Platform plugin ascend is activated
2026-02-11T19:19:16.2038832Z INFO 02-11 19:19:16 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-11T19:19:16.2061724Z INFO 02-11 19:19:16 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-11T19:19:16.2094803Z INFO 02-11 19:19:16 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-11T19:19:16.2111671Z INFO 02-11 19:19:16 [__init__.py:217] Platform plugin ascend is activated
2026-02-11T19:19:20.9287814Z 2026-02-11 19:19:20,926 - 688 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-11T19:19:20.9319438Z INFO 02-11 19:19:20 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-11T19:19:21.2308448Z 2026-02-11 19:19:21,228 - 691 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-11T19:19:21.2342684Z INFO 02-11 19:19:21 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-11T19:19:22.2089187Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-11T19:19:22.2095064Z   warnings.warn(
2026-02-11T19:19:22.6266883Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-11T19:19:22.6273142Z   warnings.warn(
2026-02-11T19:19:23.9501720Z INFO 02-11 19:19:23 [ascend_config.py:412] Dynamic EPLB is False
2026-02-11T19:19:23.9510866Z INFO 02-11 19:19:23 [ascend_config.py:413] The number of redundant experts is 0
2026-02-11T19:19:23.9521474Z INFO 02-11 19:19:23 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-11T19:19:24.3897107Z INFO 02-11 19:19:24 [parallel_state.py:1212] world_size=32 rank=13 local_rank=5 distributed_init_method=tcp://10.0.0.163:49785 backend=hccl
2026-02-11T19:19:24.3944938Z INFO 02-11 19:19:24 [ascend_config.py:412] Dynamic EPLB is False
2026-02-11T19:19:24.3953972Z INFO 02-11 19:19:24 [ascend_config.py:413] The number of redundant experts is 0
2026-02-11T19:19:24.3964046Z INFO 02-11 19:19:24 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-11T19:19:24.8297225Z INFO 02-11 19:19:24 [parallel_state.py:1212] world_size=32 rank=5 local_rank=5 distributed_init_method=tcp://10.0.0.163:49785 backend=hccl
2026-02-11T19:19:25.4028565Z INFO 02-11 19:19:25 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-11T19:19:25.4034959Z INFO 02-11 19:19:25 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-11T19:19:25.4045451Z INFO 02-11 19:19:25 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-11T19:19:25.4104699Z INFO 02-11 19:19:25 [__init__.py:217] Platform plugin ascend is activated
2026-02-11T19:19:25.8102142Z INFO 02-11 19:19:25 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-11T19:19:25.8108601Z INFO 02-11 19:19:25 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-11T19:19:25.8118312Z INFO 02-11 19:19:25 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-11T19:19:25.8186625Z INFO 02-11 19:19:25 [__init__.py:217] Platform plugin ascend is activated
2026-02-11T19:19:30.4347624Z 2026-02-11 19:19:30,432 - 792 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-11T19:19:30.4379408Z INFO 02-11 19:19:30 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-11T19:19:30.8588431Z 2026-02-11 19:19:30,856 - 795 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-11T19:19:30.8619724Z INFO 02-11 19:19:30 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-11T19:19:31.8254788Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-11T19:19:31.8261181Z   warnings.warn(
2026-02-11T19:19:32.1619922Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-11T19:19:32.1626692Z   warnings.warn(
2026-02-11T19:19:33.6997306Z INFO 02-11 19:19:33 [ascend_config.py:412] Dynamic EPLB is False
2026-02-11T19:19:33.7005528Z INFO 02-11 19:19:33 [ascend_config.py:413] The number of redundant experts is 0
2026-02-11T19:19:33.7016738Z INFO 02-11 19:19:33 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-11T19:19:33.9446180Z INFO 02-11 19:19:33 [ascend_config.py:412] Dynamic EPLB is False
2026-02-11T19:19:33.9453946Z INFO 02-11 19:19:33 [ascend_config.py:413] The number of redundant experts is 0
2026-02-11T19:19:33.9464377Z INFO 02-11 19:19:33 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-11T19:19:34.1355553Z INFO 02-11 19:19:34 [parallel_state.py:1212] world_size=32 rank=14 local_rank=6 distributed_init_method=tcp://10.0.0.163:49785 backend=hccl
2026-02-11T19:19:34.3772580Z INFO 02-11 19:19:34 [parallel_state.py:1212] world_size=32 rank=6 local_rank=6 distributed_init_method=tcp://10.0.0.163:49785 backend=hccl
2026-02-11T19:19:34.8774612Z INFO 02-11 19:19:34 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-11T19:19:34.8781244Z INFO 02-11 19:19:34 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-11T19:19:34.8792289Z INFO 02-11 19:19:34 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-11T19:19:34.8849845Z INFO 02-11 19:19:34 [__init__.py:217] Platform plugin ascend is activated
2026-02-11T19:19:35.5134483Z INFO 02-11 19:19:35 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-11T19:19:35.5143081Z INFO 02-11 19:19:35 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-11T19:19:35.5151973Z INFO 02-11 19:19:35 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-11T19:19:35.5210812Z INFO 02-11 19:19:35 [__init__.py:217] Platform plugin ascend is activated
2026-02-11T19:19:40.0650082Z 2026-02-11 19:19:40,062 - 896 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-11T19:19:40.0683231Z INFO 02-11 19:19:40 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-11T19:19:40.8198888Z 2026-02-11 19:19:40,817 - 899 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-11T19:19:40.8232148Z INFO 02-11 19:19:40 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-11T19:19:41.3533180Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-11T19:19:41.3539898Z   warnings.warn(
2026-02-11T19:19:42.1448828Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-11T19:19:42.1454494Z   warnings.warn(
2026-02-11T19:19:43.0464006Z INFO 02-11 19:19:43 [ascend_config.py:412] Dynamic EPLB is False
2026-02-11T19:19:43.0472336Z INFO 02-11 19:19:43 [ascend_config.py:413] The number of redundant experts is 0
2026-02-11T19:19:43.0483407Z INFO 02-11 19:19:43 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-11T19:19:43.4833813Z INFO 02-11 19:19:43 [parallel_state.py:1212] world_size=32 rank=15 local_rank=7 distributed_init_method=tcp://10.0.0.163:49785 backend=hccl
2026-02-11T19:19:43.8595762Z INFO 02-11 19:19:43 [ascend_config.py:412] Dynamic EPLB is False
2026-02-11T19:19:43.8605823Z INFO 02-11 19:19:43 [ascend_config.py:413] The number of redundant experts is 0
2026-02-11T19:19:43.8618286Z INFO 02-11 19:19:43 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-11T19:19:44.2834192Z INFO 02-11 19:19:44 [parallel_state.py:1212] world_size=32 rank=7 local_rank=7 distributed_init_method=tcp://10.0.0.163:49785 backend=hccl
2026-02-11T19:19:44.3277324Z [Gloo] Rank 0 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-11T19:19:44.3308939Z [Gloo] Rank 3 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-11T19:19:44.3319130Z [Gloo] Rank 2 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-11T19:19:44.3329876Z [Gloo] Rank 4 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-11T19:19:44.3339915Z [Gloo] Rank 5 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-11T19:19:44.3350101Z [Gloo] Rank 7 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-11T19:19:44.3848408Z [Gloo] Rank 1 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-11T19:19:44.4084134Z [Gloo] Rank 8 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-11T19:19:44.4102312Z [Gloo] Rank 6 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-11T19:19:44.4124861Z [Gloo] Rank 11 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-11T19:19:44.4134079Z [Gloo] Rank 10 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-11T19:19:44.4143348Z [Gloo] Rank 9 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-11T19:19:44.4153035Z [Gloo] Rank 12 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-11T19:19:44.4163049Z [Gloo] Rank 15 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-11T19:19:44.4172864Z [Gloo] Rank 13 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-11T19:19:44.4181907Z [Gloo] Rank 14 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-11T19:19:44.4819881Z [Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-11T19:19:44.4843405Z [Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-11T19:19:44.4852664Z [Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-11T19:19:44.4863273Z [Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-11T19:19:44.4874314Z [Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-11T19:19:44.4883205Z [Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-11T19:19:44.4893320Z [Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-11T19:19:44.4904555Z [Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-11T19:19:44.4913820Z [Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-11T19:19:44.4923772Z [Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-11T19:19:44.4933100Z [Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-11T19:19:44.4942894Z [Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-11T19:19:44.4953021Z [Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-11T19:19:44.4964020Z [Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-11T19:19:44.4974185Z [Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-11T19:19:44.4983606Z [Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-11T19:19:44.4993449Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-11T19:19:44.5002859Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-11T19:19:44.5012757Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-11T19:19:44.5023172Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-11T19:19:44.5033026Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-11T19:19:44.5042757Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-11T19:19:44.5053038Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-11T19:19:44.5062800Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-11T19:19:44.5073267Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-11T19:19:44.5084351Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-11T19:19:44.5094103Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-11T19:19:44.5103774Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-11T19:19:44.5114299Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-11T19:19:44.5124245Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-11T19:19:44.5135016Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-11T19:19:44.5143830Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-11T19:19:44.5153471Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-11T19:19:44.5164578Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-11T19:19:44.5174250Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-11T19:19:44.5183179Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-11T19:19:44.5192090Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-11T19:19:44.5202318Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-11T19:19:44.5212412Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-11T19:19:44.5221796Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-11T19:19:44.5837651Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-11T19:19:44.5864587Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-11T19:19:44.5874418Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-11T19:19:44.5883594Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-11T19:19:44.5892571Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-11T19:19:44.5902159Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-11T19:19:44.5910857Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-11T19:19:44.5920761Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-11T19:19:44.5930240Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-11T19:19:44.5941477Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-11T19:19:44.5949816Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-11T19:19:44.5958906Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-11T19:19:44.5968541Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-11T19:19:44.5977489Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-11T19:19:44.5986510Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-11T19:19:44.5996147Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-11T19:19:44.6007030Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-11T19:19:44.6016449Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-11T19:19:44.6025363Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-11T19:19:44.6034373Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-11T19:19:44.6044287Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-11T19:19:44.6054061Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-11T19:19:44.6063490Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-11T19:19:44.6071600Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-11T19:19:44.6081308Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-11T19:19:44.6090703Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-11T19:19:44.6101570Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-11T19:19:44.6110852Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-11T19:19:44.6120179Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-11T19:19:44.6129987Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-11T19:19:44.6138520Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-11T19:19:44.6148748Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-11T19:19:44.6158810Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-11T19:19:44.6168632Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-11T19:19:44.6178035Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-11T19:19:44.6187248Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-11T19:19:44.6196399Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-11T19:19:44.6206071Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-11T19:19:44.6215515Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-11T19:19:44.6224580Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-11T19:19:44.6352911Z [Gloo] Rank 0 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-11T19:19:44.6371138Z INFO 02-11 19:19:44 [parallel_state.py:1423] rank 0 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
2026-02-11T19:19:44.7074522Z [Gloo] Rank 1 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-11T19:19:44.7093685Z INFO 02-11 19:19:44 [parallel_state.py:1423] rank 1 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 1, EP rank 1
2026-02-11T19:19:44.7190713Z [Gloo] Rank 2 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-11T19:19:44.7208113Z INFO 02-11 19:19:44 [parallel_state.py:1423] rank 2 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 2, EP rank 2
2026-02-11T19:19:44.7217869Z [Gloo] Rank 10 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-11T19:19:44.7229823Z INFO 02-11 19:19:44 [parallel_state.py:1423] rank 10 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 2, EP rank 10
2026-02-11T19:19:44.7765559Z [Gloo] Rank 3 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-11T19:19:44.7774375Z [Gloo] Rank 4 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-11T19:19:44.7788562Z [Gloo] Rank 6 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-11T19:19:44.7801713Z [Gloo] Rank 5 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-11T19:19:44.7813036Z [Gloo] Rank 7 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-11T19:19:44.7823444Z [Gloo] Rank 8 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-11T19:19:44.7834602Z [Gloo] Rank 11 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-11T19:19:44.7847699Z [Gloo] Rank 12 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-11T19:19:44.7859608Z INFO 02-11 19:19:44 [parallel_state.py:1423] rank 4 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 4, EP rank 4
2026-02-11T19:19:44.7869503Z INFO 02-11 19:19:44 [parallel_state.py:1423] rank 3 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 3, EP rank 3
2026-02-11T19:19:44.7879614Z [Gloo] Rank 14 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-11T19:19:44.7890431Z [Gloo] Rank 13 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-11T19:19:44.7900595Z [Gloo] Rank 15 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-11T19:19:44.7910545Z INFO 02-11 19:19:44 [parallel_state.py:1423] rank 6 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 6, EP rank 6
2026-02-11T19:19:44.7920682Z INFO 02-11 19:19:44 [parallel_state.py:1423] rank 7 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 7, EP rank 7
2026-02-11T19:19:44.7930458Z INFO 02-11 19:19:44 [parallel_state.py:1423] rank 5 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 5, EP rank 5
2026-02-11T19:19:44.7939619Z [Gloo] Rank 9 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-11T19:19:44.7949391Z INFO 02-11 19:19:44 [parallel_state.py:1423] rank 12 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 4, EP rank 12
2026-02-11T19:19:44.7958801Z INFO 02-11 19:19:44 [parallel_state.py:1423] rank 8 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 0, EP rank 8
2026-02-11T19:19:44.7969417Z INFO 02-11 19:19:44 [parallel_state.py:1423] rank 11 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 3, EP rank 11
2026-02-11T19:19:44.7979563Z INFO 02-11 19:19:44 [parallel_state.py:1423] rank 15 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 7, EP rank 15
2026-02-11T19:19:44.7989999Z INFO 02-11 19:19:44 [parallel_state.py:1423] rank 14 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 6, EP rank 14
2026-02-11T19:19:44.8000886Z INFO 02-11 19:19:44 [parallel_state.py:1423] rank 13 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 5, EP rank 13
2026-02-11T19:19:44.8010463Z INFO 02-11 19:19:44 [parallel_state.py:1423] rank 9 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 1, EP rank 9
2026-02-11T19:19:44.8150823Z [Gloo] Rank 0 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-11T19:19:44.8170519Z [Gloo] Rank 1 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-11T19:19:44.8180365Z [Gloo] Rank 2 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-11T19:19:44.8189390Z [Gloo] Rank 3 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-11T19:19:44.8198765Z [Gloo] Rank 4 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-11T19:19:44.8208497Z [Gloo] Rank 5 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-11T19:19:44.8217846Z [Gloo] Rank 6 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-11T19:19:44.8227939Z [Gloo] Rank 7 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-11T19:19:44.8237331Z [Gloo] Rank 8 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-11T19:19:44.8247227Z [Gloo] Rank 9 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-11T19:19:44.8256009Z [Gloo] Rank 11 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-11T19:19:44.8281898Z [Gloo] Rank 10 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-11T19:19:44.8283753Z [Gloo] Rank 12 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-11T19:19:44.8287216Z [Gloo] Rank 13 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-11T19:19:44.8295334Z [Gloo] Rank 14 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-11T19:19:44.8304700Z [Gloo] Rank 15 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-11T19:19:44.8314863Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-11T19:19:44.8325449Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-11T19:19:44.8334852Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-11T19:19:44.8343162Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-11T19:19:44.8352888Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-11T19:19:44.8363316Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-11T19:19:44.8372561Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-11T19:19:44.8381804Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-11T19:19:44.8391831Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-11T19:19:44.8403640Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-11T19:19:44.8411203Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-11T19:19:44.8421029Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-11T19:19:44.8431072Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-11T19:19:44.8441579Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-11T19:19:44.8451806Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-11T19:19:44.8461528Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-11T19:19:44.9690217Z WARNING 02-11 19:19:44 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-11T19:19:44.9711910Z WARNING 02-11 19:19:44 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-11T19:19:44.9721507Z WARNING 02-11 19:19:44 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-11T19:19:44.9764547Z WARNING 02-11 19:19:44 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-11T19:19:44.9774938Z WARNING 02-11 19:19:44 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-11T19:19:44.9784279Z WARNING 02-11 19:19:44 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-11T19:19:44.9793867Z WARNING 02-11 19:19:44 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-11T19:19:44.9819394Z WARNING 02-11 19:19:44 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-11T19:19:44.9829382Z WARNING 02-11 19:19:44 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-11T19:19:44.9838698Z WARNING 02-11 19:19:44 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-11T19:19:44.9849554Z WARNING 02-11 19:19:44 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-11T19:19:44.9875474Z WARNING 02-11 19:19:44 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-11T19:19:44.9888370Z WARNING 02-11 19:19:44 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-11T19:19:44.9898620Z WARNING 02-11 19:19:44 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-11T19:19:44.9908688Z WARNING 02-11 19:19:44 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-11T19:19:44.9919280Z WARNING 02-11 19:19:44 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-11T19:19:45.0212601Z WARNING 02-11 19:19:45 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-11T19:19:45.0221959Z WARNING 02-11 19:19:45 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-11T19:19:45.0231610Z WARNING 02-11 19:19:45 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-11T19:19:45.0241375Z WARNING 02-11 19:19:45 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-11T19:19:45.0251638Z WARNING 02-11 19:19:45 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-11T19:19:45.0261944Z WARNING 02-11 19:19:45 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-11T19:19:45.0270804Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m INFO 02-11 19:19:45 [model_runner_v1.py:2306] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-11T19:19:45.0281814Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m INFO 02-11 19:19:45 [model_runner_v1.py:2306] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-11T19:19:45.0291093Z WARNING 02-11 19:19:45 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-11T19:19:45.0302158Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m INFO 02-11 19:19:45 [model_runner_v1.py:2306] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-11T19:19:45.0310098Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m INFO 02-11 19:19:45 [model_runner_v1.py:2306] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-11T19:19:45.0319860Z WARNING 02-11 19:19:45 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-11T19:19:45.0329483Z WARNING 02-11 19:19:45 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-11T19:19:45.0339654Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m INFO 02-11 19:19:45 [model_runner_v1.py:2306] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-11T19:19:45.0349317Z WARNING 02-11 19:19:45 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-11T19:19:45.0358327Z WARNING 02-11 19:19:45 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-11T19:19:45.0368241Z WARNING 02-11 19:19:45 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-11T19:19:45.0378030Z WARNING 02-11 19:19:45 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-11T19:19:45.0387079Z WARNING 02-11 19:19:45 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-11T19:19:45.0396394Z WARNING 02-11 19:19:45 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-11T19:19:45.0406783Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m INFO 02-11 19:19:45 [model_runner_v1.py:2306] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-11T19:19:45.0416207Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m INFO 02-11 19:19:45 [model_runner_v1.py:2306] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-11T19:19:45.0426397Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m INFO 02-11 19:19:45 [model_runner_v1.py:2306] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-11T19:19:45.0436113Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m INFO 02-11 19:19:45 [model_runner_v1.py:2306] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-11T19:19:45.0446121Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m INFO 02-11 19:19:45 [model_runner_v1.py:2306] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-11T19:19:45.0455856Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m INFO 02-11 19:19:45 [model_runner_v1.py:2306] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-11T19:19:45.0465653Z WARNING 02-11 19:19:45 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-11T19:19:45.0475671Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m INFO 02-11 19:19:45 [model_runner_v1.py:2306] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-11T19:19:45.0484932Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m INFO 02-11 19:19:45 [model_runner_v1.py:2306] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-11T19:19:45.0494792Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m INFO 02-11 19:19:45 [model_runner_v1.py:2306] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-11T19:19:45.0504128Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m INFO 02-11 19:19:45 [model_runner_v1.py:2306] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-11T19:19:45.0883371Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m INFO 02-11 19:19:45 [model_runner_v1.py:2306] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-11T19:19:45.3727295Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m [2026-02-11 19:19:45] INFO modelslim_config.py:281: Using the vLLM Ascend modelslim Quantization now!
2026-02-11T19:19:45.3760100Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m [2026-02-11 19:19:45] INFO modelslim_config.py:281: Using the vLLM Ascend modelslim Quantization now!
2026-02-11T19:19:45.4054806Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m [2026-02-11 19:19:45] INFO modelslim_config.py:281: Using the vLLM Ascend modelslim Quantization now!
2026-02-11T19:19:45.4171870Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m [2026-02-11 19:19:45] INFO modelslim_config.py:281: Using the vLLM Ascend modelslim Quantization now!
2026-02-11T19:19:45.4196611Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m [2026-02-11 19:19:45] INFO modelslim_config.py:281: Using the vLLM Ascend modelslim Quantization now!
2026-02-11T19:19:45.4295364Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m [2026-02-11 19:19:45] INFO modelslim_config.py:281: Using the vLLM Ascend modelslim Quantization now!
2026-02-11T19:19:45.4834468Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m [2026-02-11 19:19:45] INFO modelslim_config.py:281: Using the vLLM Ascend modelslim Quantization now!
2026-02-11T19:19:45.5113382Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m [2026-02-11 19:19:45] INFO modelslim_config.py:281: Using the vLLM Ascend modelslim Quantization now!
2026-02-11T19:19:45.5510522Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m INFO 02-11 19:19:45 [layer.py:475] [EP Rank 13/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->104, 1->105, 2->106, 3->107, 4->108, 5->109, 6->110, 7->111.
2026-02-11T19:19:45.5520261Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m INFO 02-11 19:19:45 [layer.py:475] [EP Rank 4/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->32, 1->33, 2->34, 3->35, 4->36, 5->37, 6->38, 7->39.
2026-02-11T19:19:45.5535731Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m INFO 02-11 19:19:45 [layer.py:475] [EP Rank 15/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->120, 1->121, 2->122, 3->123, 4->124, 5->125, 6->126, 7->127.
2026-02-11T19:19:45.5546274Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m INFO 02-11 19:19:45 [layer.py:475] [EP Rank 10/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->80, 1->81, 2->82, 3->83, 4->84, 5->85, 6->86, 7->87.
2026-02-11T19:19:45.5763490Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m [2026-02-11 19:19:45] INFO modelslim_config.py:281: Using the vLLM Ascend modelslim Quantization now!
2026-02-11T19:19:45.5796317Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m [2026-02-11 19:19:45] INFO modelslim_config.py:281: Using the vLLM Ascend modelslim Quantization now!
2026-02-11T19:19:45.5872311Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m INFO 02-11 19:19:45 [layer.py:475] [EP Rank 8/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->64, 1->65, 2->66, 3->67, 4->68, 5->69, 6->70, 7->71.
2026-02-11T19:19:45.5909898Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m INFO 02-11 19:19:45 [layer.py:475] [EP Rank 9/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->72, 1->73, 2->74, 3->75, 4->76, 5->77, 6->78, 7->79.
2026-02-11T19:19:45.6058634Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m INFO 02-11 19:19:45 [layer.py:475] [EP Rank 12/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->96, 1->97, 2->98, 3->99, 4->100, 5->101, 6->102, 7->103.
2026-02-11T19:19:45.6174054Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m [2026-02-11 19:19:45] INFO modelslim_config.py:281: Using the vLLM Ascend modelslim Quantization now!
2026-02-11T19:19:45.6214153Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m [2026-02-11 19:19:45] INFO modelslim_config.py:281: Using the vLLM Ascend modelslim Quantization now!
2026-02-11T19:19:45.6688200Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m INFO 02-11 19:19:45 [layer.py:475] [EP Rank 0/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->0, 1->1, 2->2, 3->3, 4->4, 5->5, 6->6, 7->7.
2026-02-11T19:19:45.6942289Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m INFO 02-11 19:19:45 [layer.py:475] [EP Rank 2/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->16, 1->17, 2->18, 3->19, 4->20, 5->21, 6->22, 7->23.
2026-02-11T19:19:45.6967935Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m INFO 02-11 19:19:45 [layer.py:475] [EP Rank 3/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->24, 1->25, 2->26, 3->27, 4->28, 5->29, 6->30, 7->31.
2026-02-11T19:19:45.7180590Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m [2026-02-11 19:19:45] INFO modelslim_config.py:281: Using the vLLM Ascend modelslim Quantization now!
2026-02-11T19:19:45.7257882Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m [2026-02-11 19:19:45] INFO modelslim_config.py:281: Using the vLLM Ascend modelslim Quantization now!
2026-02-11T19:19:45.7336728Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m INFO 02-11 19:19:45 [layer.py:475] [EP Rank 7/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->56, 1->57, 2->58, 3->59, 4->60, 5->61, 6->62, 7->63.
2026-02-11T19:19:45.7468873Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m INFO 02-11 19:19:45 [layer.py:475] [EP Rank 14/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->112, 1->113, 2->114, 3->115, 4->116, 5->117, 6->118, 7->119.
2026-02-11T19:19:45.7489105Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m [2026-02-11 19:19:45] INFO modelslim_config.py:281: Using the vLLM Ascend modelslim Quantization now!
2026-02-11T19:19:45.8365051Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m INFO 02-11 19:19:45 [layer.py:475] [EP Rank 5/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->40, 1->41, 2->42, 3->43, 4->44, 5->45, 6->46, 7->47.
2026-02-11T19:19:45.8593016Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m INFO 02-11 19:19:45 [layer.py:475] [EP Rank 11/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->88, 1->89, 2->90, 3->91, 4->92, 5->93, 6->94, 7->95.
2026-02-11T19:19:45.8631882Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m INFO 02-11 19:19:45 [layer.py:475] [EP Rank 6/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->48, 1->49, 2->50, 3->51, 4->52, 5->53, 6->54, 7->55.
2026-02-11T19:19:46.1514508Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m [2026-02-11 19:19:46] INFO modelslim_config.py:281: Using the vLLM Ascend modelslim Quantization now!
2026-02-11T19:19:46.2627330Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m INFO 02-11 19:19:46 [layer.py:475] [EP Rank 1/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->8, 1->9, 2->10, 3->11, 4->12, 5->13, 6->14, 7->15.
2026-02-11T19:19:47.6919416Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-11T19:19:47.6926307Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-11T19:19:47.6935246Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-11T19:19:47.6945257Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-11T19:19:47.6954192Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.6965026Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-11T19:19:47.6974250Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-11T19:19:47.6984260Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 404, in load_model
2026-02-11T19:19:47.6993947Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-11T19:19:47.7006219Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2309, in load_model
2026-02-11T19:19:47.7015395Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-11T19:19:47.7025021Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.7035468Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-11T19:19:47.7045350Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     return loader.load_model(
2026-02-11T19:19:47.7054850Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.7064904Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-11T19:19:47.7073715Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     model = initialize_model(
2026-02-11T19:19:47.7083596Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.7094063Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-11T19:19:47.7103441Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-11T19:19:47.7112789Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.7123242Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-11T19:19:47.7132380Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-11T19:19:47.7142357Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-11T19:19:47.7151730Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-11T19:19:47.7160877Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-11T19:19:47.7171555Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-11T19:19:47.7180722Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-11T19:19:47.7189908Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-11T19:19:47.7200744Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-11T19:19:47.7210216Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     + [
2026-02-11T19:19:47.7219261Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]       ^
2026-02-11T19:19:47.7229841Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-11T19:19:47.7239384Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-11T19:19:47.7249157Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.7258946Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-11T19:19:47.7269952Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-11T19:19:47.7278979Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.7288714Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-11T19:19:47.7298230Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-11T19:19:47.7307773Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-11T19:19:47.7318220Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-11T19:19:47.7327872Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-11T19:19:47.7337195Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-11T19:19:47.7347240Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 397, in __init__
2026-02-11T19:19:47.7356127Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-11T19:19:47.7366827Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 158, in __init__
2026-02-11T19:19:47.7376010Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-11T19:19:47.7385803Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-11T19:19:47.7394993Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-11T19:19:47.7405064Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.7415001Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-11T19:19:47.7424301Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-11T19:19:47.7433961Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.7444435Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 414, in get_quant_method
2026-02-11T19:19:47.7454152Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-11T19:19:47.7463760Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.7473272Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 290, in create_scheme_for_layer
2026-02-11T19:19:47.7482772Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     return scheme_cls()
2026-02-11T19:19:47.7492837Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-11T19:19:47.7502500Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-11T19:19:47.7511822Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-11T19:19:47.7521704Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.7532616Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-11T19:19:47.7541930Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772] [ERROR] 2026-02-11-19:19:46 (PID:480, Device:3, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-11T19:19:47.7550939Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772] 
2026-02-11T19:19:47.7560548Z [0;36m(Worker_DP0_TP3_EP3 pid=480)[0;0m INFO 02-11 19:19:47 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-11T19:19:47.7570325Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-11T19:19:47.7579418Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-11T19:19:47.7589192Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-11T19:19:47.7598091Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-11T19:19:47.7607867Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.7617666Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-11T19:19:47.7626345Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-11T19:19:47.7635987Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 404, in load_model
2026-02-11T19:19:47.7646322Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-11T19:19:47.7656077Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2309, in load_model
2026-02-11T19:19:47.7665261Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-11T19:19:47.7674956Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.7684891Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-11T19:19:47.7694566Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     return loader.load_model(
2026-02-11T19:19:47.7704100Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.7714322Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-11T19:19:47.7723278Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     model = initialize_model(
2026-02-11T19:19:47.7732564Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.7742637Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-11T19:19:47.7751970Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-11T19:19:47.7761754Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.7771983Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-11T19:19:47.7780794Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-11T19:19:47.7790108Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-11T19:19:47.7799503Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-11T19:19:47.7809330Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-11T19:19:47.7818394Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-11T19:19:47.7830049Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-11T19:19:47.7842477Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-11T19:19:47.7853047Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-11T19:19:47.7862571Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     + [
2026-02-11T19:19:47.7871695Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]       ^
2026-02-11T19:19:47.7882294Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-11T19:19:47.7892346Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-11T19:19:47.7901544Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.7911570Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-11T19:19:47.7920994Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-11T19:19:47.7930495Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.7939897Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-11T19:19:47.7949630Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-11T19:19:47.7958818Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-11T19:19:47.7968848Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-11T19:19:47.7978634Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-11T19:19:47.7988120Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-11T19:19:47.7997971Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 397, in __init__
2026-02-11T19:19:47.8007622Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-11T19:19:47.8017520Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 158, in __init__
2026-02-11T19:19:47.8026823Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-11T19:19:47.8036945Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-11T19:19:47.8046997Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-11T19:19:47.8056179Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.8066225Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-11T19:19:47.8075328Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-11T19:19:47.8085590Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.8095301Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 414, in get_quant_method
2026-02-11T19:19:47.8104613Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-11T19:19:47.8113894Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.8123893Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 290, in create_scheme_for_layer
2026-02-11T19:19:47.8132997Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     return scheme_cls()
2026-02-11T19:19:47.8142683Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-11T19:19:47.8152765Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-11T19:19:47.8164624Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-11T19:19:47.8173194Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.8184123Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-11T19:19:47.8192737Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772] [ERROR] 2026-02-11-19:19:47 (PID:896, Device:7, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-11T19:19:47.8206840Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772] 
2026-02-11T19:19:47.8254078Z [0;36m(Worker_DP1_TP7_EP15 pid=896)[0;0m INFO 02-11 19:19:47 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-11T19:19:47.8264302Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m INFO 02-11 19:19:47 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-11T19:19:47.8271898Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-11T19:19:47.8282520Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-11T19:19:47.8291746Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-11T19:19:47.8301825Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-11T19:19:47.8310928Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.8321708Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-11T19:19:47.8371176Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-11T19:19:47.8371977Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 404, in load_model
2026-02-11T19:19:47.8372905Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-11T19:19:47.8373741Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2309, in load_model
2026-02-11T19:19:47.8374598Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-11T19:19:47.8379531Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.8389412Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-11T19:19:47.8398601Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     return loader.load_model(
2026-02-11T19:19:47.8408843Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.8418131Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-11T19:19:47.8426435Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     model = initialize_model(
2026-02-11T19:19:47.8436027Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.8446785Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-11T19:19:47.8456334Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-11T19:19:47.8465302Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.8475295Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-11T19:19:47.8485973Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-11T19:19:47.8494770Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-11T19:19:47.8504715Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-11T19:19:47.8514137Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-11T19:19:47.8524345Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-11T19:19:47.8533985Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-11T19:19:47.8543248Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-11T19:19:47.8552645Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-11T19:19:47.8562188Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     + [
2026-02-11T19:19:47.8571209Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]       ^
2026-02-11T19:19:47.8580957Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-11T19:19:47.8590567Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-11T19:19:47.8600442Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.8610750Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-11T19:19:47.8619150Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-11T19:19:47.8628392Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.8638375Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-11T19:19:47.8648174Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-11T19:19:47.8657481Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-11T19:19:47.8667500Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-11T19:19:47.8675850Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-11T19:19:47.8685802Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-11T19:19:47.8695265Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 397, in __init__
2026-02-11T19:19:47.8742126Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-11T19:19:47.8743066Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 158, in __init__
2026-02-11T19:19:47.8743912Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-11T19:19:47.8744726Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-11T19:19:47.8745540Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-11T19:19:47.8751527Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.8761459Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-11T19:19:47.8770709Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-11T19:19:47.8782240Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.8790085Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 414, in get_quant_method
2026-02-11T19:19:47.8799928Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-11T19:19:47.8809828Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.8819033Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 290, in create_scheme_for_layer
2026-02-11T19:19:47.8828515Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     return scheme_cls()
2026-02-11T19:19:47.8838176Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-11T19:19:47.8848284Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-11T19:19:47.8857529Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-11T19:19:47.8867512Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.8877988Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-11T19:19:47.8888733Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772] [ERROR] 2026-02-11-19:19:47 (PID:899, Device:7, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-11T19:19:47.8896085Z [0;36m(Worker_DP0_TP7_EP7 pid=899)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772] 
2026-02-11T19:19:47.8905800Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m INFO 02-11 19:19:47 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-11T19:19:47.8915231Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-11T19:19:47.8925294Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-11T19:19:47.8934697Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-11T19:19:47.8943707Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-11T19:19:47.8952877Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.8963032Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-11T19:19:47.8973018Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-11T19:19:47.8982280Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 404, in load_model
2026-02-11T19:19:47.8991910Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-11T19:19:47.9001836Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2309, in load_model
2026-02-11T19:19:47.9011230Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-11T19:19:47.9020722Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.9029767Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-11T19:19:47.9039161Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     return loader.load_model(
2026-02-11T19:19:47.9049059Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.9059152Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-11T19:19:47.9068452Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     model = initialize_model(
2026-02-11T19:19:47.9078830Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.9090752Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-11T19:19:47.9100650Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-11T19:19:47.9110372Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.9120584Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-11T19:19:47.9130392Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-11T19:19:47.9139980Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-11T19:19:47.9150537Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-11T19:19:47.9160397Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-11T19:19:47.9170677Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-11T19:19:47.9180114Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-11T19:19:47.9189706Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-11T19:19:47.9199939Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-11T19:19:47.9209009Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     + [
2026-02-11T19:19:47.9263258Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]       ^
2026-02-11T19:19:47.9264003Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-11T19:19:47.9264784Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-11T19:19:47.9265516Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.9266318Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-11T19:19:47.9268828Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-11T19:19:47.9278687Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.9288586Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-11T19:19:47.9298054Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-11T19:19:47.9307858Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-11T19:19:47.9318559Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-11T19:19:47.9327819Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-11T19:19:47.9336838Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-11T19:19:47.9346747Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 397, in __init__
2026-02-11T19:19:47.9356676Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-11T19:19:47.9367431Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 158, in __init__
2026-02-11T19:19:47.9377352Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-11T19:19:47.9387143Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-11T19:19:47.9397670Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-11T19:19:47.9407360Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.9417288Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-11T19:19:47.9426908Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-11T19:19:47.9436389Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.9446798Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 414, in get_quant_method
2026-02-11T19:19:47.9457017Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-11T19:19:47.9467032Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.9476632Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 290, in create_scheme_for_layer
2026-02-11T19:19:47.9486539Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     return scheme_cls()
2026-02-11T19:19:47.9496455Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-11T19:19:47.9506015Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-11T19:19:47.9515203Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-11T19:19:47.9526090Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.9535737Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-11T19:19:47.9545654Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772] [ERROR] 2026-02-11-19:19:47 (PID:586, Device:4, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-11T19:19:47.9554367Z [0;36m(Worker_DP0_TP4_EP4 pid=586)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772] 
2026-02-11T19:19:47.9564750Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m INFO 02-11 19:19:47 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-11T19:19:47.9574888Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-11T19:19:47.9584334Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-11T19:19:47.9594863Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-11T19:19:47.9605490Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-11T19:19:47.9614396Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.9624367Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-11T19:19:47.9633497Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-11T19:19:47.9644419Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 404, in load_model
2026-02-11T19:19:47.9653890Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-11T19:19:47.9664074Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2309, in load_model
2026-02-11T19:19:47.9673787Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-11T19:19:47.9684028Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.9693525Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-11T19:19:47.9702441Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     return loader.load_model(
2026-02-11T19:19:47.9712753Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.9783299Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-11T19:19:47.9784144Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     model = initialize_model(
2026-02-11T19:19:47.9784743Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.9785540Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-11T19:19:47.9786404Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-11T19:19:47.9788540Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.9796583Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-11T19:19:47.9808100Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-11T19:19:47.9818514Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-11T19:19:47.9829792Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-11T19:19:47.9840856Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-11T19:19:47.9851568Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-11T19:19:47.9861692Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-11T19:19:47.9871059Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-11T19:19:47.9881064Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-11T19:19:47.9890885Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     + [
2026-02-11T19:19:47.9900378Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]       ^
2026-02-11T19:19:47.9910225Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-11T19:19:47.9919627Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-11T19:19:47.9929331Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.9939743Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-11T19:19:47.9948813Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-11T19:19:47.9958462Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:47.9968455Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-11T19:19:47.9977733Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-11T19:19:47.9987213Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-11T19:19:47.9997218Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-11T19:19:48.0006216Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-11T19:19:48.0015651Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-11T19:19:48.0025827Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 397, in __init__
2026-02-11T19:19:48.0034665Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-11T19:19:48.0045057Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 158, in __init__
2026-02-11T19:19:48.0054148Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-11T19:19:48.0063855Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-11T19:19:48.0073569Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-11T19:19:48.0083179Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.0093865Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-11T19:19:48.0102513Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-11T19:19:48.0111975Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.0127714Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 414, in get_quant_method
2026-02-11T19:19:48.0136613Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-11T19:19:48.0146410Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.0156183Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 290, in create_scheme_for_layer
2026-02-11T19:19:48.0165392Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     return scheme_cls()
2026-02-11T19:19:48.0174364Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-11T19:19:48.0184753Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-11T19:19:48.0193821Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-11T19:19:48.0203831Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.0214523Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-11T19:19:48.0223403Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772] [ERROR] 2026-02-11-19:19:47 (PID:220, Device:0, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-11T19:19:48.0232471Z [0;36m(Worker_DP1_TP0_EP8 pid=220)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772] 
2026-02-11T19:19:48.0243373Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m INFO 02-11 19:19:47 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-11T19:19:48.0251904Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m INFO 02-11 19:19:47 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-11T19:19:48.0262154Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-11T19:19:48.0271114Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-11T19:19:48.0281010Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-11T19:19:48.0290128Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-11T19:19:48.0299596Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.0309335Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-11T19:19:48.0318676Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-11T19:19:48.0328007Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 404, in load_model
2026-02-11T19:19:48.0339936Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-11T19:19:48.0347194Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2309, in load_model
2026-02-11T19:19:48.0356417Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-11T19:19:48.0366203Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.0375512Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-11T19:19:48.0384891Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     return loader.load_model(
2026-02-11T19:19:48.0394396Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.0404722Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-11T19:19:48.0414164Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     model = initialize_model(
2026-02-11T19:19:48.0423626Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.0433551Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-11T19:19:48.0443077Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-11T19:19:48.0452166Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.0462272Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-11T19:19:48.0471603Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-11T19:19:48.0481018Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-11T19:19:48.0490568Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-11T19:19:48.0500019Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-11T19:19:48.0509563Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-11T19:19:48.0520083Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-11T19:19:48.0529400Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-11T19:19:48.0538834Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-11T19:19:48.0548549Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     + [
2026-02-11T19:19:48.0559062Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]       ^
2026-02-11T19:19:48.0568062Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-11T19:19:48.0578018Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-11T19:19:48.0587585Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.0597550Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-11T19:19:48.0607083Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-11T19:19:48.0616818Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.0626029Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-11T19:19:48.0635159Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-11T19:19:48.0644830Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-11T19:19:48.0654684Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-11T19:19:48.0664004Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-11T19:19:48.0673697Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-11T19:19:48.0684028Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 397, in __init__
2026-02-11T19:19:48.0693260Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-11T19:19:48.0702702Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 158, in __init__
2026-02-11T19:19:48.0712199Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-11T19:19:48.0722327Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-11T19:19:48.0731649Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-11T19:19:48.0740918Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.0750659Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-11T19:19:48.0760425Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-11T19:19:48.0770087Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.0780013Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 414, in get_quant_method
2026-02-11T19:19:48.0789356Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-11T19:19:48.0799326Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.0809296Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 290, in create_scheme_for_layer
2026-02-11T19:19:48.0818346Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     return scheme_cls()
2026-02-11T19:19:48.0827359Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-11T19:19:48.0837885Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-11T19:19:48.0847392Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-11T19:19:48.0856705Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.0867179Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-11T19:19:48.0876602Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772] [ERROR] 2026-02-11-19:19:47 (PID:379, Device:2, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-11T19:19:48.0886862Z [0;36m(Worker_DP1_TP2_EP10 pid=379)[0;0m ERROR 02-11 19:19:47 [multiproc_executor.py:772] 
2026-02-11T19:19:48.0896859Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m INFO 02-11 19:19:47 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-11T19:19:48.0906785Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m INFO 02-11 19:19:47 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-11T19:19:48.0920354Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m INFO 02-11 19:19:47 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-11T19:19:48.0930779Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m INFO 02-11 19:19:48 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-11T19:19:48.0940369Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-11T19:19:48.0950118Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-11T19:19:48.0960630Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-11T19:19:48.0970581Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-11T19:19:48.0979576Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.0989395Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-11T19:19:48.0998754Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-11T19:19:48.1008970Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 404, in load_model
2026-02-11T19:19:48.1017894Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-11T19:19:48.1027809Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2309, in load_model
2026-02-11T19:19:48.1036839Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-11T19:19:48.1046741Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.1055986Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-11T19:19:48.1065142Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     return loader.load_model(
2026-02-11T19:19:48.1074432Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.1084670Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-11T19:19:48.1094037Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     model = initialize_model(
2026-02-11T19:19:48.1103546Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.1112721Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-11T19:19:48.1121871Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-11T19:19:48.1132104Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.1141482Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-11T19:19:48.1150584Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-11T19:19:48.1160676Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-11T19:19:48.1170696Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-11T19:19:48.1180036Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-11T19:19:48.1189565Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-11T19:19:48.1199339Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-11T19:19:48.1209078Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-11T19:19:48.1218768Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-11T19:19:48.1227912Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     + [
2026-02-11T19:19:48.1237616Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]       ^
2026-02-11T19:19:48.1247385Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-11T19:19:48.1256952Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-11T19:19:48.1266079Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.1275420Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-11T19:19:48.1284618Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-11T19:19:48.1293707Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.1303540Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-11T19:19:48.1313004Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-11T19:19:48.1322606Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-11T19:19:48.1332236Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-11T19:19:48.1341531Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-11T19:19:48.1350704Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-11T19:19:48.1360914Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 397, in __init__
2026-02-11T19:19:48.1369926Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-11T19:19:48.1379766Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 158, in __init__
2026-02-11T19:19:48.1389137Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-11T19:19:48.1400017Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-11T19:19:48.1409645Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-11T19:19:48.1419374Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.1429042Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-11T19:19:48.1439283Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-11T19:19:48.1448545Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.1458789Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 414, in get_quant_method
2026-02-11T19:19:48.1468123Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-11T19:19:48.1477926Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.1487420Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 290, in create_scheme_for_layer
2026-02-11T19:19:48.1496199Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     return scheme_cls()
2026-02-11T19:19:48.1505753Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-11T19:19:48.1515535Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-11T19:19:48.1525642Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-11T19:19:48.1535097Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.1545585Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-11T19:19:48.1554814Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] [ERROR] 2026-02-11-19:19:47 (PID:221, Device:0, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-11T19:19:48.1563955Z [0;36m(Worker_DP0_TP0_EP0 pid=221)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] 
2026-02-11T19:19:48.2063633Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m INFO 02-11 19:19:48 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-11T19:19:48.2185283Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-11T19:19:48.2194291Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-11T19:19:48.2204336Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-11T19:19:48.2213269Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-11T19:19:48.2222528Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.2231938Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-11T19:19:48.2241284Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-11T19:19:48.2251293Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 404, in load_model
2026-02-11T19:19:48.2260803Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-11T19:19:48.2269984Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2309, in load_model
2026-02-11T19:19:48.2279555Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-11T19:19:48.2289485Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.2299276Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-11T19:19:48.2308554Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     return loader.load_model(
2026-02-11T19:19:48.2317973Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.2327875Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-11T19:19:48.2336739Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     model = initialize_model(
2026-02-11T19:19:48.2345861Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.2355060Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-11T19:19:48.2364834Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-11T19:19:48.2374463Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.2384174Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-11T19:19:48.2392759Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-11T19:19:48.2402475Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-11T19:19:48.2412556Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-11T19:19:48.2421350Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-11T19:19:48.2430727Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-11T19:19:48.2440054Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-11T19:19:48.2457483Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-11T19:19:48.2459715Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-11T19:19:48.2468319Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     + [
2026-02-11T19:19:48.2478076Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]       ^
2026-02-11T19:19:48.2487779Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-11T19:19:48.2497363Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-11T19:19:48.2506080Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.2515782Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-11T19:19:48.2525820Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-11T19:19:48.2535426Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.2545022Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-11T19:19:48.2553658Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-11T19:19:48.2563459Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-11T19:19:48.2573139Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-11T19:19:48.2582531Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-11T19:19:48.2592827Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-11T19:19:48.2602685Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 397, in __init__
2026-02-11T19:19:48.2611629Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-11T19:19:48.2631000Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 158, in __init__
2026-02-11T19:19:48.2632488Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-11T19:19:48.2642614Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-11T19:19:48.2650916Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-11T19:19:48.2659908Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.2670309Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-11T19:19:48.2679567Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-11T19:19:48.2689001Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.2698662Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 414, in get_quant_method
2026-02-11T19:19:48.2709295Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-11T19:19:48.2717943Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.2727907Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 290, in create_scheme_for_layer
2026-02-11T19:19:48.2737156Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     return scheme_cls()
2026-02-11T19:19:48.2746655Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-11T19:19:48.2756757Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-11T19:19:48.2766722Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-11T19:19:48.2776502Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.2787130Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-11T19:19:48.2796898Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] [ERROR] 2026-02-11-19:19:47 (PID:282, Device:1, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-11T19:19:48.2808289Z [0;36m(Worker_DP0_TP1_EP1 pid=282)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] 
2026-02-11T19:19:48.2818304Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m INFO 02-11 19:19:48 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-11T19:19:48.2827646Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m INFO 02-11 19:19:48 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-11T19:19:48.2837134Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m INFO 02-11 19:19:48 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-11T19:19:48.3177020Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m INFO 02-11 19:19:48 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-11T19:19:48.3241525Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-11T19:19:48.3252096Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-11T19:19:48.3261304Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-11T19:19:48.3270354Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-11T19:19:48.3279518Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.3289601Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-11T19:19:48.3298968Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-11T19:19:48.3308666Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 404, in load_model
2026-02-11T19:19:48.3318696Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-11T19:19:48.3328960Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2309, in load_model
2026-02-11T19:19:48.3338033Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-11T19:19:48.3347733Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.3357306Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-11T19:19:48.3366493Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     return loader.load_model(
2026-02-11T19:19:48.3376056Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.3385841Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-11T19:19:48.3395051Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     model = initialize_model(
2026-02-11T19:19:48.3404946Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.3414254Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-11T19:19:48.3423247Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-11T19:19:48.3433025Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.3443153Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-11T19:19:48.3453238Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-11T19:19:48.3461613Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-11T19:19:48.3471738Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-11T19:19:48.3481816Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-11T19:19:48.3491206Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-11T19:19:48.3500486Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-11T19:19:48.3509420Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-11T19:19:48.3519712Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-11T19:19:48.3529381Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     + [
2026-02-11T19:19:48.3538332Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]       ^
2026-02-11T19:19:48.3548343Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-11T19:19:48.3558270Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-11T19:19:48.3567145Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.3577144Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-11T19:19:48.3586590Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-11T19:19:48.3595977Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.3606533Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-11T19:19:48.3615640Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-11T19:19:48.3625060Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-11T19:19:48.3634633Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-11T19:19:48.3644279Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-11T19:19:48.3653424Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-11T19:19:48.3662942Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 397, in __init__
2026-02-11T19:19:48.3671740Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-11T19:19:48.3682225Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 158, in __init__
2026-02-11T19:19:48.3691270Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-11T19:19:48.3701052Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-11T19:19:48.3710290Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-11T19:19:48.3720182Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.3729633Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-11T19:19:48.3739080Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-11T19:19:48.3748266Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.3758640Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 414, in get_quant_method
2026-02-11T19:19:48.3768433Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-11T19:19:48.3778399Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.3787559Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 290, in create_scheme_for_layer
2026-02-11T19:19:48.3797428Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     return scheme_cls()
2026-02-11T19:19:48.3806700Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-11T19:19:48.3816826Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-11T19:19:48.3825837Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-11T19:19:48.3835285Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.3846780Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-11T19:19:48.3856550Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] [ERROR] 2026-02-11-19:19:47 (PID:691, Device:5, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-11T19:19:48.3865848Z [0;36m(Worker_DP0_TP5_EP5 pid=691)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] 
2026-02-11T19:19:48.4930359Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-11T19:19:48.4939639Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-11T19:19:48.4949384Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-11T19:19:48.4959334Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-11T19:19:48.4968825Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.4977949Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-11T19:19:48.4986386Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-11T19:19:48.4996169Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 404, in load_model
2026-02-11T19:19:48.5005882Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-11T19:19:48.5015067Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2309, in load_model
2026-02-11T19:19:48.5023957Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-11T19:19:48.5033543Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.5043369Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-11T19:19:48.5052082Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     return loader.load_model(
2026-02-11T19:19:48.5061241Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.5070503Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-11T19:19:48.5080352Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     model = initialize_model(
2026-02-11T19:19:48.5089808Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.5100054Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-11T19:19:48.5109215Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-11T19:19:48.5118843Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.5128972Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-11T19:19:48.5138087Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-11T19:19:48.5147720Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-11T19:19:48.5157389Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-11T19:19:48.5167285Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-11T19:19:48.5176837Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-11T19:19:48.5186337Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-11T19:19:48.5195618Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-11T19:19:48.5206223Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-11T19:19:48.5215246Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     + [
2026-02-11T19:19:48.5223755Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]       ^
2026-02-11T19:19:48.5233844Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-11T19:19:48.5243186Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-11T19:19:48.5252521Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.5262284Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-11T19:19:48.5271770Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-11T19:19:48.5281592Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.5290897Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-11T19:19:48.5300441Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-11T19:19:48.5309874Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-11T19:19:48.5319818Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-11T19:19:48.5329529Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-11T19:19:48.5339038Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-11T19:19:48.5348439Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 397, in __init__
2026-02-11T19:19:48.5358437Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-11T19:19:48.5368397Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 158, in __init__
2026-02-11T19:19:48.5377614Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-11T19:19:48.5387316Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-11T19:19:48.5397031Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-11T19:19:48.5407081Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.5417776Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-11T19:19:48.5426106Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-11T19:19:48.5435231Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.5445262Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 414, in get_quant_method
2026-02-11T19:19:48.5454737Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-11T19:19:48.5464387Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.5474151Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 290, in create_scheme_for_layer
2026-02-11T19:19:48.5483801Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     return scheme_cls()
2026-02-11T19:19:48.5493118Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-11T19:19:48.5503209Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-11T19:19:48.5513320Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-11T19:19:48.5522213Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.5533836Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-11T19:19:48.5542445Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] [ERROR] 2026-02-11-19:19:47 (PID:376, Device:2, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-11T19:19:48.5551106Z [0;36m(Worker_DP0_TP2_EP2 pid=376)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] 
2026-02-11T19:19:48.5561009Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-11T19:19:48.5570580Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-11T19:19:48.5580370Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-11T19:19:48.5589711Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-11T19:19:48.5599445Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.5609723Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-11T19:19:48.5618521Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-11T19:19:48.5642599Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 404, in load_model
2026-02-11T19:19:48.5643405Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-11T19:19:48.5647399Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2309, in load_model
2026-02-11T19:19:48.5656477Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-11T19:19:48.5665732Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.5678094Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-11T19:19:48.5686668Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     return loader.load_model(
2026-02-11T19:19:48.5694897Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.5704564Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-11T19:19:48.5713648Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     model = initialize_model(
2026-02-11T19:19:48.5723220Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.5733357Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-11T19:19:48.5743197Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-11T19:19:48.5752759Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.5762839Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-11T19:19:48.5772325Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-11T19:19:48.5781733Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-11T19:19:48.5791315Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-11T19:19:48.5800666Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-11T19:19:48.5811125Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-11T19:19:48.5820717Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-11T19:19:48.5830025Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-11T19:19:48.5840151Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-11T19:19:48.5849387Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     + [
2026-02-11T19:19:48.5858721Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]       ^
2026-02-11T19:19:48.5869546Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-11T19:19:48.5878882Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-11T19:19:48.5888725Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.5898746Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-11T19:19:48.5908601Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-11T19:19:48.5921627Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.5932868Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-11T19:19:48.5946427Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-11T19:19:48.5962979Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-11T19:19:48.5973913Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-11T19:19:48.5983930Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-11T19:19:48.5994177Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-11T19:19:48.6005584Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 397, in __init__
2026-02-11T19:19:48.6015129Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-11T19:19:48.6024946Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 158, in __init__
2026-02-11T19:19:48.6034762Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-11T19:19:48.6044306Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-11T19:19:48.6053754Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-11T19:19:48.6063188Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.6072772Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-11T19:19:48.6082829Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-11T19:19:48.6092092Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.6101801Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 414, in get_quant_method
2026-02-11T19:19:48.6111231Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-11T19:19:48.6122516Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.6132539Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 290, in create_scheme_for_layer
2026-02-11T19:19:48.6141323Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     return scheme_cls()
2026-02-11T19:19:48.6150510Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-11T19:19:48.6161035Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-11T19:19:48.6170626Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-11T19:19:48.6179993Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.6190564Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-11T19:19:48.6199843Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] [ERROR] 2026-02-11-19:19:47 (PID:792, Device:6, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-11T19:19:48.6209307Z [0;36m(Worker_DP1_TP6_EP14 pid=792)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] 
2026-02-11T19:19:48.6218616Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-11T19:19:48.6228035Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-11T19:19:48.6238010Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-11T19:19:48.6247453Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-11T19:19:48.6256970Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.6266643Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-11T19:19:48.6275346Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-11T19:19:48.6285340Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 404, in load_model
2026-02-11T19:19:48.6294641Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-11T19:19:48.6304379Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2309, in load_model
2026-02-11T19:19:48.6314008Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-11T19:19:48.6324197Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.6334219Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-11T19:19:48.6343682Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     return loader.load_model(
2026-02-11T19:19:48.6353600Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.6363558Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-11T19:19:48.6373524Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     model = initialize_model(
2026-02-11T19:19:48.6383125Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.6392414Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-11T19:19:48.6402417Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-11T19:19:48.6411957Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.6421682Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-11T19:19:48.6431016Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-11T19:19:48.6440469Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-11T19:19:48.6450867Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-11T19:19:48.6459711Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-11T19:19:48.6469376Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-11T19:19:48.6479507Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-11T19:19:48.6489239Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-11T19:19:48.6498788Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-11T19:19:48.6508095Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     + [
2026-02-11T19:19:48.6517067Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]       ^
2026-02-11T19:19:48.6527105Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-11T19:19:48.6536593Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-11T19:19:48.6545588Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.6555057Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-11T19:19:48.6564561Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-11T19:19:48.6573957Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.6583243Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-11T19:19:48.6592703Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-11T19:19:48.6602508Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-11T19:19:48.6612941Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-11T19:19:48.6621954Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-11T19:19:48.6631295Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-11T19:19:48.6641701Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 397, in __init__
2026-02-11T19:19:48.6651014Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-11T19:19:48.6660179Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 158, in __init__
2026-02-11T19:19:48.6669226Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-11T19:19:48.6679953Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-11T19:19:48.6689872Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-11T19:19:48.6699304Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.6708863Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-11T19:19:48.6718709Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-11T19:19:48.6728419Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.6737990Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 414, in get_quant_method
2026-02-11T19:19:48.6747529Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-11T19:19:48.6757676Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.6767497Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 290, in create_scheme_for_layer
2026-02-11T19:19:48.6776171Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     return scheme_cls()
2026-02-11T19:19:48.6785422Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-11T19:19:48.6795758Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-11T19:19:48.6805558Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-11T19:19:48.6814984Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.6825420Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-11T19:19:48.6834478Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] [ERROR] 2026-02-11-19:19:47 (PID:795, Device:6, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-11T19:19:48.6843965Z [0;36m(Worker_DP0_TP6_EP6 pid=795)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] 
2026-02-11T19:19:48.6853155Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-11T19:19:48.6862812Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-11T19:19:48.6872705Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-11T19:19:48.6882192Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-11T19:19:48.6891703Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.6901639Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-11T19:19:48.6910962Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-11T19:19:48.6921325Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 404, in load_model
2026-02-11T19:19:48.6930568Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-11T19:19:48.6940126Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2309, in load_model
2026-02-11T19:19:48.6949506Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-11T19:19:48.6958638Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.6968869Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-11T19:19:48.6978702Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     return loader.load_model(
2026-02-11T19:19:48.6987548Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.6997824Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-11T19:19:48.7006845Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     model = initialize_model(
2026-02-11T19:19:48.7016238Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.7025850Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-11T19:19:48.7035025Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-11T19:19:48.7045285Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.7057166Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-11T19:19:48.7068112Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-11T19:19:48.7077980Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-11T19:19:48.7088716Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-11T19:19:48.7098378Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-11T19:19:48.7108360Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-11T19:19:48.7119280Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-11T19:19:48.7129254Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-11T19:19:48.7138282Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-11T19:19:48.7147729Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     + [
2026-02-11T19:19:48.7157785Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]       ^
2026-02-11T19:19:48.7168622Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-11T19:19:48.7178119Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-11T19:19:48.7187741Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.7198021Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-11T19:19:48.7207674Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-11T19:19:48.7217200Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.7226969Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-11T19:19:48.7236274Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-11T19:19:48.7246694Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-11T19:19:48.7256314Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-11T19:19:48.7265630Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-11T19:19:48.7275451Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-11T19:19:48.7285018Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 397, in __init__
2026-02-11T19:19:48.7298585Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-11T19:19:48.7308721Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 158, in __init__
2026-02-11T19:19:48.7318385Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-11T19:19:48.7328989Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-11T19:19:48.7338229Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-11T19:19:48.7348295Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.7358234Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-11T19:19:48.7368458Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-11T19:19:48.7378578Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.7389016Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 414, in get_quant_method
2026-02-11T19:19:48.7398803Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-11T19:19:48.7408625Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.7418631Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 290, in create_scheme_for_layer
2026-02-11T19:19:48.7428223Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     return scheme_cls()
2026-02-11T19:19:48.7438076Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-11T19:19:48.7449483Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-11T19:19:48.7458852Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-11T19:19:48.7468352Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.7479548Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-11T19:19:48.7488784Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] [ERROR] 2026-02-11-19:19:47 (PID:584, Device:4, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-11T19:19:48.7497094Z [0;36m(Worker_DP1_TP4_EP12 pid=584)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] 
2026-02-11T19:19:48.7507031Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-11T19:19:48.7516303Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-11T19:19:48.7526708Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-11T19:19:48.7535785Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-11T19:19:48.7546047Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.7555064Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-11T19:19:48.7564402Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-11T19:19:48.7574301Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 404, in load_model
2026-02-11T19:19:48.7583159Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-11T19:19:48.7593182Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2309, in load_model
2026-02-11T19:19:48.7602418Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-11T19:19:48.7611949Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.7622307Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-11T19:19:48.7630933Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     return loader.load_model(
2026-02-11T19:19:48.7640568Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.7650244Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-11T19:19:48.7665621Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     model = initialize_model(
2026-02-11T19:19:48.7667835Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.7677854Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-11T19:19:48.7687556Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-11T19:19:48.7697167Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.7706925Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-11T19:19:48.7716107Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-11T19:19:48.7726056Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-11T19:19:48.7735881Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-11T19:19:48.7745052Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-11T19:19:48.7754820Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-11T19:19:48.7765017Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-11T19:19:48.7774289Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-11T19:19:48.7783901Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-11T19:19:48.7793048Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     + [
2026-02-11T19:19:48.7802437Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]       ^
2026-02-11T19:19:48.7812257Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-11T19:19:48.7821247Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-11T19:19:48.7830471Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.7840740Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-11T19:19:48.7850067Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-11T19:19:48.7859461Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.7868981Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-11T19:19:48.7878454Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-11T19:19:48.7887645Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-11T19:19:48.7897045Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-11T19:19:48.7905876Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-11T19:19:48.7915589Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-11T19:19:48.7926315Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 397, in __init__
2026-02-11T19:19:48.7936080Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-11T19:19:48.7945854Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 158, in __init__
2026-02-11T19:19:48.7954599Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-11T19:19:48.7964967Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-11T19:19:48.7974125Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-11T19:19:48.7983781Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.7993729Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-11T19:19:48.8003898Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-11T19:19:48.8013913Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.8023567Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 414, in get_quant_method
2026-02-11T19:19:48.8032818Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-11T19:19:48.8041925Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.8051633Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 290, in create_scheme_for_layer
2026-02-11T19:19:48.8060462Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     return scheme_cls()
2026-02-11T19:19:48.8069774Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-11T19:19:48.8080138Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-11T19:19:48.8089970Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-11T19:19:48.8099325Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.8109707Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-11T19:19:48.8119311Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] [ERROR] 2026-02-11-19:19:47 (PID:688, Device:5, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-11T19:19:48.8128461Z [0;36m(Worker_DP1_TP5_EP13 pid=688)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] 
2026-02-11T19:19:48.8149512Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-11T19:19:48.8159242Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-11T19:19:48.8169532Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-11T19:19:48.8178852Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-11T19:19:48.8188003Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.8197640Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-11T19:19:48.8207385Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-11T19:19:48.8217429Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 404, in load_model
2026-02-11T19:19:48.8226672Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-11T19:19:48.8236484Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2309, in load_model
2026-02-11T19:19:48.8246964Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-11T19:19:48.8256080Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.8266264Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-11T19:19:48.8274913Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     return loader.load_model(
2026-02-11T19:19:48.8284966Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.8296140Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-11T19:19:48.8304564Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     model = initialize_model(
2026-02-11T19:19:48.8313160Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.8323881Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-11T19:19:48.8333541Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-11T19:19:48.8342341Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.8352214Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-11T19:19:48.8361195Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-11T19:19:48.8371405Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-11T19:19:48.8380781Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-11T19:19:48.8390509Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-11T19:19:48.8400534Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-11T19:19:48.8409879Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-11T19:19:48.8419322Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-11T19:19:48.8428950Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-11T19:19:48.8438474Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     + [
2026-02-11T19:19:48.8448234Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]       ^
2026-02-11T19:19:48.8457821Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-11T19:19:48.8467513Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-11T19:19:48.8476846Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.8487267Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-11T19:19:48.8495964Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-11T19:19:48.8506082Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.8515643Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-11T19:19:48.8525870Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-11T19:19:48.8535088Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-11T19:19:48.8544689Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-11T19:19:48.8554247Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-11T19:19:48.8564071Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-11T19:19:48.8574137Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 397, in __init__
2026-02-11T19:19:48.8583546Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-11T19:19:48.8593399Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 158, in __init__
2026-02-11T19:19:48.8603229Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-11T19:19:48.8613468Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-11T19:19:48.8622334Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-11T19:19:48.8631874Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.8642417Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-11T19:19:48.8652611Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-11T19:19:48.8661964Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.8672336Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 414, in get_quant_method
2026-02-11T19:19:48.8682957Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-11T19:19:48.8693067Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.8703172Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 290, in create_scheme_for_layer
2026-02-11T19:19:48.8712394Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     return scheme_cls()
2026-02-11T19:19:48.8722610Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-11T19:19:48.8733039Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-11T19:19:48.8742660Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-11T19:19:48.8752310Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.8763237Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-11T19:19:48.8773364Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] [ERROR] 2026-02-11-19:19:47 (PID:483, Device:3, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-11T19:19:48.8782896Z [0;36m(Worker_DP1_TP3_EP11 pid=483)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] 
2026-02-11T19:19:48.8797788Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-11T19:19:48.8812808Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-11T19:19:48.8822646Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-11T19:19:48.8832265Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-11T19:19:48.8841939Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.8860186Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-11T19:19:48.8870374Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-11T19:19:48.8880471Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 404, in load_model
2026-02-11T19:19:48.8889721Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-11T19:19:48.8899735Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2309, in load_model
2026-02-11T19:19:48.8909646Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-11T19:19:48.8920160Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.8930148Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-11T19:19:48.8939306Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     return loader.load_model(
2026-02-11T19:19:48.8948696Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.8958779Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-11T19:19:48.8968491Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     model = initialize_model(
2026-02-11T19:19:48.8978121Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.8988840Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-11T19:19:48.9001572Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-11T19:19:48.9013978Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.9025900Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-11T19:19:48.9037888Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-11T19:19:48.9050604Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-11T19:19:48.9060724Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-11T19:19:48.9069837Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-11T19:19:48.9080845Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-11T19:19:48.9090157Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-11T19:19:48.9100091Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-11T19:19:48.9109667Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-11T19:19:48.9119082Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     + [
2026-02-11T19:19:48.9128907Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]       ^
2026-02-11T19:19:48.9138331Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-11T19:19:48.9147710Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-11T19:19:48.9157516Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.9167298Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-11T19:19:48.9176608Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-11T19:19:48.9185971Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.9195986Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-11T19:19:48.9205807Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-11T19:19:48.9215368Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-11T19:19:48.9225120Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-11T19:19:48.9234195Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-11T19:19:48.9244229Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-11T19:19:48.9253939Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 397, in __init__
2026-02-11T19:19:48.9263868Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-11T19:19:48.9273734Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 158, in __init__
2026-02-11T19:19:48.9283206Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-11T19:19:48.9293241Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-11T19:19:48.9302368Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-11T19:19:48.9311866Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.9321761Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-11T19:19:48.9331523Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-11T19:19:48.9341124Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.9351199Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 414, in get_quant_method
2026-02-11T19:19:48.9361751Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-11T19:19:48.9371408Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.9381032Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 290, in create_scheme_for_layer
2026-02-11T19:19:48.9389500Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     return scheme_cls()
2026-02-11T19:19:48.9399188Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-11T19:19:48.9410018Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-11T19:19:48.9418793Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-11T19:19:48.9428359Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:48.9439264Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-11T19:19:48.9448894Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] [ERROR] 2026-02-11-19:19:47 (PID:284, Device:1, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-11T19:19:48.9457850Z [0;36m(Worker_DP1_TP1_EP9 pid=284)[0;0m ERROR 02-11 19:19:48 [multiproc_executor.py:772] 
2026-02-11T19:19:52.6178181Z [0;36m(EngineCore_DP0 pid=161)[0;0m ERROR 02-11 19:19:52 [core.py:946] EngineCore failed to start.
2026-02-11T19:19:52.6185198Z [0;36m(EngineCore_DP0 pid=161)[0;0m ERROR 02-11 19:19:52 [core.py:946] Traceback (most recent call last):
2026-02-11T19:19:52.6194748Z [0;36m(EngineCore_DP0 pid=161)[0;0m ERROR 02-11 19:19:52 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 929, in run_engine_core
2026-02-11T19:19:52.6204132Z [0;36m(EngineCore_DP0 pid=161)[0;0m ERROR 02-11 19:19:52 [core.py:946]     engine_core = DPEngineCoreProc(*args, **kwargs)
2026-02-11T19:19:52.6213417Z [0;36m(EngineCore_DP0 pid=161)[0;0m ERROR 02-11 19:19:52 [core.py:946]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:52.6223300Z [0;36m(EngineCore_DP0 pid=161)[0;0m ERROR 02-11 19:19:52 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 1279, in __init__
2026-02-11T19:19:52.6233104Z [0;36m(EngineCore_DP0 pid=161)[0;0m ERROR 02-11 19:19:52 [core.py:946]     super().__init__(
2026-02-11T19:19:52.6243679Z [0;36m(EngineCore_DP0 pid=161)[0;0m ERROR 02-11 19:19:52 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 691, in __init__
2026-02-11T19:19:52.6253344Z [0;36m(EngineCore_DP0 pid=161)[0;0m ERROR 02-11 19:19:52 [core.py:946]     super().__init__(
2026-02-11T19:19:52.6262630Z [0;36m(EngineCore_DP0 pid=161)[0;0m ERROR 02-11 19:19:52 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 105, in __init__
2026-02-11T19:19:52.6271411Z [0;36m(EngineCore_DP0 pid=161)[0;0m Process EngineCore_DP0:
2026-02-11T19:19:52.6282161Z [0;36m(EngineCore_DP0 pid=161)[0;0m ERROR 02-11 19:19:52 [core.py:946]     self.model_executor = executor_class(vllm_config)
2026-02-11T19:19:52.6291882Z [0;36m(EngineCore_DP0 pid=161)[0;0m ERROR 02-11 19:19:52 [core.py:946]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:52.6301934Z [0;36m(EngineCore_DP0 pid=161)[0;0m ERROR 02-11 19:19:52 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 97, in __init__
2026-02-11T19:19:52.6310870Z [0;36m(EngineCore_DP0 pid=161)[0;0m ERROR 02-11 19:19:52 [core.py:946]     super().__init__(vllm_config)
2026-02-11T19:19:52.6321705Z [0;36m(EngineCore_DP0 pid=161)[0;0m ERROR 02-11 19:19:52 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/executor/abstract.py", line 101, in __init__
2026-02-11T19:19:52.6331136Z [0;36m(EngineCore_DP0 pid=161)[0;0m ERROR 02-11 19:19:52 [core.py:946]     self._init_executor()
2026-02-11T19:19:52.6340896Z [0;36m(EngineCore_DP0 pid=161)[0;0m ERROR 02-11 19:19:52 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 165, in _init_executor
2026-02-11T19:19:52.6350690Z [0;36m(EngineCore_DP0 pid=161)[0;0m ERROR 02-11 19:19:52 [core.py:946]     self.workers = WorkerProc.wait_for_ready(unready_workers)
2026-02-11T19:19:52.6360225Z [0;36m(EngineCore_DP0 pid=161)[0;0m ERROR 02-11 19:19:52 [core.py:946]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:52.6369694Z [0;36m(EngineCore_DP0 pid=161)[0;0m ERROR 02-11 19:19:52 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 678, in wait_for_ready
2026-02-11T19:19:52.6378787Z [0;36m(EngineCore_DP0 pid=161)[0;0m ERROR 02-11 19:19:52 [core.py:946]     raise e from None
2026-02-11T19:19:52.6388932Z [0;36m(EngineCore_DP0 pid=161)[0;0m ERROR 02-11 19:19:52 [core.py:946] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
2026-02-11T19:19:52.6398106Z [0;36m(EngineCore_DP0 pid=161)[0;0m Traceback (most recent call last):
2026-02-11T19:19:52.6407517Z [0;36m(EngineCore_DP0 pid=161)[0;0m   File "/usr/local/python3.11.14/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
2026-02-11T19:19:52.6416500Z [0;36m(EngineCore_DP0 pid=161)[0;0m     self.run()
2026-02-11T19:19:52.6426246Z [0;36m(EngineCore_DP0 pid=161)[0;0m   File "/usr/local/python3.11.14/lib/python3.11/multiprocessing/process.py", line 108, in run
2026-02-11T19:19:52.6435185Z [0;36m(EngineCore_DP0 pid=161)[0;0m     self._target(*self._args, **self._kwargs)
2026-02-11T19:19:52.6445822Z [0;36m(EngineCore_DP0 pid=161)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 950, in run_engine_core
2026-02-11T19:19:52.6454975Z [0;36m(EngineCore_DP0 pid=161)[0;0m     raise e
2026-02-11T19:19:52.6464568Z [0;36m(EngineCore_DP0 pid=161)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 929, in run_engine_core
2026-02-11T19:19:52.6473837Z [0;36m(EngineCore_DP0 pid=161)[0;0m     engine_core = DPEngineCoreProc(*args, **kwargs)
2026-02-11T19:19:52.6483602Z [0;36m(EngineCore_DP0 pid=161)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:52.6492968Z [0;36m(EngineCore_DP0 pid=161)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 1279, in __init__
2026-02-11T19:19:52.6501568Z [0;36m(EngineCore_DP0 pid=161)[0;0m     super().__init__(
2026-02-11T19:19:52.6511077Z [0;36m(EngineCore_DP0 pid=161)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 691, in __init__
2026-02-11T19:19:52.6520321Z [0;36m(EngineCore_DP0 pid=161)[0;0m     super().__init__(
2026-02-11T19:19:52.6530374Z [0;36m(EngineCore_DP0 pid=161)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 105, in __init__
2026-02-11T19:19:52.6538874Z [0;36m(EngineCore_DP0 pid=161)[0;0m     self.model_executor = executor_class(vllm_config)
2026-02-11T19:19:52.6548336Z [0;36m(EngineCore_DP0 pid=161)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:52.6558882Z [0;36m(EngineCore_DP0 pid=161)[0;0m   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 97, in __init__
2026-02-11T19:19:52.6567098Z [0;36m(EngineCore_DP0 pid=161)[0;0m     super().__init__(vllm_config)
2026-02-11T19:19:52.6576567Z [0;36m(EngineCore_DP0 pid=161)[0;0m   File "/vllm-workspace/vllm/vllm/v1/executor/abstract.py", line 101, in __init__
2026-02-11T19:19:52.6585753Z [0;36m(EngineCore_DP0 pid=161)[0;0m     self._init_executor()
2026-02-11T19:19:52.6595503Z [0;36m(EngineCore_DP0 pid=161)[0;0m   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 165, in _init_executor
2026-02-11T19:19:52.6605024Z [0;36m(EngineCore_DP0 pid=161)[0;0m     self.workers = WorkerProc.wait_for_ready(unready_workers)
2026-02-11T19:19:52.6615809Z [0;36m(EngineCore_DP0 pid=161)[0;0m                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:52.6623982Z [0;36m(EngineCore_DP0 pid=161)[0;0m   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 678, in wait_for_ready
2026-02-11T19:19:52.6633048Z [0;36m(EngineCore_DP0 pid=161)[0;0m     raise e from None
2026-02-11T19:19:52.6642859Z [0;36m(EngineCore_DP0 pid=161)[0;0m Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
2026-02-11T19:19:52.6651649Z [0;36m(EngineCore_DP1 pid=180)[0;0m ERROR 02-11 19:19:52 [core.py:946] EngineCore failed to start.
2026-02-11T19:19:52.6660839Z [0;36m(EngineCore_DP1 pid=180)[0;0m ERROR 02-11 19:19:52 [core.py:946] Traceback (most recent call last):
2026-02-11T19:19:52.6670563Z [0;36m(EngineCore_DP1 pid=180)[0;0m ERROR 02-11 19:19:52 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 929, in run_engine_core
2026-02-11T19:19:52.6680292Z [0;36m(EngineCore_DP1 pid=180)[0;0m ERROR 02-11 19:19:52 [core.py:946]     engine_core = DPEngineCoreProc(*args, **kwargs)
2026-02-11T19:19:52.6689900Z [0;36m(EngineCore_DP1 pid=180)[0;0m ERROR 02-11 19:19:52 [core.py:946]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:52.6699402Z [0;36m(EngineCore_DP1 pid=180)[0;0m ERROR 02-11 19:19:52 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 1279, in __init__
2026-02-11T19:19:52.6708794Z [0;36m(EngineCore_DP1 pid=180)[0;0m ERROR 02-11 19:19:52 [core.py:946]     super().__init__(
2026-02-11T19:19:52.6718225Z [0;36m(EngineCore_DP1 pid=180)[0;0m ERROR 02-11 19:19:52 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 691, in __init__
2026-02-11T19:19:52.6740591Z [0;36m(EngineCore_DP1 pid=180)[0;0m ERROR 02-11 19:19:52 [core.py:946]     super().__init__(
2026-02-11T19:19:52.6741229Z [0;36m(EngineCore_DP1 pid=180)[0;0m ERROR 02-11 19:19:52 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 105, in __init__
2026-02-11T19:19:52.6746320Z [0;36m(EngineCore_DP1 pid=180)[0;0m ERROR 02-11 19:19:52 [core.py:946]     self.model_executor = executor_class(vllm_config)
2026-02-11T19:19:52.6755760Z [0;36m(EngineCore_DP1 pid=180)[0;0m ERROR 02-11 19:19:52 [core.py:946]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:52.6766326Z [0;36m(EngineCore_DP1 pid=180)[0;0m ERROR 02-11 19:19:52 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 97, in __init__
2026-02-11T19:19:52.6776287Z [0;36m(EngineCore_DP1 pid=180)[0;0m ERROR 02-11 19:19:52 [core.py:946]     super().__init__(vllm_config)
2026-02-11T19:19:52.6786076Z [0;36m(EngineCore_DP1 pid=180)[0;0m ERROR 02-11 19:19:52 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/executor/abstract.py", line 101, in __init__
2026-02-11T19:19:52.6795686Z [0;36m(EngineCore_DP1 pid=180)[0;0m ERROR 02-11 19:19:52 [core.py:946]     self._init_executor()
2026-02-11T19:19:52.6805725Z [0;36m(EngineCore_DP1 pid=180)[0;0m Process EngineCore_DP1:
2026-02-11T19:19:52.6815038Z [0;36m(EngineCore_DP1 pid=180)[0;0m ERROR 02-11 19:19:52 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 165, in _init_executor
2026-02-11T19:19:52.6824596Z [0;36m(EngineCore_DP1 pid=180)[0;0m ERROR 02-11 19:19:52 [core.py:946]     self.workers = WorkerProc.wait_for_ready(unready_workers)
2026-02-11T19:19:52.6833632Z [0;36m(EngineCore_DP1 pid=180)[0;0m ERROR 02-11 19:19:52 [core.py:946]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:52.6843718Z [0;36m(EngineCore_DP1 pid=180)[0;0m ERROR 02-11 19:19:52 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 678, in wait_for_ready
2026-02-11T19:19:52.6852671Z [0;36m(EngineCore_DP1 pid=180)[0;0m ERROR 02-11 19:19:52 [core.py:946]     raise e from None
2026-02-11T19:19:52.6862523Z [0;36m(EngineCore_DP1 pid=180)[0;0m ERROR 02-11 19:19:52 [core.py:946] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
2026-02-11T19:19:52.6871144Z [0;36m(EngineCore_DP1 pid=180)[0;0m Traceback (most recent call last):
2026-02-11T19:19:52.6881366Z [0;36m(EngineCore_DP1 pid=180)[0;0m   File "/usr/local/python3.11.14/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
2026-02-11T19:19:52.6890700Z [0;36m(EngineCore_DP1 pid=180)[0;0m     self.run()
2026-02-11T19:19:52.6900738Z [0;36m(EngineCore_DP1 pid=180)[0;0m   File "/usr/local/python3.11.14/lib/python3.11/multiprocessing/process.py", line 108, in run
2026-02-11T19:19:52.6910602Z [0;36m(EngineCore_DP1 pid=180)[0;0m     self._target(*self._args, **self._kwargs)
2026-02-11T19:19:52.6919759Z [0;36m(EngineCore_DP1 pid=180)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 950, in run_engine_core
2026-02-11T19:19:52.6928861Z [0;36m(EngineCore_DP1 pid=180)[0;0m     raise e
2026-02-11T19:19:52.6938487Z [0;36m(EngineCore_DP1 pid=180)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 929, in run_engine_core
2026-02-11T19:19:52.6947156Z [0;36m(EngineCore_DP1 pid=180)[0;0m     engine_core = DPEngineCoreProc(*args, **kwargs)
2026-02-11T19:19:52.6956831Z [0;36m(EngineCore_DP1 pid=180)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:52.6967458Z [0;36m(EngineCore_DP1 pid=180)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 1279, in __init__
2026-02-11T19:19:52.6976415Z [0;36m(EngineCore_DP1 pid=180)[0;0m     super().__init__(
2026-02-11T19:19:52.6985858Z [0;36m(EngineCore_DP1 pid=180)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 691, in __init__
2026-02-11T19:19:52.6994663Z [0;36m(EngineCore_DP1 pid=180)[0;0m     super().__init__(
2026-02-11T19:19:52.7004817Z [0;36m(EngineCore_DP1 pid=180)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 105, in __init__
2026-02-11T19:19:52.7013989Z [0;36m(EngineCore_DP1 pid=180)[0;0m     self.model_executor = executor_class(vllm_config)
2026-02-11T19:19:52.7022886Z [0;36m(EngineCore_DP1 pid=180)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:52.7032518Z [0;36m(EngineCore_DP1 pid=180)[0;0m   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 97, in __init__
2026-02-11T19:19:52.7041499Z [0;36m(EngineCore_DP1 pid=180)[0;0m     super().__init__(vllm_config)
2026-02-11T19:19:52.7051043Z [0;36m(EngineCore_DP1 pid=180)[0;0m   File "/vllm-workspace/vllm/vllm/v1/executor/abstract.py", line 101, in __init__
2026-02-11T19:19:52.7060463Z [0;36m(EngineCore_DP1 pid=180)[0;0m     self._init_executor()
2026-02-11T19:19:52.7069760Z [0;36m(EngineCore_DP1 pid=180)[0;0m   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 165, in _init_executor
2026-02-11T19:19:52.7079229Z [0;36m(EngineCore_DP1 pid=180)[0;0m     self.workers = WorkerProc.wait_for_ready(unready_workers)
2026-02-11T19:19:52.7088794Z [0;36m(EngineCore_DP1 pid=180)[0;0m                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-11T19:19:52.7098065Z [0;36m(EngineCore_DP1 pid=180)[0;0m   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 678, in wait_for_ready
2026-02-11T19:19:52.7107015Z [0;36m(EngineCore_DP1 pid=180)[0;0m     raise e from None
2026-02-11T19:19:52.7116859Z [0;36m(EngineCore_DP1 pid=180)[0;0m Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
2026-02-11T19:19:54.4019675Z Traceback (most recent call last):
2026-02-11T19:19:54.4028237Z   File "/usr/local/python3.11.14/bin/vllm", line 7, in <module>
2026-02-11T19:19:54.4036819Z     sys.exit(main())
2026-02-11T19:19:54.4046950Z              ^^^^^^
2026-02-11T19:19:54.4055814Z   File "/vllm-workspace/vllm/vllm/entrypoints/cli/main.py", line 73, in main
2026-02-11T19:19:54.4064975Z     args.dispatch_function(args)
2026-02-11T19:19:54.4076027Z   File "/vllm-workspace/vllm/vllm/entrypoints/cli/serve.py", line 108, in cmd
2026-02-11T19:19:54.4084332Z     run_multi_api_server(args)
2026-02-11T19:19:54.4092917Z   File "/vllm-workspace/vllm/vllm/entrypoints/cli/serve.py", line 248, in run_multi_api_server
2026-02-11T19:19:54.4102703Z     with launch_core_engines(
2026-02-11T19:19:54.4111935Z   File "/usr/local/python3.11.14/lib/python3.11/contextlib.py", line 144, in __exit__
2026-02-11T19:19:54.4121754Z     next(self.gen)
2026-02-11T19:19:54.4131491Z   File "/vllm-workspace/vllm/vllm/v1/engine/utils.py", line 933, in launch_core_engines
2026-02-11T19:19:54.4140448Z     wait_for_engine_startup(
2026-02-11T19:19:54.4150784Z   File "/vllm-workspace/vllm/vllm/v1/engine/utils.py", line 992, in wait_for_engine_startup
2026-02-11T19:19:54.4160859Z     raise RuntimeError(
2026-02-11T19:19:54.4170671Z RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}
2026-02-11T19:19:55.2274586Z [ERROR] 2026-02-11-19:19:54 (PID:138, Device:-1, RankID:-1) ERR99999 UNKNOWN applicaiton exception
2026-02-11T19:19:55.5623648Z sys:1: DeprecationWarning: builtin type swigvarlink has no __module__ attribute
2026-02-11T19:19:57.1424092Z /usr/local/python3.11.14/lib/python3.11/multiprocessing/resource_tracker.py:254: UserWarning: resource_tracker: There appear to be 18 leaked shared_memory objects to clean up at shutdown
2026-02-11T19:19:57.1432725Z   warnings.warn('resource_tracker: There appear to be %d '
2026-02-11T19:20:01.5465295Z FAILED
2026-02-11T19:20:01.5473414Z 
2026-02-11T19:20:01.5482482Z =================================== FAILURES ===================================
2026-02-11T19:20:01.5492949Z _______________________________ test_multi_node ________________________________
2026-02-11T19:20:01.5501674Z 
2026-02-11T19:20:01.5511579Z     @pytest.mark.asyncio
2026-02-11T19:20:01.5520733Z     async def test_multi_node() -> None:
2026-02-11T19:20:01.5530226Z         config = MultiNodeConfigLoader.from_yaml()
2026-02-11T19:20:01.5540560Z     
2026-02-11T19:20:01.5549103Z         with ProxyLauncher(
2026-02-11T19:20:01.5560165Z                 nodes=config.nodes,
2026-02-11T19:20:01.5571832Z                 disagg_cfg=config.disagg_cfg,
2026-02-11T19:20:01.5579198Z                 envs=config.envs,
2026-02-11T19:20:01.5587783Z                 proxy_port=config.proxy_port,
2026-02-11T19:20:01.5597330Z                 cur_index=config.cur_index,
2026-02-11T19:20:01.5606433Z         ) as proxy:
2026-02-11T19:20:01.5615919Z     
2026-02-11T19:20:01.5625010Z >           with RemoteOpenAIServer(
2026-02-11T19:20:01.5634803Z                     model=config.model,
2026-02-11T19:20:01.5644915Z                     vllm_serve_args=config.server_cmd,
2026-02-11T19:20:01.5653831Z                     server_port=config.server_port,
2026-02-11T19:20:01.5663169Z                     server_host=config.master_ip,
2026-02-11T19:20:01.5673175Z                     env_dict=config.envs,
2026-02-11T19:20:01.5683262Z                     auto_port=False,
2026-02-11T19:20:01.5692383Z                     proxy_port=proxy.proxy_port,
2026-02-11T19:20:01.5702315Z                     disaggregated_prefill=config.disagg_cfg,
2026-02-11T19:20:01.5711876Z                     nodes_info=config.nodes,
2026-02-11T19:20:01.5721429Z                     max_wait_seconds=2800,
2026-02-11T19:20:01.5730527Z             ) as server:
2026-02-11T19:20:01.5739695Z 
2026-02-11T19:20:01.5748942Z tests/e2e/nightly/multi_node/scripts/test_multi_node.py:21: 
2026-02-11T19:20:01.5760253Z _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
2026-02-11T19:20:01.5771370Z tests/e2e/conftest.py:306: in __init__
2026-02-11T19:20:01.5781277Z     self._wait_for_multiple_servers(
2026-02-11T19:20:01.5791873Z _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
2026-02-11T19:20:01.5801423Z 
2026-02-11T19:20:01.5811497Z self = <tests.e2e.conftest.RemoteOpenAIServer object at 0xffff1b8af450>
2026-02-11T19:20:01.5820879Z targets = [('10.0.0.163', 'http://10.0.0.163:8080/health')], timeout = 2800
2026-02-11T19:20:01.5829980Z log_interval = 30.0
2026-02-11T19:20:01.5839081Z 
2026-02-11T19:20:01.5849007Z     def _wait_for_multiple_servers(self,
2026-02-11T19:20:01.5859361Z                                    targets,
2026-02-11T19:20:01.5869139Z                                    timeout: float,
2026-02-11T19:20:01.5879183Z                                    log_interval: float = 30.0):
2026-02-11T19:20:01.5889342Z         """
2026-02-11T19:20:01.5899652Z         targets: List[(node_ip, url)]
2026-02-11T19:20:01.5908300Z         log_interval
2026-02-11T19:20:01.5918138Z         """
2026-02-11T19:20:01.5928290Z         start = time.time()
2026-02-11T19:20:01.5937529Z         client = requests
2026-02-11T19:20:01.5947021Z     
2026-02-11T19:20:01.5957774Z         ready = {node_ip: False for node_ip, _ in targets}
2026-02-11T19:20:01.5966573Z     
2026-02-11T19:20:01.5975750Z         last_log_time = 0.0
2026-02-11T19:20:01.5984759Z     
2026-02-11T19:20:01.5994386Z         while True:
2026-02-11T19:20:01.6004010Z             now = time.time()
2026-02-11T19:20:01.6013502Z             all_ready = True
2026-02-11T19:20:01.6023038Z             should_log = (now - last_log_time) >= log_interval
2026-02-11T19:20:01.6032289Z     
2026-02-11T19:20:01.6042224Z             for node_ip, url in targets:
2026-02-11T19:20:01.6051585Z                 if ready[node_ip]:
2026-02-11T19:20:01.6062088Z                     continue
2026-02-11T19:20:01.6070448Z     
2026-02-11T19:20:01.6081555Z                 try:
2026-02-11T19:20:01.6091122Z                     resp = client.get(url)
2026-02-11T19:20:01.6100276Z                     if resp.status_code == 200:
2026-02-11T19:20:01.6109354Z                         ready[node_ip] = True
2026-02-11T19:20:01.6119526Z                         logger.info(f"[READY] Node {node_ip} is ready.")
2026-02-11T19:20:01.6129267Z                 except RequestException:
2026-02-11T19:20:01.6154753Z                     all_ready = False
2026-02-11T19:20:01.6155090Z                     if should_log:
2026-02-11T19:20:01.6157942Z                         logger.debug(f"[WAIT] {url}: connection failed")
2026-02-11T19:20:01.6167636Z     
2026-02-11T19:20:01.6177263Z                     # check unexpected exit
2026-02-11T19:20:01.6189616Z                     result = self._poll()
2026-02-11T19:20:01.6198508Z                     if result is not None and result != 0:
2026-02-11T19:20:01.6208644Z >                       raise RuntimeError(
2026-02-11T19:20:01.6218417Z                             f"Server at {node_ip} exited unexpectedly."
2026-02-11T19:20:01.6229547Z                         ) from None
2026-02-11T19:20:01.6240301Z E                       RuntimeError: Server at 10.0.0.163 exited unexpectedly.
2026-02-11T19:20:01.6250593Z 
2026-02-11T19:20:01.6261492Z tests/e2e/conftest.py:399: RuntimeError
2026-02-11T19:20:01.6272114Z =============================== warnings summary ===============================
2026-02-11T19:20:01.6281875Z <frozen importlib._bootstrap>:241
2026-02-11T19:20:01.6293006Z   <frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyPacked has no __module__ attribute
2026-02-11T19:20:01.6302509Z 
2026-02-11T19:20:01.6312635Z <frozen importlib._bootstrap>:241
2026-02-11T19:20:01.6323124Z   <frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyObject has no __module__ attribute
2026-02-11T19:20:01.6332505Z 
2026-02-11T19:20:01.6343223Z ../../usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647
2026-02-11T19:20:01.6355278Z   /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-11T19:20:01.6364717Z     warnings.warn(
2026-02-11T19:20:01.6374392Z 
2026-02-11T19:20:01.6384768Z -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
2026-02-11T19:20:01.6394763Z =========================== short test summary info ============================
2026-02-11T19:20:01.6405487Z FAILED tests/e2e/nightly/multi_node/scripts/test_multi_node.py::test_multi_node
2026-02-11T19:20:01.6416277Z ================== 1 failed, 3 warnings in 140.94s (0:02:20) ===================
2026-02-11T19:20:03.5089818Z [0;31mFAIL_TAG_DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml âœ— ERROR: Some tests failed, please check the error stack above for details. If this is insufficient to pinpoint the error, please download and review the logs of all other nodes from the job's summary.[0m
2026-02-11T19:20:03.6885345Z Cleaning up background log streams...
2026-02-11T19:20:03.7819181Z ##[error]Error: failed to run script step: Error: command terminated with non-zero exit code: command terminated with exit code 1
2026-02-11T19:20:03.7857172Z ##[error]Process completed with exit code 1.
2026-02-11T19:20:03.7957521Z ##[error]Executing the custom container implementation failed. Please contact your self hosted runner administrator.
2026-02-11T19:20:03.8343571Z ##[group]Run actions/upload-artifact@v6
2026-02-11T19:20:03.8343859Z with:
2026-02-11T19:20:03.8344131Z   name: DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml-pod-logs
2026-02-11T19:20:03.8344416Z   path: /tmp/vllm*_logs.txt
2026-02-11T19:20:03.8344660Z   retention-days: 7
2026-02-11T19:20:03.8344896Z   if-no-files-found: warn
2026-02-11T19:20:03.8345110Z   compression-level: 6
2026-02-11T19:20:03.8345328Z   overwrite: false
2026-02-11T19:20:03.8345564Z   include-hidden-files: false
2026-02-11T19:20:03.8345786Z env:
2026-02-11T19:20:03.8346152Z   FAIL_TAG: FAIL_TAG_DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-02-11T19:20:03.8346429Z ##[endgroup]
2026-02-11T19:20:03.8371811Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-11T19:20:03.8372696Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-11T19:20:03.8372977Z ##[endgroup]
2026-02-11T19:20:04.1953096Z (node:856) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-11T19:20:04.1953877Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-11T19:20:05.1912159Z With the provided path, there will be 1 file uploaded
2026-02-11T19:20:05.1916469Z Artifact name is valid!
2026-02-11T19:20:05.1916818Z Root directory input is valid!
2026-02-11T19:20:06.1258920Z Beginning upload of artifact content to blob storage
2026-02-11T19:20:08.1834362Z Uploaded bytes 16673
2026-02-11T19:20:08.4584620Z Finished uploading artifact content to blob storage!
2026-02-11T19:20:08.4585357Z SHA256 digest of uploaded artifact zip is 2c10cead8be7c6faba3a4b14fa2f071dae5e9c4bf56e6ca66156ad0a32a77a96
2026-02-11T19:20:08.4585922Z Finalizing artifact upload
2026-02-11T19:20:09.4076213Z Artifact DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml-pod-logs.zip successfully finalized. Artifact ID 5471252221
2026-02-11T19:20:09.4077118Z Artifact DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml-pod-logs has been successfully uploaded! Final size is 16673 bytes. Artifact ID is 5471252221
2026-02-11T19:20:09.4078560Z Artifact download URL: https://github.com/vllm-project/vllm-ascend/actions/runs/21914310156/artifacts/5471252221
2026-02-11T19:20:11.0863056Z ##[group]Run kubectl get pods -n "$NAMESPACE" --ignore-not-found=true
2026-02-11T19:20:11.0863593Z [36;1mkubectl get pods -n "$NAMESPACE" --ignore-not-found=true[0m
2026-02-11T19:20:11.0864058Z [36;1mkubectl delete -f ./lws.yaml --ignore-not-found=true || true[0m
2026-02-11T19:20:11.0864493Z shell: bash -el {0}
2026-02-11T19:20:11.0864706Z env:
2026-02-11T19:20:11.0864982Z   FAIL_TAG: FAIL_TAG_DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-02-11T19:20:11.0865293Z ##[endgroup]
2026-02-11T19:20:11.0961784Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-11T19:20:11.0962699Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-11T19:20:11.0962988Z ##[endgroup]
2026-02-11T19:20:11.4440420Z (node:1020) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-11T19:20:11.4441567Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-11T19:20:12.1196981Z NAME                                             READY   STATUS    RESTARTS     AGE
2026-02-11T19:20:12.1197578Z linux-aarch64-a3-0-n4cwm-runner-8vlf4            1/1     Running   0            4m21s
2026-02-11T19:20:12.1198084Z linux-aarch64-a3-0-n4cwm-runner-8vlf4-workflow   1/1     Running   0            3m43s
2026-02-11T19:20:12.1198508Z vllm-0                                           1/1     Running   1 (9s ago)   3m16s
2026-02-11T19:20:12.1198872Z vllm-0-1                                         1/1     Running   0            3m16s
2026-02-11T19:20:12.1844345Z leaderworkerset.leaderworkerset.x-k8s.io "vllm" deleted from vllm-project namespace
2026-02-11T19:20:12.2056238Z service "vllm-leader" deleted from vllm-project namespace
2026-02-11T19:20:12.7227173Z Post job cleanup.
2026-02-11T19:20:12.7251194Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-11T19:20:12.7252100Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-11T19:20:12.7252405Z ##[endgroup]
2026-02-11T19:20:13.0741381Z (node:1146) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-11T19:20:13.0742317Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-11T19:20:13.8617806Z [command]/usr/bin/git version
2026-02-11T19:20:13.8806531Z git version 2.34.1
2026-02-11T19:20:13.8838133Z Copying '/root/.gitconfig' to '/__w/_temp/c797e56e-3093-465f-9700-39b02c369df0/.gitconfig'
2026-02-11T19:20:13.8876206Z Temporarily overriding HOME='/__w/_temp/c797e56e-3093-465f-9700-39b02c369df0' before making global git config changes
2026-02-11T19:20:13.8877047Z Adding repository directory to the temporary git global config as a safe directory
2026-02-11T19:20:13.8880792Z [command]/usr/bin/git config --global --add safe.directory /__w/vllm-ascend/vllm-ascend
2026-02-11T19:20:13.8917839Z Removing SSH command configuration
2026-02-11T19:20:13.8923029Z [command]/usr/bin/git config --local --name-only --get-regexp core\.sshCommand
2026-02-11T19:20:13.8979530Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'core\.sshCommand' && git config --local --unset-all 'core.sshCommand' || :"
2026-02-11T19:20:13.9445932Z Removing HTTP extra header
2026-02-11T19:20:13.9448783Z [command]/usr/bin/git config --local --name-only --get-regexp http\.https\:\/\/github\.com\/\.extraheader
2026-02-11T19:20:13.9475575Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'http\.https\:\/\/github\.com\/\.extraheader' && git config --local --unset-all 'http.https://github.com/.extraheader' || :"
2026-02-11T19:20:13.9653257Z Removing includeIf entries pointing to credentials config files
2026-02-11T19:20:13.9658920Z [command]/usr/bin/git config --local --name-only --get-regexp ^includeIf\.gitdir:
2026-02-11T19:20:13.9676381Z includeif.gitdir:/__w/vllm-ascend/vllm-ascend/.git.path
2026-02-11T19:20:13.9676844Z includeif.gitdir:/__w/vllm-ascend/vllm-ascend/.git/worktrees/*.path
2026-02-11T19:20:13.9677228Z includeif.gitdir:/github/workspace/.git.path
2026-02-11T19:20:13.9677571Z includeif.gitdir:/github/workspace/.git/worktrees/*.path
2026-02-11T19:20:13.9683379Z [command]/usr/bin/git config --local --get-all includeif.gitdir:/__w/vllm-ascend/vllm-ascend/.git.path
2026-02-11T19:20:13.9701387Z /__w/_temp/git-credentials-3dcfa604-4b42-4181-a805-dea57f72262e.config
2026-02-11T19:20:13.9710189Z [command]/usr/bin/git config --local --unset includeif.gitdir:/__w/vllm-ascend/vllm-ascend/.git.path /__w/_temp/git-credentials-3dcfa604-4b42-4181-a805-dea57f72262e.config
2026-02-11T19:20:13.9738452Z [command]/usr/bin/git config --local --get-all includeif.gitdir:/__w/vllm-ascend/vllm-ascend/.git/worktrees/*.path
2026-02-11T19:20:13.9757800Z /__w/_temp/git-credentials-3dcfa604-4b42-4181-a805-dea57f72262e.config
2026-02-11T19:20:13.9764579Z [command]/usr/bin/git config --local --unset includeif.gitdir:/__w/vllm-ascend/vllm-ascend/.git/worktrees/*.path /__w/_temp/git-credentials-3dcfa604-4b42-4181-a805-dea57f72262e.config
2026-02-11T19:20:13.9802222Z [command]/usr/bin/git config --local --get-all includeif.gitdir:/github/workspace/.git.path
2026-02-11T19:20:13.9809117Z /github/runner_temp/git-credentials-3dcfa604-4b42-4181-a805-dea57f72262e.config
2026-02-11T19:20:13.9815736Z [command]/usr/bin/git config --local --unset includeif.gitdir:/github/workspace/.git.path /github/runner_temp/git-credentials-3dcfa604-4b42-4181-a805-dea57f72262e.config
2026-02-11T19:20:13.9847233Z [command]/usr/bin/git config --local --get-all includeif.gitdir:/github/workspace/.git/worktrees/*.path
2026-02-11T19:20:13.9864658Z /github/runner_temp/git-credentials-3dcfa604-4b42-4181-a805-dea57f72262e.config
2026-02-11T19:20:13.9870952Z [command]/usr/bin/git config --local --unset includeif.gitdir:/github/workspace/.git/worktrees/*.path /github/runner_temp/git-credentials-3dcfa604-4b42-4181-a805-dea57f72262e.config
2026-02-11T19:20:13.9899020Z [command]/usr/bin/git submodule foreach --recursive git config --local --show-origin --name-only --get-regexp remote.origin.url
2026-02-11T19:20:14.0086245Z Removing credentials config '/__w/_temp/git-credentials-3dcfa604-4b42-4181-a805-dea57f72262e.config'
2026-02-11T19:20:32.5814442Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-11T19:20:32.5815279Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-11T19:20:32.5815820Z ##[endgroup]
2026-02-11T19:20:32.9793874Z Cleaning up orphan processes
