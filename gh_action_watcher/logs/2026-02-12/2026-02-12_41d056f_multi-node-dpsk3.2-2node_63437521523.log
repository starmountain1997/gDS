# Run ID: 21955633637
# Commit: 41d056f94716d2ac74b73f26547a109c099e82dd
# Job: multi-node (multi-node-dpsk3.2-2node, DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml, 2) / DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
# Date: 2026-02-12
============================================================

ï»¿2026-02-12T19:18:57.9380955Z Current runner version: '2.330.0'
2026-02-12T19:18:57.9385542Z Runner name: 'linux-aarch64-a3-0-n4cwm-runner-v5b2h'
2026-02-12T19:18:57.9386239Z Runner group name: 'Default'
2026-02-12T19:18:57.9386913Z Machine name: 'linux-aarch64-a3-0-n4cwm-runner-v5b2h'
2026-02-12T19:18:57.9390462Z ##[group]GITHUB_TOKEN Permissions
2026-02-12T19:18:57.9392591Z Actions: write
2026-02-12T19:18:57.9393011Z ArtifactMetadata: write
2026-02-12T19:18:57.9393532Z Attestations: write
2026-02-12T19:18:57.9393934Z Checks: write
2026-02-12T19:18:57.9394283Z Contents: write
2026-02-12T19:18:57.9394682Z Deployments: write
2026-02-12T19:18:57.9395081Z Discussions: write
2026-02-12T19:18:57.9395433Z Issues: write
2026-02-12T19:18:57.9395818Z Metadata: read
2026-02-12T19:18:57.9396197Z Models: read
2026-02-12T19:18:57.9396539Z Packages: write
2026-02-12T19:18:57.9396930Z Pages: write
2026-02-12T19:18:57.9397272Z PullRequests: write
2026-02-12T19:18:57.9397686Z RepositoryProjects: write
2026-02-12T19:18:57.9398412Z SecurityEvents: write
2026-02-12T19:18:57.9398897Z Statuses: write
2026-02-12T19:18:57.9399283Z ##[endgroup]
2026-02-12T19:18:57.9401030Z Secret source: Actions
2026-02-12T19:18:57.9401546Z Prepare workflow directory
2026-02-12T19:18:57.9939954Z Prepare all required actions
2026-02-12T19:18:57.9971436Z Getting action download info
2026-02-12T19:18:59.3662588Z Download action repository 'actions/checkout@v6' (SHA:de0fac2e4500dabe0009e67214ff5f5447ce83dd)
2026-02-12T19:19:05.2129483Z Download action repository 'actions/upload-artifact@v6' (SHA:b7c566a772e6b6bfb58ed0dc250532a479d7789f)
2026-02-12T19:19:12.6124049Z Uses: vllm-project/vllm-ascend/.github/workflows/_e2e_nightly_multi_node.yaml@refs/heads/main (41d056f94716d2ac74b73f26547a109c099e82dd)
2026-02-12T19:19:12.6127029Z ##[group] Inputs
2026-02-12T19:19:12.6127284Z   soc_version: a3
2026-02-12T19:19:12.6127545Z   runner: linux-aarch64-a3-0
2026-02-12T19:19:12.6127930Z   image: swr.cn-southwest-2.myhuaweicloud.com/base_image/ascend-ci/vllm-ascend:nightly-a3
2026-02-12T19:19:12.6128403Z   config_file_path: DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-02-12T19:19:12.6128703Z   replicas: 1
2026-02-12T19:19:12.6128883Z   size: 2
2026-02-12T19:19:12.6129109Z   vllm_version: v0.15.0
2026-02-12T19:19:12.6129475Z   vllm_ascend_remote_url: https://github.com/vllm-project/vllm-ascend.git
2026-02-12T19:19:12.6129793Z   vllm_ascend_ref: main
2026-02-12T19:19:12.6130046Z ##[endgroup]
2026-02-12T19:19:12.6130530Z Complete job name: multi-node (multi-node-dpsk3.2-2node, DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml, 2) / DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-02-12T19:19:12.6607085Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-12T19:19:12.6609492Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-12T19:19:12.6609900Z ##[endgroup]
2026-02-12T19:19:28.1935442Z (node:70) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-12T19:19:28.1936421Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-12T19:19:30.1488231Z ##[group]Run # Decode and save kubeconfig
2026-02-12T19:19:30.1488705Z [36;1m# Decode and save kubeconfig[0m
2026-02-12T19:19:30.1521107Z [36;1mecho "***" | base64 -d > "$KUBECONFIG"[0m
2026-02-12T19:19:30.1521665Z shell: bash -el {0}
2026-02-12T19:19:30.1521876Z ##[endgroup]
2026-02-12T19:19:30.1647630Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-12T19:19:30.1648610Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-12T19:19:30.1649024Z ##[endgroup]
2026-02-12T19:19:30.5350917Z (node:400) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-12T19:19:30.5351736Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-12T19:19:31.4263409Z ##[group]Run actions/checkout@v6
2026-02-12T19:19:31.4263745Z with:
2026-02-12T19:19:31.4264048Z   repository: vllm-project/vllm-ascend
2026-02-12T19:19:31.4264741Z   token: ***
2026-02-12T19:19:31.4264948Z   ssh-strict: true
2026-02-12T19:19:31.4265220Z   ssh-user: git
2026-02-12T19:19:31.4265439Z   persist-credentials: true
2026-02-12T19:19:31.4265690Z   clean: true
2026-02-12T19:19:31.4265950Z   sparse-checkout-cone-mode: true
2026-02-12T19:19:31.4266267Z   fetch-depth: 1
2026-02-12T19:19:31.4266508Z   fetch-tags: false
2026-02-12T19:19:31.4266759Z   show-progress: true
2026-02-12T19:19:31.4266961Z   lfs: false
2026-02-12T19:19:31.4267293Z   submodules: false
2026-02-12T19:19:31.4267518Z   set-safe-directory: true
2026-02-12T19:19:31.4267771Z ##[endgroup]
2026-02-12T19:19:31.4308145Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-12T19:19:31.4309000Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-12T19:19:31.4309273Z ##[endgroup]
2026-02-12T19:19:31.7830667Z (node:431) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-12T19:19:31.7831506Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-12T19:19:32.3847697Z Syncing repository: vllm-project/vllm-ascend
2026-02-12T19:19:32.3848841Z ##[group]Getting Git version info
2026-02-12T19:19:32.3849267Z Working directory is '/__w/vllm-ascend/vllm-ascend'
2026-02-12T19:19:32.3849738Z [command]/usr/bin/git version
2026-02-12T19:19:32.3849967Z git version 2.34.1
2026-02-12T19:19:32.3851250Z ##[endgroup]
2026-02-12T19:19:32.3854208Z Copying '/root/.gitconfig' to '/__w/_temp/a07ca0db-0254-4195-a88d-2582dbca2c07/.gitconfig'
2026-02-12T19:19:32.3861954Z Temporarily overriding HOME='/__w/_temp/a07ca0db-0254-4195-a88d-2582dbca2c07' before making global git config changes
2026-02-12T19:19:32.3862735Z Adding repository directory to the temporary git global config as a safe directory
2026-02-12T19:19:32.3864882Z [command]/usr/bin/git config --global --add safe.directory /__w/vllm-ascend/vllm-ascend
2026-02-12T19:19:32.3896435Z Deleting the contents of '/__w/vllm-ascend/vllm-ascend'
2026-02-12T19:19:32.3899586Z ##[group]Initializing the repository
2026-02-12T19:19:32.3903299Z [command]/usr/bin/git init /__w/vllm-ascend/vllm-ascend
2026-02-12T19:19:32.4024263Z hint: Using 'master' as the name for the initial branch. This default branch name
2026-02-12T19:19:32.4024805Z hint: is subject to change. To configure the initial branch name to use in all
2026-02-12T19:19:32.4025255Z hint: of your new repositories, which will suppress this warning, call:
2026-02-12T19:19:32.4025695Z hint: 
2026-02-12T19:19:32.4026005Z hint: 	git config --global init.defaultBranch <name>
2026-02-12T19:19:32.4026266Z hint: 
2026-02-12T19:19:32.4026570Z hint: Names commonly chosen instead of 'master' are 'main', 'trunk' and
2026-02-12T19:19:32.4027029Z hint: 'development'. The just-created branch can be renamed via this command:
2026-02-12T19:19:32.4027403Z hint: 
2026-02-12T19:19:32.4027655Z hint: 	git branch -m <name>
2026-02-12T19:19:32.4028854Z Initialized empty Git repository in /__w/vllm-ascend/vllm-ascend/.git/
2026-02-12T19:19:32.4037380Z [command]/usr/bin/git remote add origin https://github.com/vllm-project/vllm-ascend
2026-02-12T19:19:32.4082291Z ##[endgroup]
2026-02-12T19:19:32.4082779Z ##[group]Disabling automatic garbage collection
2026-02-12T19:19:32.4085565Z [command]/usr/bin/git config --local gc.auto 0
2026-02-12T19:19:32.4111850Z ##[endgroup]
2026-02-12T19:19:32.4112385Z ##[group]Setting up auth
2026-02-12T19:19:32.4113511Z Removing SSH command configuration
2026-02-12T19:19:32.4118149Z [command]/usr/bin/git config --local --name-only --get-regexp core\.sshCommand
2026-02-12T19:19:32.4144966Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'core\.sshCommand' && git config --local --unset-all 'core.sshCommand' || :"
2026-02-12T19:19:32.4325945Z Removing HTTP extra header
2026-02-12T19:19:32.4327595Z [command]/usr/bin/git config --local --name-only --get-regexp http\.https\:\/\/github\.com\/\.extraheader
2026-02-12T19:19:32.4352532Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'http\.https\:\/\/github\.com\/\.extraheader' && git config --local --unset-all 'http.https://github.com/.extraheader' || :"
2026-02-12T19:19:32.4526698Z Removing includeIf entries pointing to credentials config files
2026-02-12T19:19:32.4531163Z [command]/usr/bin/git config --local --name-only --get-regexp ^includeIf\.gitdir:
2026-02-12T19:19:32.4555868Z [command]/usr/bin/git submodule foreach --recursive git config --local --show-origin --name-only --get-regexp remote.origin.url
2026-02-12T19:19:32.4734898Z [command]/usr/bin/git config --file /__w/_temp/git-credentials-15532928-7e63-408c-ae6b-fbd2a5fd33f0.config http.https://github.com/.extraheader AUTHORIZATION: basic ***
2026-02-12T19:19:32.4771009Z [command]/usr/bin/git config --local includeIf.gitdir:/__w/vllm-ascend/vllm-ascend/.git.path /__w/_temp/git-credentials-15532928-7e63-408c-ae6b-fbd2a5fd33f0.config
2026-02-12T19:19:32.4797842Z [command]/usr/bin/git config --local includeIf.gitdir:/__w/vllm-ascend/vllm-ascend/.git/worktrees/*.path /__w/_temp/git-credentials-15532928-7e63-408c-ae6b-fbd2a5fd33f0.config
2026-02-12T19:19:32.4829861Z [command]/usr/bin/git config --local includeIf.gitdir:/github/workspace/.git.path /github/runner_temp/git-credentials-15532928-7e63-408c-ae6b-fbd2a5fd33f0.config
2026-02-12T19:19:32.4861184Z [command]/usr/bin/git config --local includeIf.gitdir:/github/workspace/.git/worktrees/*.path /github/runner_temp/git-credentials-15532928-7e63-408c-ae6b-fbd2a5fd33f0.config
2026-02-12T19:19:32.4884867Z ##[endgroup]
2026-02-12T19:19:32.4885264Z ##[group]Fetching the repository
2026-02-12T19:19:32.4892293Z [command]/usr/bin/git -c protocol.version=2 fetch --no-tags --prune --no-recurse-submodules --depth=1 origin +41d056f94716d2ac74b73f26547a109c099e82dd:refs/remotes/origin/main
2026-02-12T19:19:34.2844096Z From https://gh-proxy.test.osinfra.cn/https://github.com/vllm-project/vllm-ascend
2026-02-12T19:19:34.2844698Z  * [new ref]         41d056f94716d2ac74b73f26547a109c099e82dd -> origin/main
2026-02-12T19:19:34.2863891Z [command]/usr/bin/git branch --list --remote origin/main
2026-02-12T19:19:34.2889351Z   origin/main
2026-02-12T19:19:34.2896343Z [command]/usr/bin/git rev-parse refs/remotes/origin/main
2026-02-12T19:19:34.2915058Z 41d056f94716d2ac74b73f26547a109c099e82dd
2026-02-12T19:19:34.2918879Z ##[endgroup]
2026-02-12T19:19:34.2919250Z ##[group]Determining the checkout info
2026-02-12T19:19:34.2920923Z ##[endgroup]
2026-02-12T19:19:34.2924123Z [command]/usr/bin/git sparse-checkout disable
2026-02-12T19:19:34.2968857Z [command]/usr/bin/git config --local --unset-all extensions.worktreeConfig
2026-02-12T19:19:34.2999254Z ##[group]Checking out the ref
2026-02-12T19:19:34.3002833Z [command]/usr/bin/git checkout --progress --force -B main refs/remotes/origin/main
2026-02-12T19:19:34.3853285Z Switched to a new branch 'main'
2026-02-12T19:19:34.3853682Z Branch 'main' set up to track remote branch 'main' from 'origin'.
2026-02-12T19:19:34.3862902Z ##[endgroup]
2026-02-12T19:19:34.3903585Z [command]/usr/bin/git log -1 --format=%H
2026-02-12T19:19:34.3924598Z 41d056f94716d2ac74b73f26547a109c099e82dd
2026-02-12T19:19:34.8551377Z ##[group]Run # prepare for lws entrypoint scripts
2026-02-12T19:19:34.8551844Z [36;1m# prepare for lws entrypoint scripts[0m
2026-02-12T19:19:34.8552389Z [36;1minstall -D tests/e2e/nightly/multi_node/scripts/run.sh /root/.cache/tests/run.sh[0m
2026-02-12T19:19:34.8552879Z shell: bash -el {0}
2026-02-12T19:19:34.8553111Z ##[endgroup]
2026-02-12T19:19:34.8632150Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-12T19:19:34.8633014Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-12T19:19:34.8633324Z ##[endgroup]
2026-02-12T19:19:35.2131356Z (node:472) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-12T19:19:35.2132194Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-12T19:19:36.1482213Z ##[group]Run set -euo pipefail
2026-02-12T19:19:36.1482591Z [36;1mset -euo pipefail[0m
2026-02-12T19:19:36.1482847Z [36;1m[0m
2026-02-12T19:19:36.1483077Z [36;1mCRD_NAME="${CRD_NAME:-vllm}"[0m
2026-02-12T19:19:36.1483342Z [36;1mTIMEOUT=${TIMEOUT:-120}[0m
2026-02-12T19:19:36.1483617Z [36;1mSLEEP_INTERVAL=2[0m
2026-02-12T19:19:36.1483848Z [36;1m[0m
2026-02-12T19:19:36.1484159Z [36;1mecho "Deleting leaderworkerset [$CRD_NAME] in namespace [$NAMESPACE]..."[0m
2026-02-12T19:19:36.1484651Z [36;1mkubectl delete leaderworkerset "$CRD_NAME" -n "$NAMESPACE" --ignore-not-found[0m
2026-02-12T19:19:36.1485017Z [36;1m[0m
2026-02-12T19:19:36.1485292Z [36;1mecho "Waiting for all pods starting with 'vllm' to be deleted..."[0m
2026-02-12T19:19:36.1485654Z [36;1mSTART_TIME=$(date +%s)[0m
2026-02-12T19:19:36.1485900Z [36;1m[0m
2026-02-12T19:19:36.1486092Z [36;1mwhile true; do[0m
2026-02-12T19:19:36.1486345Z [36;1m  NOW=$(date +%s)[0m
2026-02-12T19:19:36.1486673Z [36;1m  ELAPSED=$((NOW - START_TIME))[0m
2026-02-12T19:19:36.1486950Z [36;1m[0m
2026-02-12T19:19:36.1487160Z [36;1m  if [[ $ELAPSED -ge $TIMEOUT ]]; then[0m
2026-02-12T19:19:36.1487525Z [36;1m    echo "Timeout reached ($TIMEOUT seconds), some pods still exist:"[0m
2026-02-12T19:19:36.1487935Z [36;1m    kubectl get pods -n "$NAMESPACE" | grep '^vllm' || true[0m
2026-02-12T19:19:36.1488238Z [36;1m    exit 1[0m
2026-02-12T19:19:36.1488543Z [36;1m  fi[0m
2026-02-12T19:19:36.1488763Z [36;1m[0m
2026-02-12T19:19:36.1489195Z [36;1m  PODS_EXIST=$(kubectl get pods -n "$NAMESPACE" -o jsonpath='{.items[*].metadata.name}' 2>/dev/null | tr ' ' '\n' | grep '^vllm' || true)[0m
2026-02-12T19:19:36.1489673Z [36;1m[0m
2026-02-12T19:19:36.1489910Z [36;1m  if [[ -z "$PODS_EXIST" ]]; then[0m
2026-02-12T19:19:36.1490163Z [36;1m    echo "All vllm pods deleted."[0m
2026-02-12T19:19:36.1490439Z [36;1m    break[0m
2026-02-12T19:19:36.1490661Z [36;1m  else[0m
2026-02-12T19:19:36.1490913Z [36;1m    echo "Waiting for pods to be deleted: $PODS_EXIST"[0m
2026-02-12T19:19:36.1491246Z [36;1m    sleep $SLEEP_INTERVAL[0m
2026-02-12T19:19:36.1491501Z [36;1m  fi[0m
2026-02-12T19:19:36.1491686Z [36;1mdone[0m
2026-02-12T19:19:36.1492322Z shell: bash -el {0}
2026-02-12T19:19:36.1492575Z ##[endgroup]
2026-02-12T19:19:36.1611872Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-12T19:19:36.1612769Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-12T19:19:36.1613063Z ##[endgroup]
2026-02-12T19:19:36.5073110Z (node:526) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-12T19:19:36.5073863Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-12T19:19:37.0090047Z Deleting leaderworkerset [vllm] in namespace [vllm-project]...
2026-02-12T19:19:37.0927246Z Waiting for all pods starting with 'vllm' to be deleted...
2026-02-12T19:19:37.1579318Z All vllm pods deleted.
2026-02-12T19:19:37.5843979Z ##[group]Run set -e
2026-02-12T19:19:37.5844267Z [36;1mset -e[0m
2026-02-12T19:19:37.5844468Z [36;1m[0m
2026-02-12T19:19:37.5844685Z [36;1msize="2"[0m
2026-02-12T19:19:37.5844928Z [36;1mreplicas="1"[0m
2026-02-12T19:19:37.5845308Z [36;1mimage="swr.cn-southwest-2.myhuaweicloud.com/base_image/ascend-ci/vllm-ascend:nightly-a3"[0m
2026-02-12T19:19:37.5845804Z [36;1mconfig_file_path="DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml"[0m
2026-02-12T19:19:37.5846197Z [36;1mfail_tag=FAIL_TAG_"DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml"[0m
2026-02-12T19:19:37.5846530Z [36;1mecho "FAIL_TAG=${fail_tag}" >> "$GITHUB_ENV"[0m
2026-02-12T19:19:37.5846832Z [36;1m[0m
2026-02-12T19:19:37.5847119Z [36;1mrequired_params=("size" "replicas" "image" "config_file_path")[0m
2026-02-12T19:19:37.5847474Z [36;1mfor param in "${required_params[@]}"; do[0m
2026-02-12T19:19:37.5847779Z [36;1m  if [ -z "${!param}" ]; then[0m
2026-02-12T19:19:37.5848305Z [36;1m    echo "Error: Parameter '$param' is required but empty"[0m
2026-02-12T19:19:37.5848654Z [36;1m    exit 1[0m
2026-02-12T19:19:37.5849006Z [36;1m  fi[0m
2026-02-12T19:19:37.5849228Z [36;1mdone[0m
2026-02-12T19:19:37.5849445Z [36;1m[0m
2026-02-12T19:19:37.5849659Z [36;1mif [ "a3" = "a3" ]; then[0m
2026-02-12T19:19:37.5849925Z [36;1m  npu_per_node=16[0m
2026-02-12T19:19:37.5850275Z [36;1m  TEMPLATE_FILE="tests/e2e/nightly/multi_node/scripts/lws.yaml.jinja2"[0m
2026-02-12T19:19:37.5850612Z [36;1melse[0m
2026-02-12T19:19:37.5850828Z [36;1m  npu_per_node=8[0m
2026-02-12T19:19:37.5851156Z [36;1m  TEMPLATE_FILE="tests/e2e/nightly/multi_node/scripts/lws-a2.yaml.jinja2"[0m
2026-02-12T19:19:37.5851503Z [36;1mfi[0m
2026-02-12T19:19:37.5851702Z [36;1m[0m
2026-02-12T19:19:37.5851919Z [36;1mjinja2 $TEMPLATE_FILE \[0m
2026-02-12T19:19:37.5852331Z [36;1m  -D size="$size" \[0m
2026-02-12T19:19:37.5852608Z [36;1m  -D replicas="$replicas" \[0m
2026-02-12T19:19:37.5852886Z [36;1m  -D image="$image" \[0m
2026-02-12T19:19:37.5853161Z [36;1m  -D config_file_path="$config_file_path" \[0m
2026-02-12T19:19:37.5853471Z [36;1m  -D npu_per_node="$npu_per_node" \[0m
2026-02-12T19:19:37.5853747Z [36;1m  -D fail_tag="$fail_tag" \[0m
2026-02-12T19:19:37.5853991Z [36;1m  --outfile lws.yaml[0m
2026-02-12T19:19:37.5854229Z [36;1m[0m
2026-02-12T19:19:37.5854452Z [36;1mkubectl apply -f ./lws.yaml[0m
2026-02-12T19:19:37.5854811Z shell: bash -el {0}
2026-02-12T19:19:37.5855039Z ##[endgroup]
2026-02-12T19:19:37.5947139Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-12T19:19:37.5948198Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-12T19:19:37.5948525Z ##[endgroup]
2026-02-12T19:19:37.9421572Z (node:592) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-12T19:19:37.9422405Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-12T19:19:38.8620659Z leaderworkerset.leaderworkerset.x-k8s.io/vllm created
2026-02-12T19:19:38.8978718Z service/vllm-leader created
2026-02-12T19:19:40.5079778Z ##[group]Run POD_PREFIX="${POD_PREFIX:-vllm-0}"
2026-02-12T19:19:40.5080107Z [36;1mPOD_PREFIX="${POD_PREFIX:-vllm-0}"[0m
2026-02-12T19:19:40.5080305Z [36;1mSIZE="2"[0m
2026-02-12T19:19:40.5080491Z [36;1mTIMEOUT=1200  # default timeout 20 minutes[0m
2026-02-12T19:19:40.5080702Z [36;1m[0m
2026-02-12T19:19:40.5080998Z [36;1mecho "Waiting for Pods in namespace [$NAMESPACE] to become Running and Ready (timeout ${TIMEOUT}s)..."[0m
2026-02-12T19:19:40.5081340Z [36;1m[0m
2026-02-12T19:19:40.5081488Z [36;1mSTART_TIME=$(date +%s)[0m
2026-02-12T19:19:40.5081655Z [36;1m[0m
2026-02-12T19:19:40.5081793Z [36;1mwhile true; do[0m
2026-02-12T19:19:40.5081952Z [36;1m  NOW=$(date +%s)[0m
2026-02-12T19:19:40.5082316Z [36;1m  ELAPSED=$((NOW - START_TIME))[0m
2026-02-12T19:19:40.5082538Z [36;1m  if [[ $ELAPSED -ge $TIMEOUT ]]; then[0m
2026-02-12T19:19:40.5082786Z [36;1m    echo "Timeout reached after ${ELAPSED}s"[0m
2026-02-12T19:19:40.5083068Z [36;1m    echo "Dumping pod status for debugging:"[0m
2026-02-12T19:19:40.5083290Z [36;1m    kubectl get pods -n "$NAMESPACE"[0m
2026-02-12T19:19:40.5083542Z [36;1m    kubectl describe pod "$LEADER_POD" -n "$NAMESPACE"[0m
2026-02-12T19:19:40.5083774Z [36;1m    exit 1[0m
2026-02-12T19:19:40.5083914Z [36;1m  fi[0m
2026-02-12T19:19:40.5084050Z [36;1m[0m
2026-02-12T19:19:40.5084195Z [36;1m  # 1) check follower pods[0m
2026-02-12T19:19:40.5084379Z [36;1m  ALL_FOLLOWERS_READY=true[0m
2026-02-12T19:19:40.5084571Z [36;1m  for ((i=1; i<SIZE; i++)); do[0m
2026-02-12T19:19:40.5084761Z [36;1m    POD="${POD_PREFIX}-${i}"[0m
2026-02-12T19:19:40.5085124Z [36;1m    PHASE=$(kubectl get pod "$POD" -n "$NAMESPACE" -o jsonpath='{.status.phase}' 2>/dev/null || echo "NotFound")[0m
2026-02-12T19:19:40.5085650Z [36;1m    READY=$(kubectl get pod "$POD" -n "$NAMESPACE" -o jsonpath='{.status.containerStatuses[*].ready}' 2>/dev/null)[0m
2026-02-12T19:19:40.5086134Z [36;1m[0m
2026-02-12T19:19:40.5086318Z [36;1m    echo "Follower [$POD] phase=$PHASE ready=$READY"[0m
2026-02-12T19:19:40.5086549Z [36;1m[0m
2026-02-12T19:19:40.5086731Z [36;1m    if [[ "$PHASE" != "Running" || "$READY" != "true" ]]; then[0m
2026-02-12T19:19:40.5087006Z [36;1m      echo "Follower [$POD] not Ready yet..."[0m
2026-02-12T19:19:40.5087232Z [36;1m      ALL_FOLLOWERS_READY=false[0m
2026-02-12T19:19:40.5087413Z [36;1m      break[0m
2026-02-12T19:19:40.5087562Z [36;1m    fi[0m
2026-02-12T19:19:40.5087703Z [36;1m  done[0m
2026-02-12T19:19:40.5087831Z [36;1m[0m
2026-02-12T19:19:40.5087969Z [36;1m  # 2) check leader pod[0m
2026-02-12T19:19:40.5088351Z [36;1m  LEADER_PHASE=$(kubectl get pod "$LEADER_POD" -n "$NAMESPACE" -o jsonpath='{.status.phase}' 2>/dev/null || echo "NotFound")[0m
2026-02-12T19:19:40.5088933Z [36;1m  LEADER_READY=$(kubectl get pod "$LEADER_POD" -n "$NAMESPACE" -o jsonpath='{.status.containerStatuses[*].ready}' 2>/dev/null)[0m
2026-02-12T19:19:40.5089322Z [36;1m[0m
2026-02-12T19:19:40.5089615Z [36;1m  echo "Leader [$LEADER_POD] phase=$LEADER_PHASE ready=$LEADER_READY"[0m
2026-02-12T19:19:40.5089878Z [36;1m[0m
2026-02-12T19:19:40.5090088Z [36;1m  if [[ "$LEADER_PHASE" != "Running" || "$LEADER_READY" != "true" ]]; then[0m
2026-02-12T19:19:40.5090368Z [36;1m    echo "Leader not Ready yet..."[0m
2026-02-12T19:19:40.5090570Z [36;1m    ALL_FOLLOWERS_READY=false[0m
2026-02-12T19:19:40.5090754Z [36;1m  fi[0m
2026-02-12T19:19:40.5090882Z [36;1m[0m
2026-02-12T19:19:40.5091048Z [36;1m  if [[ "$ALL_FOLLOWERS_READY" == "true" ]]; then[0m
2026-02-12T19:19:40.5091369Z [36;1m    echo "All follower pods and leader pod are Running and Ready â€” continuing."[0m
2026-02-12T19:19:40.5091651Z [36;1m    break[0m
2026-02-12T19:19:40.5091801Z [36;1m  fi[0m
2026-02-12T19:19:40.5091936Z [36;1m[0m
2026-02-12T19:19:40.5092180Z [36;1m  sleep 2[0m
2026-02-12T19:19:40.5092332Z [36;1mdone[0m
2026-02-12T19:19:40.5092617Z shell: bash -el {0}
2026-02-12T19:19:40.5092758Z env:
2026-02-12T19:19:40.5093087Z   FAIL_TAG: FAIL_TAG_DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-02-12T19:19:40.5093314Z ##[endgroup]
2026-02-12T19:19:40.5174128Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-12T19:19:40.5174942Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-12T19:19:40.5175188Z ##[endgroup]
2026-02-12T19:19:40.8680598Z (node:704) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-12T19:19:40.8681325Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-12T19:19:41.4004930Z Waiting for Pods in namespace [vllm-project] to become Running and Ready (timeout 1200s)...
2026-02-12T19:19:41.5346126Z Follower [vllm-0-1] phase=Pending ready=
2026-02-12T19:19:41.5346427Z Follower [vllm-0-1] not Ready yet...
2026-02-12T19:19:41.6473620Z Leader [vllm-0] phase=Pending ready=
2026-02-12T19:19:41.6473847Z Leader not Ready yet...
2026-02-12T19:19:43.7721668Z Follower [vllm-0-1] phase=Pending ready=
2026-02-12T19:19:43.7721939Z Follower [vllm-0-1] not Ready yet...
2026-02-12T19:19:43.8805773Z Leader [vllm-0] phase=Pending ready=
2026-02-12T19:19:43.8806031Z Leader not Ready yet...
2026-02-12T19:19:45.9915265Z Follower [vllm-0-1] phase=Pending ready=
2026-02-12T19:19:45.9915529Z Follower [vllm-0-1] not Ready yet...
2026-02-12T19:19:46.1084637Z Leader [vllm-0] phase=Pending ready=
2026-02-12T19:19:46.1084892Z Leader not Ready yet...
2026-02-12T19:19:48.2256698Z Follower [vllm-0-1] phase=Pending ready=
2026-02-12T19:19:48.2256972Z Follower [vllm-0-1] not Ready yet...
2026-02-12T19:19:48.3400877Z Leader [vllm-0] phase=Pending ready=
2026-02-12T19:19:48.3401141Z Leader not Ready yet...
2026-02-12T19:19:50.4524837Z Follower [vllm-0-1] phase=Pending ready=
2026-02-12T19:19:50.4525103Z Follower [vllm-0-1] not Ready yet...
2026-02-12T19:19:50.5594979Z Leader [vllm-0] phase=Pending ready=
2026-02-12T19:19:50.5595515Z Leader not Ready yet...
2026-02-12T19:19:52.6817968Z Follower [vllm-0-1] phase=Pending ready=
2026-02-12T19:19:52.6818243Z Follower [vllm-0-1] not Ready yet...
2026-02-12T19:19:52.7926256Z Leader [vllm-0] phase=Pending ready=false
2026-02-12T19:19:52.7926488Z Leader not Ready yet...
2026-02-12T19:19:54.9067909Z Follower [vllm-0-1] phase=Pending ready=false
2026-02-12T19:19:54.9068313Z Follower [vllm-0-1] not Ready yet...
2026-02-12T19:19:55.0252363Z Leader [vllm-0] phase=Running ready=true
2026-02-12T19:19:57.1386586Z Follower [vllm-0-1] phase=Running ready=true
2026-02-12T19:19:57.2542752Z Leader [vllm-0] phase=Running ready=true
2026-02-12T19:19:57.2543371Z All follower pods and leader pod are Running and Ready â€” continuing.
2026-02-12T19:19:57.7143092Z ##[group]Run set -euo pipefail
2026-02-12T19:19:57.7143526Z [36;1mset -euo pipefail[0m
2026-02-12T19:19:57.7143749Z [36;1m[0m
2026-02-12T19:19:57.7143987Z [36;1msize="2"[0m
2026-02-12T19:19:57.7144264Z [36;1mpids=()[0m
2026-02-12T19:19:57.7144512Z [36;1m[0m
2026-02-12T19:19:57.7144736Z [36;1mcleanup() {[0m
2026-02-12T19:19:57.7145011Z [36;1m  echo "Cleaning up background log streams..."[0m
2026-02-12T19:19:57.7145345Z [36;1m  for pid in "${pids[@]}"; do[0m
2026-02-12T19:19:57.7145638Z [36;1m    kill "$pid" 2>/dev/null || true[0m
2026-02-12T19:19:57.7145911Z [36;1m  done[0m
2026-02-12T19:19:57.7146129Z [36;1m}[0m
2026-02-12T19:19:57.7146356Z [36;1mtrap cleanup EXIT[0m
2026-02-12T19:19:57.7146586Z [36;1m[0m
2026-02-12T19:19:57.7146816Z [36;1mfor i in $(seq 1 $((size - 1))); do[0m
2026-02-12T19:19:57.7147056Z [36;1m  POD="vllm-0-${i}"[0m
2026-02-12T19:19:57.7147337Z [36;1m[0m
2026-02-12T19:19:57.7147684Z [36;1m  echo "==== Collecting logs from worker pod: $POD ===="[0m
2026-02-12T19:19:57.7148050Z [36;1m  kubectl logs -f "$POD" -n "$NAMESPACE" \[0m
2026-02-12T19:19:57.7148361Z [36;1m    > "/tmp/${POD}_logs.txt" 2>&1 &[0m
2026-02-12T19:19:57.7148626Z [36;1m[0m
2026-02-12T19:19:57.7148839Z [36;1m  pids+=($!)[0m
2026-02-12T19:19:57.7149076Z [36;1mdone[0m
2026-02-12T19:19:57.7149249Z [36;1m[0m
2026-02-12T19:19:57.7149581Z [36;1mecho "==== Streaming logs from leader pod: $LEADER_POD ===="[0m
2026-02-12T19:19:57.7149945Z [36;1mecho "Looking for logs containing: $FAIL_TAG"[0m
2026-02-12T19:19:57.7150194Z [36;1m[0m
2026-02-12T19:19:57.7150546Z [36;1mkubectl logs -f "$LEADER_POD" -n "$NAMESPACE" | while IFS= read -r line; do[0m
2026-02-12T19:19:57.7150909Z [36;1m  echo "$line"[0m
2026-02-12T19:19:57.7151172Z [36;1m  if echo "$line" | grep -q "$FAIL_TAG"; then[0m
2026-02-12T19:19:57.7151470Z [36;1m    exit 1[0m
2026-02-12T19:19:57.7151707Z [36;1m  fi[0m
2026-02-12T19:19:57.7151901Z [36;1mdone[0m
2026-02-12T19:19:57.7152485Z shell: bash -el {0}
2026-02-12T19:19:57.7152689Z env:
2026-02-12T19:19:57.7153032Z   FAIL_TAG: FAIL_TAG_DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-02-12T19:19:57.7153366Z ##[endgroup]
2026-02-12T19:19:57.7238372Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-12T19:19:57.7239159Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-12T19:19:57.7239594Z ##[endgroup]
2026-02-12T19:19:58.0790361Z (node:798) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-12T19:19:58.0791066Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-12T19:19:58.6141294Z ==== Collecting logs from worker pod: vllm-0-1 ====
2026-02-12T19:19:58.6141764Z ==== Streaming logs from leader pod: vllm-0 ====
2026-02-12T19:19:58.6142508Z Looking for logs containing: FAIL_TAG_DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-02-12T19:19:58.6888494Z /usr/local/Ascend/ascend-toolkit/set_env.sh: line 31: CMAKE_PREFIX_PATH: unbound variable
2026-02-12T19:19:58.6901848Z ====> Check NPU info
2026-02-12T19:19:58.6912053Z +------------------------------------------------------------------------------------------------+
2026-02-12T19:19:58.6922248Z | npu-smi 25.5.0                   Version: 25.5.0                                               |
2026-02-12T19:19:58.6931785Z +---------------------------+---------------+----------------------------------------------------+
2026-02-12T19:19:58.6942079Z | NPU   Name                | Health        | Power(W)    Temp(C)           Hugepages-Usage(page)|
2026-02-12T19:19:58.6953031Z | Chip  Phy-ID              | Bus-Id        | AICore(%)   Memory-Usage(MB)  HBM-Usage(MB)        |
2026-02-12T19:19:58.6964476Z +===========================+===============+====================================================+
2026-02-12T19:19:58.7013964Z | 0     Ascend910           | OK            | 165.0       36                0    / 0             |
2026-02-12T19:19:58.7014648Z | 0     0                   | 0000:9D:00.0  | 0           0    / 0          3158 / 65536         |
2026-02-12T19:19:58.7015007Z +------------------------------------------------------------------------------------------------+
2026-02-12T19:19:58.7015381Z | 0     Ascend910           | OK            | -           36                0    / 0             |
2026-02-12T19:19:58.7015690Z | 1     1                   | 0000:9F:00.0  | 0           0    / 0          2893 / 65536         |
2026-02-12T19:19:58.7023108Z +===========================+===============+====================================================+
2026-02-12T19:19:58.7033292Z | 1     Ascend910           | OK            | 163.2       36                0    / 0             |
2026-02-12T19:19:58.7042266Z | 0     2                   | 0000:99:00.0  | 0           0    / 0          3166 / 65536         |
2026-02-12T19:19:58.7052909Z +------------------------------------------------------------------------------------------------+
2026-02-12T19:19:58.7062754Z | 1     Ascend910           | OK            | -           36                0    / 0             |
2026-02-12T19:19:58.7072594Z | 1     3                   | 0000:9B:00.0  | 0           0    / 0          2883 / 65536         |
2026-02-12T19:19:58.7082994Z +===========================+===============+====================================================+
2026-02-12T19:19:58.7091603Z | 2     Ascend910           | OK            | 161.5       35                0    / 0             |
2026-02-12T19:19:58.7101074Z | 0     4                   | 0000:95:00.0  | 0           0    / 0          3150 / 65536         |
2026-02-12T19:19:58.7110991Z +------------------------------------------------------------------------------------------------+
2026-02-12T19:19:58.7120627Z | 2     Ascend910           | OK            | -           36                0    / 0             |
2026-02-12T19:19:58.7131252Z | 1     5                   | 0000:97:00.0  | 0           0    / 0          2893 / 65536         |
2026-02-12T19:19:58.7141915Z +===========================+===============+====================================================+
2026-02-12T19:19:58.7150585Z | 3     Ascend910           | OK            | 164.9       35                0    / 0             |
2026-02-12T19:19:58.7160241Z | 0     6                   | 0000:91:00.0  | 0           0    / 0          3162 / 65536         |
2026-02-12T19:19:58.7169336Z +------------------------------------------------------------------------------------------------+
2026-02-12T19:19:58.7178523Z | 3     Ascend910           | OK            | -           34                0    / 0             |
2026-02-12T19:19:58.7189632Z | 1     7                   | 0000:93:00.0  | 0           0    / 0          2882 / 65536         |
2026-02-12T19:19:58.7199626Z +===========================+===============+====================================================+
2026-02-12T19:19:58.7209932Z | 4     Ascend910           | OK            | 167.4       34                0    / 0             |
2026-02-12T19:19:58.7219134Z | 0     8                   | 0000:8D:00.0  | 0           0    / 0          3154 / 65536         |
2026-02-12T19:19:58.7228994Z +------------------------------------------------------------------------------------------------+
2026-02-12T19:19:58.7239631Z | 4     Ascend910           | OK            | -           36                0    / 0             |
2026-02-12T19:19:58.7248711Z | 1     9                   | 0000:8F:00.0  | 0           0    / 0          2893 / 65536         |
2026-02-12T19:19:58.7258148Z +===========================+===============+====================================================+
2026-02-12T19:19:58.7269113Z | 5     Ascend910           | OK            | 166.6       34                0    / 0             |
2026-02-12T19:19:58.7279002Z | 0     10                  | 0000:89:00.0  | 0           0    / 0          3147 / 65536         |
2026-02-12T19:19:58.7289606Z +------------------------------------------------------------------------------------------------+
2026-02-12T19:19:58.7298672Z | 5     Ascend910           | OK            | -           38                0    / 0             |
2026-02-12T19:19:58.7309232Z | 1     11                  | 0000:8B:00.0  | 0           0    / 0          2894 / 65536         |
2026-02-12T19:19:58.7319451Z +===========================+===============+====================================================+
2026-02-12T19:19:58.7328822Z | 6     Ascend910           | OK            | 162.2       36                0    / 0             |
2026-02-12T19:19:58.7337784Z | 0     12                  | 0000:85:00.0  | 0           0    / 0          3149 / 65536         |
2026-02-12T19:19:58.7347557Z +------------------------------------------------------------------------------------------------+
2026-02-12T19:19:58.7357487Z | 6     Ascend910           | OK            | -           36                0    / 0             |
2026-02-12T19:19:58.7367503Z | 1     13                  | 0000:87:00.0  | 0           0    / 0          2895 / 65536         |
2026-02-12T19:19:58.7377194Z +===========================+===============+====================================================+
2026-02-12T19:19:58.7386892Z | 7     Ascend910           | OK            | 159.2       35                0    / 0             |
2026-02-12T19:19:58.7396984Z | 0     14                  | 0000:81:00.0  | 0           0    / 0          3159 / 65536         |
2026-02-12T19:19:58.7406735Z +------------------------------------------------------------------------------------------------+
2026-02-12T19:19:58.7415743Z | 7     Ascend910           | OK            | -           36                0    / 0             |
2026-02-12T19:19:58.7425973Z | 1     15                  | 0000:83:00.0  | 0           0    / 0          2883 / 65536         |
2026-02-12T19:19:58.7435392Z +===========================+===============+====================================================+
2026-02-12T19:19:58.7445958Z +---------------------------+---------------+----------------------------------------------------+
2026-02-12T19:19:58.7456343Z | NPU     Chip              | Process id    | Process name             | Process memory(MB)      |
2026-02-12T19:19:58.7465626Z +===========================+===============+====================================================+
2026-02-12T19:19:58.7475484Z | No running processes found in NPU 0                                                            |
2026-02-12T19:19:58.7484795Z +===========================+===============+====================================================+
2026-02-12T19:19:58.7494955Z | No running processes found in NPU 1                                                            |
2026-02-12T19:19:58.7504952Z +===========================+===============+====================================================+
2026-02-12T19:19:58.7514777Z | No running processes found in NPU 2                                                            |
2026-02-12T19:19:58.7526288Z +===========================+===============+====================================================+
2026-02-12T19:19:58.7536052Z | No running processes found in NPU 3                                                            |
2026-02-12T19:19:58.7546058Z +===========================+===============+====================================================+
2026-02-12T19:19:58.7556027Z | No running processes found in NPU 4                                                            |
2026-02-12T19:19:58.7565409Z +===========================+===============+====================================================+
2026-02-12T19:19:58.7575076Z | No running processes found in NPU 5                                                            |
2026-02-12T19:19:58.7584630Z +===========================+===============+====================================================+
2026-02-12T19:19:58.7594025Z | No running processes found in NPU 6                                                            |
2026-02-12T19:19:58.7603586Z +===========================+===============+====================================================+
2026-02-12T19:19:58.7613612Z | No running processes found in NPU 7                                                            |
2026-02-12T19:19:58.7622964Z +===========================+===============+====================================================+
2026-02-12T19:19:58.7632546Z package_name=Ascend-cann-toolkit
2026-02-12T19:19:58.7642769Z version=8.5.0
2026-02-12T19:19:58.7651690Z innerversion=V100R001C25SPC001B232
2026-02-12T19:19:58.7661238Z compatible_version=[V100R001C15],[V100R001C18],[V100R001C19],[V100R001C20],[V100R001C21],[V100R001C23]
2026-02-12T19:19:58.7671163Z arch=aarch64
2026-02-12T19:19:58.7681932Z os=linux
2026-02-12T19:19:58.7690777Z path=/usr/local/Ascend/cann-8.5.0
2026-02-12T19:19:58.7700225Z ====> Configure mirrors and git proxy
2026-02-12T19:19:58.7709751Z Writing to /root/.config/pip/pip.conf
2026-02-12T19:19:58.7719356Z Installed vLLM-related Python packages:
2026-02-12T19:19:58.7729507Z ais_bench_benchmark               3.0.20250930                /vllm-workspace/vllm-ascend/benchmark
2026-02-12T19:19:58.7739100Z vllm                              0.15.0+empty                /vllm-workspace/vllm
2026-02-12T19:19:58.7748711Z vllm_ascend                       0.14.0rc2.dev160+g41d056f94 /vllm-workspace/vllm-ascend
2026-02-12T19:19:58.7758571Z 
2026-02-12T19:19:58.7769030Z ============================
2026-02-12T19:19:58.7778770Z vLLM Git information
2026-02-12T19:19:58.7789711Z ============================
2026-02-12T19:19:58.7798710Z Branch:      HEAD
2026-02-12T19:19:58.7808653Z Commit hash: f176443446f659dbab5315e056e605d8984fd976
2026-02-12T19:19:58.7818233Z Author:      TJian <tunjian.tan@embeddedllm.com>
2026-02-12T19:19:58.7827721Z Date:        2026-01-29 14:45:42 +0800
2026-02-12T19:19:58.7837458Z Message:     [Release] [CI] Optim release pipeline (#33156)
2026-02-12T19:19:58.7847488Z Tags:        v0.15.0
2026-02-12T19:19:58.7857342Z Remote:      origin	https://ghfast.top/https://github.com/vllm-project/vllm.git (fetch)
2026-02-12T19:19:58.7866769Z 
2026-02-12T19:19:58.7876922Z 
2026-02-12T19:19:58.7886955Z ============================
2026-02-12T19:19:58.7896251Z vLLM-Ascend Git information
2026-02-12T19:19:58.7905710Z ============================
2026-02-12T19:19:58.7914867Z Branch:      main
2026-02-12T19:19:58.7925665Z Commit hash: 41d056f94716d2ac74b73f26547a109c099e82dd
2026-02-12T19:19:58.7935215Z Author:      taoyao1221 <taoyao1221@gmail.com>
2026-02-12T19:19:58.7944960Z Date:        2026-02-12 16:08:17 +0800
2026-02-12T19:19:58.7954949Z Message:     [doc] add A2 series doc for GLM5.md (#6717)
2026-02-12T19:19:58.7964480Z Tags:        
2026-02-12T19:19:58.7974685Z Remote:      origin	https://ghfast.top/https://github.com/vllm-project/vllm-ascend (fetch)
2026-02-12T19:19:58.7983573Z 
2026-02-12T19:19:58.7992910Z ====> Check triton ascend info
2026-02-12T19:19:58.8003052Z Ubuntu clang version 15.0.7
2026-02-12T19:19:58.8012790Z Target: aarch64-unknown-linux-gnu
2026-02-12T19:19:58.8022268Z Thread model: posix
2026-02-12T19:19:58.8032864Z InstalledDir: /usr/bin
2026-02-12T19:19:58.8041981Z Found candidate GCC installation: /usr/bin/../lib/gcc/aarch64-linux-gnu/11
2026-02-12T19:19:58.8051807Z Selected GCC installation: /usr/bin/../lib/gcc/aarch64-linux-gnu/11
2026-02-12T19:19:58.8061248Z Candidate multilib: .;@m64
2026-02-12T19:19:58.8070036Z Selected multilib: .;@m64
2026-02-12T19:19:58.8080800Z /usr/local/Ascend/cann-8.5.0/tools/bishengir/bin/bishengir-compile
2026-02-12T19:19:59.1305863Z Name: triton-ascend
2026-02-12T19:19:59.1317822Z Version: 3.2.0
2026-02-12T19:19:59.1327665Z Summary: A language and compiler for custom Deep Learning operations on Ascend hardwares
2026-02-12T19:19:59.1336566Z Home-page: https://gitcode.com/Ascend/triton-ascend/
2026-02-12T19:19:59.1346300Z Author: 
2026-02-12T19:19:59.1355250Z Author-email: 
2026-02-12T19:19:59.1364830Z License: 
2026-02-12T19:19:59.1373575Z Location: /usr/local/python3.11.14/lib/python3.11/site-packages
2026-02-12T19:19:59.1383146Z Requires: 
2026-02-12T19:19:59.1391968Z Required-by: vllm_ascend
2026-02-12T19:20:18.3246517Z INFO 02-12 19:20:18 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-12T19:20:18.3337692Z INFO 02-12 19:20:18 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-12T19:20:18.3349902Z INFO 02-12 19:20:18 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-12T19:20:18.3733280Z INFO 02-12 19:20:18 [__init__.py:217] Platform plugin ascend is activated
2026-02-12T19:20:25.1516882Z ============================= test session starts ==============================
2026-02-12T19:20:25.1526345Z platform linux -- Python 3.11.14, pytest-8.4.2, pluggy-1.6.0 -- /usr/local/python3.11.14/bin/python3
2026-02-12T19:20:25.1535416Z cachedir: .pytest_cache
2026-02-12T19:20:25.1545366Z rootdir: /vllm-workspace/vllm-ascend
2026-02-12T19:20:25.1554915Z configfile: pyproject.toml
2026-02-12T19:20:25.1564884Z plugins: cov-7.0.0, mock-3.15.1, asyncio-1.3.0, anyio-4.12.1
2026-02-12T19:20:25.1575045Z asyncio: mode=Mode.STRICT, debug=False, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function
2026-02-12T19:20:26.0427399Z collecting ... collected 1 item
2026-02-12T19:20:26.0439100Z 
2026-02-12T19:20:26.0453567Z [2026-02-12 19:20:26] INFO multi_node_config.py:294: Loading config yaml: tests/e2e/nightly/multi_node/config/DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-02-12T19:20:26.0503602Z [2026-02-12 19:20:26] INFO multi_node_config.py:351: Resolving cluster IPs via DNS...
2026-02-12T19:20:26.0604601Z [2026-02-12 19:20:26] INFO multi_node_config.py:212: Node 0 envs: {'HCCL_OP_EXPANSION_MODE': 'AIV', 'VLLM_USE_MODELSCOPE': 'True', 'HCCL_BUFFSIZE': '1024', 'SERVER_PORT': '8080', 'OMP_PROC_BIND': 'False', 'OMP_NUM_THREADS': '1', 'PYTORCH_NPU_ALLOC_CONF': 'expandable_segments:True', 'VLLM_ASCEND_ENABLE_FLASHCOMM1': '1', 'ASCEND_A3_EBA_ENABLE': '1', 'HCCL_IF_IP': '10.0.0.210', 'HCCL_SOCKET_IFNAME': 'eth0', 'GLOO_SOCKET_IFNAME': 'eth0', 'TP_SOCKET_IFNAME': 'eth0', 'LOCAL_IP': '10.0.0.210', 'NIC_NAME': 'eth0', 'MASTER_IP': '10.0.0.210'}
2026-02-12T19:20:26.0623332Z [2026-02-12 19:20:26] INFO multi_node_config.py:137: Not launching proxy on non-master node
2026-02-12T19:20:26.0649818Z [2026-02-12 19:20:26] INFO conftest.py:241: Starting server with command: vllm serve vllm-ascend/DeepSeek-V3.2-W8A8 --host 0.0.0.0 --port 8080 --data-parallel-size 4 --data-parallel-size-local 2 --data-parallel-address 10.0.0.210 --data-parallel-rpc-port 13399 --tensor-parallel-size 8 --quantization ascend --seed 1024 --enable-expert-parallel --max-num-seqs 16 --max-model-len 8192 --max-num-batched-tokens 4096 --no-enable-prefix-caching --gpu-memory-utilization 0.85 --trust-remote-code --speculative-config {"num_speculative_tokens": 2, "method":"deepseek_mtp"} --compilation-config {"cudagraph_capture_sizes": [3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45, 48], "cudagraph_mode": "FULL_DECODE_ONLY"} --additional-config {"layer_sharding": ["q_b_proj", "o_proj"]} --tokenizer-mode deepseek_v32 --reasoning-parser deepseek_v3
2026-02-12T19:20:30.5861601Z tests/e2e/nightly/multi_node/scripts/test_multi_node.py::test_multi_node INFO 02-12 19:20:30 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-12T19:20:30.5872519Z INFO 02-12 19:20:30 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-12T19:20:30.5883533Z INFO 02-12 19:20:30 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-12T19:20:30.5925734Z INFO 02-12 19:20:30 [__init__.py:217] Platform plugin ascend is activated
2026-02-12T19:20:37.0059139Z 2026-02-12 19:20:37,003 - 138 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-12T19:20:37.0363292Z INFO 02-12 19:20:37 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-12T19:20:37.1771798Z INFO 02-12 19:20:37 [serve.py:100] Defaulting api_server_count to data_parallel_size (4).
2026-02-12T19:20:37.1794032Z INFO 02-12 19:20:37 [utils.py:325] 
2026-02-12T19:20:37.1805209Z INFO 02-12 19:20:37 [utils.py:325]        â–ˆ     â–ˆ     â–ˆâ–„   â–„â–ˆ
2026-02-12T19:20:37.1814656Z INFO 02-12 19:20:37 [utils.py:325]  â–„â–„ â–„â–ˆ â–ˆ     â–ˆ     â–ˆ â–€â–„â–€ â–ˆ  version 0.15.0
2026-02-12T19:20:37.1824747Z INFO 02-12 19:20:37 [utils.py:325]   â–ˆâ–„â–ˆâ–€ â–ˆ     â–ˆ     â–ˆ     â–ˆ  model   vllm-ascend/DeepSeek-V3.2-W8A8
2026-02-12T19:20:37.1834067Z INFO 02-12 19:20:37 [utils.py:325]    â–€â–€  â–€â–€â–€â–€â–€ â–€â–€â–€â–€â–€ â–€     â–€
2026-02-12T19:20:37.1844646Z INFO 02-12 19:20:37 [utils.py:325] 
2026-02-12T19:20:37.1872266Z INFO 02-12 19:20:37 [utils.py:261] non-default args: {'model_tag': 'vllm-ascend/DeepSeek-V3.2-W8A8', 'api_server_count': 4, 'host': '0.0.0.0', 'port': 8080, 'model': 'vllm-ascend/DeepSeek-V3.2-W8A8', 'tokenizer_mode': 'deepseek_v32', 'trust_remote_code': True, 'seed': 1024, 'max_model_len': 8192, 'quantization': 'ascend', 'reasoning_parser': 'deepseek_v3', 'tensor_parallel_size': 8, 'data_parallel_size': 4, 'data_parallel_size_local': 2, 'data_parallel_address': '10.0.0.210', 'data_parallel_rpc_port': 13399, 'enable_expert_parallel': True, 'gpu_memory_utilization': 0.85, 'enable_prefix_caching': False, 'max_num_batched_tokens': 4096, 'max_num_seqs': 16, 'speculative_config': {'num_speculative_tokens': 2, 'method': 'deepseek_mtp'}, 'compilation_config': {'level': None, 'mode': None, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'vllm_ascend.compilation.compiler_interface.AscendCompiler', 'custom_ops': [], 'splitting_ops': None, 'compile_mm_encoder': False, 'compile_sizes': None, 'compile_ranges_split_points': None, 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_DECODE_ONLY: (2, 0)>, 'cudagraph_num_of_warmups': 0, 'cudagraph_capture_sizes': [3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45, 48], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': None, 'pass_config': {}, 'max_cudagraph_capture_size': None, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>, 'evaluate_guards': False, 'assume_32_bit_indexing': True}, 'local_cache_dir': None}, 'additional_config': {'layer_sharding': ['q_b_proj', 'o_proj']}}
2026-02-12T19:20:37.2268859Z 2026-02-12 19:20:37,225 - modelscope - WARNING - We can not confirm the cached file is for revision: master
2026-02-12T19:20:37.2278237Z INFO 02-12 19:20:37 [arg_utils.py:602] HF_HUB_OFFLINE is True, replace model_id [vllm-ascend/DeepSeek-V3.2-W8A8] to model_path [/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8]
2026-02-12T19:20:37.2288631Z The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-12T19:20:37.2330205Z The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-12T19:20:37.2350290Z The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-12T19:20:37.2360353Z You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-12T19:20:46.2718954Z INFO 02-12 19:20:46 [model.py:541] Resolved architecture: DeepseekV32ForCausalLM
2026-02-12T19:20:46.2740257Z INFO 02-12 19:20:46 [model.py:1561] Using max model len 8192
2026-02-12T19:20:46.5603918Z WARNING 02-12 19:20:46 [speculative.py:270] method `deepseek_mtp` is deprecated and replaced with mtp.
2026-02-12T19:20:46.5625909Z The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-12T19:20:46.5635376Z The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-12T19:20:46.5648501Z You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-12T19:20:56.0453109Z INFO 02-12 19:20:56 [model.py:541] Resolved architecture: DeepSeekMTPModel
2026-02-12T19:20:56.0474195Z INFO 02-12 19:20:56 [model.py:1561] Using max model len 163840
2026-02-12T19:20:56.0485729Z WARNING 02-12 19:20:56 [speculative.py:388] Enabling num_speculative_tokens > 1 will runmultiple times of forward on same MTP layer,which may result in lower acceptance rate
2026-02-12T19:20:56.0495161Z INFO 02-12 19:20:56 [scheduler.py:226] Chunked prefill is enabled with max_num_batched_tokens=4096.
2026-02-12T19:20:56.3760207Z INFO 02-12 19:20:56 [vllm.py:624] Asynchronous scheduling is enabled.
2026-02-12T19:20:56.3768359Z INFO 02-12 19:20:56 [vllm.py:634] Disabling NCCL for DP synchronization when using async scheduling.
2026-02-12T19:20:56.3778081Z WARNING 02-12 19:20:56 [platform.py:734] Speculative quantization is set but Ascend automatically uses the main model's quantization method. Resetting to None.
2026-02-12T19:20:56.3789346Z WARNING 02-12 19:20:56 [platform.py:775] Ignored parameter 'use_trtllm_ragged_deepseek_prefill'. This is a GPU-specific feature not supported on Ascend. Resetting to False.
2026-02-12T19:20:56.3798239Z INFO 02-12 19:20:56 [ascend_config.py:412] Dynamic EPLB is False
2026-02-12T19:20:56.3807116Z INFO 02-12 19:20:56 [ascend_config.py:413] The number of redundant experts is 0
2026-02-12T19:20:56.3817680Z INFO 02-12 19:20:56 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-12T19:20:56.3827403Z WARNING 02-12 19:20:56 [vllm.py:1062] Batch sizes [3, 6, 9, 12, 15, 18, 21, 27, 30, 33, 36, 39, 42, 45] are removed because they are not multiple of tp_size 8 when sequence parallelism is enabled
2026-02-12T19:20:56.3836931Z INFO 02-12 19:20:56 [platform.py:322] FULL_DECODE_ONLY compilation enabled on NPU. use_inductor not supported - using only ACL Graph mode
2026-02-12T19:20:56.3847297Z WARNING 02-12 19:20:56 [platform.py:339] [91m
2026-02-12T19:20:56.3856449Z WARNING 02-12 19:20:56 [platform.py:339]             **********************************************************************************
2026-02-12T19:20:56.3866140Z WARNING 02-12 19:20:56 [platform.py:339]             * WARNING: You have enabled the *full graph* feature.
2026-02-12T19:20:56.3875901Z WARNING 02-12 19:20:56 [platform.py:339]             * This is an early experimental stage and may involve various unknown issues.
2026-02-12T19:20:56.3886095Z WARNING 02-12 19:20:56 [platform.py:339]             * A known problem is that capturing too many batch sizes can lead to OOM
2026-02-12T19:20:56.3895739Z WARNING 02-12 19:20:56 [platform.py:339]             * (Out of Memory) errors or inference hangs. If you encounter such issues,
2026-02-12T19:20:56.3904615Z WARNING 02-12 19:20:56 [platform.py:339]             * consider reducing `gpu_memory_utilization` or manually specifying a smaller
2026-02-12T19:20:56.3913502Z WARNING 02-12 19:20:56 [platform.py:339]             * batch size for graph capture.
2026-02-12T19:20:56.3924085Z WARNING 02-12 19:20:56 [platform.py:339]             * For more details, please refer to:
2026-02-12T19:20:56.3935020Z WARNING 02-12 19:20:56 [platform.py:339]             * https://docs.vllm.ai/en/stable/configuration/conserving_memory.html#reduce-cuda-graphs
2026-02-12T19:20:56.3944126Z WARNING 02-12 19:20:56 [platform.py:339]             **********************************************************************************[0m
2026-02-12T19:20:56.3953289Z WARNING 02-12 19:20:56 [platform.py:339]             
2026-02-12T19:20:56.3963642Z INFO 02-12 19:20:56 [platform.py:447] Set PYTORCH_NPU_ALLOC_CONF=expandable_segments:True
2026-02-12T19:20:56.3973512Z INFO 02-12 19:20:56 [utils.py:851] Started DP Coordinator process (PID: 165)
2026-02-12T19:21:01.0975438Z INFO 02-12 19:21:01 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-12T19:21:01.0984969Z INFO 02-12 19:21:01 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-12T19:21:01.0995475Z INFO 02-12 19:21:01 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-12T19:21:01.1045370Z INFO 02-12 19:21:01 [__init__.py:217] Platform plugin ascend is activated
2026-02-12T19:21:01.2687405Z INFO 02-12 19:21:01 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-12T19:21:01.2696455Z INFO 02-12 19:21:01 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-12T19:21:01.2706925Z INFO 02-12 19:21:01 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-12T19:21:01.2772509Z INFO 02-12 19:21:01 [__init__.py:217] Platform plugin ascend is activated
2026-02-12T19:21:10.8913051Z INFO 02-12 19:21:10 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-12T19:21:10.8923269Z INFO 02-12 19:21:10 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-12T19:21:10.8934879Z INFO 02-12 19:21:10 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-12T19:21:10.8979193Z INFO 02-12 19:21:10 [__init__.py:217] Platform plugin ascend is activated
2026-02-12T19:21:16.1330835Z INFO 02-12 19:21:16 [utils.py:218] Started 4 API server processes
2026-02-12T19:21:16.3222534Z [0;36m(EngineCore_DP0 pid=168)[0;0m 2026-02-12 19:21:16,320 - 168 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-12T19:21:16.3247744Z [0;36m(EngineCore_DP1 pid=187)[0;0m 2026-02-12 19:21:16,323 - 187 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-12T19:21:16.3278279Z [0;36m(EngineCore_DP0 pid=168)[0;0m INFO 02-12 19:21:16 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-12T19:21:16.3303958Z [0;36m(EngineCore_DP0 pid=168)[0;0m INFO 02-12 19:21:16 [core.py:96] Initializing a V1 LLM engine (v0.15.0) with config: model='/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8', speculative_config=SpeculativeConfig(method='mtp', model='/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8', num_spec_tokens=2), tokenizer='/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8', skip_tokenizer_init=False, tokenizer_mode=deepseek_v32, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=8, pipeline_parallel_size=1, data_parallel_size=4, disable_custom_all_reduce=True, quantization=ascend, enforce_eager=False, enable_return_routed_experts=False, kv_cache_dtype=bfloat16, device_config=npu, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='deepseek_v3', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01, cudagraph_metrics=False, enable_layerwise_nvtx_tracing=False, enable_mfu_metrics=False, enable_mm_processor_stats=False, enable_logging_iteration_details=False), seed=1024, served_model_name=/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'vllm_ascend.compilation.compiler_interface.AscendCompiler', 'custom_ops': ['all'], 'splitting_ops': [], 'compile_mm_encoder': False, 'compile_sizes': [], 'compile_ranges_split_points': [4096], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_DECODE_ONLY: (2, 0)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [24, 48], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': True, 'fuse_act_quant': True, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 48, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>, 'evaluate_guards': False, 'assume_32_bit_indexing': True}, 'local_cache_dir': None}
2026-02-12T19:21:16.3311482Z [0;36m(EngineCore_DP1 pid=187)[0;0m INFO 02-12 19:21:16 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-12T19:21:21.0960077Z INFO 02-12 19:21:21 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-12T19:21:21.0973377Z INFO 02-12 19:21:21 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-12T19:21:21.0982867Z INFO 02-12 19:21:21 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-12T19:21:21.1056328Z INFO 02-12 19:21:21 [__init__.py:217] Platform plugin ascend is activated
2026-02-12T19:21:21.2674083Z INFO 02-12 19:21:21 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-12T19:21:21.2682143Z INFO 02-12 19:21:21 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-12T19:21:21.2690852Z INFO 02-12 19:21:21 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-12T19:21:21.2740282Z INFO 02-12 19:21:21 [__init__.py:217] Platform plugin ascend is activated
2026-02-12T19:21:21.5660834Z INFO 02-12 19:21:21 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-12T19:21:21.5682523Z INFO 02-12 19:21:21 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-12T19:21:21.5692350Z INFO 02-12 19:21:21 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-12T19:21:21.5745478Z INFO 02-12 19:21:21 [__init__.py:217] Platform plugin ascend is activated
2026-02-12T19:21:21.6572408Z INFO 02-12 19:21:21 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-12T19:21:21.6581129Z INFO 02-12 19:21:21 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-12T19:21:21.6590854Z INFO 02-12 19:21:21 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-12T19:21:21.6599731Z INFO 02-12 19:21:21 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-12T19:21:21.6609248Z INFO 02-12 19:21:21 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-12T19:21:21.6618961Z INFO 02-12 19:21:21 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-12T19:21:21.6668411Z INFO 02-12 19:21:21 [__init__.py:217] Platform plugin ascend is activated
2026-02-12T19:21:21.6678291Z INFO 02-12 19:21:21 [__init__.py:217] Platform plugin ascend is activated
2026-02-12T19:21:21.6907161Z INFO 02-12 19:21:21 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-12T19:21:21.6916207Z INFO 02-12 19:21:21 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-12T19:21:21.6926519Z INFO 02-12 19:21:21 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-12T19:21:21.7009321Z INFO 02-12 19:21:21 [__init__.py:217] Platform plugin ascend is activated
2026-02-12T19:21:27.3236300Z 2026-02-12 19:21:27,321 - 216 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-12T19:21:27.3270219Z INFO 02-12 19:21:27 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-12T19:21:27.3464496Z 2026-02-12 19:21:27,344 - 215 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-12T19:21:27.3508953Z INFO 02-12 19:21:27 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-12T19:21:27.3851579Z [0;36m(ApiServer_1 pid=199)[0;0m 2026-02-12 19:21:27,383 - 199 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-12T19:21:27.4019047Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:21:27 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-12T19:21:27.4302277Z [0;36m(ApiServer_1 pid=199)[0;0m 2026-02-12 19:21:27,428 - modelscope - WARNING - We can not confirm the cached file is for revision: master
2026-02-12T19:21:27.4312308Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:21:27 [arg_utils.py:602] HF_HUB_OFFLINE is True, replace model_id [vllm-ascend/DeepSeek-V3.2-W8A8] to model_path [/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8]
2026-02-12T19:21:27.5288320Z [0;36m(ApiServer_1 pid=199)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-12T19:21:27.5315563Z [0;36m(ApiServer_1 pid=199)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-12T19:21:27.5363369Z [0;36m(ApiServer_1 pid=199)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-12T19:21:27.5373446Z [0;36m(ApiServer_1 pid=199)[0;0m You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-12T19:21:27.5444779Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:21:27 [model.py:541] Resolved architecture: DeepseekV32ForCausalLM
2026-02-12T19:21:27.5454469Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:21:27 [model.py:1561] Using max model len 8192
2026-02-12T19:21:27.6536370Z [0;36m(ApiServer_1 pid=199)[0;0m WARNING 02-12 19:21:27 [speculative.py:270] method `deepseek_mtp` is deprecated and replaced with mtp.
2026-02-12T19:21:27.6551322Z [0;36m(ApiServer_1 pid=199)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-12T19:21:27.6560050Z [0;36m(ApiServer_1 pid=199)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-12T19:21:27.6569746Z [0;36m(ApiServer_1 pid=199)[0;0m You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-12T19:21:27.6637458Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:21:27 [model.py:541] Resolved architecture: DeepSeekMTPModel
2026-02-12T19:21:27.6660231Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:21:27 [model.py:1561] Using max model len 163840
2026-02-12T19:21:27.6669884Z [0;36m(ApiServer_1 pid=199)[0;0m WARNING 02-12 19:21:27 [speculative.py:388] Enabling num_speculative_tokens > 1 will runmultiple times of forward on same MTP layer,which may result in lower acceptance rate
2026-02-12T19:21:27.6679212Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:21:27 [scheduler.py:226] Chunked prefill is enabled with max_num_batched_tokens=4096.
2026-02-12T19:21:27.7826854Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:21:27 [vllm.py:624] Asynchronous scheduling is enabled.
2026-02-12T19:21:27.7835680Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:21:27 [vllm.py:634] Disabling NCCL for DP synchronization when using async scheduling.
2026-02-12T19:21:27.7845719Z [0;36m(ApiServer_1 pid=199)[0;0m WARNING 02-12 19:21:27 [platform.py:734] Speculative quantization is set but Ascend automatically uses the main model's quantization method. Resetting to None.
2026-02-12T19:21:27.7856070Z [0;36m(ApiServer_1 pid=199)[0;0m WARNING 02-12 19:21:27 [platform.py:775] Ignored parameter 'use_trtllm_ragged_deepseek_prefill'. This is a GPU-specific feature not supported on Ascend. Resetting to False.
2026-02-12T19:21:27.7864956Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:21:27 [ascend_config.py:412] Dynamic EPLB is False
2026-02-12T19:21:27.7874811Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:21:27 [ascend_config.py:413] The number of redundant experts is 0
2026-02-12T19:21:27.7885865Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:21:27 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-12T19:21:27.7896286Z [0;36m(ApiServer_1 pid=199)[0;0m WARNING 02-12 19:21:27 [vllm.py:1062] Batch sizes [3, 6, 9, 12, 15, 18, 21, 27, 30, 33, 36, 39, 42, 45] are removed because they are not multiple of tp_size 8 when sequence parallelism is enabled
2026-02-12T19:21:27.7905513Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:21:27 [platform.py:322] FULL_DECODE_ONLY compilation enabled on NPU. use_inductor not supported - using only ACL Graph mode
2026-02-12T19:21:27.7914896Z [0;36m(ApiServer_1 pid=199)[0;0m WARNING 02-12 19:21:27 [platform.py:339] [91m
2026-02-12T19:21:27.7925737Z [0;36m(ApiServer_1 pid=199)[0;0m WARNING 02-12 19:21:27 [platform.py:339]             **********************************************************************************
2026-02-12T19:21:27.7934576Z [0;36m(ApiServer_1 pid=199)[0;0m WARNING 02-12 19:21:27 [platform.py:339]             * WARNING: You have enabled the *full graph* feature.
2026-02-12T19:21:27.7944052Z [0;36m(ApiServer_1 pid=199)[0;0m WARNING 02-12 19:21:27 [platform.py:339]             * This is an early experimental stage and may involve various unknown issues.
2026-02-12T19:21:27.7953111Z [0;36m(ApiServer_1 pid=199)[0;0m WARNING 02-12 19:21:27 [platform.py:339]             * A known problem is that capturing too many batch sizes can lead to OOM
2026-02-12T19:21:27.7963963Z [0;36m(ApiServer_1 pid=199)[0;0m WARNING 02-12 19:21:27 [platform.py:339]             * (Out of Memory) errors or inference hangs. If you encounter such issues,
2026-02-12T19:21:27.7973654Z [0;36m(ApiServer_1 pid=199)[0;0m WARNING 02-12 19:21:27 [platform.py:339]             * consider reducing `gpu_memory_utilization` or manually specifying a smaller
2026-02-12T19:21:27.7983397Z [0;36m(ApiServer_1 pid=199)[0;0m WARNING 02-12 19:21:27 [platform.py:339]             * batch size for graph capture.
2026-02-12T19:21:27.7993304Z [0;36m(ApiServer_1 pid=199)[0;0m WARNING 02-12 19:21:27 [platform.py:339]             * For more details, please refer to:
2026-02-12T19:21:27.8003315Z [0;36m(ApiServer_1 pid=199)[0;0m WARNING 02-12 19:21:27 [platform.py:339]             * https://docs.vllm.ai/en/stable/configuration/conserving_memory.html#reduce-cuda-graphs
2026-02-12T19:21:27.8013198Z [0;36m(ApiServer_1 pid=199)[0;0m WARNING 02-12 19:21:27 [platform.py:339]             **********************************************************************************[0m
2026-02-12T19:21:27.8022688Z [0;36m(ApiServer_1 pid=199)[0;0m WARNING 02-12 19:21:27 [platform.py:339]             
2026-02-12T19:21:27.8031799Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:21:27 [platform.py:447] Set PYTORCH_NPU_ALLOC_CONF=expandable_segments:True
2026-02-12T19:21:27.8132526Z [0;36m(ApiServer_3 pid=201)[0;0m 2026-02-12 19:21:27,811 - 201 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-12T19:21:27.8300929Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:21:27 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-12T19:21:27.8450462Z [0;36m(ApiServer_3 pid=201)[0;0m 2026-02-12 19:21:27,843 - modelscope - WARNING - We can not confirm the cached file is for revision: master
2026-02-12T19:21:27.8468088Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:21:27 [arg_utils.py:602] HF_HUB_OFFLINE is True, replace model_id [vllm-ascend/DeepSeek-V3.2-W8A8] to model_path [/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8]
2026-02-12T19:21:27.9523521Z [0;36m(ApiServer_3 pid=201)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-12T19:21:27.9547462Z [0;36m(ApiServer_3 pid=201)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-12T19:21:27.9557003Z [0;36m(ApiServer_3 pid=201)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-12T19:21:27.9574837Z [0;36m(ApiServer_3 pid=201)[0;0m You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-12T19:21:27.9623639Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:21:27 [model.py:541] Resolved architecture: DeepseekV32ForCausalLM
2026-02-12T19:21:27.9644087Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:21:27 [model.py:1561] Using max model len 8192
2026-02-12T19:21:28.0760275Z [0;36m(ApiServer_3 pid=201)[0;0m WARNING 02-12 19:21:28 [speculative.py:270] method `deepseek_mtp` is deprecated and replaced with mtp.
2026-02-12T19:21:28.0779667Z [0;36m(ApiServer_3 pid=201)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-12T19:21:28.0789009Z [0;36m(ApiServer_3 pid=201)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-12T19:21:28.0798838Z [0;36m(ApiServer_3 pid=201)[0;0m You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-12T19:21:28.0851917Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:21:28 [model.py:541] Resolved architecture: DeepSeekMTPModel
2026-02-12T19:21:28.0874777Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:21:28 [model.py:1561] Using max model len 163840
2026-02-12T19:21:28.0885483Z [0;36m(ApiServer_3 pid=201)[0;0m WARNING 02-12 19:21:28 [speculative.py:388] Enabling num_speculative_tokens > 1 will runmultiple times of forward on same MTP layer,which may result in lower acceptance rate
2026-02-12T19:21:28.0894942Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:21:28 [scheduler.py:226] Chunked prefill is enabled with max_num_batched_tokens=4096.
2026-02-12T19:21:28.1518639Z [0;36m(ApiServer_2 pid=200)[0;0m 2026-02-12 19:21:28,150 - 200 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-12T19:21:28.1689259Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:21:28 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-12T19:21:28.1848281Z [0;36m(ApiServer_2 pid=200)[0;0m 2026-02-12 19:21:28,183 - modelscope - WARNING - We can not confirm the cached file is for revision: master
2026-02-12T19:21:28.1870361Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:21:28 [arg_utils.py:602] HF_HUB_OFFLINE is True, replace model_id [vllm-ascend/DeepSeek-V3.2-W8A8] to model_path [/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8]
2026-02-12T19:21:28.2052187Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:21:28 [vllm.py:624] Asynchronous scheduling is enabled.
2026-02-12T19:21:28.2060079Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:21:28 [vllm.py:634] Disabling NCCL for DP synchronization when using async scheduling.
2026-02-12T19:21:28.2072526Z [0;36m(ApiServer_3 pid=201)[0;0m WARNING 02-12 19:21:28 [platform.py:734] Speculative quantization is set but Ascend automatically uses the main model's quantization method. Resetting to None.
2026-02-12T19:21:28.2082740Z [0;36m(ApiServer_3 pid=201)[0;0m WARNING 02-12 19:21:28 [platform.py:775] Ignored parameter 'use_trtllm_ragged_deepseek_prefill'. This is a GPU-specific feature not supported on Ascend. Resetting to False.
2026-02-12T19:21:28.2090592Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:21:28 [ascend_config.py:412] Dynamic EPLB is False
2026-02-12T19:21:28.2100038Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:21:28 [ascend_config.py:413] The number of redundant experts is 0
2026-02-12T19:21:28.2110466Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:21:28 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-12T19:21:28.2119881Z [0;36m(ApiServer_3 pid=201)[0;0m WARNING 02-12 19:21:28 [vllm.py:1062] Batch sizes [3, 6, 9, 12, 15, 18, 21, 27, 30, 33, 36, 39, 42, 45] are removed because they are not multiple of tp_size 8 when sequence parallelism is enabled
2026-02-12T19:21:28.2128869Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:21:28 [platform.py:322] FULL_DECODE_ONLY compilation enabled on NPU. use_inductor not supported - using only ACL Graph mode
2026-02-12T19:21:28.2138067Z [0;36m(ApiServer_3 pid=201)[0;0m WARNING 02-12 19:21:28 [platform.py:339] [91m
2026-02-12T19:21:28.2147624Z [0;36m(ApiServer_3 pid=201)[0;0m WARNING 02-12 19:21:28 [platform.py:339]             **********************************************************************************
2026-02-12T19:21:28.2157102Z [0;36m(ApiServer_3 pid=201)[0;0m WARNING 02-12 19:21:28 [platform.py:339]             * WARNING: You have enabled the *full graph* feature.
2026-02-12T19:21:28.2166913Z [0;36m(ApiServer_3 pid=201)[0;0m WARNING 02-12 19:21:28 [platform.py:339]             * This is an early experimental stage and may involve various unknown issues.
2026-02-12T19:21:28.2176285Z [0;36m(ApiServer_3 pid=201)[0;0m WARNING 02-12 19:21:28 [platform.py:339]             * A known problem is that capturing too many batch sizes can lead to OOM
2026-02-12T19:21:28.2186628Z [0;36m(ApiServer_3 pid=201)[0;0m WARNING 02-12 19:21:28 [platform.py:339]             * (Out of Memory) errors or inference hangs. If you encounter such issues,
2026-02-12T19:21:28.2196324Z [0;36m(ApiServer_3 pid=201)[0;0m WARNING 02-12 19:21:28 [platform.py:339]             * consider reducing `gpu_memory_utilization` or manually specifying a smaller
2026-02-12T19:21:28.2205982Z [0;36m(ApiServer_3 pid=201)[0;0m WARNING 02-12 19:21:28 [platform.py:339]             * batch size for graph capture.
2026-02-12T19:21:28.2215746Z [0;36m(ApiServer_3 pid=201)[0;0m WARNING 02-12 19:21:28 [platform.py:339]             * For more details, please refer to:
2026-02-12T19:21:28.2225619Z [0;36m(ApiServer_3 pid=201)[0;0m WARNING 02-12 19:21:28 [platform.py:339]             * https://docs.vllm.ai/en/stable/configuration/conserving_memory.html#reduce-cuda-graphs
2026-02-12T19:21:28.2234976Z [0;36m(ApiServer_3 pid=201)[0;0m WARNING 02-12 19:21:28 [platform.py:339]             **********************************************************************************[0m
2026-02-12T19:21:28.2244370Z [0;36m(ApiServer_3 pid=201)[0;0m WARNING 02-12 19:21:28 [platform.py:339]             
2026-02-12T19:21:28.2253496Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:21:28 [platform.py:447] Set PYTORCH_NPU_ALLOC_CONF=expandable_segments:True
2026-02-12T19:21:28.2897571Z [0;36m(ApiServer_2 pid=200)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-12T19:21:28.2941936Z [0;36m(ApiServer_2 pid=200)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-12T19:21:28.2952083Z [0;36m(ApiServer_2 pid=200)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-12T19:21:28.2963275Z [0;36m(ApiServer_2 pid=200)[0;0m You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-12T19:21:28.3115572Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:21:28 [model.py:541] Resolved architecture: DeepseekV32ForCausalLM
2026-02-12T19:21:28.3116077Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:21:28 [model.py:1561] Using max model len 8192
2026-02-12T19:21:28.3504461Z [0;36m(ApiServer_0 pid=198)[0;0m 2026-02-12 19:21:28,349 - 198 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-12T19:21:28.3681537Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:21:28 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-12T19:21:28.3854521Z [0;36m(ApiServer_0 pid=198)[0;0m 2026-02-12 19:21:28,384 - modelscope - WARNING - We can not confirm the cached file is for revision: master
2026-02-12T19:21:28.3864207Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:21:28 [arg_utils.py:602] HF_HUB_OFFLINE is True, replace model_id [vllm-ascend/DeepSeek-V3.2-W8A8] to model_path [/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8]
2026-02-12T19:21:28.4114568Z [0;36m(ApiServer_2 pid=200)[0;0m WARNING 02-12 19:21:28 [speculative.py:270] method `deepseek_mtp` is deprecated and replaced with mtp.
2026-02-12T19:21:28.4137916Z [0;36m(ApiServer_2 pid=200)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-12T19:21:28.4147635Z [0;36m(ApiServer_2 pid=200)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-12T19:21:28.4156673Z [0;36m(ApiServer_2 pid=200)[0;0m You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-12T19:21:28.4205175Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:21:28 [model.py:541] Resolved architecture: DeepSeekMTPModel
2026-02-12T19:21:28.4227125Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:21:28 [model.py:1561] Using max model len 163840
2026-02-12T19:21:28.4237529Z [0;36m(ApiServer_2 pid=200)[0;0m WARNING 02-12 19:21:28 [speculative.py:388] Enabling num_speculative_tokens > 1 will runmultiple times of forward on same MTP layer,which may result in lower acceptance rate
2026-02-12T19:21:28.4247358Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:21:28 [scheduler.py:226] Chunked prefill is enabled with max_num_batched_tokens=4096.
2026-02-12T19:21:28.4893664Z [0;36m(ApiServer_0 pid=198)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-12T19:21:28.4913085Z [0;36m(ApiServer_0 pid=198)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-12T19:21:28.4932542Z [0;36m(ApiServer_0 pid=198)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-12T19:21:28.4942411Z [0;36m(ApiServer_0 pid=198)[0;0m You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-12T19:21:28.4990562Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:21:28 [model.py:541] Resolved architecture: DeepseekV32ForCausalLM
2026-02-12T19:21:28.5010632Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:21:28 [model.py:1561] Using max model len 8192
2026-02-12T19:21:28.5435262Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:21:28 [vllm.py:624] Asynchronous scheduling is enabled.
2026-02-12T19:21:28.5444124Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:21:28 [vllm.py:634] Disabling NCCL for DP synchronization when using async scheduling.
2026-02-12T19:21:28.5456279Z [0;36m(ApiServer_2 pid=200)[0;0m WARNING 02-12 19:21:28 [platform.py:734] Speculative quantization is set but Ascend automatically uses the main model's quantization method. Resetting to None.
2026-02-12T19:21:28.5465529Z [0;36m(ApiServer_2 pid=200)[0;0m WARNING 02-12 19:21:28 [platform.py:775] Ignored parameter 'use_trtllm_ragged_deepseek_prefill'. This is a GPU-specific feature not supported on Ascend. Resetting to False.
2026-02-12T19:21:28.5473696Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:21:28 [ascend_config.py:412] Dynamic EPLB is False
2026-02-12T19:21:28.5483249Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:21:28 [ascend_config.py:413] The number of redundant experts is 0
2026-02-12T19:21:28.5494170Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:21:28 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-12T19:21:28.5503674Z [0;36m(ApiServer_2 pid=200)[0;0m WARNING 02-12 19:21:28 [vllm.py:1062] Batch sizes [3, 6, 9, 12, 15, 18, 21, 27, 30, 33, 36, 39, 42, 45] are removed because they are not multiple of tp_size 8 when sequence parallelism is enabled
2026-02-12T19:21:28.5513008Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:21:28 [platform.py:322] FULL_DECODE_ONLY compilation enabled on NPU. use_inductor not supported - using only ACL Graph mode
2026-02-12T19:21:28.5522385Z [0;36m(ApiServer_2 pid=200)[0;0m WARNING 02-12 19:21:28 [platform.py:339] [91m
2026-02-12T19:21:28.5532283Z [0;36m(ApiServer_2 pid=200)[0;0m WARNING 02-12 19:21:28 [platform.py:339]             **********************************************************************************
2026-02-12T19:21:28.5541414Z [0;36m(ApiServer_2 pid=200)[0;0m WARNING 02-12 19:21:28 [platform.py:339]             * WARNING: You have enabled the *full graph* feature.
2026-02-12T19:21:28.5551087Z [0;36m(ApiServer_2 pid=200)[0;0m WARNING 02-12 19:21:28 [platform.py:339]             * This is an early experimental stage and may involve various unknown issues.
2026-02-12T19:21:28.5560922Z [0;36m(ApiServer_2 pid=200)[0;0m WARNING 02-12 19:21:28 [platform.py:339]             * A known problem is that capturing too many batch sizes can lead to OOM
2026-02-12T19:21:28.5570482Z [0;36m(ApiServer_2 pid=200)[0;0m WARNING 02-12 19:21:28 [platform.py:339]             * (Out of Memory) errors or inference hangs. If you encounter such issues,
2026-02-12T19:21:28.5580128Z [0;36m(ApiServer_2 pid=200)[0;0m WARNING 02-12 19:21:28 [platform.py:339]             * consider reducing `gpu_memory_utilization` or manually specifying a smaller
2026-02-12T19:21:28.5589633Z [0;36m(ApiServer_2 pid=200)[0;0m WARNING 02-12 19:21:28 [platform.py:339]             * batch size for graph capture.
2026-02-12T19:21:28.5599020Z [0;36m(ApiServer_2 pid=200)[0;0m WARNING 02-12 19:21:28 [platform.py:339]             * For more details, please refer to:
2026-02-12T19:21:28.5608762Z [0;36m(ApiServer_2 pid=200)[0;0m WARNING 02-12 19:21:28 [platform.py:339]             * https://docs.vllm.ai/en/stable/configuration/conserving_memory.html#reduce-cuda-graphs
2026-02-12T19:21:28.5617731Z [0;36m(ApiServer_2 pid=200)[0;0m WARNING 02-12 19:21:28 [platform.py:339]             **********************************************************************************[0m
2026-02-12T19:21:28.5626655Z [0;36m(ApiServer_2 pid=200)[0;0m WARNING 02-12 19:21:28 [platform.py:339]             
2026-02-12T19:21:28.5636521Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:21:28 [platform.py:447] Set PYTORCH_NPU_ALLOC_CONF=expandable_segments:True
2026-02-12T19:21:28.6156174Z [0;36m(ApiServer_0 pid=198)[0;0m WARNING 02-12 19:21:28 [speculative.py:270] method `deepseek_mtp` is deprecated and replaced with mtp.
2026-02-12T19:21:28.6175783Z [0;36m(ApiServer_0 pid=198)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-12T19:21:28.6184898Z [0;36m(ApiServer_0 pid=198)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-12T19:21:28.6194763Z [0;36m(ApiServer_0 pid=198)[0;0m You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-12T19:21:28.6289409Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:21:28 [model.py:541] Resolved architecture: DeepSeekMTPModel
2026-02-12T19:21:28.6298945Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:21:28 [model.py:1561] Using max model len 163840
2026-02-12T19:21:28.6308005Z [0;36m(ApiServer_0 pid=198)[0;0m WARNING 02-12 19:21:28 [speculative.py:388] Enabling num_speculative_tokens > 1 will runmultiple times of forward on same MTP layer,which may result in lower acceptance rate
2026-02-12T19:21:28.6318158Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:21:28 [scheduler.py:226] Chunked prefill is enabled with max_num_batched_tokens=4096.
2026-02-12T19:21:28.7460552Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:21:28 [vllm.py:624] Asynchronous scheduling is enabled.
2026-02-12T19:21:28.7469622Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:21:28 [vllm.py:634] Disabling NCCL for DP synchronization when using async scheduling.
2026-02-12T19:21:28.7486087Z [0;36m(ApiServer_0 pid=198)[0;0m WARNING 02-12 19:21:28 [platform.py:734] Speculative quantization is set but Ascend automatically uses the main model's quantization method. Resetting to None.
2026-02-12T19:21:28.7495982Z [0;36m(ApiServer_0 pid=198)[0;0m WARNING 02-12 19:21:28 [platform.py:775] Ignored parameter 'use_trtllm_ragged_deepseek_prefill'. This is a GPU-specific feature not supported on Ascend. Resetting to False.
2026-02-12T19:21:28.7504908Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:21:28 [ascend_config.py:412] Dynamic EPLB is False
2026-02-12T19:21:28.7514515Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:21:28 [ascend_config.py:413] The number of redundant experts is 0
2026-02-12T19:21:28.7525466Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:21:28 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-12T19:21:28.7534826Z [0;36m(ApiServer_0 pid=198)[0;0m WARNING 02-12 19:21:28 [vllm.py:1062] Batch sizes [3, 6, 9, 12, 15, 18, 21, 27, 30, 33, 36, 39, 42, 45] are removed because they are not multiple of tp_size 8 when sequence parallelism is enabled
2026-02-12T19:21:28.7544313Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:21:28 [platform.py:322] FULL_DECODE_ONLY compilation enabled on NPU. use_inductor not supported - using only ACL Graph mode
2026-02-12T19:21:28.7553201Z [0;36m(ApiServer_0 pid=198)[0;0m WARNING 02-12 19:21:28 [platform.py:339] [91m
2026-02-12T19:21:28.7566127Z [0;36m(ApiServer_0 pid=198)[0;0m WARNING 02-12 19:21:28 [platform.py:339]             **********************************************************************************
2026-02-12T19:21:28.7573333Z [0;36m(ApiServer_0 pid=198)[0;0m WARNING 02-12 19:21:28 [platform.py:339]             * WARNING: You have enabled the *full graph* feature.
2026-02-12T19:21:28.7582382Z [0;36m(ApiServer_0 pid=198)[0;0m WARNING 02-12 19:21:28 [platform.py:339]             * This is an early experimental stage and may involve various unknown issues.
2026-02-12T19:21:28.7591603Z [0;36m(ApiServer_0 pid=198)[0;0m WARNING 02-12 19:21:28 [platform.py:339]             * A known problem is that capturing too many batch sizes can lead to OOM
2026-02-12T19:21:28.7602064Z [0;36m(ApiServer_0 pid=198)[0;0m WARNING 02-12 19:21:28 [platform.py:339]             * (Out of Memory) errors or inference hangs. If you encounter such issues,
2026-02-12T19:21:28.7611574Z [0;36m(ApiServer_0 pid=198)[0;0m WARNING 02-12 19:21:28 [platform.py:339]             * consider reducing `gpu_memory_utilization` or manually specifying a smaller
2026-02-12T19:21:28.7620527Z [0;36m(ApiServer_0 pid=198)[0;0m WARNING 02-12 19:21:28 [platform.py:339]             * batch size for graph capture.
2026-02-12T19:21:28.7630544Z [0;36m(ApiServer_0 pid=198)[0;0m WARNING 02-12 19:21:28 [platform.py:339]             * For more details, please refer to:
2026-02-12T19:21:28.7640412Z [0;36m(ApiServer_0 pid=198)[0;0m WARNING 02-12 19:21:28 [platform.py:339]             * https://docs.vllm.ai/en/stable/configuration/conserving_memory.html#reduce-cuda-graphs
2026-02-12T19:21:28.7650133Z [0;36m(ApiServer_0 pid=198)[0;0m WARNING 02-12 19:21:28 [platform.py:339]             **********************************************************************************[0m
2026-02-12T19:21:28.7659171Z [0;36m(ApiServer_0 pid=198)[0;0m WARNING 02-12 19:21:28 [platform.py:339]             
2026-02-12T19:21:28.7668984Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:21:28 [platform.py:447] Set PYTORCH_NPU_ALLOC_CONF=expandable_segments:True
2026-02-12T19:21:29.2978037Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-12T19:21:29.2986379Z   warnings.warn(
2026-02-12T19:21:29.3080966Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-12T19:21:29.3089181Z   warnings.warn(
2026-02-12T19:21:31.9327122Z INFO 02-12 19:21:31 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-12T19:21:31.9337208Z INFO 02-12 19:21:31 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-12T19:21:31.9347477Z INFO 02-12 19:21:31 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-12T19:21:31.9399200Z INFO 02-12 19:21:31 [__init__.py:217] Platform plugin ascend is activated
2026-02-12T19:21:32.0674575Z INFO 02-12 19:21:32 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-12T19:21:32.0683341Z INFO 02-12 19:21:32 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-12T19:21:32.0693968Z INFO 02-12 19:21:32 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-12T19:21:32.0765583Z INFO 02-12 19:21:32 [__init__.py:217] Platform plugin ascend is activated
2026-02-12T19:21:32.9652633Z INFO 02-12 19:21:32 [ascend_config.py:412] Dynamic EPLB is False
2026-02-12T19:21:32.9661141Z INFO 02-12 19:21:32 [ascend_config.py:413] The number of redundant experts is 0
2026-02-12T19:21:32.9674003Z INFO 02-12 19:21:32 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-12T19:21:32.9685102Z INFO 02-12 19:21:32 [ascend_config.py:412] Dynamic EPLB is False
2026-02-12T19:21:32.9701033Z INFO 02-12 19:21:32 [ascend_config.py:413] The number of redundant experts is 0
2026-02-12T19:21:32.9713962Z INFO 02-12 19:21:32 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-12T19:21:33.0200687Z INFO 02-12 19:21:33 [parallel_state.py:1212] world_size=32 rank=8 local_rank=0 distributed_init_method=tcp://10.0.0.210:37965 backend=hccl
2026-02-12T19:21:33.0228509Z INFO 02-12 19:21:33 [parallel_state.py:1212] world_size=32 rank=0 local_rank=0 distributed_init_method=tcp://10.0.0.210:37965 backend=hccl
2026-02-12T19:21:37.0395022Z 2026-02-12 19:21:37,037 - 266 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-12T19:21:37.0426705Z INFO 02-12 19:21:37 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-12T19:21:37.2318206Z 2026-02-12 19:21:37,230 - 265 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-12T19:21:37.2383994Z INFO 02-12 19:21:37 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-12T19:21:38.4001233Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-12T19:21:38.4011134Z   warnings.warn(
2026-02-12T19:21:38.6932767Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-12T19:21:38.6940514Z   warnings.warn(
2026-02-12T19:21:40.5298495Z INFO 02-12 19:21:40 [ascend_config.py:412] Dynamic EPLB is False
2026-02-12T19:21:40.5309166Z INFO 02-12 19:21:40 [ascend_config.py:413] The number of redundant experts is 0
2026-02-12T19:21:40.5320077Z INFO 02-12 19:21:40 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-12T19:21:40.8902384Z INFO 02-12 19:21:40 [ascend_config.py:412] Dynamic EPLB is False
2026-02-12T19:21:40.8912307Z INFO 02-12 19:21:40 [ascend_config.py:413] The number of redundant experts is 0
2026-02-12T19:21:40.8922734Z INFO 02-12 19:21:40 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-12T19:21:40.9588601Z INFO 02-12 19:21:40 [parallel_state.py:1212] world_size=32 rank=9 local_rank=1 distributed_init_method=tcp://10.0.0.210:37965 backend=hccl
2026-02-12T19:21:41.3207497Z INFO 02-12 19:21:41 [parallel_state.py:1212] world_size=32 rank=1 local_rank=1 distributed_init_method=tcp://10.0.0.210:37965 backend=hccl
2026-02-12T19:21:41.6341946Z INFO 02-12 19:21:41 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-12T19:21:41.6350492Z INFO 02-12 19:21:41 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-12T19:21:41.6362327Z INFO 02-12 19:21:41 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-12T19:21:41.6416369Z INFO 02-12 19:21:41 [__init__.py:217] Platform plugin ascend is activated
2026-02-12T19:21:41.9288681Z INFO 02-12 19:21:41 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-12T19:21:41.9296519Z INFO 02-12 19:21:41 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-12T19:21:41.9307358Z INFO 02-12 19:21:41 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-12T19:21:41.9370801Z INFO 02-12 19:21:41 [__init__.py:217] Platform plugin ascend is activated
2026-02-12T19:21:46.8040303Z 2026-02-12 19:21:46,801 - 383 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-12T19:21:46.8070368Z INFO 02-12 19:21:46 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-12T19:21:47.2323067Z 2026-02-12 19:21:47,230 - 386 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-12T19:21:47.2359288Z INFO 02-12 19:21:47 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-12T19:21:48.1207965Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-12T19:21:48.1214796Z   warnings.warn(
2026-02-12T19:21:48.5567367Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-12T19:21:48.5573924Z   warnings.warn(
2026-02-12T19:21:50.3085370Z INFO 02-12 19:21:50 [ascend_config.py:412] Dynamic EPLB is False
2026-02-12T19:21:50.3095455Z INFO 02-12 19:21:50 [ascend_config.py:413] The number of redundant experts is 0
2026-02-12T19:21:50.3106820Z INFO 02-12 19:21:50 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-12T19:21:50.7412145Z INFO 02-12 19:21:50 [parallel_state.py:1212] world_size=32 rank=10 local_rank=2 distributed_init_method=tcp://10.0.0.210:37965 backend=hccl
2026-02-12T19:21:50.9962103Z INFO 02-12 19:21:50 [ascend_config.py:412] Dynamic EPLB is False
2026-02-12T19:21:50.9969829Z INFO 02-12 19:21:50 [ascend_config.py:413] The number of redundant experts is 0
2026-02-12T19:21:50.9981636Z INFO 02-12 19:21:50 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-12T19:21:51.4474208Z INFO 02-12 19:21:51 [parallel_state.py:1212] world_size=32 rank=2 local_rank=2 distributed_init_method=tcp://10.0.0.210:37965 backend=hccl
2026-02-12T19:21:51.4544234Z INFO 02-12 19:21:51 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-12T19:21:51.4553949Z INFO 02-12 19:21:51 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-12T19:21:51.4563043Z INFO 02-12 19:21:51 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-12T19:21:51.4632890Z INFO 02-12 19:21:51 [__init__.py:217] Platform plugin ascend is activated
2026-02-12T19:21:51.9819582Z INFO 02-12 19:21:51 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-12T19:21:51.9826526Z INFO 02-12 19:21:51 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-12T19:21:51.9836751Z INFO 02-12 19:21:51 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-12T19:21:51.9897067Z INFO 02-12 19:21:51 [__init__.py:217] Platform plugin ascend is activated
2026-02-12T19:21:56.5853718Z 2026-02-12 19:21:56,583 - 487 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-12T19:21:56.5887321Z INFO 02-12 19:21:56 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-12T19:21:57.1640017Z 2026-02-12 19:21:57,161 - 490 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-12T19:21:57.1667076Z INFO 02-12 19:21:57 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-12T19:21:57.8832618Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-12T19:21:57.8838875Z   warnings.warn(
2026-02-12T19:21:58.4679538Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-12T19:21:58.4686021Z   warnings.warn(
2026-02-12T19:22:00.0271821Z INFO 02-12 19:22:00 [ascend_config.py:412] Dynamic EPLB is False
2026-02-12T19:22:00.0288387Z INFO 02-12 19:22:00 [ascend_config.py:413] The number of redundant experts is 0
2026-02-12T19:22:00.0295247Z INFO 02-12 19:22:00 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-12T19:22:00.4606265Z INFO 02-12 19:22:00 [parallel_state.py:1212] world_size=32 rank=11 local_rank=3 distributed_init_method=tcp://10.0.0.210:37965 backend=hccl
2026-02-12T19:22:00.5844943Z INFO 02-12 19:22:00 [ascend_config.py:412] Dynamic EPLB is False
2026-02-12T19:22:00.5855023Z INFO 02-12 19:22:00 [ascend_config.py:413] The number of redundant experts is 0
2026-02-12T19:22:00.5864153Z INFO 02-12 19:22:00 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-12T19:22:01.0247851Z INFO 02-12 19:22:01 [parallel_state.py:1212] world_size=32 rank=3 local_rank=3 distributed_init_method=tcp://10.0.0.210:37965 backend=hccl
2026-02-12T19:22:01.0953368Z INFO 02-12 19:22:01 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-12T19:22:01.0961638Z INFO 02-12 19:22:01 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-12T19:22:01.0971092Z INFO 02-12 19:22:01 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-12T19:22:01.1065076Z INFO 02-12 19:22:01 [__init__.py:217] Platform plugin ascend is activated
2026-02-12T19:22:01.3909291Z INFO 02-12 19:22:01 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-12T19:22:01.3918535Z INFO 02-12 19:22:01 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-12T19:22:01.3926982Z INFO 02-12 19:22:01 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-12T19:22:01.3976285Z INFO 02-12 19:22:01 [__init__.py:217] Platform plugin ascend is activated
2026-02-12T19:22:06.4019447Z 2026-02-12 19:22:06,399 - 594 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-12T19:22:06.4055469Z INFO 02-12 19:22:06 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-12T19:22:06.5574122Z 2026-02-12 19:22:06,555 - 591 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-12T19:22:06.5619549Z INFO 02-12 19:22:06 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-12T19:22:07.7837324Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-12T19:22:07.7846106Z   warnings.warn(
2026-02-12T19:22:08.0106140Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-12T19:22:08.0116604Z   warnings.warn(
2026-02-12T19:22:09.8395582Z INFO 02-12 19:22:09 [ascend_config.py:412] Dynamic EPLB is False
2026-02-12T19:22:09.8406413Z INFO 02-12 19:22:09 [ascend_config.py:413] The number of redundant experts is 0
2026-02-12T19:22:09.8417281Z INFO 02-12 19:22:09 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-12T19:22:10.2635387Z INFO 02-12 19:22:10 [parallel_state.py:1212] world_size=32 rank=4 local_rank=4 distributed_init_method=tcp://10.0.0.210:37965 backend=hccl
2026-02-12T19:22:10.2718809Z INFO 02-12 19:22:10 [ascend_config.py:412] Dynamic EPLB is False
2026-02-12T19:22:10.2726847Z INFO 02-12 19:22:10 [ascend_config.py:413] The number of redundant experts is 0
2026-02-12T19:22:10.2737333Z INFO 02-12 19:22:10 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-12T19:22:10.7196259Z INFO 02-12 19:22:10 [parallel_state.py:1212] world_size=32 rank=12 local_rank=4 distributed_init_method=tcp://10.0.0.210:37965 backend=hccl
2026-02-12T19:22:11.0887823Z INFO 02-12 19:22:11 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-12T19:22:11.0896613Z INFO 02-12 19:22:11 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-12T19:22:11.0906235Z INFO 02-12 19:22:11 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-12T19:22:11.0968927Z INFO 02-12 19:22:11 [__init__.py:217] Platform plugin ascend is activated
2026-02-12T19:22:11.3880895Z INFO 02-12 19:22:11 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-12T19:22:11.3888809Z INFO 02-12 19:22:11 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-12T19:22:11.3898970Z INFO 02-12 19:22:11 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-12T19:22:11.3958832Z INFO 02-12 19:22:11 [__init__.py:217] Platform plugin ascend is activated
2026-02-12T19:22:16.1898300Z 2026-02-12 19:22:16,187 - 695 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-12T19:22:16.1930501Z INFO 02-12 19:22:16 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-12T19:22:16.8582383Z 2026-02-12 19:22:16,856 - 698 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-12T19:22:16.8621319Z INFO 02-12 19:22:16 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-12T19:22:17.8985168Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-12T19:22:17.8992284Z   warnings.warn(
2026-02-12T19:22:18.3005193Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-12T19:22:18.3006051Z   warnings.warn(
2026-02-12T19:22:20.0043172Z INFO 02-12 19:22:20 [ascend_config.py:412] Dynamic EPLB is False
2026-02-12T19:22:20.0054094Z INFO 02-12 19:22:20 [ascend_config.py:413] The number of redundant experts is 0
2026-02-12T19:22:20.0066247Z INFO 02-12 19:22:20 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-12T19:22:20.4576820Z INFO 02-12 19:22:20 [parallel_state.py:1212] world_size=32 rank=5 local_rank=5 distributed_init_method=tcp://10.0.0.210:37965 backend=hccl
2026-02-12T19:22:20.7319117Z INFO 02-12 19:22:20 [ascend_config.py:412] Dynamic EPLB is False
2026-02-12T19:22:20.7326977Z INFO 02-12 19:22:20 [ascend_config.py:413] The number of redundant experts is 0
2026-02-12T19:22:20.7340106Z INFO 02-12 19:22:20 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-12T19:22:20.7371500Z INFO 02-12 19:22:20 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-12T19:22:20.7380746Z INFO 02-12 19:22:20 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-12T19:22:20.7392435Z INFO 02-12 19:22:20 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-12T19:22:20.7456838Z INFO 02-12 19:22:20 [__init__.py:217] Platform plugin ascend is activated
2026-02-12T19:22:21.1810635Z INFO 02-12 19:22:21 [parallel_state.py:1212] world_size=32 rank=13 local_rank=5 distributed_init_method=tcp://10.0.0.210:37965 backend=hccl
2026-02-12T19:22:21.5469311Z INFO 02-12 19:22:21 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-12T19:22:21.5476995Z INFO 02-12 19:22:21 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-12T19:22:21.5487999Z INFO 02-12 19:22:21 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-12T19:22:21.5546345Z INFO 02-12 19:22:21 [__init__.py:217] Platform plugin ascend is activated
2026-02-12T19:22:25.8181403Z 2026-02-12 19:22:25,816 - 799 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-12T19:22:25.8225047Z INFO 02-12 19:22:25 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-12T19:22:26.8238439Z 2026-02-12 19:22:26,821 - 802 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-12T19:22:26.8273029Z INFO 02-12 19:22:26 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-12T19:22:27.2707055Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-12T19:22:27.2713602Z   warnings.warn(
2026-02-12T19:22:28.2106564Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-12T19:22:28.2112487Z   warnings.warn(
2026-02-12T19:22:29.4117843Z INFO 02-12 19:22:29 [ascend_config.py:412] Dynamic EPLB is False
2026-02-12T19:22:29.4118235Z INFO 02-12 19:22:29 [ascend_config.py:413] The number of redundant experts is 0
2026-02-12T19:22:29.4119292Z INFO 02-12 19:22:29 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-12T19:22:29.8429910Z INFO 02-12 19:22:29 [parallel_state.py:1212] world_size=32 rank=6 local_rank=6 distributed_init_method=tcp://10.0.0.210:37965 backend=hccl
2026-02-12T19:22:30.4055349Z INFO 02-12 19:22:30 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-12T19:22:30.4064680Z INFO 02-12 19:22:30 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-12T19:22:30.4077977Z INFO 02-12 19:22:30 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-12T19:22:30.4129612Z INFO 02-12 19:22:30 [__init__.py:217] Platform plugin ascend is activated
2026-02-12T19:22:30.5350771Z INFO 02-12 19:22:30 [ascend_config.py:412] Dynamic EPLB is False
2026-02-12T19:22:30.5359330Z INFO 02-12 19:22:30 [ascend_config.py:413] The number of redundant experts is 0
2026-02-12T19:22:30.5369933Z INFO 02-12 19:22:30 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-12T19:22:30.9793803Z INFO 02-12 19:22:30 [parallel_state.py:1212] world_size=32 rank=14 local_rank=6 distributed_init_method=tcp://10.0.0.210:37965 backend=hccl
2026-02-12T19:22:31.4087796Z INFO 02-12 19:22:31 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-12T19:22:31.4096041Z INFO 02-12 19:22:31 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-12T19:22:31.4105408Z INFO 02-12 19:22:31 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-12T19:22:31.4164863Z INFO 02-12 19:22:31 [__init__.py:217] Platform plugin ascend is activated
2026-02-12T19:22:35.6197258Z 2026-02-12 19:22:35,617 - 903 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-12T19:22:35.6227960Z INFO 02-12 19:22:35 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-12T19:22:36.7389497Z 2026-02-12 19:22:36,736 - 906 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-12T19:22:36.7422556Z INFO 02-12 19:22:36 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-12T19:22:36.9220421Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-12T19:22:36.9228793Z   warnings.warn(
2026-02-12T19:22:38.0751757Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-12T19:22:38.0759988Z   warnings.warn(
2026-02-12T19:22:38.9729465Z INFO 02-12 19:22:38 [ascend_config.py:412] Dynamic EPLB is False
2026-02-12T19:22:38.9738174Z INFO 02-12 19:22:38 [ascend_config.py:413] The number of redundant experts is 0
2026-02-12T19:22:38.9748951Z INFO 02-12 19:22:38 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-12T19:22:39.3942158Z INFO 02-12 19:22:39 [parallel_state.py:1212] world_size=32 rank=7 local_rank=7 distributed_init_method=tcp://10.0.0.210:37965 backend=hccl
2026-02-12T19:22:40.1769260Z INFO 02-12 19:22:40 [ascend_config.py:412] Dynamic EPLB is False
2026-02-12T19:22:40.1778442Z INFO 02-12 19:22:40 [ascend_config.py:413] The number of redundant experts is 0
2026-02-12T19:22:40.1789977Z INFO 02-12 19:22:40 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-12T19:22:40.5993915Z INFO 02-12 19:22:40 [parallel_state.py:1212] world_size=32 rank=15 local_rank=7 distributed_init_method=tcp://10.0.0.210:37965 backend=hccl
2026-02-12T19:22:40.6331865Z [Gloo] Rank 0 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-12T19:22:40.6355538Z [Gloo] Rank 4 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-12T19:22:40.6365336Z [Gloo] Rank 5 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-12T19:22:40.6374678Z [Gloo] Rank 6 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-12T19:22:40.6384023Z [Gloo] Rank 7 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-12T19:22:40.7062245Z [Gloo] Rank 1 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-12T19:22:40.7071778Z [Gloo] Rank 3 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-12T19:22:40.7081884Z [Gloo] Rank 2 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-12T19:22:40.7137157Z [Gloo] Rank 11 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-12T19:22:40.7157683Z [Gloo] Rank 13 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-12T19:22:40.7167488Z [Gloo] Rank 9 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-12T19:22:40.7176852Z [Gloo] Rank 10 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-12T19:22:40.7185746Z [Gloo] Rank 12 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-12T19:22:40.7195018Z [Gloo] Rank 14 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-12T19:22:40.7205161Z [Gloo] Rank 15 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-12T19:22:40.7214853Z [Gloo] Rank 8 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-12T19:22:40.8551859Z [Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-12T19:22:40.8560370Z [Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-12T19:22:40.8576049Z [Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-12T19:22:40.8585950Z [Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-12T19:22:40.8603513Z [Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-12T19:22:40.8619061Z [Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-12T19:22:40.8632729Z [Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-12T19:22:40.8645632Z [Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-12T19:22:40.8656204Z [Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-12T19:22:40.8666482Z [Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-12T19:22:40.8676950Z [Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-12T19:22:40.8686519Z [Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-12T19:22:40.8697321Z [Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-12T19:22:40.8704790Z [Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-12T19:22:40.8714917Z [Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-12T19:22:40.8725130Z [Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-12T19:22:40.8734017Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-12T19:22:40.8743376Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-12T19:22:40.8753588Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-12T19:22:40.8763867Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-12T19:22:40.8773649Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-12T19:22:40.8782845Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-12T19:22:40.8792507Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-12T19:22:40.8802235Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-12T19:22:40.8811771Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-12T19:22:40.8821062Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-12T19:22:40.8830938Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-12T19:22:40.8841142Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-12T19:22:40.8850454Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-12T19:22:40.8859450Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-12T19:22:40.8868541Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-12T19:22:40.8878805Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-12T19:22:40.8888534Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-12T19:22:40.8897925Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-12T19:22:40.8907470Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-12T19:22:40.8917119Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-12T19:22:40.8926118Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-12T19:22:40.8935586Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-12T19:22:40.8944931Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-12T19:22:40.8954905Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-12T19:22:40.9312247Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-12T19:22:40.9328103Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-12T19:22:40.9338030Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-12T19:22:40.9348804Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-12T19:22:40.9358359Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-12T19:22:40.9368730Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-12T19:22:40.9378839Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-12T19:22:40.9388323Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-12T19:22:40.9399197Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-12T19:22:40.9408809Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-12T19:22:40.9418592Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-12T19:22:40.9428806Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-12T19:22:40.9438771Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-12T19:22:40.9448834Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-12T19:22:40.9458270Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-12T19:22:40.9467815Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-12T19:22:40.9478164Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-12T19:22:40.9488096Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-12T19:22:40.9498143Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-12T19:22:40.9507592Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-12T19:22:40.9517814Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-12T19:22:40.9527471Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-12T19:22:40.9536881Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-12T19:22:40.9546212Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-12T19:22:40.9556073Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-12T19:22:40.9565939Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-12T19:22:40.9575877Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-12T19:22:40.9585264Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-12T19:22:40.9594492Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-12T19:22:40.9605173Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-12T19:22:40.9615473Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-12T19:22:40.9624392Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-12T19:22:40.9634187Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-12T19:22:40.9644775Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-12T19:22:40.9654148Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-12T19:22:40.9664177Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-12T19:22:40.9673965Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-12T19:22:40.9683959Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-12T19:22:40.9693738Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-12T19:22:40.9703480Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-12T19:22:41.0347650Z [Gloo] Rank 1 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-12T19:22:41.0368340Z INFO 02-12 19:22:41 [parallel_state.py:1423] rank 1 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 1, EP rank 1
2026-02-12T19:22:41.0386858Z [Gloo] Rank 7 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-12T19:22:41.0396695Z [Gloo] Rank 0 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-12T19:22:41.0406611Z [Gloo] Rank 2 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-12T19:22:41.0414796Z [Gloo] Rank 9 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-12T19:22:41.0424275Z INFO 02-12 19:22:41 [parallel_state.py:1423] rank 7 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 7, EP rank 7
2026-02-12T19:22:41.0433470Z INFO 02-12 19:22:41 [parallel_state.py:1423] rank 2 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 2, EP rank 2
2026-02-12T19:22:41.0442997Z INFO 02-12 19:22:41 [parallel_state.py:1423] rank 9 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 1, EP rank 9
2026-02-12T19:22:41.0452493Z INFO 02-12 19:22:41 [parallel_state.py:1423] rank 0 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
2026-02-12T19:22:41.1115605Z [Gloo] Rank 5 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-12T19:22:41.1125456Z INFO 02-12 19:22:41 [parallel_state.py:1423] rank 5 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 5, EP rank 5
2026-02-12T19:22:41.1133930Z [Gloo] Rank 6 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-12T19:22:41.1143443Z INFO 02-12 19:22:41 [parallel_state.py:1423] rank 6 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 6, EP rank 6
2026-02-12T19:22:41.1256692Z [Gloo] Rank 3 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-12T19:22:41.1266523Z [Gloo] Rank 4 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-12T19:22:41.1280267Z [Gloo] Rank 8 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-12T19:22:41.1290131Z [Gloo] Rank 13 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-12T19:22:41.1300360Z [Gloo] Rank 15 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-12T19:22:41.1307912Z INFO 02-12 19:22:41 [parallel_state.py:1423] rank 4 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 4, EP rank 4
2026-02-12T19:22:41.1317859Z [Gloo] Rank 14 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-12T19:22:41.1327513Z INFO 02-12 19:22:41 [parallel_state.py:1423] rank 3 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 3, EP rank 3
2026-02-12T19:22:41.1337156Z INFO 02-12 19:22:41 [parallel_state.py:1423] rank 8 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 0, EP rank 8
2026-02-12T19:22:41.1347026Z INFO 02-12 19:22:41 [parallel_state.py:1423] rank 15 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 7, EP rank 15
2026-02-12T19:22:41.1355971Z INFO 02-12 19:22:41 [parallel_state.py:1423] rank 13 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 5, EP rank 13
2026-02-12T19:22:41.1366134Z INFO 02-12 19:22:41 [parallel_state.py:1423] rank 14 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 6, EP rank 14
2026-02-12T19:22:41.1375252Z [Gloo] Rank 12 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-12T19:22:41.1384870Z [Gloo] Rank 10 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-12T19:22:41.1393749Z [Gloo] Rank 11 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-12T19:22:41.1403130Z INFO 02-12 19:22:41 [parallel_state.py:1423] rank 12 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 4, EP rank 12
2026-02-12T19:22:41.1412707Z INFO 02-12 19:22:41 [parallel_state.py:1423] rank 11 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 3, EP rank 11
2026-02-12T19:22:41.1422574Z INFO 02-12 19:22:41 [parallel_state.py:1423] rank 10 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 2, EP rank 10
2026-02-12T19:22:41.1517296Z [Gloo] Rank 4 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-12T19:22:41.1525910Z [Gloo] Rank 8 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-12T19:22:41.1535469Z [Gloo] Rank 13 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-12T19:22:41.1544269Z [Gloo] Rank 3 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-12T19:22:41.1557052Z [Gloo] Rank 5 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-12T19:22:41.1566440Z [Gloo] Rank 0 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-12T19:22:41.1577269Z [Gloo] Rank 1 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-12T19:22:41.1586663Z [Gloo] Rank 11 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-12T19:22:41.1596510Z [Gloo] Rank 10 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-12T19:22:41.1606460Z [Gloo] Rank 14 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-12T19:22:41.1620258Z [Gloo] Rank 9 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-12T19:22:41.1630257Z [Gloo] Rank 7 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-12T19:22:41.1640152Z [Gloo] Rank 6 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-12T19:22:41.1653649Z [Gloo] Rank 2 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-12T19:22:41.1663443Z [Gloo] Rank 12 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-12T19:22:41.1673041Z [Gloo] Rank 15 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-12T19:22:41.1724117Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-12T19:22:41.1733919Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-12T19:22:41.1744013Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-12T19:22:41.1753831Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-12T19:22:41.1764881Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-12T19:22:41.1775081Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-12T19:22:41.1785292Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-12T19:22:41.1795811Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-12T19:22:41.1805968Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-12T19:22:41.1815444Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-12T19:22:41.1825239Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-12T19:22:41.1835336Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-12T19:22:41.1844259Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-12T19:22:41.1853698Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-12T19:22:41.1862728Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-12T19:22:41.1872211Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-12T19:22:41.2824749Z WARNING 02-12 19:22:41 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-12T19:22:41.2846294Z WARNING 02-12 19:22:41 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-12T19:22:41.2854928Z WARNING 02-12 19:22:41 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-12T19:22:41.2865091Z WARNING 02-12 19:22:41 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-12T19:22:41.2873226Z WARNING 02-12 19:22:41 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-12T19:22:41.2882428Z WARNING 02-12 19:22:41 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-12T19:22:41.2891183Z WARNING 02-12 19:22:41 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-12T19:22:41.2900884Z WARNING 02-12 19:22:41 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-12T19:22:41.2910144Z WARNING 02-12 19:22:41 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-12T19:22:41.2919891Z WARNING 02-12 19:22:41 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-12T19:22:41.2929083Z WARNING 02-12 19:22:41 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-12T19:22:41.2938567Z WARNING 02-12 19:22:41 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-12T19:22:41.2947479Z WARNING 02-12 19:22:41 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-12T19:22:41.2956732Z WARNING 02-12 19:22:41 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-12T19:22:41.2965633Z WARNING 02-12 19:22:41 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-12T19:22:41.2975747Z WARNING 02-12 19:22:41 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-12T19:22:41.3366537Z WARNING 02-12 19:22:41 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-12T19:22:41.3375797Z WARNING 02-12 19:22:41 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-12T19:22:41.3385831Z WARNING 02-12 19:22:41 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-12T19:22:41.3394055Z WARNING 02-12 19:22:41 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-12T19:22:41.3403648Z WARNING 02-12 19:22:41 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-12T19:22:41.3412953Z WARNING 02-12 19:22:41 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-12T19:22:41.3422477Z WARNING 02-12 19:22:41 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-12T19:22:41.3431866Z WARNING 02-12 19:22:41 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-12T19:22:41.3441496Z WARNING 02-12 19:22:41 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-12T19:22:41.3451057Z WARNING 02-12 19:22:41 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-12T19:22:41.3461160Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m INFO 02-12 19:22:41 [model_runner_v1.py:2308] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-12T19:22:41.3470159Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m INFO 02-12 19:22:41 [model_runner_v1.py:2308] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-12T19:22:41.3479657Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m INFO 02-12 19:22:41 [model_runner_v1.py:2308] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-12T19:22:41.3489334Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m INFO 02-12 19:22:41 [model_runner_v1.py:2308] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-12T19:22:41.3499175Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m INFO 02-12 19:22:41 [model_runner_v1.py:2308] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-12T19:22:41.3508669Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m INFO 02-12 19:22:41 [model_runner_v1.py:2308] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-12T19:22:41.3518462Z WARNING 02-12 19:22:41 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-12T19:22:41.3528491Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m INFO 02-12 19:22:41 [model_runner_v1.py:2308] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-12T19:22:41.3538082Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m INFO 02-12 19:22:41 [model_runner_v1.py:2308] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-12T19:22:41.3547758Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m INFO 02-12 19:22:41 [model_runner_v1.py:2308] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-12T19:22:41.3557718Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m INFO 02-12 19:22:41 [model_runner_v1.py:2308] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-12T19:22:41.3567176Z WARNING 02-12 19:22:41 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-12T19:22:41.3576750Z WARNING 02-12 19:22:41 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-12T19:22:41.3585900Z WARNING 02-12 19:22:41 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-12T19:22:41.3594866Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m INFO 02-12 19:22:41 [model_runner_v1.py:2308] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-12T19:22:41.3604390Z WARNING 02-12 19:22:41 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-12T19:22:41.3614148Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m INFO 02-12 19:22:41 [model_runner_v1.py:2308] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-12T19:22:41.3623377Z WARNING 02-12 19:22:41 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-12T19:22:41.3633615Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m INFO 02-12 19:22:41 [model_runner_v1.py:2308] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-12T19:22:41.3643655Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m INFO 02-12 19:22:41 [model_runner_v1.py:2308] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-12T19:22:41.3665134Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m INFO 02-12 19:22:41 [model_runner_v1.py:2308] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-12T19:22:41.3931131Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m INFO 02-12 19:22:41 [model_runner_v1.py:2308] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-12T19:22:41.7446422Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m [2026-02-12 19:22:41] INFO modelslim_config.py:286: Using the vLLM Ascend modelslim Quantization now!
2026-02-12T19:22:41.7511492Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m [2026-02-12 19:22:41] INFO modelslim_config.py:286: Using the vLLM Ascend modelslim Quantization now!
2026-02-12T19:22:41.7694628Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m [2026-02-12 19:22:41] INFO modelslim_config.py:286: Using the vLLM Ascend modelslim Quantization now!
2026-02-12T19:22:41.7835379Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m [2026-02-12 19:22:41] INFO modelslim_config.py:286: Using the vLLM Ascend modelslim Quantization now!
2026-02-12T19:22:41.7930462Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m [2026-02-12 19:22:41] INFO modelslim_config.py:286: Using the vLLM Ascend modelslim Quantization now!
2026-02-12T19:22:41.7952387Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m [2026-02-12 19:22:41] INFO modelslim_config.py:286: Using the vLLM Ascend modelslim Quantization now!
2026-02-12T19:22:41.8134345Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m [2026-02-12 19:22:41] INFO modelslim_config.py:286: Using the vLLM Ascend modelslim Quantization now!
2026-02-12T19:22:41.8182134Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m [2026-02-12 19:22:41] INFO modelslim_config.py:286: Using the vLLM Ascend modelslim Quantization now!
2026-02-12T19:22:41.8654038Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m [2026-02-12 19:22:41] INFO modelslim_config.py:286: Using the vLLM Ascend modelslim Quantization now!
2026-02-12T19:22:41.9379431Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m [2026-02-12 19:22:41] INFO modelslim_config.py:286: Using the vLLM Ascend modelslim Quantization now!
2026-02-12T19:22:41.9452867Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m INFO 02-12 19:22:41 [layer.py:475] [EP Rank 11/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->88, 1->89, 2->90, 3->91, 4->92, 5->93, 6->94, 7->95.
2026-02-12T19:22:41.9462545Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m INFO 02-12 19:22:41 [layer.py:475] [EP Rank 1/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->8, 1->9, 2->10, 3->11, 4->12, 5->13, 6->14, 7->15.
2026-02-12T19:22:41.9472359Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m INFO 02-12 19:22:41 [layer.py:475] [EP Rank 10/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->80, 1->81, 2->82, 3->83, 4->84, 5->85, 6->86, 7->87.
2026-02-12T19:22:41.9482925Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m INFO 02-12 19:22:41 [layer.py:475] [EP Rank 15/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->120, 1->121, 2->122, 3->123, 4->124, 5->125, 6->126, 7->127.
2026-02-12T19:22:41.9492607Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m INFO 02-12 19:22:41 [layer.py:475] [EP Rank 9/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->72, 1->73, 2->74, 3->75, 4->76, 5->77, 6->78, 7->79.
2026-02-12T19:22:41.9503017Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m INFO 02-12 19:22:41 [layer.py:475] [EP Rank 4/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->32, 1->33, 2->34, 3->35, 4->36, 5->37, 6->38, 7->39.
2026-02-12T19:22:41.9513090Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m INFO 02-12 19:22:41 [layer.py:475] [EP Rank 12/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->96, 1->97, 2->98, 3->99, 4->100, 5->101, 6->102, 7->103.
2026-02-12T19:22:41.9523409Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m INFO 02-12 19:22:41 [layer.py:475] [EP Rank 2/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->16, 1->17, 2->18, 3->19, 4->20, 5->21, 6->22, 7->23.
2026-02-12T19:22:41.9842529Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m INFO 02-12 19:22:41 [layer.py:475] [EP Rank 5/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->40, 1->41, 2->42, 3->43, 4->44, 5->45, 6->46, 7->47.
2026-02-12T19:22:42.0450437Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m INFO 02-12 19:22:42 [layer.py:475] [EP Rank 14/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->112, 1->113, 2->114, 3->115, 4->116, 5->117, 6->118, 7->119.
2026-02-12T19:22:42.0991024Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m [2026-02-12 19:22:42] INFO modelslim_config.py:286: Using the vLLM Ascend modelslim Quantization now!
2026-02-12T19:22:42.1122809Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m [2026-02-12 19:22:42] INFO modelslim_config.py:286: Using the vLLM Ascend modelslim Quantization now!
2026-02-12T19:22:42.1491674Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m [2026-02-12 19:22:42] INFO modelslim_config.py:286: Using the vLLM Ascend modelslim Quantization now!
2026-02-12T19:22:42.1846273Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m [2026-02-12 19:22:42] INFO modelslim_config.py:286: Using the vLLM Ascend modelslim Quantization now!
2026-02-12T19:22:42.2267982Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m INFO 02-12 19:22:42 [layer.py:475] [EP Rank 13/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->104, 1->105, 2->106, 3->107, 4->108, 5->109, 6->110, 7->111.
2026-02-12T19:22:42.2322942Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m [2026-02-12 19:22:42] INFO modelslim_config.py:286: Using the vLLM Ascend modelslim Quantization now!
2026-02-12T19:22:42.2603243Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m INFO 02-12 19:22:42 [layer.py:475] [EP Rank 0/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->0, 1->1, 2->2, 3->3, 4->4, 5->5, 6->6, 7->7.
2026-02-12T19:22:42.2683385Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m INFO 02-12 19:22:42 [layer.py:475] [EP Rank 7/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->56, 1->57, 2->58, 3->59, 4->60, 5->61, 6->62, 7->63.
2026-02-12T19:22:42.2977316Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m INFO 02-12 19:22:42 [layer.py:475] [EP Rank 6/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->48, 1->49, 2->50, 3->51, 4->52, 5->53, 6->54, 7->55.
2026-02-12T19:22:42.3186744Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m [2026-02-12 19:22:42] INFO modelslim_config.py:286: Using the vLLM Ascend modelslim Quantization now!
2026-02-12T19:22:42.3437114Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m INFO 02-12 19:22:42 [layer.py:475] [EP Rank 3/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->24, 1->25, 2->26, 3->27, 4->28, 5->29, 6->30, 7->31.
2026-02-12T19:22:42.4894533Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m INFO 02-12 19:22:42 [layer.py:475] [EP Rank 8/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->64, 1->65, 2->66, 3->67, 4->68, 5->69, 6->70, 7->71.
2026-02-12T19:22:43.4178906Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-02-12T19:22:43.4187611Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m   return func(*args, **kwargs)
2026-02-12T19:22:43.4882405Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m INFO 02-12 19:22:43 [fused_moe.py:207] [EP Rank 0/32] Expert parallelism is enabled. Local/global number of experts: 8/256. Experts local to global index map: 0->0, 1->1, 2->2, 3->3, 4->4, 5->5, 6->6, 7->7.
2026-02-12T19:22:43.6328696Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-02-12T19:22:43.6335923Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m   return func(*args, **kwargs)
2026-02-12T19:22:43.6351857Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-02-12T19:22:43.6360346Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m   return func(*args, **kwargs)
2026-02-12T19:22:43.6373714Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-02-12T19:22:43.6382267Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m   return func(*args, **kwargs)
2026-02-12T19:22:43.6471186Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-02-12T19:22:43.6481115Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m   return func(*args, **kwargs)
2026-02-12T19:22:43.6497846Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-02-12T19:22:43.6506707Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m   return func(*args, **kwargs)
2026-02-12T19:22:43.6518343Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-02-12T19:22:43.6527143Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m   return func(*args, **kwargs)
2026-02-12T19:22:43.6573883Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-02-12T19:22:43.6583067Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m   return func(*args, **kwargs)
2026-02-12T19:22:43.6842825Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-02-12T19:22:43.6852187Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m   return func(*args, **kwargs)
2026-02-12T19:22:43.6933608Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m INFO 02-12 19:22:43 [fused_moe.py:207] [EP Rank 8/32] Expert parallelism is enabled. Local/global number of experts: 8/256. Experts local to global index map: 0->64, 1->65, 2->66, 3->67, 4->68, 5->69, 6->70, 7->71.
2026-02-12T19:22:43.6964939Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-02-12T19:22:43.6974657Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m   return func(*args, **kwargs)
2026-02-12T19:22:43.7009231Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-02-12T19:22:43.7010476Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m   return func(*args, **kwargs)
2026-02-12T19:22:43.7016868Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-02-12T19:22:43.7025818Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m   return func(*args, **kwargs)
2026-02-12T19:22:43.7037001Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m INFO 02-12 19:22:43 [fused_moe.py:207] [EP Rank 9/32] Expert parallelism is enabled. Local/global number of experts: 8/256. Experts local to global index map: 0->72, 1->73, 2->74, 3->75, 4->76, 5->77, 6->78, 7->79.
2026-02-12T19:22:43.7049620Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-02-12T19:22:43.7060050Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m   return func(*args, **kwargs)
2026-02-12T19:22:43.7074804Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m INFO 02-12 19:22:43 [fused_moe.py:207] [EP Rank 15/32] Expert parallelism is enabled. Local/global number of experts: 8/256. Experts local to global index map: 0->120, 1->121, 2->122, 3->123, 4->124, 5->125, 6->126, 7->127.
2026-02-12T19:22:43.7108694Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m INFO 02-12 19:22:43 [fused_moe.py:207] [EP Rank 13/32] Expert parallelism is enabled. Local/global number of experts: 8/256. Experts local to global index map: 0->104, 1->105, 2->106, 3->107, 4->108, 5->109, 6->110, 7->111.
2026-02-12T19:22:43.7120671Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m INFO 02-12 19:22:43 [fused_moe.py:207] [EP Rank 7/32] Expert parallelism is enabled. Local/global number of experts: 8/256. Experts local to global index map: 0->56, 1->57, 2->58, 3->59, 4->60, 5->61, 6->62, 7->63.
2026-02-12T19:22:43.7238931Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-02-12T19:22:43.7240194Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m   return func(*args, **kwargs)
2026-02-12T19:22:43.7241389Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-02-12T19:22:43.7242612Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m   return func(*args, **kwargs)
2026-02-12T19:22:43.7246534Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m INFO 02-12 19:22:43 [fused_moe.py:207] [EP Rank 2/32] Expert parallelism is enabled. Local/global number of experts: 8/256. Experts local to global index map: 0->16, 1->17, 2->18, 3->19, 4->20, 5->21, 6->22, 7->23.
2026-02-12T19:22:43.7403185Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-02-12T19:22:43.7412848Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m   return func(*args, **kwargs)
2026-02-12T19:22:43.7427957Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m INFO 02-12 19:22:43 [fused_moe.py:207] [EP Rank 4/32] Expert parallelism is enabled. Local/global number of experts: 8/256. Experts local to global index map: 0->32, 1->33, 2->34, 3->35, 4->36, 5->37, 6->38, 7->39.
2026-02-12T19:22:43.7453973Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m INFO 02-12 19:22:43 [fused_moe.py:207] [EP Rank 11/32] Expert parallelism is enabled. Local/global number of experts: 8/256. Experts local to global index map: 0->88, 1->89, 2->90, 3->91, 4->92, 5->93, 6->94, 7->95.
2026-02-12T19:22:43.7622694Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m INFO 02-12 19:22:43 [fused_moe.py:207] [EP Rank 1/32] Expert parallelism is enabled. Local/global number of experts: 8/256. Experts local to global index map: 0->8, 1->9, 2->10, 3->11, 4->12, 5->13, 6->14, 7->15.
2026-02-12T19:22:43.7631535Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m INFO 02-12 19:22:43 [fused_moe.py:207] [EP Rank 12/32] Expert parallelism is enabled. Local/global number of experts: 8/256. Experts local to global index map: 0->96, 1->97, 2->98, 3->99, 4->100, 5->101, 6->102, 7->103.
2026-02-12T19:22:43.7641323Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m INFO 02-12 19:22:43 [fused_moe.py:207] [EP Rank 6/32] Expert parallelism is enabled. Local/global number of experts: 8/256. Experts local to global index map: 0->48, 1->49, 2->50, 3->51, 4->52, 5->53, 6->54, 7->55.
2026-02-12T19:22:43.7732769Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m INFO 02-12 19:22:43 [fused_moe.py:207] [EP Rank 14/32] Expert parallelism is enabled. Local/global number of experts: 8/256. Experts local to global index map: 0->112, 1->113, 2->114, 3->115, 4->116, 5->117, 6->118, 7->119.
2026-02-12T19:22:43.7817280Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m INFO 02-12 19:22:43 [fused_moe.py:207] [EP Rank 5/32] Expert parallelism is enabled. Local/global number of experts: 8/256. Experts local to global index map: 0->40, 1->41, 2->42, 3->43, 4->44, 5->45, 6->46, 7->47.
2026-02-12T19:22:43.7840988Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m INFO 02-12 19:22:43 [fused_moe.py:207] [EP Rank 3/32] Expert parallelism is enabled. Local/global number of experts: 8/256. Experts local to global index map: 0->24, 1->25, 2->26, 3->27, 4->28, 5->29, 6->30, 7->31.
2026-02-12T19:22:43.7997725Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m INFO 02-12 19:22:43 [fused_moe.py:207] [EP Rank 10/32] Expert parallelism is enabled. Local/global number of experts: 8/256. Experts local to global index map: 0->80, 1->81, 2->82, 3->83, 4->84, 5->85, 6->86, 7->87.
2026-02-12T19:22:43.9843827Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m INFO 02-12 19:22:43 [fused_moe.py:414] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-02-12T19:22:44.0320344Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m INFO 02-12 19:22:43 [fused_moe.py:414] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-02-12T19:22:44.0321127Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m INFO 02-12 19:22:44 [fused_moe.py:414] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-02-12T19:22:44.0321894Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m INFO 02-12 19:22:44 [fused_moe.py:414] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-02-12T19:22:44.0325932Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m INFO 02-12 19:22:44 [fused_moe.py:414] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-02-12T19:22:44.0326677Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m INFO 02-12 19:22:44 [fused_moe.py:414] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-02-12T19:22:44.0480999Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m INFO 02-12 19:22:44 [fused_moe.py:414] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-02-12T19:22:44.0544102Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m INFO 02-12 19:22:44 [fused_moe.py:414] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-02-12T19:22:44.0553477Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m INFO 02-12 19:22:44 [fused_moe.py:414] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-02-12T19:22:44.0663914Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m INFO 02-12 19:22:44 [fused_moe.py:414] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-02-12T19:22:44.0742445Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m INFO 02-12 19:22:44 [fused_moe.py:414] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-02-12T19:22:44.0812522Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m INFO 02-12 19:22:44 [fused_moe.py:414] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-02-12T19:22:44.0864128Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m INFO 02-12 19:22:44 [fused_moe.py:414] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-02-12T19:22:44.1040971Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m INFO 02-12 19:22:44 [fused_moe.py:414] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-02-12T19:22:44.1268837Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m INFO 02-12 19:22:44 [fused_moe.py:414] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-02-12T19:22:44.1290499Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m INFO 02-12 19:22:44 [fused_moe.py:414] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-02-12T19:22:47.3960343Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m INFO 02-12 19:22:47 [compilation.py:863] Using OOT custom backend for compilation.
2026-02-12T19:22:47.4213114Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m INFO 02-12 19:22:47 [compilation.py:863] Using OOT custom backend for compilation.
2026-02-12T19:22:47.4565915Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m INFO 02-12 19:22:47 [compilation.py:863] Using OOT custom backend for compilation.
2026-02-12T19:22:47.4732498Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m INFO 02-12 19:22:47 [compilation.py:863] Using OOT custom backend for compilation.
2026-02-12T19:22:47.4855218Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m INFO 02-12 19:22:47 [compilation.py:863] Using OOT custom backend for compilation.
2026-02-12T19:22:47.4907764Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m INFO 02-12 19:22:47 [compilation.py:863] Using OOT custom backend for compilation.
2026-02-12T19:22:47.5072418Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m INFO 02-12 19:22:47 [compilation.py:863] Using OOT custom backend for compilation.
2026-02-12T19:22:47.5351727Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m INFO 02-12 19:22:47 [compilation.py:863] Using OOT custom backend for compilation.
2026-02-12T19:22:47.5690469Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m INFO 02-12 19:22:47 [compilation.py:863] Using OOT custom backend for compilation.
2026-02-12T19:22:47.5930040Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m INFO 02-12 19:22:47 [compilation.py:863] Using OOT custom backend for compilation.
2026-02-12T19:22:47.6183943Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m INFO 02-12 19:22:47 [compilation.py:863] Using OOT custom backend for compilation.
2026-02-12T19:22:47.6209564Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m INFO 02-12 19:22:47 [compilation.py:863] Using OOT custom backend for compilation.
2026-02-12T19:22:47.6220720Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m INFO 02-12 19:22:47 [compilation.py:863] Using OOT custom backend for compilation.
2026-02-12T19:22:47.6575274Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m INFO 02-12 19:22:47 [compilation.py:863] Using OOT custom backend for compilation.
2026-02-12T19:22:47.6701617Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m INFO 02-12 19:22:47 [compilation.py:863] Using OOT custom backend for compilation.
2026-02-12T19:22:47.6803178Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:22:47.6803482Z Loading safetensors checkpoint shards:   0% Completed | 0/163 [00:00<?, ?it/s]
2026-02-12T19:22:47.7386534Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m INFO 02-12 19:22:47 [compilation.py:863] Using OOT custom backend for compilation.
2026-02-12T19:22:48.9211494Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:22:48.9211853Z Loading safetensors checkpoint shards:   1% Completed | 1/163 [00:01<03:20,  1.24s/it]
2026-02-12T19:22:51.7816648Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:22:51.7817028Z Loading safetensors checkpoint shards:   1% Completed | 2/163 [00:04<05:52,  2.19s/it]
2026-02-12T19:22:53.1624395Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:22:53.1624793Z Loading safetensors checkpoint shards:   2% Completed | 3/163 [00:05<04:51,  1.82s/it]
2026-02-12T19:22:54.5045565Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:22:54.5045923Z Loading safetensors checkpoint shards:   2% Completed | 4/163 [00:06<04:19,  1.63s/it]
2026-02-12T19:22:56.6823382Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:22:56.6824043Z Loading safetensors checkpoint shards:   3% Completed | 5/163 [00:08<04:48,  1.83s/it]
2026-02-12T19:22:59.3769625Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:22:59.3769997Z Loading safetensors checkpoint shards:   4% Completed | 6/163 [00:11<05:33,  2.12s/it]
2026-02-12T19:23:01.5430165Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:23:01.5430586Z Loading safetensors checkpoint shards:   4% Completed | 7/163 [00:13<05:33,  2.14s/it]
2026-02-12T19:23:03.5706208Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:23:03.5706585Z Loading safetensors checkpoint shards:   5% Completed | 8/163 [00:15<05:25,  2.10s/it]
2026-02-12T19:23:05.2311523Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:23:05.2312244Z Loading safetensors checkpoint shards:   6% Completed | 9/163 [00:17<05:02,  1.96s/it]
2026-02-12T19:23:06.8175841Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:23:06.8176209Z Loading safetensors checkpoint shards:   6% Completed | 10/163 [00:19<04:42,  1.85s/it]
2026-02-12T19:23:08.3494559Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:23:08.3494927Z Loading safetensors checkpoint shards:   7% Completed | 11/163 [00:20<04:26,  1.75s/it]
2026-02-12T19:23:10.0364431Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:23:10.0364806Z Loading safetensors checkpoint shards:   7% Completed | 12/163 [00:22<04:21,  1.73s/it]
2026-02-12T19:23:11.5123778Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:23:11.5124154Z Loading safetensors checkpoint shards:   8% Completed | 13/163 [00:23<04:08,  1.65s/it]
2026-02-12T19:23:13.3780083Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:23:13.3780472Z Loading safetensors checkpoint shards:   9% Completed | 14/163 [00:25<04:15,  1.72s/it]
2026-02-12T19:23:16.1848659Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:23:16.1849046Z Loading safetensors checkpoint shards:   9% Completed | 15/163 [00:28<05:02,  2.05s/it]
2026-02-12T19:23:18.6134489Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:23:18.6134929Z Loading safetensors checkpoint shards:  10% Completed | 16/163 [00:30<05:17,  2.16s/it]
2026-02-12T19:23:21.0046528Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:23:21.0046897Z Loading safetensors checkpoint shards:  10% Completed | 17/163 [00:33<05:25,  2.23s/it]
2026-02-12T19:23:23.3153729Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:23:23.3154096Z Loading safetensors checkpoint shards:  11% Completed | 18/163 [00:35<05:26,  2.25s/it]
2026-02-12T19:23:24.5265906Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:23:24.5266280Z Loading safetensors checkpoint shards:  12% Completed | 19/163 [00:36<04:39,  1.94s/it]
2026-02-12T19:23:26.1483001Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:23:26.1483378Z Loading safetensors checkpoint shards:  12% Completed | 20/163 [00:38<04:23,  1.84s/it]
2026-02-12T19:23:28.5389182Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:23:28.5389548Z Loading safetensors checkpoint shards:  13% Completed | 21/163 [00:40<04:45,  2.01s/it]
2026-02-12T19:23:30.0556426Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:23:30.0556805Z Loading safetensors checkpoint shards:  13% Completed | 22/163 [00:42<04:22,  1.86s/it]
2026-02-12T19:23:31.7389756Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:23:31.7390112Z Loading safetensors checkpoint shards:  14% Completed | 23/163 [00:44<04:13,  1.81s/it]
2026-02-12T19:23:33.1327654Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:23:33.1328014Z Loading safetensors checkpoint shards:  15% Completed | 24/163 [00:45<03:54,  1.68s/it]
2026-02-12T19:23:35.6239773Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:23:35.6240180Z Loading safetensors checkpoint shards:  15% Completed | 25/163 [00:47<04:25,  1.93s/it]
2026-02-12T19:23:36.6539088Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:23:36.6539455Z Loading safetensors checkpoint shards:  16% Completed | 26/163 [00:48<03:47,  1.66s/it]
2026-02-12T19:23:37.9802803Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:23:37.9803184Z Loading safetensors checkpoint shards:  17% Completed | 27/163 [00:50<03:31,  1.56s/it]
2026-02-12T19:23:40.5097982Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:23:40.5098352Z Loading safetensors checkpoint shards:  17% Completed | 28/163 [00:52<04:09,  1.85s/it]
2026-02-12T19:23:41.9380805Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:23:41.9381171Z Loading safetensors checkpoint shards:  18% Completed | 29/163 [00:54<03:50,  1.72s/it]
2026-02-12T19:23:43.2013598Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:23:43.2013965Z Loading safetensors checkpoint shards:  18% Completed | 30/163 [00:55<03:30,  1.59s/it]
2026-02-12T19:23:44.4532868Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:23:44.4533245Z Loading safetensors checkpoint shards:  19% Completed | 31/163 [00:56<03:16,  1.49s/it]
2026-02-12T19:23:45.9544302Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:23:45.9544692Z Loading safetensors checkpoint shards:  20% Completed | 32/163 [00:58<03:15,  1.49s/it]
2026-02-12T19:23:47.5968883Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:23:47.5969244Z Loading safetensors checkpoint shards:  20% Completed | 33/163 [00:59<03:19,  1.54s/it]
2026-02-12T19:23:49.3695043Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:23:49.3695425Z Loading safetensors checkpoint shards:  21% Completed | 34/163 [01:01<03:27,  1.61s/it]
2026-02-12T19:23:51.0463859Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:23:51.0464235Z Loading safetensors checkpoint shards:  21% Completed | 35/163 [01:03<03:28,  1.63s/it]
2026-02-12T19:23:54.2894610Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:23:54.2895015Z Loading safetensors checkpoint shards:  22% Completed | 36/163 [01:06<04:28,  2.11s/it]
2026-02-12T19:23:55.7178133Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:23:55.7178488Z Loading safetensors checkpoint shards:  23% Completed | 37/163 [01:08<04:00,  1.91s/it]
2026-02-12T19:23:57.1888733Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:23:57.1889119Z Loading safetensors checkpoint shards:  23% Completed | 38/163 [01:09<03:42,  1.78s/it]
2026-02-12T19:23:58.4246373Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:23:58.4246742Z Loading safetensors checkpoint shards:  24% Completed | 39/163 [01:10<03:20,  1.61s/it]
2026-02-12T19:24:01.5473315Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:24:01.5473678Z Loading safetensors checkpoint shards:  25% Completed | 40/163 [01:13<04:14,  2.07s/it]
2026-02-12T19:24:02.7034758Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:24:02.7035149Z Loading safetensors checkpoint shards:  25% Completed | 41/163 [01:15<03:38,  1.79s/it]
2026-02-12T19:24:04.1636934Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:24:04.1637289Z Loading safetensors checkpoint shards:  26% Completed | 42/163 [01:16<03:24,  1.69s/it]
2026-02-12T19:24:07.1645448Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:24:07.1645851Z Loading safetensors checkpoint shards:  26% Completed | 43/163 [01:19<04:10,  2.09s/it]
2026-02-12T19:24:08.1926771Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:24:08.1927156Z Loading safetensors checkpoint shards:  27% Completed | 44/163 [01:20<03:30,  1.77s/it]
2026-02-12T19:24:09.3631319Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:24:09.3631704Z Loading safetensors checkpoint shards:  28% Completed | 45/163 [01:21<03:07,  1.59s/it]
2026-02-12T19:24:10.7838292Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:24:10.7838652Z Loading safetensors checkpoint shards:  28% Completed | 46/163 [01:23<03:00,  1.54s/it]
2026-02-12T19:24:17.1205003Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:24:17.1205393Z Loading safetensors checkpoint shards:  29% Completed | 47/163 [01:29<05:45,  2.98s/it]
2026-02-12T19:24:19.1006680Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:24:19.1007033Z Loading safetensors checkpoint shards:  29% Completed | 48/163 [01:31<05:07,  2.68s/it]
2026-02-12T19:24:19.3131707Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:24:19.3132136Z Loading safetensors checkpoint shards:  30% Completed | 49/163 [01:31<03:41,  1.94s/it]
2026-02-12T19:24:20.7301074Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:24:20.7301444Z Loading safetensors checkpoint shards:  31% Completed | 50/163 [01:33<03:21,  1.78s/it]
2026-02-12T19:24:23.2882326Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:24:23.2882692Z Loading safetensors checkpoint shards:  31% Completed | 51/163 [01:35<03:45,  2.02s/it]
2026-02-12T19:24:24.2480690Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:24:24.2481408Z Loading safetensors checkpoint shards:  32% Completed | 52/163 [01:36<03:08,  1.70s/it]
2026-02-12T19:24:26.9245737Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:24:26.9246127Z Loading safetensors checkpoint shards:  33% Completed | 53/163 [01:39<03:39,  1.99s/it]
2026-02-12T19:24:27.8746302Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:24:27.8746662Z Loading safetensors checkpoint shards:  33% Completed | 54/163 [01:40<03:03,  1.68s/it]
2026-02-12T19:24:29.3119316Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:24:29.3119694Z Loading safetensors checkpoint shards:  34% Completed | 55/163 [01:41<02:53,  1.61s/it]
2026-02-12T19:24:30.7117120Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:24:30.7117505Z Loading safetensors checkpoint shards:  34% Completed | 56/163 [01:43<02:45,  1.54s/it]
2026-02-12T19:24:32.0557331Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:24:32.0557696Z Loading safetensors checkpoint shards:  35% Completed | 57/163 [01:44<02:37,  1.48s/it]
2026-02-12T19:24:33.2924286Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:24:33.2924671Z Loading safetensors checkpoint shards:  36% Completed | 58/163 [01:45<02:28,  1.41s/it]
2026-02-12T19:24:36.3687258Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:24:36.3687644Z Loading safetensors checkpoint shards:  36% Completed | 59/163 [01:48<03:18,  1.91s/it]
2026-02-12T19:24:37.5770678Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:24:37.5771065Z Loading safetensors checkpoint shards:  37% Completed | 60/163 [01:49<02:55,  1.70s/it]
2026-02-12T19:24:38.8123505Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:24:38.8123869Z Loading safetensors checkpoint shards:  37% Completed | 61/163 [01:51<02:39,  1.56s/it]
2026-02-12T19:24:41.6216974Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:24:41.6217337Z Loading safetensors checkpoint shards:  38% Completed | 62/163 [01:53<03:15,  1.93s/it]
2026-02-12T19:24:43.0701318Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:24:43.0701683Z Loading safetensors checkpoint shards:  39% Completed | 63/163 [01:55<02:58,  1.79s/it]
2026-02-12T19:24:44.7423169Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:24:44.7423517Z Loading safetensors checkpoint shards:  39% Completed | 64/163 [01:57<02:53,  1.75s/it]
2026-02-12T19:24:47.7304219Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:24:47.7304582Z Loading safetensors checkpoint shards:  40% Completed | 65/163 [02:00<03:28,  2.12s/it]
2026-02-12T19:24:49.9187136Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:24:49.9187494Z Loading safetensors checkpoint shards:  40% Completed | 66/163 [02:02<03:27,  2.14s/it]
2026-02-12T19:24:51.1067378Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:24:51.1067740Z Loading safetensors checkpoint shards:  41% Completed | 67/163 [02:03<02:58,  1.86s/it]
2026-02-12T19:24:53.4223373Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:24:53.4223738Z Loading safetensors checkpoint shards:  42% Completed | 68/163 [02:05<03:09,  1.99s/it]
2026-02-12T19:24:54.7952863Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:24:54.7953225Z Loading safetensors checkpoint shards:  42% Completed | 69/163 [02:07<02:49,  1.81s/it]
2026-02-12T19:24:55.9949597Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:24:55.9950234Z Loading safetensors checkpoint shards:  43% Completed | 70/163 [02:08<02:31,  1.63s/it]
2026-02-12T19:24:57.9312387Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:24:57.9312758Z Loading safetensors checkpoint shards:  44% Completed | 71/163 [02:10<02:38,  1.72s/it]
2026-02-12T19:25:00.6249129Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:25:00.6249546Z Loading safetensors checkpoint shards:  44% Completed | 72/163 [02:12<03:02,  2.01s/it]
2026-02-12T19:25:01.9086493Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:25:01.9086865Z Loading safetensors checkpoint shards:  45% Completed | 73/163 [02:14<02:41,  1.79s/it]
2026-02-12T19:25:03.4835580Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:25:03.4836257Z Loading safetensors checkpoint shards:  45% Completed | 74/163 [02:15<02:33,  1.73s/it]
2026-02-12T19:25:05.0123576Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:25:05.0123948Z Loading safetensors checkpoint shards:  46% Completed | 75/163 [02:17<02:26,  1.67s/it]
2026-02-12T19:25:06.3564265Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:25:06.3564625Z Loading safetensors checkpoint shards:  47% Completed | 76/163 [02:18<02:16,  1.57s/it]
2026-02-12T19:25:08.6212728Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:25:08.6213091Z Loading safetensors checkpoint shards:  47% Completed | 77/163 [02:20<02:32,  1.78s/it]
2026-02-12T19:25:10.3572789Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:25:10.3573159Z Loading safetensors checkpoint shards:  48% Completed | 78/163 [02:22<02:30,  1.77s/it]
2026-02-12T19:25:11.6268880Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:25:11.6269277Z Loading safetensors checkpoint shards:  48% Completed | 79/163 [02:23<02:15,  1.62s/it]
2026-02-12T19:25:13.9743717Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:25:13.9744081Z Loading safetensors checkpoint shards:  49% Completed | 80/163 [02:26<02:32,  1.84s/it]
2026-02-12T19:25:16.7408992Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:25:16.7409395Z Loading safetensors checkpoint shards:  50% Completed | 81/163 [02:29<02:53,  2.12s/it]
2026-02-12T19:25:18.2046672Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:25:18.2047047Z Loading safetensors checkpoint shards:  50% Completed | 82/163 [02:30<02:35,  1.92s/it]
2026-02-12T19:25:20.3777250Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:25:20.3777638Z Loading safetensors checkpoint shards:  51% Completed | 83/163 [02:32<02:39,  2.00s/it]
2026-02-12T19:25:21.7177357Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:25:21.7177725Z Loading safetensors checkpoint shards:  52% Completed | 84/163 [02:34<02:22,  1.80s/it]
2026-02-12T19:25:23.8471030Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:25:23.8471401Z Loading safetensors checkpoint shards:  52% Completed | 85/163 [02:36<02:28,  1.90s/it]
2026-02-12T19:25:25.1281499Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:25:25.1281903Z Loading safetensors checkpoint shards:  53% Completed | 86/163 [02:37<02:11,  1.71s/it]
2026-02-12T19:25:26.8041234Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:25:26.8041604Z Loading safetensors checkpoint shards:  53% Completed | 87/163 [02:39<02:09,  1.70s/it]
2026-02-12T19:25:29.5892365Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:25:29.5892744Z Loading safetensors checkpoint shards:  54% Completed | 88/163 [02:41<02:32,  2.03s/it]
2026-02-12T19:25:31.0017680Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:25:31.0018054Z Loading safetensors checkpoint shards:  55% Completed | 89/163 [02:43<02:16,  1.84s/it]
2026-02-12T19:25:33.8990780Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:25:33.8991179Z Loading safetensors checkpoint shards:  55% Completed | 90/163 [02:46<02:37,  2.16s/it]
2026-02-12T19:25:35.4945251Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:25:35.4945615Z Loading safetensors checkpoint shards:  56% Completed | 91/163 [02:47<02:23,  1.99s/it]
2026-02-12T19:25:38.4330210Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:25:38.4330613Z Loading safetensors checkpoint shards:  56% Completed | 92/163 [02:50<02:41,  2.27s/it]
2026-02-12T19:25:39.6169316Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:25:39.6169666Z Loading safetensors checkpoint shards:  57% Completed | 93/163 [02:51<02:16,  1.95s/it]
2026-02-12T19:25:40.9939239Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:25:40.9939600Z Loading safetensors checkpoint shards:  58% Completed | 94/163 [02:53<02:02,  1.78s/it]
2026-02-12T19:25:42.4530224Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:25:42.4530613Z Loading safetensors checkpoint shards:  58% Completed | 95/163 [02:54<01:54,  1.68s/it]
2026-02-12T19:25:44.8262484Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:25:44.8262856Z Loading safetensors checkpoint shards:  59% Completed | 96/163 [02:57<02:06,  1.89s/it]
2026-02-12T19:25:46.1197333Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:25:46.1197713Z Loading safetensors checkpoint shards:  60% Completed | 97/163 [02:58<01:52,  1.71s/it]
2026-02-12T19:25:47.4455434Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:25:47.4455800Z Loading safetensors checkpoint shards:  60% Completed | 98/163 [02:59<01:43,  1.60s/it]
2026-02-12T19:25:48.8980482Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:25:48.8980832Z Loading safetensors checkpoint shards:  61% Completed | 99/163 [03:01<01:39,  1.55s/it]
2026-02-12T19:25:50.4172379Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:25:50.4172750Z Loading safetensors checkpoint shards:  61% Completed | 100/163 [03:02<01:37,  1.54s/it]
2026-02-12T19:25:51.4420253Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:25:51.4420741Z Loading safetensors checkpoint shards:  62% Completed | 101/163 [03:03<01:26,  1.39s/it]
2026-02-12T19:25:54.0825452Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:25:54.0825819Z Loading safetensors checkpoint shards:  63% Completed | 102/163 [03:06<01:47,  1.76s/it]
2026-02-12T19:25:56.4083094Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:25:56.4083465Z Loading safetensors checkpoint shards:  63% Completed | 103/163 [03:08<01:55,  1.93s/it]
2026-02-12T19:25:59.0134609Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:25:59.0134980Z Loading safetensors checkpoint shards:  64% Completed | 104/163 [03:11<02:05,  2.13s/it]
2026-02-12T19:26:00.5127158Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:26:00.5127523Z Loading safetensors checkpoint shards:  64% Completed | 105/163 [03:12<01:52,  1.94s/it]
2026-02-12T19:26:02.8254848Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:26:02.8255236Z Loading safetensors checkpoint shards:  65% Completed | 106/163 [03:15<01:57,  2.05s/it]
2026-02-12T19:26:04.3555616Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:26:04.3555964Z Loading safetensors checkpoint shards:  66% Completed | 107/163 [03:16<01:46,  1.90s/it]
2026-02-12T19:26:06.9878799Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:26:06.9879192Z Loading safetensors checkpoint shards:  66% Completed | 108/163 [03:19<01:56,  2.12s/it]
2026-02-12T19:26:08.2258504Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:26:08.2258867Z Loading safetensors checkpoint shards:  67% Completed | 109/163 [03:20<01:40,  1.85s/it]
2026-02-12T19:26:10.6075396Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:26:10.6075823Z Loading safetensors checkpoint shards:  67% Completed | 110/163 [03:22<01:46,  2.01s/it]
2026-02-12T19:26:13.4435051Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:26:13.4435422Z Loading safetensors checkpoint shards:  68% Completed | 111/163 [03:25<01:57,  2.26s/it]
2026-02-12T19:26:15.5382743Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:26:15.5383120Z Loading safetensors checkpoint shards:  69% Completed | 112/163 [03:27<01:52,  2.21s/it]
2026-02-12T19:26:17.6361574Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:26:17.6361937Z Loading safetensors checkpoint shards:  69% Completed | 113/163 [03:29<01:48,  2.18s/it]
2026-02-12T19:26:18.8912621Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:26:18.8912978Z Loading safetensors checkpoint shards:  70% Completed | 114/163 [03:31<01:33,  1.90s/it]
2026-02-12T19:26:20.3117979Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:26:20.3118395Z Loading safetensors checkpoint shards:  71% Completed | 115/163 [03:32<01:24,  1.76s/it]
2026-02-12T19:26:23.0715488Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:26:23.0715881Z Loading safetensors checkpoint shards:  71% Completed | 116/163 [03:35<01:36,  2.06s/it]
2026-02-12T19:26:24.5289181Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:26:24.5289868Z Loading safetensors checkpoint shards:  72% Completed | 117/163 [03:36<01:26,  1.88s/it]
2026-02-12T19:26:27.1736497Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:26:27.1736865Z Loading safetensors checkpoint shards:  72% Completed | 118/163 [03:39<01:34,  2.11s/it]
2026-02-12T19:26:28.4477759Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:26:28.4478135Z Loading safetensors checkpoint shards:  73% Completed | 119/163 [03:40<01:21,  1.86s/it]
2026-02-12T19:26:29.9716612Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:26:29.9716969Z Loading safetensors checkpoint shards:  74% Completed | 120/163 [03:42<01:15,  1.76s/it]
2026-02-12T19:26:31.6232225Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:26:31.6232618Z Loading safetensors checkpoint shards:  74% Completed | 121/163 [03:43<01:12,  1.73s/it]
2026-02-12T19:26:32.9448932Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:26:32.9449300Z Loading safetensors checkpoint shards:  75% Completed | 122/163 [03:45<01:05,  1.60s/it]
2026-02-12T19:26:35.2724237Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:26:35.2724598Z Loading safetensors checkpoint shards:  75% Completed | 123/163 [03:47<01:12,  1.82s/it]
2026-02-12T19:26:36.5459215Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:26:36.5459614Z Loading safetensors checkpoint shards:  76% Completed | 124/163 [03:48<01:04,  1.66s/it]
2026-02-12T19:26:39.1261225Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:26:39.1261612Z Loading safetensors checkpoint shards:  77% Completed | 125/163 [03:51<01:13,  1.93s/it]
2026-02-12T19:26:40.4545541Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:26:40.4545900Z Loading safetensors checkpoint shards:  77% Completed | 126/163 [03:52<01:04,  1.75s/it]
2026-02-12T19:26:41.8171857Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:26:41.8172337Z Loading safetensors checkpoint shards:  78% Completed | 127/163 [03:54<00:58,  1.64s/it]
2026-02-12T19:26:44.1932920Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:26:44.1933302Z Loading safetensors checkpoint shards:  79% Completed | 128/163 [03:56<01:05,  1.86s/it]
2026-02-12T19:26:46.1502943Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:26:46.1503320Z Loading safetensors checkpoint shards:  79% Completed | 129/163 [03:58<01:04,  1.89s/it]
2026-02-12T19:26:47.5169161Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:26:47.5169536Z Loading safetensors checkpoint shards:  80% Completed | 130/163 [03:59<00:57,  1.73s/it]
2026-02-12T19:26:48.6955242Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:26:48.6955650Z Loading safetensors checkpoint shards:  80% Completed | 131/163 [04:01<00:50,  1.57s/it]
2026-02-12T19:26:50.1092281Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:26:50.1092767Z Loading safetensors checkpoint shards:  81% Completed | 132/163 [04:02<00:47,  1.52s/it]
2026-02-12T19:26:52.3038417Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:26:52.3038896Z Loading safetensors checkpoint shards:  82% Completed | 133/163 [04:04<00:51,  1.72s/it]
2026-02-12T19:26:53.8475837Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:26:53.8476268Z Loading safetensors checkpoint shards:  82% Completed | 134/163 [04:06<00:48,  1.67s/it]
2026-02-12T19:26:56.8460428Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:26:56.8461174Z Loading safetensors checkpoint shards:  83% Completed | 135/163 [04:09<00:57,  2.07s/it]
2026-02-12T19:26:58.1400067Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:26:58.1400489Z Loading safetensors checkpoint shards:  83% Completed | 136/163 [04:10<00:49,  1.84s/it]
2026-02-12T19:26:59.6894154Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:26:59.6894566Z Loading safetensors checkpoint shards:  84% Completed | 137/163 [04:12<00:45,  1.75s/it]
2026-02-12T19:27:02.9860295Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:27:02.9860698Z Loading safetensors checkpoint shards:  85% Completed | 138/163 [04:15<00:55,  2.21s/it]
2026-02-12T19:27:05.5595481Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:27:05.5595925Z Loading safetensors checkpoint shards:  85% Completed | 139/163 [04:17<00:55,  2.32s/it]
2026-02-12T19:27:06.8006360Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:27:06.8006794Z Loading safetensors checkpoint shards:  86% Completed | 140/163 [04:19<00:45,  2.00s/it]
2026-02-12T19:27:08.2272164Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:27:08.2272616Z Loading safetensors checkpoint shards:  87% Completed | 141/163 [04:20<00:40,  1.83s/it]
2026-02-12T19:27:09.5732593Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:27:09.5733037Z Loading safetensors checkpoint shards:  87% Completed | 142/163 [04:21<00:35,  1.68s/it]
2026-02-12T19:27:11.9668348Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:27:11.9668768Z Loading safetensors checkpoint shards:  88% Completed | 143/163 [04:24<00:37,  1.90s/it]
2026-02-12T19:27:14.4605094Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:27:14.4605566Z Loading safetensors checkpoint shards:  88% Completed | 144/163 [04:26<00:39,  2.08s/it]
2026-02-12T19:27:16.0466027Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:27:16.0466492Z Loading safetensors checkpoint shards:  89% Completed | 145/163 [04:28<00:34,  1.93s/it]
2026-02-12T19:27:18.3097844Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:27:18.3098252Z Loading safetensors checkpoint shards:  90% Completed | 146/163 [04:30<00:34,  2.03s/it]
2026-02-12T19:27:19.9459492Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:27:19.9460080Z Loading safetensors checkpoint shards:  90% Completed | 147/163 [04:32<00:30,  1.91s/it]
2026-02-12T19:27:21.1491685Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:27:21.1492276Z Loading safetensors checkpoint shards:  91% Completed | 148/163 [04:33<00:25,  1.70s/it]
2026-02-12T19:27:22.3878404Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:27:22.3878885Z Loading safetensors checkpoint shards:  91% Completed | 149/163 [04:34<00:21,  1.56s/it]
2026-02-12T19:27:24.9225897Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:27:24.9226326Z Loading safetensors checkpoint shards:  93% Completed | 151/163 [04:37<00:17,  1.43s/it]
2026-02-12T19:27:26.3020068Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:27:26.3020533Z Loading safetensors checkpoint shards:  93% Completed | 152/163 [04:38<00:15,  1.41s/it]
2026-02-12T19:27:27.6445538Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:27:27.6445989Z Loading safetensors checkpoint shards:  94% Completed | 153/163 [04:39<00:13,  1.40s/it]
2026-02-12T19:27:29.0447115Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:27:29.0447560Z Loading safetensors checkpoint shards:  94% Completed | 154/163 [04:41<00:12,  1.40s/it]
2026-02-12T19:27:30.6051216Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:27:30.6051654Z Loading safetensors checkpoint shards:  95% Completed | 155/163 [04:42<00:11,  1.44s/it]
2026-02-12T19:27:32.1196739Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:27:32.1197205Z Loading safetensors checkpoint shards:  96% Completed | 156/163 [04:44<00:10,  1.46s/it]
2026-02-12T19:27:33.4938259Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:27:33.4938764Z Loading safetensors checkpoint shards:  96% Completed | 157/163 [04:45<00:08,  1.44s/it]
2026-02-12T19:27:36.1749384Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:27:36.1749873Z Loading safetensors checkpoint shards:  97% Completed | 158/163 [04:48<00:09,  1.80s/it]
2026-02-12T19:27:37.6305735Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:27:37.6306310Z Loading safetensors checkpoint shards:  98% Completed | 159/163 [04:49<00:06,  1.70s/it]
2026-02-12T19:27:39.1658472Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:27:39.1658982Z Loading safetensors checkpoint shards:  98% Completed | 160/163 [04:51<00:04,  1.65s/it]
2026-02-12T19:27:40.4908334Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:27:40.4909146Z Loading safetensors checkpoint shards:  99% Completed | 161/163 [04:52<00:03,  1.55s/it]
2026-02-12T19:27:42.4856692Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:27:42.4857196Z Loading safetensors checkpoint shards:  99% Completed | 162/163 [04:54<00:01,  1.69s/it]
2026-02-12T19:27:43.8920885Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:27:43.8921336Z Loading safetensors checkpoint shards: 100% Completed | 163/163 [04:56<00:00,  1.60s/it]
2026-02-12T19:27:43.8983167Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:27:43.8983541Z Loading safetensors checkpoint shards: 100% Completed | 163/163 [04:56<00:00,  1.82s/it]
2026-02-12T19:27:43.8991650Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:27:43.9083548Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m INFO 02-12 19:27:43 [default_loader.py:291] Loading weights took 296.23 seconds
2026-02-12T19:27:44.0471135Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m INFO 02-12 19:27:44 [default_loader.py:291] Loading weights took 296.23 seconds
2026-02-12T19:27:57.3066496Z INFO 02-12 19:27:57 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-12T19:27:57.3075941Z INFO 02-12 19:27:57 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-12T19:27:57.3085831Z INFO 02-12 19:27:57 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-12T19:27:57.3095737Z INFO 02-12 19:27:57 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-12T19:27:57.3105589Z INFO 02-12 19:27:57 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-12T19:27:57.3114663Z INFO 02-12 19:27:57 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-12T19:27:57.3125099Z INFO 02-12 19:27:57 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-12T19:27:57.3134408Z INFO 02-12 19:27:57 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-12T19:27:57.3143969Z INFO 02-12 19:27:57 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-12T19:27:57.3208698Z INFO 02-12 19:27:57 [__init__.py:217] Platform plugin ascend is activated
2026-02-12T19:27:57.3217456Z INFO 02-12 19:27:57 [__init__.py:217] Platform plugin ascend is activated
2026-02-12T19:27:57.3226511Z INFO 02-12 19:27:57 [__init__.py:217] Platform plugin ascend is activated
2026-02-12T19:27:57.3511256Z INFO 02-12 19:27:57 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-12T19:27:57.3520451Z INFO 02-12 19:27:57 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-12T19:27:57.3530682Z INFO 02-12 19:27:57 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-12T19:27:57.3539243Z INFO 02-12 19:27:57 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-12T19:27:57.3548278Z INFO 02-12 19:27:57 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-12T19:27:57.3558107Z INFO 02-12 19:27:57 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-12T19:27:57.3567356Z INFO 02-12 19:27:57 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-12T19:27:57.3576993Z INFO 02-12 19:27:57 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-12T19:27:57.3585893Z INFO 02-12 19:27:57 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-12T19:27:57.3595632Z INFO 02-12 19:27:57 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-12T19:27:57.3605941Z INFO 02-12 19:27:57 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-12T19:27:57.3615396Z INFO 02-12 19:27:57 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-12T19:27:57.3624903Z INFO 02-12 19:27:57 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-12T19:27:57.3633863Z INFO 02-12 19:27:57 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-12T19:27:57.3643318Z INFO 02-12 19:27:57 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-12T19:27:57.3653107Z INFO 02-12 19:27:57 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-12T19:27:57.3662672Z INFO 02-12 19:27:57 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-12T19:27:57.3672635Z INFO 02-12 19:27:57 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-12T19:27:57.3682467Z INFO 02-12 19:27:57 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-12T19:27:57.3691818Z INFO 02-12 19:27:57 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-12T19:27:57.3701626Z INFO 02-12 19:27:57 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-12T19:27:57.3711651Z INFO 02-12 19:27:57 [__init__.py:217] Platform plugin ascend is activated
2026-02-12T19:27:57.3721818Z INFO 02-12 19:27:57 [__init__.py:217] Platform plugin ascend is activated
2026-02-12T19:27:57.3731742Z INFO 02-12 19:27:57 [__init__.py:217] Platform plugin ascend is activated
2026-02-12T19:27:57.3741297Z INFO 02-12 19:27:57 [__init__.py:217] Platform plugin ascend is activated
2026-02-12T19:27:57.3750743Z INFO 02-12 19:27:57 [__init__.py:217] Platform plugin ascend is activated
2026-02-12T19:27:57.3760924Z INFO 02-12 19:27:57 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-12T19:27:57.3770959Z INFO 02-12 19:27:57 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-12T19:27:57.3780947Z INFO 02-12 19:27:57 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-12T19:27:57.3790272Z INFO 02-12 19:27:57 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-12T19:27:57.3800349Z INFO 02-12 19:27:57 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-12T19:27:57.3812723Z INFO 02-12 19:27:57 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-12T19:27:57.3820180Z INFO 02-12 19:27:57 [__init__.py:217] Platform plugin ascend is activated
2026-02-12T19:27:57.3829519Z INFO 02-12 19:27:57 [__init__.py:217] Platform plugin ascend is activated
2026-02-12T19:27:57.3840025Z INFO 02-12 19:27:57 [__init__.py:217] Platform plugin ascend is activated
2026-02-12T19:27:57.3849204Z INFO 02-12 19:27:57 [__init__.py:217] Platform plugin ascend is activated
2026-02-12T19:27:57.4432508Z INFO 02-12 19:27:57 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-12T19:27:57.4441171Z INFO 02-12 19:27:57 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-12T19:27:57.4450470Z INFO 02-12 19:27:57 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-12T19:27:57.4520687Z INFO 02-12 19:27:57 [__init__.py:217] Platform plugin ascend is activated
2026-02-12T19:27:57.4824369Z INFO 02-12 19:27:57 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-12T19:27:57.4833030Z INFO 02-12 19:27:57 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-12T19:27:57.4842848Z INFO 02-12 19:27:57 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-12T19:27:57.4852562Z INFO 02-12 19:27:57 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-12T19:27:57.4861629Z INFO 02-12 19:27:57 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-12T19:27:57.4870594Z INFO 02-12 19:27:57 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-12T19:27:57.4905699Z INFO 02-12 19:27:57 [__init__.py:217] Platform plugin ascend is activated
2026-02-12T19:27:57.4915434Z INFO 02-12 19:27:57 [__init__.py:217] Platform plugin ascend is activated
2026-02-12T19:27:57.5257994Z INFO 02-12 19:27:57 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-12T19:27:57.5258386Z INFO 02-12 19:27:57 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-12T19:27:57.5258900Z INFO 02-12 19:27:57 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-12T19:27:57.5296988Z INFO 02-12 19:27:57 [__init__.py:217] Platform plugin ascend is activated
2026-02-12T19:28:24.2189673Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m WARNING 02-12 19:28:24 [sfa_v1.py:523] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-02-12T19:28:24.2200875Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m WARNING 02-12 19:28:24 [sfa_v1.py:523] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-02-12T19:28:24.2231754Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m WARNING 02-12 19:28:24 [sfa_v1.py:523] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-02-12T19:28:24.2392877Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m WARNING 02-12 19:28:24 [sfa_v1.py:523] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-02-12T19:28:24.2405147Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m WARNING 02-12 19:28:24 [sfa_v1.py:523] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-02-12T19:28:24.2416475Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m WARNING 02-12 19:28:24 [sfa_v1.py:523] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-02-12T19:28:24.2445617Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m WARNING 02-12 19:28:24 [sfa_v1.py:523] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-02-12T19:28:24.2454314Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m WARNING 02-12 19:28:24 [sfa_v1.py:523] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-02-12T19:28:24.2556100Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m WARNING 02-12 19:28:24 [sfa_v1.py:523] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-02-12T19:28:24.2614450Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m WARNING 02-12 19:28:24 [sfa_v1.py:523] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-02-12T19:28:24.2679504Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m INFO 02-12 19:28:24 [model_runner_v1.py:2315] Loading drafter model...
2026-02-12T19:28:24.2775854Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m WARNING 02-12 19:28:24 [sfa_v1.py:523] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-02-12T19:28:24.2785837Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m INFO 02-12 19:28:24 [model_runner_v1.py:2315] Loading drafter model...
2026-02-12T19:28:24.2796387Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m WARNING 02-12 19:28:24 [sfa_v1.py:523] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-02-12T19:28:24.2824639Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m WARNING 02-12 19:28:24 [sfa_v1.py:523] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-02-12T19:28:24.2841179Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m WARNING 02-12 19:28:24 [sfa_v1.py:523] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-02-12T19:28:24.2944549Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m INFO 02-12 19:28:24 [model_runner_v1.py:2315] Loading drafter model...
2026-02-12T19:28:24.3043472Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m INFO 02-12 19:28:24 [model_runner_v1.py:2315] Loading drafter model...
2026-02-12T19:28:24.3082538Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m INFO 02-12 19:28:24 [model_runner_v1.py:2315] Loading drafter model...
2026-02-12T19:28:24.3115569Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m INFO 02-12 19:28:24 [model_runner_v1.py:2315] Loading drafter model...
2026-02-12T19:28:24.3126545Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m WARNING 02-12 19:28:24 [sfa_v1.py:523] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-02-12T19:28:24.3136438Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m INFO 02-12 19:28:24 [model_runner_v1.py:2315] Loading drafter model...
2026-02-12T19:28:24.3170779Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m INFO 02-12 19:28:24 [model_runner_v1.py:2315] Loading drafter model...
2026-02-12T19:28:24.3240156Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m INFO 02-12 19:28:24 [model_runner_v1.py:2315] Loading drafter model...
2026-02-12T19:28:24.3297251Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m INFO 02-12 19:28:24 [model_runner_v1.py:2315] Loading drafter model...
2026-02-12T19:28:24.3370849Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m INFO 02-12 19:28:24 [model_runner_v1.py:2315] Loading drafter model...
2026-02-12T19:28:24.3380227Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m INFO 02-12 19:28:24 [model_runner_v1.py:2315] Loading drafter model...
2026-02-12T19:28:24.3432154Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m INFO 02-12 19:28:24 [model_runner_v1.py:2315] Loading drafter model...
2026-02-12T19:28:24.3442418Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m WARNING 02-12 19:28:24 [sfa_v1.py:523] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-02-12T19:28:24.3702455Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m INFO 02-12 19:28:24 [model_runner_v1.py:2315] Loading drafter model...
2026-02-12T19:28:24.3711450Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m INFO 02-12 19:28:24 [model_runner_v1.py:2315] Loading drafter model...
2026-02-12T19:28:24.4281854Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:28:24.4283917Z Loading safetensors checkpoint shards:   0% Completed | 0/163 [00:00<?, ?it/s]
2026-02-12T19:28:24.4645964Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m INFO 02-12 19:28:24 [model_runner_v1.py:2315] Loading drafter model...
2026-02-12T19:28:25.4299652Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:28:25.4300071Z Loading safetensors checkpoint shards:   1% Completed | 1/163 [00:01<02:42,  1.00s/it]
2026-02-12T19:28:26.4842175Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:28:26.4842673Z Loading safetensors checkpoint shards:   1% Completed | 2/163 [00:02<02:46,  1.03s/it]
2026-02-12T19:28:27.7419036Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:28:27.7419434Z Loading safetensors checkpoint shards:   2% Completed | 3/163 [00:03<03:01,  1.14s/it]
2026-02-12T19:28:29.0325627Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:28:29.0326079Z Loading safetensors checkpoint shards:   2% Completed | 4/163 [00:04<03:10,  1.20s/it]
2026-02-12T19:28:30.2727640Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:28:30.2728067Z Loading safetensors checkpoint shards:   3% Completed | 5/163 [00:05<03:11,  1.21s/it]
2026-02-12T19:28:31.4596006Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:28:31.4596512Z Loading safetensors checkpoint shards:   4% Completed | 6/163 [00:07<03:08,  1.20s/it]
2026-02-12T19:28:32.5332882Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:28:32.5333358Z Loading safetensors checkpoint shards:   4% Completed | 7/163 [00:08<03:01,  1.16s/it]
2026-02-12T19:28:33.7146115Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:28:33.7146722Z Loading safetensors checkpoint shards:   5% Completed | 8/163 [00:09<03:00,  1.17s/it]
2026-02-12T19:28:34.8879775Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:28:34.8880170Z Loading safetensors checkpoint shards:   6% Completed | 9/163 [00:10<03:00,  1.17s/it]
2026-02-12T19:28:36.3530773Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:28:36.3531198Z Loading safetensors checkpoint shards:   6% Completed | 10/163 [00:11<03:12,  1.26s/it]
2026-02-12T19:28:37.5397187Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:28:37.5397607Z Loading safetensors checkpoint shards:   7% Completed | 11/163 [00:13<03:08,  1.24s/it]
2026-02-12T19:28:38.7266049Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:28:38.7266508Z Loading safetensors checkpoint shards:   7% Completed | 12/163 [00:14<03:04,  1.22s/it]
2026-02-12T19:28:39.9940047Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:28:39.9940463Z Loading safetensors checkpoint shards:   8% Completed | 13/163 [00:15<03:05,  1.24s/it]
2026-02-12T19:28:41.1851585Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:28:41.1852116Z Loading safetensors checkpoint shards:   9% Completed | 14/163 [00:16<03:02,  1.22s/it]
2026-02-12T19:28:42.3047976Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:28:42.3048422Z Loading safetensors checkpoint shards:   9% Completed | 15/163 [00:17<02:56,  1.19s/it]
2026-02-12T19:28:43.3935369Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:28:43.3935806Z Loading safetensors checkpoint shards:  10% Completed | 16/163 [00:18<02:50,  1.16s/it]
2026-02-12T19:28:44.5845005Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:28:44.5845478Z Loading safetensors checkpoint shards:  10% Completed | 17/163 [00:20<02:50,  1.17s/it]
2026-02-12T19:28:45.6786177Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:28:45.6786725Z Loading safetensors checkpoint shards:  11% Completed | 18/163 [00:21<02:46,  1.15s/it]
2026-02-12T19:28:46.9377521Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:28:46.9378182Z Loading safetensors checkpoint shards:  12% Completed | 19/163 [00:22<02:50,  1.18s/it]
2026-02-12T19:28:48.0720868Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:28:48.0721359Z Loading safetensors checkpoint shards:  12% Completed | 20/163 [00:23<02:46,  1.17s/it]
2026-02-12T19:28:49.1791726Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:28:49.1792257Z Loading safetensors checkpoint shards:  13% Completed | 21/163 [00:24<02:43,  1.15s/it]
2026-02-12T19:28:50.3407874Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:28:50.3408353Z Loading safetensors checkpoint shards:  13% Completed | 22/163 [00:25<02:42,  1.15s/it]
2026-02-12T19:28:51.5135038Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:28:51.5135529Z Loading safetensors checkpoint shards:  14% Completed | 23/163 [00:27<02:42,  1.16s/it]
2026-02-12T19:28:52.7940038Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:28:52.7940495Z Loading safetensors checkpoint shards:  15% Completed | 24/163 [00:28<02:46,  1.20s/it]
2026-02-12T19:28:54.1208137Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:28:54.1208589Z Loading safetensors checkpoint shards:  15% Completed | 25/163 [00:29<02:50,  1.23s/it]
2026-02-12T19:28:55.5283300Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:28:55.5283732Z Loading safetensors checkpoint shards:  16% Completed | 26/163 [00:31<02:56,  1.29s/it]
2026-02-12T19:28:56.8030188Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:28:56.8030714Z Loading safetensors checkpoint shards:  17% Completed | 27/163 [00:32<02:54,  1.28s/it]
2026-02-12T19:28:57.9964998Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:28:57.9965454Z Loading safetensors checkpoint shards:  17% Completed | 28/163 [00:33<02:49,  1.26s/it]
2026-02-12T19:28:59.2154327Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:28:59.2154820Z Loading safetensors checkpoint shards:  18% Completed | 29/163 [00:34<02:46,  1.25s/it]
2026-02-12T19:29:00.3336521Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:00.3336996Z Loading safetensors checkpoint shards:  18% Completed | 30/163 [00:35<02:40,  1.21s/it]
2026-02-12T19:29:01.3758194Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:01.3758650Z Loading safetensors checkpoint shards:  19% Completed | 31/163 [00:36<02:32,  1.16s/it]
2026-02-12T19:29:02.4927362Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:02.4927886Z Loading safetensors checkpoint shards:  20% Completed | 32/163 [00:38<02:30,  1.15s/it]
2026-02-12T19:29:03.6222672Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:03.6223303Z Loading safetensors checkpoint shards:  20% Completed | 33/163 [00:39<02:28,  1.14s/it]
2026-02-12T19:29:04.7402534Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:04.7403072Z Loading safetensors checkpoint shards:  21% Completed | 34/163 [00:40<02:26,  1.13s/it]
2026-02-12T19:29:05.8706412Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:05.8706838Z Loading safetensors checkpoint shards:  21% Completed | 35/163 [00:41<02:25,  1.13s/it]
2026-02-12T19:29:06.8931182Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:06.8931623Z Loading safetensors checkpoint shards:  22% Completed | 36/163 [00:42<02:19,  1.10s/it]
2026-02-12T19:29:08.0098149Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:08.0098550Z Loading safetensors checkpoint shards:  23% Completed | 37/163 [00:43<02:19,  1.10s/it]
2026-02-12T19:29:09.1669045Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:09.1669479Z Loading safetensors checkpoint shards:  23% Completed | 38/163 [00:44<02:19,  1.12s/it]
2026-02-12T19:29:10.3166082Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:10.3166510Z Loading safetensors checkpoint shards:  24% Completed | 39/163 [00:45<02:20,  1.13s/it]
2026-02-12T19:29:11.3733691Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:11.3734122Z Loading safetensors checkpoint shards:  25% Completed | 40/163 [00:46<02:16,  1.11s/it]
2026-02-12T19:29:12.4701538Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:12.4701966Z Loading safetensors checkpoint shards:  25% Completed | 41/163 [00:48<02:14,  1.10s/it]
2026-02-12T19:29:13.6548069Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:13.6548554Z Loading safetensors checkpoint shards:  26% Completed | 42/163 [00:49<02:16,  1.13s/it]
2026-02-12T19:29:14.6930415Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:14.6930926Z Loading safetensors checkpoint shards:  26% Completed | 43/163 [00:50<02:12,  1.10s/it]
2026-02-12T19:29:15.7838215Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:15.7838680Z Loading safetensors checkpoint shards:  27% Completed | 44/163 [00:51<02:10,  1.10s/it]
2026-02-12T19:29:16.9078532Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:16.9079070Z Loading safetensors checkpoint shards:  28% Completed | 45/163 [00:52<02:10,  1.11s/it]
2026-02-12T19:29:18.0725159Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:18.0725553Z Loading safetensors checkpoint shards:  28% Completed | 46/163 [00:53<02:11,  1.12s/it]
2026-02-12T19:29:18.7847878Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:18.7848302Z Loading safetensors checkpoint shards:  29% Completed | 47/163 [00:54<01:56,  1.00s/it]
2026-02-12T19:29:19.9009267Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:19.9009684Z Loading safetensors checkpoint shards:  30% Completed | 49/163 [00:55<01:30,  1.26it/s]
2026-02-12T19:29:21.0509404Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:21.0509840Z Loading safetensors checkpoint shards:  31% Completed | 50/163 [00:56<01:39,  1.13it/s]
2026-02-12T19:29:22.1082491Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:22.1082894Z Loading safetensors checkpoint shards:  31% Completed | 51/163 [00:57<01:44,  1.08it/s]
2026-02-12T19:29:23.3290171Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:23.3290792Z Loading safetensors checkpoint shards:  32% Completed | 52/163 [00:58<01:51,  1.01s/it]
2026-02-12T19:29:24.3841675Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:24.3842256Z Loading safetensors checkpoint shards:  33% Completed | 53/163 [00:59<01:52,  1.02s/it]
2026-02-12T19:29:25.4765446Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:25.4765941Z Loading safetensors checkpoint shards:  33% Completed | 54/163 [01:01<01:53,  1.04s/it]
2026-02-12T19:29:26.6039606Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:26.6040048Z Loading safetensors checkpoint shards:  34% Completed | 55/163 [01:02<01:55,  1.07s/it]
2026-02-12T19:29:27.7092663Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:27.7093567Z Loading safetensors checkpoint shards:  34% Completed | 56/163 [01:03<01:55,  1.08s/it]
2026-02-12T19:29:28.8500876Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:28.8501354Z Loading safetensors checkpoint shards:  35% Completed | 57/163 [01:04<01:56,  1.10s/it]
2026-02-12T19:29:29.9566434Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:29.9566926Z Loading safetensors checkpoint shards:  36% Completed | 58/163 [01:05<01:55,  1.10s/it]
2026-02-12T19:29:31.0507198Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:31.0507591Z Loading safetensors checkpoint shards:  36% Completed | 59/163 [01:06<01:54,  1.10s/it]
2026-02-12T19:29:32.1379226Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:32.1379733Z Loading safetensors checkpoint shards:  37% Completed | 60/163 [01:07<01:52,  1.09s/it]
2026-02-12T19:29:33.2362175Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:33.2362624Z Loading safetensors checkpoint shards:  37% Completed | 61/163 [01:08<01:51,  1.10s/it]
2026-02-12T19:29:34.3298435Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:34.3298871Z Loading safetensors checkpoint shards:  38% Completed | 62/163 [01:09<01:50,  1.10s/it]
2026-02-12T19:29:35.3973552Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:35.3973990Z Loading safetensors checkpoint shards:  39% Completed | 63/163 [01:10<01:48,  1.09s/it]
2026-02-12T19:29:36.5296092Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:36.5296548Z Loading safetensors checkpoint shards:  39% Completed | 64/163 [01:12<01:48,  1.10s/it]
2026-02-12T19:29:37.5901161Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:37.5901645Z Loading safetensors checkpoint shards:  40% Completed | 65/163 [01:13<01:46,  1.09s/it]
2026-02-12T19:29:38.5912706Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:38.5913128Z Loading safetensors checkpoint shards:  40% Completed | 66/163 [01:14<01:43,  1.06s/it]
2026-02-12T19:29:39.6431057Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:39.6431662Z Loading safetensors checkpoint shards:  41% Completed | 67/163 [01:15<01:41,  1.06s/it]
2026-02-12T19:29:40.7573728Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:40.7574236Z Loading safetensors checkpoint shards:  42% Completed | 68/163 [01:16<01:42,  1.08s/it]
2026-02-12T19:29:41.9472287Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:41.9472929Z Loading safetensors checkpoint shards:  42% Completed | 69/163 [01:17<01:44,  1.11s/it]
2026-02-12T19:29:43.0571157Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:43.0571581Z Loading safetensors checkpoint shards:  43% Completed | 70/163 [01:18<01:43,  1.11s/it]
2026-02-12T19:29:44.1598530Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:44.1598946Z Loading safetensors checkpoint shards:  44% Completed | 71/163 [01:19<01:41,  1.11s/it]
2026-02-12T19:29:45.2205994Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:45.2206448Z Loading safetensors checkpoint shards:  44% Completed | 72/163 [01:20<01:39,  1.09s/it]
2026-02-12T19:29:46.2960122Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:46.2960551Z Loading safetensors checkpoint shards:  45% Completed | 73/163 [01:21<01:37,  1.09s/it]
2026-02-12T19:29:47.3436757Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:47.3437442Z Loading safetensors checkpoint shards:  45% Completed | 74/163 [01:22<01:35,  1.08s/it]
2026-02-12T19:29:48.4259391Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:48.4259824Z Loading safetensors checkpoint shards:  46% Completed | 75/163 [01:23<01:34,  1.08s/it]
2026-02-12T19:29:49.5295520Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:49.5295958Z Loading safetensors checkpoint shards:  47% Completed | 76/163 [01:25<01:34,  1.09s/it]
2026-02-12T19:29:50.5824678Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:50.5825239Z Loading safetensors checkpoint shards:  47% Completed | 77/163 [01:26<01:32,  1.08s/it]
2026-02-12T19:29:51.6908498Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:51.6908932Z Loading safetensors checkpoint shards:  48% Completed | 78/163 [01:27<01:32,  1.09s/it]
2026-02-12T19:29:52.8841105Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:52.8841583Z Loading safetensors checkpoint shards:  48% Completed | 79/163 [01:28<01:33,  1.12s/it]
2026-02-12T19:29:53.8817677Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:53.8818069Z Loading safetensors checkpoint shards:  49% Completed | 80/163 [01:29<01:29,  1.08s/it]
2026-02-12T19:29:54.8945278Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:54.8945714Z Loading safetensors checkpoint shards:  50% Completed | 81/163 [01:30<01:27,  1.06s/it]
2026-02-12T19:29:56.0900169Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:56.0900605Z Loading safetensors checkpoint shards:  50% Completed | 82/163 [01:31<01:29,  1.10s/it]
2026-02-12T19:29:57.1907279Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:57.1907693Z Loading safetensors checkpoint shards:  51% Completed | 83/163 [01:32<01:28,  1.10s/it]
2026-02-12T19:29:58.3543328Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:58.3543775Z Loading safetensors checkpoint shards:  52% Completed | 84/163 [01:33<01:28,  1.12s/it]
2026-02-12T19:29:59.4554788Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:29:59.4555222Z Loading safetensors checkpoint shards:  52% Completed | 85/163 [01:35<01:26,  1.11s/it]
2026-02-12T19:30:00.4312188Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:30:00.4312660Z Loading safetensors checkpoint shards:  53% Completed | 86/163 [01:36<01:22,  1.07s/it]
2026-02-12T19:30:00.5536569Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:30:00.5537023Z Loading safetensors checkpoint shards:  55% Completed | 89/163 [01:36<00:36,  2.03it/s]
2026-02-12T19:30:00.6575501Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:30:00.6576008Z Loading safetensors checkpoint shards:  56% Completed | 92/163 [01:36<00:20,  3.47it/s]
2026-02-12T19:30:00.7682165Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:30:00.7682631Z Loading safetensors checkpoint shards:  58% Completed | 95/163 [01:36<00:12,  5.25it/s]
2026-02-12T19:30:00.8767418Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:30:00.8767896Z Loading safetensors checkpoint shards:  60% Completed | 98/163 [01:36<00:08,  7.38it/s]
2026-02-12T19:30:01.0991745Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:30:01.0992257Z Loading safetensors checkpoint shards:  62% Completed | 101/163 [01:36<00:07,  8.72it/s]
2026-02-12T19:30:01.2087776Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:30:01.2088351Z Loading safetensors checkpoint shards:  64% Completed | 104/163 [01:36<00:05, 11.20it/s]
2026-02-12T19:30:02.8892237Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:30:02.8892744Z Loading safetensors checkpoint shards:  66% Completed | 107/163 [01:38<00:13,  4.19it/s]
2026-02-12T19:30:03.0003510Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:30:03.0003896Z Loading safetensors checkpoint shards:  67% Completed | 110/163 [01:38<00:09,  5.69it/s]
2026-02-12T19:30:03.1098259Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:30:03.1098860Z Loading safetensors checkpoint shards:  69% Completed | 113/163 [01:38<00:06,  7.53it/s]
2026-02-12T19:30:03.2202171Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:30:03.2202579Z Loading safetensors checkpoint shards:  71% Completed | 116/163 [01:38<00:04,  9.66it/s]
2026-02-12T19:30:03.3253476Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:30:03.3253897Z Loading safetensors checkpoint shards:  73% Completed | 119/163 [01:38<00:03, 12.10it/s]
2026-02-12T19:30:03.4336630Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:30:03.4337039Z Loading safetensors checkpoint shards:  75% Completed | 122/163 [01:39<00:02, 14.58it/s]
2026-02-12T19:30:03.5435470Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:30:03.5436118Z Loading safetensors checkpoint shards:  77% Completed | 125/163 [01:39<00:02, 16.97it/s]
2026-02-12T19:30:03.6566168Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:30:03.6566556Z Loading safetensors checkpoint shards:  79% Completed | 128/163 [01:39<00:01, 19.03it/s]
2026-02-12T19:30:03.7705498Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:30:03.7705937Z Loading safetensors checkpoint shards:  81% Completed | 132/163 [01:39<00:01, 22.96it/s]
2026-02-12T19:30:03.8789193Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:30:03.8789560Z Loading safetensors checkpoint shards:  83% Completed | 135/163 [01:39<00:01, 23.99it/s]
2026-02-12T19:30:03.9874333Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:30:03.9874812Z Loading safetensors checkpoint shards:  85% Completed | 138/163 [01:39<00:01, 24.93it/s]
2026-02-12T19:30:04.0964196Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:30:04.0964643Z Loading safetensors checkpoint shards:  87% Completed | 141/163 [01:39<00:00, 25.63it/s]
2026-02-12T19:30:04.2054739Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:30:04.2055156Z Loading safetensors checkpoint shards:  88% Completed | 144/163 [01:39<00:00, 26.16it/s]
2026-02-12T19:30:04.3128306Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:30:04.3128788Z Loading safetensors checkpoint shards:  90% Completed | 147/163 [01:39<00:00, 26.66it/s]
2026-02-12T19:30:07.0789153Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:30:07.0789796Z Loading safetensors checkpoint shards:  92% Completed | 150/163 [01:42<00:03,  3.34it/s]
2026-02-12T19:30:09.2770368Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:30:09.2770866Z Loading safetensors checkpoint shards:  93% Completed | 152/163 [01:44<00:05,  2.10it/s]
2026-02-12T19:30:11.4603129Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:30:11.4603618Z Loading safetensors checkpoint shards:  94% Completed | 154/163 [01:47<00:05,  1.60it/s]
2026-02-12T19:30:13.6459099Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:30:13.6459620Z Loading safetensors checkpoint shards:  96% Completed | 156/163 [01:49<00:05,  1.35it/s]
2026-02-12T19:30:14.8354909Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:30:14.8355319Z Loading safetensors checkpoint shards:  96% Completed | 157/163 [01:50<00:04,  1.23it/s]
2026-02-12T19:30:15.8385936Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:30:15.8386335Z Loading safetensors checkpoint shards:  97% Completed | 158/163 [01:51<00:04,  1.18it/s]
2026-02-12T19:30:16.9300556Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:30:16.9300986Z Loading safetensors checkpoint shards:  98% Completed | 159/163 [01:52<00:03,  1.12it/s]
2026-02-12T19:30:18.2543983Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:30:18.2544408Z Loading safetensors checkpoint shards:  98% Completed | 160/163 [01:53<00:02,  1.01it/s]
2026-02-12T19:30:19.3323305Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:30:19.3323719Z Loading safetensors checkpoint shards:  99% Completed | 161/163 [01:54<00:02,  1.01s/it]
2026-02-12T19:30:20.1108854Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:30:20.1109375Z Loading safetensors checkpoint shards:  99% Completed | 162/163 [01:55<00:00,  1.05it/s]
2026-02-12T19:30:20.9420968Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:30:20.9421590Z Loading safetensors checkpoint shards: 100% Completed | 163/163 [01:56<00:00,  1.09it/s]
2026-02-12T19:30:20.9441710Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:30:20.9442243Z Loading safetensors checkpoint shards: 100% Completed | 163/163 [01:56<00:00,  1.40it/s]
2026-02-12T19:30:20.9451458Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:30:21.0401512Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m INFO 02-12 19:30:21 [eagle_proposer.py:236] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-02-12T19:30:21.1907655Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m INFO 02-12 19:30:21 [default_loader.py:291] Loading weights took 116.71 seconds
2026-02-12T19:30:21.2294792Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m INFO 02-12 19:30:21 [eagle_proposer.py:236] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-02-12T19:30:21.2319177Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m INFO 02-12 19:30:21 [eagle_proposer.py:236] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-02-12T19:30:21.2339357Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m INFO 02-12 19:30:21 [eagle_proposer.py:236] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-02-12T19:30:21.2349465Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m INFO 02-12 19:30:21 [eagle_proposer.py:236] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-02-12T19:30:21.2360552Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m INFO 02-12 19:30:21 [eagle_proposer.py:236] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-02-12T19:30:21.2370543Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m INFO 02-12 19:30:21 [eagle_proposer.py:236] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-02-12T19:30:21.2380784Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m INFO 02-12 19:30:21 [eagle_proposer.py:236] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-02-12T19:30:21.7410851Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m INFO 02-12 19:30:21 [default_loader.py:291] Loading weights took 117.31 seconds
2026-02-12T19:30:21.7819804Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m INFO 02-12 19:30:21 [eagle_proposer.py:236] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-02-12T19:30:21.7855615Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m INFO 02-12 19:30:21 [eagle_proposer.py:236] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-02-12T19:30:21.7982341Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m INFO 02-12 19:30:21 [eagle_proposer.py:236] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-02-12T19:30:21.8021494Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m INFO 02-12 19:30:21 [eagle_proposer.py:236] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-02-12T19:30:21.8095068Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m INFO 02-12 19:30:21 [eagle_proposer.py:236] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-02-12T19:30:21.8121124Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m INFO 02-12 19:30:21 [eagle_proposer.py:236] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-02-12T19:30:21.8145323Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m INFO 02-12 19:30:21 [eagle_proposer.py:236] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-02-12T19:30:21.8177861Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m INFO 02-12 19:30:21 [eagle_proposer.py:236] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-02-12T19:30:22.2074723Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m INFO 02-12 19:30:22 [model_runner_v1.py:2323] Loading model weights took 30.8108 GB
2026-02-12T19:30:22.6714304Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m INFO 02-12 19:30:22 [model_runner_v1.py:2323] Loading model weights took 30.8108 GB
2026-02-12T19:30:22.9628929Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m INFO 02-12 19:30:22 [model_runner_v1.py:2323] Loading model weights took 30.8108 GB
2026-02-12T19:30:23.0322298Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m INFO 02-12 19:30:23 [model_runner_v1.py:2323] Loading model weights took 30.8108 GB
2026-02-12T19:30:23.1045028Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m INFO 02-12 19:30:23 [model_runner_v1.py:2323] Loading model weights took 30.8108 GB
2026-02-12T19:30:23.1758934Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m INFO 02-12 19:30:23 [model_runner_v1.py:2323] Loading model weights took 30.8108 GB
2026-02-12T19:30:23.2986869Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m INFO 02-12 19:30:23 [model_runner_v1.py:2323] Loading model weights took 30.8108 GB
2026-02-12T19:30:23.3743242Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m INFO 02-12 19:30:23 [model_runner_v1.py:2323] Loading model weights took 30.8108 GB
2026-02-12T19:30:23.4961555Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m INFO 02-12 19:30:23 [model_runner_v1.py:2323] Loading model weights took 30.8108 GB
2026-02-12T19:30:23.5446286Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m INFO 02-12 19:30:23 [model_runner_v1.py:2323] Loading model weights took 30.8108 GB
2026-02-12T19:30:23.5750515Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m INFO 02-12 19:30:23 [model_runner_v1.py:2323] Loading model weights took 30.8108 GB
2026-02-12T19:30:23.6771553Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m INFO 02-12 19:30:23 [model_runner_v1.py:2323] Loading model weights took 30.8108 GB
2026-02-12T19:30:23.9932737Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m INFO 02-12 19:30:23 [model_runner_v1.py:2323] Loading model weights took 30.8108 GB
2026-02-12T19:30:24.0784674Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m INFO 02-12 19:30:24 [model_runner_v1.py:2323] Loading model weights took 30.8108 GB
2026-02-12T19:30:24.1233718Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m INFO 02-12 19:30:24 [model_runner_v1.py:2323] Loading model weights took 30.8108 GB
2026-02-12T19:30:24.1701792Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m INFO 02-12 19:30:24 [model_runner_v1.py:2323] Loading model weights took 30.8108 GB
2026-02-12T19:30:29.7228667Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m INFO 02-12 19:30:29 [backends.py:805] Using cache directory: /root/.cache/vllm/torch_compile_cache/e1f52cae88/rank_0_0/backbone for vLLM's torch.compile
2026-02-12T19:30:29.7338399Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m INFO 02-12 19:30:29 [backends.py:865] Dynamo bytecode transform time: 4.80 s
2026-02-12T19:30:29.7912743Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m INFO 02-12 19:30:29 [backends.py:805] Using cache directory: /root/.cache/vllm/torch_compile_cache/e1f52cae88/rank_0_1/backbone for vLLM's torch.compile
2026-02-12T19:30:29.8030986Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m INFO 02-12 19:30:29 [backends.py:865] Dynamo bytecode transform time: 4.87 s
2026-02-12T19:30:36.1216966Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in reduce-overhead mode: config.experimental_config.enable_view_optimize:True, set_dim_gears, dynamo_export, scope, npu_print
2026-02-12T19:30:36.1224577Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m   warnings.warn(
2026-02-12T19:30:36.1347405Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in reduce-overhead mode: config.experimental_config.enable_view_optimize:True, set_dim_gears, dynamo_export, scope, npu_print
2026-02-12T19:30:36.1354778Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m   warnings.warn(
2026-02-12T19:30:36.1373916Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in reduce-overhead mode: config.experimental_config.enable_view_optimize:True, set_dim_gears, dynamo_export, scope, npu_print
2026-02-12T19:30:36.1382815Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m   warnings.warn(
2026-02-12T19:30:36.1793842Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in reduce-overhead mode: config.experimental_config.enable_view_optimize:True, set_dim_gears, dynamo_export, scope, npu_print
2026-02-12T19:30:36.1802339Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m   warnings.warn(
2026-02-12T19:30:36.2272997Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in reduce-overhead mode: config.experimental_config.enable_view_optimize:True, set_dim_gears, dynamo_export, scope, npu_print
2026-02-12T19:30:36.2281708Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m   warnings.warn(
2026-02-12T19:30:36.2579515Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in reduce-overhead mode: config.experimental_config.enable_view_optimize:True, set_dim_gears, dynamo_export, scope, npu_print
2026-02-12T19:30:36.2585727Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m   warnings.warn(
2026-02-12T19:30:36.2600939Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in reduce-overhead mode: config.experimental_config.enable_view_optimize:True, set_dim_gears, dynamo_export, scope, npu_print
2026-02-12T19:30:36.2610457Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m   warnings.warn(
2026-02-12T19:30:36.2741202Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in reduce-overhead mode: config.experimental_config.enable_view_optimize:True, set_dim_gears, dynamo_export, scope, npu_print
2026-02-12T19:30:36.2748595Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m   warnings.warn(
2026-02-12T19:30:36.2839539Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in reduce-overhead mode: config.experimental_config.enable_view_optimize:True, set_dim_gears, dynamo_export, scope, npu_print
2026-02-12T19:30:36.2846964Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m   warnings.warn(
2026-02-12T19:30:36.3302648Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in reduce-overhead mode: config.experimental_config.enable_view_optimize:True, set_dim_gears, dynamo_export, scope, npu_print
2026-02-12T19:30:36.3310621Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m   warnings.warn(
2026-02-12T19:30:36.3394361Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in reduce-overhead mode: config.experimental_config.enable_view_optimize:True, set_dim_gears, dynamo_export, scope, npu_print
2026-02-12T19:30:36.3403125Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m   warnings.warn(
2026-02-12T19:30:36.3759382Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in reduce-overhead mode: config.experimental_config.enable_view_optimize:True, set_dim_gears, dynamo_export, scope, npu_print
2026-02-12T19:30:36.3766855Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m   warnings.warn(
2026-02-12T19:30:36.4050805Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in reduce-overhead mode: config.experimental_config.enable_view_optimize:True, set_dim_gears, dynamo_export, scope, npu_print
2026-02-12T19:30:36.4057790Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m   warnings.warn(
2026-02-12T19:30:36.4122340Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in reduce-overhead mode: config.experimental_config.enable_view_optimize:True, set_dim_gears, dynamo_export, scope, npu_print
2026-02-12T19:30:36.4131506Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m   warnings.warn(
2026-02-12T19:30:36.4281834Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in reduce-overhead mode: config.experimental_config.enable_view_optimize:True, set_dim_gears, dynamo_export, scope, npu_print
2026-02-12T19:30:36.4290436Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m   warnings.warn(
2026-02-12T19:30:36.5140468Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in reduce-overhead mode: config.experimental_config.enable_view_optimize:True, set_dim_gears, dynamo_export, scope, npu_print
2026-02-12T19:30:36.5147381Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m   warnings.warn(
2026-02-12T19:30:49.8306440Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m INFO 02-12 19:30:49 [backends.py:319] Compiling a graph for compile range (1, 4096) takes 13.56 s
2026-02-12T19:30:49.8315713Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m INFO 02-12 19:30:49 [monitor.py:34] torch.compile takes 18.36 s in total
2026-02-12T19:30:50.0357013Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m INFO 02-12 19:30:50 [backends.py:319] Compiling a graph for compile range (1, 4096) takes 13.86 s
2026-02-12T19:30:50.0365719Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m INFO 02-12 19:30:50 [monitor.py:34] torch.compile takes 18.72 s in total
2026-02-12T19:30:56.3197214Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m INFO 02-12 19:30:56 [worker.py:338] Available memory: 18253748736, total memory: 65787658240
2026-02-12T19:30:56.3499246Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m INFO 02-12 19:30:56 [worker.py:338] Available memory: 18547221196, total memory: 65796046848
2026-02-12T19:30:56.3578518Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m INFO 02-12 19:30:56 [worker.py:338] Available memory: 18546352844, total memory: 65796046848
2026-02-12T19:30:56.3916973Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m INFO 02-12 19:30:56 [worker.py:338] Available memory: 18530816716, total memory: 65796046848
2026-02-12T19:30:56.4359272Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m INFO 02-12 19:30:56 [worker.py:338] Available memory: 18260919808, total memory: 65787658240
2026-02-12T19:30:56.5739457Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m INFO 02-12 19:30:56 [worker.py:338] Available memory: 18544988876, total memory: 65796046848
2026-02-12T19:30:56.6084780Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m INFO 02-12 19:30:56 [worker.py:338] Available memory: 18553114316, total memory: 65796046848
2026-02-12T19:30:56.6386407Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m INFO 02-12 19:30:56 [worker.py:338] Available memory: 18271293952, total memory: 65787658240
2026-02-12T19:30:56.8116934Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m INFO 02-12 19:30:56 [worker.py:338] Available memory: 17856506368, total memory: 65787658240
2026-02-12T19:30:56.8146019Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m INFO 02-12 19:30:56 [worker.py:338] Available memory: 18286210560, total memory: 65787658240
2026-02-12T19:30:57.2637993Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m INFO 02-12 19:30:57 [worker.py:338] Available memory: 17866191360, total memory: 65787658240
2026-02-12T19:30:57.5095395Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m INFO 02-12 19:30:57 [worker.py:338] Available memory: 18269796864, total memory: 65787658240
2026-02-12T19:30:57.5123518Z [0;36m(EngineCore_DP1 pid=187)[0;0m INFO 02-12 19:30:57 [kv_cache_utils.py:1307] GPU KV cache size: 204,544 tokens
2026-02-12T19:30:57.5132144Z [0;36m(EngineCore_DP1 pid=187)[0;0m INFO 02-12 19:30:57 [kv_cache_utils.py:1312] Maximum concurrency for 8,192 tokens per request: 24.97x
2026-02-12T19:30:57.7748001Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m INFO 02-12 19:30:57 [worker.py:338] Available memory: 18560680652, total memory: 65796046848
2026-02-12T19:30:57.9870590Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m INFO 02-12 19:30:57 [worker.py:338] Available memory: 18561648332, total memory: 65796046848
2026-02-12T19:30:58.3560596Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m INFO 02-12 19:30:58 [worker.py:338] Available memory: 18543857356, total memory: 65796046848
2026-02-12T19:30:58.3710245Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m INFO 02-12 19:30:58 [worker.py:338] Available memory: 18284604928, total memory: 65787658240
2026-02-12T19:30:58.3737203Z [0;36m(EngineCore_DP0 pid=168)[0;0m INFO 02-12 19:30:58 [kv_cache_utils.py:1307] GPU KV cache size: 204,544 tokens
2026-02-12T19:30:58.3746861Z [0;36m(EngineCore_DP0 pid=168)[0;0m INFO 02-12 19:30:58 [kv_cache_utils.py:1312] Maximum concurrency for 8,192 tokens per request: 24.97x
2026-02-12T19:31:15.6517473Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m 
2026-02-12T19:31:15.6518336Z Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s][rank3]:[W212 19:31:15.603912354 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-02-12T19:31:15.6528337Z [rank7]:[W212 19:31:15.603926484 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-02-12T19:31:15.6539053Z [rank6]:[W212 19:31:15.603946324 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-02-12T19:31:15.6550365Z [rank5]:[W212 19:31:15.604320806 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-02-12T19:31:15.6560044Z [rank2]:[W212 19:31:15.604341787 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-02-12T19:31:15.6569635Z [rank0]:[W212 19:31:15.604397957 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-02-12T19:31:15.6580649Z [rank15]:[W212 19:31:15.604673539 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-02-12T19:31:15.6589639Z [rank12]:[W212 19:31:15.604776540 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-02-12T19:31:15.6600669Z [rank10]:[W212 19:31:15.604942261 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-02-12T19:31:15.6610789Z [rank13]:[W212 19:31:15.604944771 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-02-12T19:31:15.6620188Z [rank11]:[W212 19:31:15.604988161 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-02-12T19:31:15.6629868Z [rank14]:[W212 19:31:15.605045941 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-02-12T19:31:15.6640688Z [rank4]:[W212 19:31:15.605154182 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-02-12T19:31:15.6650477Z [rank1]:[W212 19:31:15.606324370 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-02-12T19:31:15.6660617Z [rank8]:[W212 19:31:15.616120157 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-02-12T19:31:15.6677789Z [rank9]:[W212 19:31:15.621797926 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-02-12T19:31:17.5895419Z [rank3]:[W212 19:31:17.542910116 compiler_depend.ts:3667] Warning: Tensor not is not allocated by NPUCachingAllocator, skip eraseStream. (function operator())
2026-02-12T19:31:17.5903433Z [rank4]:[W212 19:31:17.542924556 compiler_depend.ts:3667] Warning: Tensor not is not allocated by NPUCachingAllocator, skip eraseStream. (function operator())
2026-02-12T19:31:17.5913863Z [rank7]:[W212 19:31:17.542952306 compiler_depend.ts:3667] Warning: Tensor not is not allocated by NPUCachingAllocator, skip eraseStream. (function operator())
2026-02-12T19:31:17.5923663Z [rank6]:[W212 19:31:17.543055917 compiler_depend.ts:3667] Warning: Tensor not is not allocated by NPUCachingAllocator, skip eraseStream. (function operator())
2026-02-12T19:31:17.5933662Z [rank5]:[W212 19:31:17.543208558 compiler_depend.ts:3667] Warning: Tensor not is not allocated by NPUCachingAllocator, skip eraseStream. (function operator())
2026-02-12T19:31:17.5943723Z [rank0]:[W212 19:31:17.543208948 compiler_depend.ts:3667] Warning: Tensor not is not allocated by NPUCachingAllocator, skip eraseStream. (function operator())
2026-02-12T19:31:17.5953079Z [rank1]:[W212 19:31:17.543269129 compiler_depend.ts:3667] Warning: Tensor not is not allocated by NPUCachingAllocator, skip eraseStream. (function operator())
2026-02-12T19:31:17.5987496Z [rank2]:[W212 19:31:17.544168545 compiler_depend.ts:3667] Warning: Tensor not is not allocated by NPUCachingAllocator, skip eraseStream. (function operator())
2026-02-12T19:31:17.7565121Z [rank9]:[W212 19:31:17.709998329 compiler_depend.ts:3667] Warning: Tensor not is not allocated by NPUCachingAllocator, skip eraseStream. (function operator())
2026-02-12T19:31:17.7572250Z [rank15]:[W212 19:31:17.710100320 compiler_depend.ts:3667] Warning: Tensor not is not allocated by NPUCachingAllocator, skip eraseStream. (function operator())
2026-02-12T19:31:17.7581927Z [rank11]:[W212 19:31:17.710193140 compiler_depend.ts:3667] Warning: Tensor not is not allocated by NPUCachingAllocator, skip eraseStream. (function operator())
2026-02-12T19:31:17.7591074Z [rank10]:[W212 19:31:17.710473752 compiler_depend.ts:3667] Warning: Tensor not is not allocated by NPUCachingAllocator, skip eraseStream. (function operator())
2026-02-12T19:31:17.7601389Z [rank14]:[W212 19:31:17.710750804 compiler_depend.ts:3667] Warning: Tensor not is not allocated by NPUCachingAllocator, skip eraseStream. (function operator())
2026-02-12T19:31:17.7610869Z [rank12]:[W212 19:31:17.711106597 compiler_depend.ts:3667] Warning: Tensor not is not allocated by NPUCachingAllocator, skip eraseStream. (function operator())
2026-02-12T19:31:17.7620539Z [rank8]:[W212 19:31:17.711229097 compiler_depend.ts:3667] Warning: Tensor not is not allocated by NPUCachingAllocator, skip eraseStream. (function operator())
2026-02-12T19:31:17.7629761Z [rank13]:[W212 19:31:17.711308128 compiler_depend.ts:3667] Warning: Tensor not is not allocated by NPUCachingAllocator, skip eraseStream. (function operator())
2026-02-12T19:31:20.6712363Z 
2026-02-12T19:31:20.6713087Z Capturing CUDA graphs (decode, FULL):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:16<00:16, 16.84s/it]
2026-02-12T19:31:20.6713639Z Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:19<00:00,  8.64s/it]
2026-02-12T19:31:20.6714194Z Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:19<00:00,  9.87s/it]
2026-02-12T19:31:21.3948667Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m INFO 02-12 19:31:21 [gpu_model_runner.py:5051] Graph capturing finished in 21 secs, took 0.27 GiB
2026-02-12T19:31:21.4049900Z [0;36m(EngineCore_DP0 pid=168)[0;0m INFO 02-12 19:31:21 [core.py:272] init engine (profile, create kv cache, warmup model) took 57.28 seconds
2026-02-12T19:31:22.1830727Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m INFO 02-12 19:31:22 [gpu_model_runner.py:5051] Graph capturing finished in 23 secs, took 0.27 GiB
2026-02-12T19:31:22.1939150Z [0;36m(EngineCore_DP1 pid=187)[0;0m INFO 02-12 19:31:22 [core.py:272] init engine (profile, create kv cache, warmup model) took 58.02 seconds
2026-02-12T19:31:22.9405089Z INFO 02-12 19:31:22 [coordinator.py:200] All engine subscriptions received by DP coordinator
2026-02-12T19:31:22.9415637Z [0;36m(ApiServer_2 pid=200)[0;0m WARNING 02-12 19:31:22 [loggers.py:1219] AsyncLLM created with api_server_count more than 1; disabling stats logging to avoid incomplete stats.
2026-02-12T19:31:22.9423435Z [0;36m(EngineCore_DP1 pid=187)[0;0m INFO 02-12 19:31:22 [vllm.py:624] Asynchronous scheduling is enabled.
2026-02-12T19:31:22.9433737Z [0;36m(ApiServer_0 pid=198)[0;0m WARNING 02-12 19:31:22 [loggers.py:1219] AsyncLLM created with api_server_count more than 1; disabling stats logging to avoid incomplete stats.
2026-02-12T19:31:22.9443448Z [0;36m(EngineCore_DP0 pid=168)[0;0m INFO 02-12 19:31:22 [vllm.py:624] Asynchronous scheduling is enabled.
2026-02-12T19:31:22.9453142Z [0;36m(EngineCore_DP1 pid=187)[0;0m INFO 02-12 19:31:22 [ascend_config.py:412] Dynamic EPLB is False
2026-02-12T19:31:22.9462546Z [0;36m(EngineCore_DP1 pid=187)[0;0m INFO 02-12 19:31:22 [ascend_config.py:413] The number of redundant experts is 0
2026-02-12T19:31:22.9472665Z [0;36m(ApiServer_3 pid=201)[0;0m WARNING 02-12 19:31:22 [loggers.py:1219] AsyncLLM created with api_server_count more than 1; disabling stats logging to avoid incomplete stats.
2026-02-12T19:31:22.9483302Z [0;36m(EngineCore_DP1 pid=187)[0;0m INFO 02-12 19:31:22 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-12T19:31:22.9492437Z [0;36m(EngineCore_DP0 pid=168)[0;0m INFO 02-12 19:31:22 [ascend_config.py:412] Dynamic EPLB is False
2026-02-12T19:31:22.9545704Z [0;36m(ApiServer_1 pid=199)[0;0m WARNING 02-12 19:31:22 [loggers.py:1219] AsyncLLM created with api_server_count more than 1; disabling stats logging to avoid incomplete stats.
2026-02-12T19:31:22.9546489Z [0;36m(EngineCore_DP0 pid=168)[0;0m INFO 02-12 19:31:22 [ascend_config.py:413] The number of redundant experts is 0
2026-02-12T19:31:22.9547589Z [0;36m(EngineCore_DP0 pid=168)[0;0m INFO 02-12 19:31:22 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-12T19:31:22.9548759Z [0;36m(EngineCore_DP1 pid=187)[0;0m INFO 02-12 19:31:22 [platform.py:322] FULL_DECODE_ONLY compilation enabled on NPU. use_inductor not supported - using only ACL Graph mode
2026-02-12T19:31:22.9549595Z [0;36m(EngineCore_DP1 pid=187)[0;0m WARNING 02-12 19:31:22 [platform.py:339] [91m
2026-02-12T19:31:22.9554731Z [0;36m(EngineCore_DP1 pid=187)[0;0m WARNING 02-12 19:31:22 [platform.py:339]             **********************************************************************************
2026-02-12T19:31:22.9565483Z [0;36m(EngineCore_DP1 pid=187)[0;0m WARNING 02-12 19:31:22 [platform.py:339]             * WARNING: You have enabled the *full graph* feature.
2026-02-12T19:31:22.9576005Z [0;36m(EngineCore_DP1 pid=187)[0;0m WARNING 02-12 19:31:22 [platform.py:339]             * This is an early experimental stage and may involve various unknown issues.
2026-02-12T19:31:22.9585442Z [0;36m(EngineCore_DP1 pid=187)[0;0m WARNING 02-12 19:31:22 [platform.py:339]             * A known problem is that capturing too many batch sizes can lead to OOM
2026-02-12T19:31:22.9596081Z [0;36m(EngineCore_DP1 pid=187)[0;0m WARNING 02-12 19:31:22 [platform.py:339]             * (Out of Memory) errors or inference hangs. If you encounter such issues,
2026-02-12T19:31:22.9606477Z [0;36m(EngineCore_DP1 pid=187)[0;0m WARNING 02-12 19:31:22 [platform.py:339]             * consider reducing `gpu_memory_utilization` or manually specifying a smaller
2026-02-12T19:31:22.9616181Z [0;36m(EngineCore_DP1 pid=187)[0;0m WARNING 02-12 19:31:22 [platform.py:339]             * batch size for graph capture.
2026-02-12T19:31:22.9626808Z [0;36m(EngineCore_DP1 pid=187)[0;0m WARNING 02-12 19:31:22 [platform.py:339]             * For more details, please refer to:
2026-02-12T19:31:22.9636409Z [0;36m(EngineCore_DP1 pid=187)[0;0m WARNING 02-12 19:31:22 [platform.py:339]             * https://docs.vllm.ai/en/stable/configuration/conserving_memory.html#reduce-cuda-graphs
2026-02-12T19:31:22.9646805Z [0;36m(EngineCore_DP1 pid=187)[0;0m WARNING 02-12 19:31:22 [platform.py:339]             **********************************************************************************[0m
2026-02-12T19:31:22.9656363Z [0;36m(EngineCore_DP1 pid=187)[0;0m WARNING 02-12 19:31:22 [platform.py:339]             
2026-02-12T19:31:22.9667000Z [0;36m(EngineCore_DP0 pid=168)[0;0m INFO 02-12 19:31:22 [platform.py:322] FULL_DECODE_ONLY compilation enabled on NPU. use_inductor not supported - using only ACL Graph mode
2026-02-12T19:31:22.9677200Z INFO 02-12 19:31:22 [utils.py:249] Waiting for API servers to complete ...
2026-02-12T19:31:22.9687101Z [0;36m(EngineCore_DP0 pid=168)[0;0m WARNING 02-12 19:31:22 [platform.py:339] [91m
2026-02-12T19:31:22.9696671Z [0;36m(EngineCore_DP0 pid=168)[0;0m WARNING 02-12 19:31:22 [platform.py:339]             **********************************************************************************
2026-02-12T19:31:22.9706260Z [0;36m(EngineCore_DP0 pid=168)[0;0m WARNING 02-12 19:31:22 [platform.py:339]             * WARNING: You have enabled the *full graph* feature.
2026-02-12T19:31:22.9717302Z [0;36m(EngineCore_DP0 pid=168)[0;0m WARNING 02-12 19:31:22 [platform.py:339]             * This is an early experimental stage and may involve various unknown issues.
2026-02-12T19:31:22.9727067Z [0;36m(EngineCore_DP0 pid=168)[0;0m WARNING 02-12 19:31:22 [platform.py:339]             * A known problem is that capturing too many batch sizes can lead to OOM
2026-02-12T19:31:22.9736330Z [0;36m(EngineCore_DP0 pid=168)[0;0m WARNING 02-12 19:31:22 [platform.py:339]             * (Out of Memory) errors or inference hangs. If you encounter such issues,
2026-02-12T19:31:22.9746183Z [0;36m(EngineCore_DP0 pid=168)[0;0m WARNING 02-12 19:31:22 [platform.py:339]             * consider reducing `gpu_memory_utilization` or manually specifying a smaller
2026-02-12T19:31:22.9756671Z [0;36m(EngineCore_DP0 pid=168)[0;0m WARNING 02-12 19:31:22 [platform.py:339]             * batch size for graph capture.
2026-02-12T19:31:22.9766951Z [0;36m(EngineCore_DP0 pid=168)[0;0m WARNING 02-12 19:31:22 [platform.py:339]             * For more details, please refer to:
2026-02-12T19:31:22.9777001Z [0;36m(EngineCore_DP0 pid=168)[0;0m WARNING 02-12 19:31:22 [platform.py:339]             * https://docs.vllm.ai/en/stable/configuration/conserving_memory.html#reduce-cuda-graphs
2026-02-12T19:31:22.9786876Z [0;36m(EngineCore_DP0 pid=168)[0;0m WARNING 02-12 19:31:22 [platform.py:339]             **********************************************************************************[0m
2026-02-12T19:31:22.9797042Z [0;36m(EngineCore_DP0 pid=168)[0;0m WARNING 02-12 19:31:22 [platform.py:339]             
2026-02-12T19:31:22.9807180Z [0;36m(EngineCore_DP1 pid=187)[0;0m INFO 02-12 19:31:22 [platform.py:447] Set PYTORCH_NPU_ALLOC_CONF=expandable_segments:True
2026-02-12T19:31:22.9817191Z [0;36m(EngineCore_DP0 pid=168)[0;0m INFO 02-12 19:31:22 [platform.py:447] Set PYTORCH_NPU_ALLOC_CONF=expandable_segments:True
2026-02-12T19:31:23.4465539Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:31:23 [api_server.py:665] Supported tasks: ['generate']
2026-02-12T19:31:23.4493333Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:31:23 [api_server.py:665] Supported tasks: ['generate']
2026-02-12T19:31:23.4521444Z [0;36m(ApiServer_2 pid=200)[0;0m WARNING 02-12 19:31:23 [model.py:1371] Default vLLM sampling parameters have been overridden by the model's `generation_config.json`: `{'top_p': 0.95}`. If this is not intended, please relaunch vLLM instance with `--generation-config vllm`.
2026-02-12T19:31:23.4529555Z [0;36m(ApiServer_3 pid=201)[0;0m WARNING 02-12 19:31:23 [model.py:1371] Default vLLM sampling parameters have been overridden by the model's `generation_config.json`: `{'top_p': 0.95}`. If this is not intended, please relaunch vLLM instance with `--generation-config vllm`.
2026-02-12T19:31:23.4543787Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:31:23 [serving.py:177] Warming up chat template processing...
2026-02-12T19:31:23.4559874Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:31:23 [serving.py:177] Warming up chat template processing...
2026-02-12T19:31:23.4696568Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:31:23 [api_server.py:665] Supported tasks: ['generate']
2026-02-12T19:31:23.4717732Z [0;36m(ApiServer_1 pid=199)[0;0m WARNING 02-12 19:31:23 [model.py:1371] Default vLLM sampling parameters have been overridden by the model's `generation_config.json`: `{'top_p': 0.95}`. If this is not intended, please relaunch vLLM instance with `--generation-config vllm`.
2026-02-12T19:31:23.4743844Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:31:23 [serving.py:177] Warming up chat template processing...
2026-02-12T19:31:23.4819502Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:31:23 [serving.py:212] Chat template warmup completed in 29.2ms
2026-02-12T19:31:23.4857383Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:31:23 [serving.py:212] Chat template warmup completed in 32.4ms
2026-02-12T19:31:23.4881197Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:31:23 [api_server.py:946] Starting vLLM API server 3 on http://0.0.0.0:8080
2026-02-12T19:31:23.4890688Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:31:23 [launcher.py:38] Available routes are:
2026-02-12T19:31:23.4899400Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /openapi.json, Methods: GET, HEAD
2026-02-12T19:31:23.4908992Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /docs, Methods: GET, HEAD
2026-02-12T19:31:23.4918310Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /docs/oauth2-redirect, Methods: GET, HEAD
2026-02-12T19:31:23.4927287Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /redoc, Methods: GET, HEAD
2026-02-12T19:31:23.4936345Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /scale_elastic_ep, Methods: POST
2026-02-12T19:31:23.4945993Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /is_scaling_elastic_ep, Methods: POST
2026-02-12T19:31:23.4955347Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /tokenize, Methods: POST
2026-02-12T19:31:23.4965015Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /detokenize, Methods: POST
2026-02-12T19:31:23.4975084Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /inference/v1/generate, Methods: POST
2026-02-12T19:31:23.4984436Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /pause, Methods: POST
2026-02-12T19:31:23.4993164Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /resume, Methods: POST
2026-02-12T19:31:23.5003083Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /is_paused, Methods: GET
2026-02-12T19:31:23.5012923Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /metrics, Methods: GET
2026-02-12T19:31:23.5022428Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /health, Methods: GET
2026-02-12T19:31:23.5030715Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/chat/completions, Methods: POST
2026-02-12T19:31:23.5040310Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/chat/completions/render, Methods: POST
2026-02-12T19:31:23.5050076Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/responses, Methods: POST
2026-02-12T19:31:23.5059347Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/responses/{response_id}, Methods: GET
2026-02-12T19:31:23.5069537Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/responses/{response_id}/cancel, Methods: POST
2026-02-12T19:31:23.5081489Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/audio/transcriptions, Methods: POST
2026-02-12T19:31:23.5089022Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/audio/translations, Methods: POST
2026-02-12T19:31:23.5098318Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/completions, Methods: POST
2026-02-12T19:31:23.5110804Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/completions/render, Methods: POST
2026-02-12T19:31:23.5116408Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/messages, Methods: POST
2026-02-12T19:31:23.5133147Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/models, Methods: GET
2026-02-12T19:31:23.5135885Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /load, Methods: GET
2026-02-12T19:31:23.5145351Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /version, Methods: GET
2026-02-12T19:31:23.5154864Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /ping, Methods: GET
2026-02-12T19:31:23.5164843Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /ping, Methods: POST
2026-02-12T19:31:23.5173862Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /invocations, Methods: POST
2026-02-12T19:31:23.5183252Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /classify, Methods: POST
2026-02-12T19:31:23.5192405Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/embeddings, Methods: POST
2026-02-12T19:31:23.5201368Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /score, Methods: POST
2026-02-12T19:31:23.5210929Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/score, Methods: POST
2026-02-12T19:31:23.5220353Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /rerank, Methods: POST
2026-02-12T19:31:23.5230332Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/rerank, Methods: POST
2026-02-12T19:31:23.5239930Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v2/rerank, Methods: POST
2026-02-12T19:31:23.5249623Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /pooling, Methods: POST
2026-02-12T19:31:23.5259125Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:31:23 [api_server.py:946] Starting vLLM API server 2 on http://0.0.0.0:8080
2026-02-12T19:31:23.5268130Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:31:23 [launcher.py:38] Available routes are:
2026-02-12T19:31:23.5281002Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /openapi.json, Methods: HEAD, GET
2026-02-12T19:31:23.5288241Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /docs, Methods: HEAD, GET
2026-02-12T19:31:23.5297157Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /docs/oauth2-redirect, Methods: HEAD, GET
2026-02-12T19:31:23.5306312Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /redoc, Methods: HEAD, GET
2026-02-12T19:31:23.5316536Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /scale_elastic_ep, Methods: POST
2026-02-12T19:31:23.5326039Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /is_scaling_elastic_ep, Methods: POST
2026-02-12T19:31:23.5335118Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /tokenize, Methods: POST
2026-02-12T19:31:23.5344466Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /detokenize, Methods: POST
2026-02-12T19:31:23.5353861Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /inference/v1/generate, Methods: POST
2026-02-12T19:31:23.5363666Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /pause, Methods: POST
2026-02-12T19:31:23.5373366Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /resume, Methods: POST
2026-02-12T19:31:23.5384655Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /is_paused, Methods: GET
2026-02-12T19:31:23.5395825Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /metrics, Methods: GET
2026-02-12T19:31:23.5405683Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /health, Methods: GET
2026-02-12T19:31:23.5414874Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/chat/completions, Methods: POST
2026-02-12T19:31:23.5424512Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/chat/completions/render, Methods: POST
2026-02-12T19:31:23.5435409Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/responses, Methods: POST
2026-02-12T19:31:23.5443894Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/responses/{response_id}, Methods: GET
2026-02-12T19:31:23.5453714Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/responses/{response_id}/cancel, Methods: POST
2026-02-12T19:31:23.5462788Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/audio/transcriptions, Methods: POST
2026-02-12T19:31:23.5471486Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/audio/translations, Methods: POST
2026-02-12T19:31:23.5481562Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/completions, Methods: POST
2026-02-12T19:31:23.5491122Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/completions/render, Methods: POST
2026-02-12T19:31:23.5500615Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/messages, Methods: POST
2026-02-12T19:31:23.5509265Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/models, Methods: GET
2026-02-12T19:31:23.5518928Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /load, Methods: GET
2026-02-12T19:31:23.5528717Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /version, Methods: GET
2026-02-12T19:31:23.5538189Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /ping, Methods: GET
2026-02-12T19:31:23.5547335Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /ping, Methods: POST
2026-02-12T19:31:23.5558315Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /invocations, Methods: POST
2026-02-12T19:31:23.5566721Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /classify, Methods: POST
2026-02-12T19:31:23.5575902Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/embeddings, Methods: POST
2026-02-12T19:31:23.5584818Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /score, Methods: POST
2026-02-12T19:31:23.5593735Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/score, Methods: POST
2026-02-12T19:31:23.5603973Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /rerank, Methods: POST
2026-02-12T19:31:23.5613175Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/rerank, Methods: POST
2026-02-12T19:31:23.5622683Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v2/rerank, Methods: POST
2026-02-12T19:31:23.5631588Z [0;36m(ApiServer_2 pid=200)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /pooling, Methods: POST
2026-02-12T19:31:23.5641964Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:31:23 [serving.py:212] Chat template warmup completed in 20.0ms
2026-02-12T19:31:23.5652212Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:31:23 [api_server.py:946] Starting vLLM API server 1 on http://0.0.0.0:8080
2026-02-12T19:31:23.5666819Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:31:23 [launcher.py:38] Available routes are:
2026-02-12T19:31:23.5669325Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /openapi.json, Methods: GET, HEAD
2026-02-12T19:31:23.5679091Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /docs, Methods: GET, HEAD
2026-02-12T19:31:23.5688141Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /docs/oauth2-redirect, Methods: GET, HEAD
2026-02-12T19:31:23.5697076Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /redoc, Methods: GET, HEAD
2026-02-12T19:31:23.5706569Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /scale_elastic_ep, Methods: POST
2026-02-12T19:31:23.5715935Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /is_scaling_elastic_ep, Methods: POST
2026-02-12T19:31:23.5725672Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /tokenize, Methods: POST
2026-02-12T19:31:23.5735147Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /detokenize, Methods: POST
2026-02-12T19:31:23.5744558Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /inference/v1/generate, Methods: POST
2026-02-12T19:31:23.5753851Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /pause, Methods: POST
2026-02-12T19:31:23.5763667Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /resume, Methods: POST
2026-02-12T19:31:23.5774977Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /is_paused, Methods: GET
2026-02-12T19:31:23.5783941Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /metrics, Methods: GET
2026-02-12T19:31:23.5793482Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /health, Methods: GET
2026-02-12T19:31:23.5805234Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/chat/completions, Methods: POST
2026-02-12T19:31:23.5814144Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/chat/completions/render, Methods: POST
2026-02-12T19:31:23.5823850Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/responses, Methods: POST
2026-02-12T19:31:23.5833612Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/responses/{response_id}, Methods: GET
2026-02-12T19:31:23.5843478Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/responses/{response_id}/cancel, Methods: POST
2026-02-12T19:31:23.5854002Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/audio/transcriptions, Methods: POST
2026-02-12T19:31:23.5863781Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/audio/translations, Methods: POST
2026-02-12T19:31:23.5873356Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/completions, Methods: POST
2026-02-12T19:31:23.5883541Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/completions/render, Methods: POST
2026-02-12T19:31:23.5893452Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/messages, Methods: POST
2026-02-12T19:31:23.5903189Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/models, Methods: GET
2026-02-12T19:31:23.5912930Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /load, Methods: GET
2026-02-12T19:31:23.5923267Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /version, Methods: GET
2026-02-12T19:31:23.5933108Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /ping, Methods: GET
2026-02-12T19:31:23.5942934Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /ping, Methods: POST
2026-02-12T19:31:23.5952662Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /invocations, Methods: POST
2026-02-12T19:31:23.5963610Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /classify, Methods: POST
2026-02-12T19:31:23.5972878Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/embeddings, Methods: POST
2026-02-12T19:31:23.6024128Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /score, Methods: POST
2026-02-12T19:31:23.6024688Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/score, Methods: POST
2026-02-12T19:31:23.6025210Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /rerank, Methods: POST
2026-02-12T19:31:23.6025709Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/rerank, Methods: POST
2026-02-12T19:31:23.6026267Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v2/rerank, Methods: POST
2026-02-12T19:31:23.6031936Z [0;36m(ApiServer_1 pid=199)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /pooling, Methods: POST
2026-02-12T19:31:23.6043994Z [0;36m(ApiServer_1 pid=199)[0;0m WARNING 02-12 19:31:23 [warnings.py:110] /usr/local/python3.11.14/lib/python3.11/site-packages/websockets/legacy/__init__.py:6: DeprecationWarning: websockets.legacy is deprecated; see https://websockets.readthedocs.io/en/stable/howto/upgrade.html for upgrade instructions
2026-02-12T19:31:23.6054589Z [0;36m(ApiServer_2 pid=200)[0;0m WARNING 02-12 19:31:23 [warnings.py:110] /usr/local/python3.11.14/lib/python3.11/site-packages/websockets/legacy/__init__.py:6: DeprecationWarning: websockets.legacy is deprecated; see https://websockets.readthedocs.io/en/stable/howto/upgrade.html for upgrade instructions
2026-02-12T19:31:23.6065030Z [0;36m(ApiServer_3 pid=201)[0;0m WARNING 02-12 19:31:23 [warnings.py:110] /usr/local/python3.11.14/lib/python3.11/site-packages/websockets/legacy/__init__.py:6: DeprecationWarning: websockets.legacy is deprecated; see https://websockets.readthedocs.io/en/stable/howto/upgrade.html for upgrade instructions
2026-02-12T19:31:23.6081452Z [0;36m(ApiServer_1 pid=199)[0;0m WARNING 02-12 19:31:23 [warnings.py:110] /usr/local/python3.11.14/lib/python3.11/site-packages/uvicorn/protocols/websockets/websockets_impl.py:17: DeprecationWarning: websockets.server.WebSocketServerProtocol is deprecated
2026-02-12T19:31:23.6086176Z [0;36m(ApiServer_3 pid=201)[0;0m WARNING 02-12 19:31:23 [warnings.py:110] /usr/local/python3.11.14/lib/python3.11/site-packages/uvicorn/protocols/websockets/websockets_impl.py:17: DeprecationWarning: websockets.server.WebSocketServerProtocol is deprecated
2026-02-12T19:31:23.6096351Z [0;36m(ApiServer_2 pid=200)[0;0m WARNING 02-12 19:31:23 [warnings.py:110] /usr/local/python3.11.14/lib/python3.11/site-packages/uvicorn/protocols/websockets/websockets_impl.py:17: DeprecationWarning: websockets.server.WebSocketServerProtocol is deprecated
2026-02-12T19:31:23.6105162Z [0;36m(ApiServer_2 pid=200)[0;0m INFO:     Started server process [200]
2026-02-12T19:31:23.6114232Z [0;36m(ApiServer_1 pid=199)[0;0m INFO:     Started server process [199]
2026-02-12T19:31:23.6131209Z [0;36m(ApiServer_3 pid=201)[0;0m INFO:     Started server process [201]
2026-02-12T19:31:23.6163627Z [0;36m(ApiServer_1 pid=199)[0;0m INFO:     Waiting for application startup.
2026-02-12T19:31:23.6170083Z [0;36m(ApiServer_2 pid=200)[0;0m INFO:     Waiting for application startup.
2026-02-12T19:31:23.6179498Z [0;36m(ApiServer_3 pid=201)[0;0m INFO:     Waiting for application startup.
2026-02-12T19:31:23.6540100Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:31:23 [api_server.py:665] Supported tasks: ['generate']
2026-02-12T19:31:23.6589256Z [0;36m(ApiServer_0 pid=198)[0;0m WARNING 02-12 19:31:23 [model.py:1371] Default vLLM sampling parameters have been overridden by the model's `generation_config.json`: `{'top_p': 0.95}`. If this is not intended, please relaunch vLLM instance with `--generation-config vllm`.
2026-02-12T19:31:23.6599076Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:31:23 [serving.py:177] Warming up chat template processing...
2026-02-12T19:31:23.6763601Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:31:23 [serving.py:212] Chat template warmup completed in 20.1ms
2026-02-12T19:31:23.6803881Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:31:23 [api_server.py:946] Starting vLLM API server 0 on http://0.0.0.0:8080
2026-02-12T19:31:23.6825531Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:31:23 [launcher.py:38] Available routes are:
2026-02-12T19:31:23.6834955Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /openapi.json, Methods: HEAD, GET
2026-02-12T19:31:23.6844931Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /docs, Methods: HEAD, GET
2026-02-12T19:31:23.6855108Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /docs/oauth2-redirect, Methods: HEAD, GET
2026-02-12T19:31:23.6863846Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /redoc, Methods: HEAD, GET
2026-02-12T19:31:23.6873354Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /scale_elastic_ep, Methods: POST
2026-02-12T19:31:23.6883122Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /is_scaling_elastic_ep, Methods: POST
2026-02-12T19:31:23.6893111Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /tokenize, Methods: POST
2026-02-12T19:31:23.6902883Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /detokenize, Methods: POST
2026-02-12T19:31:23.6911649Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /inference/v1/generate, Methods: POST
2026-02-12T19:31:23.6921354Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /pause, Methods: POST
2026-02-12T19:31:23.6930716Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /resume, Methods: POST
2026-02-12T19:31:23.6940474Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /is_paused, Methods: GET
2026-02-12T19:31:23.6949608Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /metrics, Methods: GET
2026-02-12T19:31:23.6959694Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /health, Methods: GET
2026-02-12T19:31:23.6969861Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/chat/completions, Methods: POST
2026-02-12T19:31:23.6979993Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/chat/completions/render, Methods: POST
2026-02-12T19:31:23.7001264Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/responses, Methods: POST
2026-02-12T19:31:23.7001950Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/responses/{response_id}, Methods: GET
2026-02-12T19:31:23.7009857Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/responses/{response_id}/cancel, Methods: POST
2026-02-12T19:31:23.7019040Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/audio/transcriptions, Methods: POST
2026-02-12T19:31:23.7030446Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/audio/translations, Methods: POST
2026-02-12T19:31:23.7038547Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/completions, Methods: POST
2026-02-12T19:31:23.7048061Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/completions/render, Methods: POST
2026-02-12T19:31:23.7057647Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/messages, Methods: POST
2026-02-12T19:31:23.7066824Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/models, Methods: GET
2026-02-12T19:31:23.7076403Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /load, Methods: GET
2026-02-12T19:31:23.7086604Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /version, Methods: GET
2026-02-12T19:31:23.7096224Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /ping, Methods: GET
2026-02-12T19:31:23.7105746Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /ping, Methods: POST
2026-02-12T19:31:23.7164699Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /invocations, Methods: POST
2026-02-12T19:31:23.7173554Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /classify, Methods: POST
2026-02-12T19:31:23.7183295Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/embeddings, Methods: POST
2026-02-12T19:31:23.7191870Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /score, Methods: POST
2026-02-12T19:31:23.7201496Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/score, Methods: POST
2026-02-12T19:31:23.7211043Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /rerank, Methods: POST
2026-02-12T19:31:23.7219780Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v1/rerank, Methods: POST
2026-02-12T19:31:23.7229264Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /v2/rerank, Methods: POST
2026-02-12T19:31:23.7239170Z [0;36m(ApiServer_0 pid=198)[0;0m INFO 02-12 19:31:23 [launcher.py:46] Route: /pooling, Methods: POST
2026-02-12T19:31:23.7250055Z [0;36m(ApiServer_0 pid=198)[0;0m WARNING 02-12 19:31:23 [warnings.py:110] /usr/local/python3.11.14/lib/python3.11/site-packages/websockets/legacy/__init__.py:6: DeprecationWarning: websockets.legacy is deprecated; see https://websockets.readthedocs.io/en/stable/howto/upgrade.html for upgrade instructions
2026-02-12T19:31:23.7259296Z [0;36m(ApiServer_0 pid=198)[0;0m WARNING 02-12 19:31:23 [warnings.py:110] /usr/local/python3.11.14/lib/python3.11/site-packages/uvicorn/protocols/websockets/websockets_impl.py:17: DeprecationWarning: websockets.server.WebSocketServerProtocol is deprecated
2026-02-12T19:31:23.7267350Z [0;36m(ApiServer_0 pid=198)[0;0m INFO:     Started server process [198]
2026-02-12T19:31:23.7276522Z [0;36m(ApiServer_0 pid=198)[0;0m INFO:     Waiting for application startup.
2026-02-12T19:31:23.8730328Z [0;36m(ApiServer_3 pid=201)[0;0m INFO:     Application startup complete.
2026-02-12T19:31:23.8815797Z [0;36m(ApiServer_1 pid=199)[0;0m INFO:     Application startup complete.
2026-02-12T19:31:23.9173696Z [0;36m(ApiServer_2 pid=200)[0;0m INFO:     Application startup complete.
2026-02-12T19:31:24.3041947Z [0;36m(ApiServer_0 pid=198)[0;0m INFO:     Application startup complete.
2026-02-12T19:31:24.6949259Z [0;36m(ApiServer_0 pid=198)[0;0m INFO:     10.0.0.50:39498 - "GET /health HTTP/1.1" 200 OK
2026-02-12T19:31:24.7035719Z [0;36m(ApiServer_1 pid=199)[0;0m INFO:     10.0.0.50:39500 - "GET /health HTTP/1.1" 200 OK
2026-02-12T19:31:26.2601790Z [0;36m(ApiServer_2 pid=200)[0;0m INFO:     10.0.0.210:38654 - "GET /health HTTP/1.1" 200 OK
2026-02-12T19:31:26.2627269Z [2026-02-12 19:31:26] INFO conftest.py:390: [READY] Node 10.0.0.210 is ready.
2026-02-12T19:31:26.3094005Z 2026-02-12 19:31:26,307 - modelscope - WARNING - We can not confirm the cached file is for revision: master
2026-02-12T19:31:26.3393475Z 2026-02-12 19:31:26,337 - modelscope - WARNING - We can not confirm the cached file is for revision: master
2026-02-12T19:31:29.7064740Z [0;36m(ApiServer_0 pid=198)[0;0m INFO:     10.0.0.50:35470 - "GET /health HTTP/1.1" 200 OK
2026-02-12T19:31:34.7110153Z [0;36m(ApiServer_0 pid=198)[0;0m INFO:     10.0.0.50:35472 - "GET /health HTTP/1.1" 200 OK
2026-02-12T19:31:39.7160623Z [0;36m(ApiServer_0 pid=198)[0;0m INFO:     10.0.0.50:56526 - "GET /health HTTP/1.1" 200 OK
2026-02-12T19:31:42.8318043Z [0;36m(ApiServer_0 pid=198)[0;0m WARNING 02-12 19:31:42 [warnings.py:110] /vllm-workspace/vllm/vllm/entrypoints/openai/engine/serving.py:1067: DeprecationWarning: max_tokens is deprecated in favor of the max_completion_tokens field
2026-02-12T19:31:42.8330102Z [0;36m(ApiServer_0 pid=198)[0;0m WARNING 02-12 19:31:42 [warnings.py:110] /vllm-workspace/vllm/vllm/entrypoints/utils.py:218: DeprecationWarning: max_tokens is deprecated in favor of the max_completion_tokens field
2026-02-12T19:31:42.8339741Z [0;36m(ApiServer_2 pid=200)[0;0m WARNING 02-12 19:31:42 [warnings.py:110] /vllm-workspace/vllm/vllm/entrypoints/openai/engine/serving.py:1067: DeprecationWarning: max_tokens is deprecated in favor of the max_completion_tokens field
2026-02-12T19:31:42.8350544Z [0;36m(ApiServer_2 pid=200)[0;0m WARNING 02-12 19:31:42 [warnings.py:110] /vllm-workspace/vllm/vllm/entrypoints/utils.py:218: DeprecationWarning: max_tokens is deprecated in favor of the max_completion_tokens field
2026-02-12T19:31:42.8374530Z [0;36m(ApiServer_3 pid=201)[0;0m WARNING 02-12 19:31:42 [warnings.py:110] /vllm-workspace/vllm/vllm/entrypoints/openai/engine/serving.py:1067: DeprecationWarning: max_tokens is deprecated in favor of the max_completion_tokens field
2026-02-12T19:31:42.8384037Z [0;36m(ApiServer_3 pid=201)[0;0m WARNING 02-12 19:31:42 [warnings.py:110] /vllm-workspace/vllm/vllm/entrypoints/utils.py:218: DeprecationWarning: max_tokens is deprecated in favor of the max_completion_tokens field
2026-02-12T19:31:42.8401551Z [0;36m(ApiServer_1 pid=199)[0;0m WARNING 02-12 19:31:42 [warnings.py:110] /vllm-workspace/vllm/vllm/entrypoints/openai/engine/serving.py:1067: DeprecationWarning: max_tokens is deprecated in favor of the max_completion_tokens field
2026-02-12T19:31:42.8411668Z [0;36m(ApiServer_1 pid=199)[0;0m WARNING 02-12 19:31:42 [warnings.py:110] /vllm-workspace/vllm/vllm/entrypoints/utils.py:218: DeprecationWarning: max_tokens is deprecated in favor of the max_completion_tokens field
2026-02-12T19:31:43.8201454Z ................[0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m INFO 02-12 19:31:43 [acl_graph.py:185] Replaying aclgraph
2026-02-12T19:31:43.8211232Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m INFO 02-12 19:31:43 [acl_graph.py:185] Replaying aclgraph
2026-02-12T19:31:43.8221054Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m INFO 02-12 19:31:43 [acl_graph.py:185] Replaying aclgraph
2026-02-12T19:31:43.8230026Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m INFO 02-12 19:31:43 [acl_graph.py:185] Replaying aclgraph
2026-02-12T19:31:43.8239519Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m INFO 02-12 19:31:43 [acl_graph.py:185] Replaying aclgraph
2026-02-12T19:31:43.8250236Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m INFO 02-12 19:31:43 [acl_graph.py:185] Replaying aclgraph
2026-02-12T19:31:43.8259431Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m INFO 02-12 19:31:43 [acl_graph.py:185] Replaying aclgraph
2026-02-12T19:31:43.8270452Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m INFO 02-12 19:31:43 [acl_graph.py:185] Replaying aclgraph
2026-02-12T19:31:43.8280182Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m INFO 02-12 19:31:43 [acl_graph.py:185] Replaying aclgraph
2026-02-12T19:31:43.8289719Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m INFO 02-12 19:31:43 [acl_graph.py:185] Replaying aclgraph
2026-02-12T19:31:43.8299204Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m INFO 02-12 19:31:43 [acl_graph.py:185] Replaying aclgraph
2026-02-12T19:31:43.8308885Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m INFO 02-12 19:31:43 [acl_graph.py:185] Replaying aclgraph
2026-02-12T19:31:43.8318986Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m INFO 02-12 19:31:43 [acl_graph.py:185] Replaying aclgraph
2026-02-12T19:31:43.8328549Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m INFO 02-12 19:31:43 [acl_graph.py:185] Replaying aclgraph
2026-02-12T19:31:43.8338708Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m INFO 02-12 19:31:43 [acl_graph.py:185] Replaying aclgraph
2026-02-12T19:31:43.8348117Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m INFO 02-12 19:31:43 [acl_graph.py:185] Replaying aclgraph
2026-02-12T19:31:44.7189353Z [0;36m(ApiServer_0 pid=198)[0;0m INFO:     10.0.0.50:56534 - "GET /health HTTP/1.1" 200 OK
2026-02-12T19:31:49.7232683Z [0;36m(ApiServer_0 pid=198)[0;0m INFO:     10.0.0.50:56634 - "GET /health HTTP/1.1" 200 OK
2026-02-12T19:31:54.7266847Z [0;36m(ApiServer_0 pid=198)[0;0m INFO:     10.0.0.50:56650 - "GET /health HTTP/1.1" 200 OK
2026-02-12T19:31:59.7303865Z [0;36m(ApiServer_0 pid=198)[0;0m INFO:     10.0.0.50:39748 - "GET /health HTTP/1.1" 200 OK
2026-02-12T19:32:04.7338240Z [0;36m(ApiServer_0 pid=198)[0;0m INFO:     10.0.0.50:39758 - "GET /health HTTP/1.1" 200 OK
2026-02-12T19:32:09.7378496Z [0;36m(ApiServer_0 pid=198)[0;0m INFO:     10.0.0.50:51106 - "GET /health HTTP/1.1" 200 OK
2026-02-12T19:32:14.7406653Z [0;36m(ApiServer_0 pid=198)[0;0m INFO:     10.0.0.50:51118 - "GET /health HTTP/1.1" 200 OK
2026-02-12T19:32:19.7443868Z [0;36m(ApiServer_0 pid=198)[0;0m INFO:     10.0.0.50:45078 - "GET /health HTTP/1.1" 200 OK
2026-02-12T19:32:24.7507752Z [0;36m(ApiServer_0 pid=198)[0;0m INFO:     10.0.0.50:45094 - "GET /health HTTP/1.1" 200 OK
2026-02-12T19:32:29.7511878Z [0;36m(ApiServer_0 pid=198)[0;0m INFO:     10.0.0.50:49312 - "GET /health HTTP/1.1" 200 OK
2026-02-12T19:32:34.7539995Z [0;36m(ApiServer_0 pid=198)[0;0m INFO:     10.0.0.50:49326 - "GET /health HTTP/1.1" 200 OK
2026-02-12T19:32:38.7567563Z [0;36m(ApiServer_2 pid=200)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693] AsyncLLM output_handler failed.
2026-02-12T19:32:38.7577508Z [0;36m(ApiServer_2 pid=200)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693] Traceback (most recent call last):
2026-02-12T19:32:38.7588302Z [0;36m(ApiServer_2 pid=200)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]   File "/vllm-workspace/vllm/vllm/v1/engine/async_llm.py", line 664, in output_handler
2026-02-12T19:32:38.7606853Z [0;36m(ApiServer_2 pid=200)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]     processed_outputs = output_processor.process_outputs(
2026-02-12T19:32:38.7625691Z [0;36m(ApiServer_2 pid=200)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:38.7636637Z [0;36m(ApiServer_2 pid=200)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]   File "/vllm-workspace/vllm/vllm/v1/engine/output_processor.py", line 632, in process_outputs
2026-02-12T19:32:38.7648925Z [0;36m(ApiServer_2 pid=200)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]     stop_string = req_state.detokenizer.update(
2026-02-12T19:32:38.7661236Z [0;36m(ApiServer_2 pid=200)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:38.7671277Z [0;36m(ApiServer_2 pid=200)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]   File "/vllm-workspace/vllm/vllm/v1/engine/detokenizer.py", line 120, in update
2026-02-12T19:32:38.7682140Z [0;36m(ApiServer_2 pid=200)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]     self.output_text += self.decode_next(new_token_id)
2026-02-12T19:32:38.7691549Z [0;36m(ApiServer_2 pid=200)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:38.7701518Z [0;36m(ApiServer_2 pid=200)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]   File "/vllm-workspace/vllm/vllm/v1/engine/detokenizer.py", line 299, in decode_next
2026-02-12T19:32:38.7711721Z [0;36m(ApiServer_2 pid=200)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]     new_tokens, decoded_text, prefix_offset, read_offset = detokenize_incrementally(
2026-02-12T19:32:38.7721659Z [0;36m(ApiServer_2 pid=200)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:38.7732908Z [0;36m(ApiServer_2 pid=200)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]   File "/vllm-workspace/vllm/vllm/tokenizers/detokenizer_utils.py", line 175, in detokenize_incrementally
2026-02-12T19:32:38.7742530Z [0;36m(ApiServer_2 pid=200)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]     new_text = tokenizer.convert_tokens_to_string(output_tokens[prefix_offset:])
2026-02-12T19:32:38.7753173Z [0;36m(ApiServer_2 pid=200)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:38.7763384Z [0;36m(ApiServer_2 pid=200)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]   File "/vllm-workspace/vllm/vllm/tokenizers/deepseek_v32.py", line 175, in convert_tokens_to_string
2026-02-12T19:32:38.7773191Z [0;36m(ApiServer_2 pid=200)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]     return self.tokenizer.convert_tokens_to_string(tokens)
2026-02-12T19:32:38.7782751Z [0;36m(ApiServer_2 pid=200)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:38.7793258Z [0;36m(ApiServer_2 pid=200)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/transformers/tokenization_utils_fast.py", line 666, in convert_tokens_to_string
2026-02-12T19:32:38.7803214Z [0;36m(ApiServer_2 pid=200)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]     self.backend_tokenizer.decoder.decode(tokens)
2026-02-12T19:32:38.7813559Z [0;36m(ApiServer_2 pid=200)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693] TypeError: argument 'tokens': 'NoneType' object cannot be converted to 'PyString'
2026-02-12T19:32:38.7823830Z [0;36m(ApiServer_1 pid=199)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693] AsyncLLM output_handler failed.
2026-02-12T19:32:38.7832248Z [0;36m(ApiServer_1 pid=199)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693] Traceback (most recent call last):
2026-02-12T19:32:38.7843244Z [0;36m(ApiServer_1 pid=199)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]   File "/vllm-workspace/vllm/vllm/v1/engine/async_llm.py", line 664, in output_handler
2026-02-12T19:32:38.7853308Z [0;36m(ApiServer_1 pid=199)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]     processed_outputs = output_processor.process_outputs(
2026-02-12T19:32:38.7863232Z [0;36m(ApiServer_1 pid=199)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:38.7873317Z [0;36m(ApiServer_1 pid=199)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]   File "/vllm-workspace/vllm/vllm/v1/engine/output_processor.py", line 632, in process_outputs
2026-02-12T19:32:38.7882988Z [0;36m(ApiServer_1 pid=199)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]     stop_string = req_state.detokenizer.update(
2026-02-12T19:32:38.7892837Z [0;36m(ApiServer_1 pid=199)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:38.7902554Z [0;36m(ApiServer_1 pid=199)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]   File "/vllm-workspace/vllm/vllm/v1/engine/detokenizer.py", line 120, in update
2026-02-12T19:32:38.7913171Z [0;36m(ApiServer_1 pid=199)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]     self.output_text += self.decode_next(new_token_id)
2026-02-12T19:32:38.7923474Z [0;36m(ApiServer_1 pid=199)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:38.7933751Z [0;36m(ApiServer_1 pid=199)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]   File "/vllm-workspace/vllm/vllm/v1/engine/detokenizer.py", line 299, in decode_next
2026-02-12T19:32:38.7944160Z [0;36m(ApiServer_1 pid=199)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]     new_tokens, decoded_text, prefix_offset, read_offset = detokenize_incrementally(
2026-02-12T19:32:38.7953670Z [0;36m(ApiServer_1 pid=199)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:38.7964956Z [0;36m(ApiServer_1 pid=199)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]   File "/vllm-workspace/vllm/vllm/tokenizers/detokenizer_utils.py", line 175, in detokenize_incrementally
2026-02-12T19:32:38.7975492Z [0;36m(ApiServer_1 pid=199)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]     new_text = tokenizer.convert_tokens_to_string(output_tokens[prefix_offset:])
2026-02-12T19:32:38.7984821Z [0;36m(ApiServer_1 pid=199)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:38.7994428Z [0;36m(ApiServer_1 pid=199)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]   File "/vllm-workspace/vllm/vllm/tokenizers/deepseek_v32.py", line 175, in convert_tokens_to_string
2026-02-12T19:32:38.8005376Z [0;36m(ApiServer_1 pid=199)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]     return self.tokenizer.convert_tokens_to_string(tokens)
2026-02-12T19:32:38.8014943Z [0;36m(ApiServer_1 pid=199)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:38.8026149Z [0;36m(ApiServer_1 pid=199)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/transformers/tokenization_utils_fast.py", line 666, in convert_tokens_to_string
2026-02-12T19:32:38.8034928Z [0;36m(ApiServer_1 pid=199)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]     self.backend_tokenizer.decoder.decode(tokens)
2026-02-12T19:32:38.8045392Z [0;36m(ApiServer_1 pid=199)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693] TypeError: argument 'tokens': 'NoneType' object cannot be converted to 'PyString'
2026-02-12T19:32:38.8055116Z [0;36m(ApiServer_0 pid=198)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693] AsyncLLM output_handler failed.
2026-02-12T19:32:38.8064710Z [0;36m(ApiServer_0 pid=198)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693] Traceback (most recent call last):
2026-02-12T19:32:38.8074676Z [0;36m(ApiServer_0 pid=198)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]   File "/vllm-workspace/vllm/vllm/v1/engine/async_llm.py", line 664, in output_handler
2026-02-12T19:32:38.8085111Z [0;36m(ApiServer_0 pid=198)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]     processed_outputs = output_processor.process_outputs(
2026-02-12T19:32:38.8094479Z [0;36m(ApiServer_0 pid=198)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:38.8104118Z [0;36m(ApiServer_0 pid=198)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]   File "/vllm-workspace/vllm/vllm/v1/engine/output_processor.py", line 632, in process_outputs
2026-02-12T19:32:38.8113937Z [0;36m(ApiServer_0 pid=198)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]     stop_string = req_state.detokenizer.update(
2026-02-12T19:32:38.8124747Z [0;36m(ApiServer_0 pid=198)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:38.8134831Z [0;36m(ApiServer_0 pid=198)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]   File "/vllm-workspace/vllm/vllm/v1/engine/detokenizer.py", line 120, in update
2026-02-12T19:32:38.8144163Z [0;36m(ApiServer_0 pid=198)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]     self.output_text += self.decode_next(new_token_id)
2026-02-12T19:32:38.8153682Z [0;36m(ApiServer_0 pid=198)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:38.8164847Z [0;36m(ApiServer_0 pid=198)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]   File "/vllm-workspace/vllm/vllm/v1/engine/detokenizer.py", line 299, in decode_next
2026-02-12T19:32:38.8173391Z [0;36m(ApiServer_0 pid=198)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]     new_tokens, decoded_text, prefix_offset, read_offset = detokenize_incrementally(
2026-02-12T19:32:38.8183302Z [0;36m(ApiServer_0 pid=198)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:38.8193353Z [0;36m(ApiServer_0 pid=198)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]   File "/vllm-workspace/vllm/vllm/tokenizers/detokenizer_utils.py", line 175, in detokenize_incrementally
2026-02-12T19:32:38.8202941Z [0;36m(ApiServer_0 pid=198)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]     new_text = tokenizer.convert_tokens_to_string(output_tokens[prefix_offset:])
2026-02-12T19:32:38.8213028Z [0;36m(ApiServer_0 pid=198)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:38.8222609Z [0;36m(ApiServer_0 pid=198)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]   File "/vllm-workspace/vllm/vllm/tokenizers/deepseek_v32.py", line 175, in convert_tokens_to_string
2026-02-12T19:32:38.8233722Z [0;36m(ApiServer_0 pid=198)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]     return self.tokenizer.convert_tokens_to_string(tokens)
2026-02-12T19:32:38.8246971Z [0;36m(ApiServer_0 pid=198)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:38.8257325Z [0;36m(ApiServer_0 pid=198)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/transformers/tokenization_utils_fast.py", line 666, in convert_tokens_to_string
2026-02-12T19:32:38.8266610Z [0;36m(ApiServer_0 pid=198)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693]     self.backend_tokenizer.decoder.decode(tokens)
2026-02-12T19:32:38.8276557Z [0;36m(ApiServer_0 pid=198)[0;0m ERROR 02-12 19:32:38 [async_llm.py:693] TypeError: argument 'tokens': 'NoneType' object cannot be converted to 'PyString'
2026-02-12T19:32:38.8287512Z [0;36m(ApiServer_1 pid=199)[0;0m INFO:     10.0.0.210:47228 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-12T19:32:38.8295929Z [0;36m(ApiServer_2 pid=200)[0;0m INFO:     10.0.0.210:47168 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-12T19:32:38.8305587Z [0;36m(ApiServer_0 pid=198)[0;0m INFO:     10.0.0.210:47164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-12T19:32:38.8315198Z [0;36m(ApiServer_1 pid=199)[0;0m INFO:     10.0.0.210:47252 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-12T19:32:38.8326890Z [0;36m(ApiServer_2 pid=200)[0;0m INFO:     10.0.0.210:47178 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-12T19:32:38.8334798Z [0;36m(ApiServer_1 pid=199)[0;0m INFO:     10.0.0.210:47276 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-12T19:32:38.8344433Z [0;36m(ApiServer_2 pid=200)[0;0m INFO:     10.0.0.210:47190 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-12T19:32:38.8353852Z [0;36m(ApiServer_1 pid=199)[0;0m INFO:     10.0.0.210:47294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-12T19:32:38.8363549Z [0;36m(ApiServer_2 pid=200)[0;0m INFO:     10.0.0.210:47218 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-12T19:32:38.8373453Z [0;36m(ApiServer_1 pid=199)[0;0m INFO:     10.0.0.210:47314 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-12T19:32:38.8382857Z [0;36m(ApiServer_0 pid=198)[0;0m INFO:     10.0.0.210:47176 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-12T19:32:38.8392209Z [0;36m(ApiServer_2 pid=200)[0;0m INFO:     10.0.0.210:47324 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-12T19:32:38.8401835Z [0;36m(ApiServer_1 pid=199)[0;0m INFO:     10.0.0.210:47318 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-12T19:32:38.8410976Z [0;36m(ApiServer_0 pid=198)[0;0m INFO:     10.0.0.210:47186 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-12T19:32:38.8420221Z [0;36m(ApiServer_2 pid=200)[0;0m INFO:     10.0.0.210:47326 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-12T19:32:38.8429593Z [0;36m(ApiServer_0 pid=198)[0;0m INFO:     10.0.0.210:47202 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-12T19:32:38.8439611Z [0;36m(ApiServer_2 pid=200)[0;0m INFO:     10.0.0.210:47352 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-12T19:32:38.8449108Z [0;36m(ApiServer_0 pid=198)[0;0m INFO:     10.0.0.210:47220 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-12T19:32:38.8459151Z [0;36m(ApiServer_2 pid=200)[0;0m INFO:     10.0.0.210:47372 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-12T19:32:38.8468292Z [0;36m(ApiServer_0 pid=198)[0;0m INFO:     10.0.0.210:47328 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-12T19:32:38.8478114Z [0;36m(ApiServer_2 pid=200)[0;0m INFO:     10.0.0.210:47394 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-12T19:32:38.8487397Z [0;36m(ApiServer_0 pid=198)[0;0m INFO:     10.0.0.210:47338 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-12T19:32:38.8496356Z [0;36m(ApiServer_2 pid=200)[0;0m INFO:     10.0.0.210:47414 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-12T19:32:38.8505915Z [0;36m(ApiServer_0 pid=198)[0;0m INFO:     10.0.0.210:47364 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-12T19:32:38.8515304Z [0;36m(ApiServer_0 pid=198)[0;0m INFO:     10.0.0.210:47378 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-12T19:32:38.8525514Z [0;36m(ApiServer_0 pid=198)[0;0m INFO:     10.0.0.210:47402 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-12T19:32:39.7566879Z [0;36m(ApiServer_0 pid=198)[0;0m INFO:     10.0.0.50:57752 - "GET /health HTTP/1.1" 503 Service Unavailable
2026-02-12T19:32:43.5723227Z [0;36m(ApiServer_1 pid=199)[0;0m INFO:     Shutting down
2026-02-12T19:32:43.6267771Z [0;36m(ApiServer_2 pid=200)[0;0m INFO:     Shutting down
2026-02-12T19:32:43.6721300Z [0;36m(ApiServer_1 pid=199)[0;0m INFO:     Waiting for application shutdown.
2026-02-12T19:32:43.6749451Z [0;36m(ApiServer_1 pid=199)[0;0m INFO:     Application shutdown complete.
2026-02-12T19:32:43.6762338Z [0;36m(ApiServer_1 pid=199)[0;0m INFO:     Finished server process [199]
2026-02-12T19:32:43.7274733Z [0;36m(ApiServer_2 pid=200)[0;0m INFO:     Waiting for application shutdown.
2026-02-12T19:32:43.7295901Z [0;36m(ApiServer_2 pid=200)[0;0m INFO:     Application shutdown complete.
2026-02-12T19:32:43.7306539Z [0;36m(ApiServer_2 pid=200)[0;0m INFO:     Finished server process [200]
2026-02-12T19:32:43.7400384Z [0;36m(ApiServer_1 pid=199)[0;0m sys:1: DeprecationWarning: builtin type swigvarlink has no __module__ attribute
2026-02-12T19:32:43.7712388Z [0;36m(ApiServer_2 pid=200)[0;0m sys:1: DeprecationWarning: builtin type swigvarlink has no __module__ attribute
2026-02-12T19:32:43.7974152Z [0;36m(ApiServer_0 pid=198)[0;0m INFO:     Shutting down
2026-02-12T19:32:43.8978127Z [0;36m(ApiServer_0 pid=198)[0;0m INFO:     Waiting for application shutdown.
2026-02-12T19:32:43.8999933Z [0;36m(ApiServer_0 pid=198)[0;0m INFO:     Application shutdown complete.
2026-02-12T19:32:43.9019175Z [0;36m(ApiServer_0 pid=198)[0;0m INFO:     Finished server process [198]
2026-02-12T19:32:43.9650163Z [0;36m(ApiServer_0 pid=198)[0;0m sys:1: DeprecationWarning: builtin type swigvarlink has no __module__ attribute
2026-02-12T19:32:44.5180908Z ERROR 02-12 19:32:44 [utils.py:290] Exception occurred while running API servers: Process ApiServer_1 (PID: 199) died with exit code None
2026-02-12T19:32:44.5190516Z ERROR 02-12 19:32:44 [utils.py:290] Traceback (most recent call last):
2026-02-12T19:32:44.5201167Z ERROR 02-12 19:32:44 [utils.py:290]   File "/vllm-workspace/vllm/vllm/v1/utils.py", line 277, in wait_for_completion_or_failure
2026-02-12T19:32:44.5210768Z ERROR 02-12 19:32:44 [utils.py:290]     raise RuntimeError(
2026-02-12T19:32:44.5220185Z ERROR 02-12 19:32:44 [utils.py:290] RuntimeError: Process ApiServer_1 (PID: 199) died with exit code None
2026-02-12T19:32:44.5229980Z INFO 02-12 19:32:44 [utils.py:293] Terminating remaining processes ...
2026-02-12T19:32:44.6066870Z [0;36m(ApiServer_3 pid=201)[0;0m INFO 02-12 19:32:44 [launcher.py:110] Shutting down FastAPI HTTP server.
2026-02-12T19:32:44.6087457Z [0;36m(ApiServer_3 pid=201)[0;0m INFO:     Shutting down
2026-02-12T19:32:44.7075907Z [0;36m(ApiServer_3 pid=201)[0;0m INFO:     Waiting for connections to close. (CTRL+C to force quit)
2026-02-12T19:32:44.7938659Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] WorkerProc hit an exception.
2026-02-12T19:32:44.7947285Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:44.7959185Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:44.7969863Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:44.8076330Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:44.8077189Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:44.8078142Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:44.8078824Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:44.8079702Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:44.8080611Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:44.8081431Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:44.8082494Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:44.8083384Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:44.8084067Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:44.8088354Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:44.8099508Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:44.8109326Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:44.8123981Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:44.8132419Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:44.8143067Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:44.8153495Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:44.8163530Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:44.8174983Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:44.8185204Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:44.8194635Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:44.8219752Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:44.8220591Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:44.8229264Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:58789
2026-02-12T19:32:44.8239043Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:44.8249973Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:44.8259892Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:44.8270586Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:44.8281752Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:44.8292182Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:44.8303135Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:44.8313957Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:44.8325115Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:44.8335271Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:44.8346294Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:44.8356085Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:44.8366887Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:44.8377366Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:44.8386990Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:44.8397849Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:44.8409265Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:44.8419854Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:44.8429612Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:44.8440514Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:44.8451054Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:44.8461365Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:44.8471598Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:44.8482529Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:44.8497248Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:44.8507684Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:44.8518158Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:58789
2026-02-12T19:32:44.8528435Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] 
2026-02-12T19:32:44.8538995Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] WorkerProc hit an exception.
2026-02-12T19:32:44.8548955Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:44.8559908Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:44.8570088Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:44.8580385Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:44.8590989Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:44.8602225Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:44.8612318Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:44.8623159Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:44.8633436Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:44.8643407Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:44.8654260Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:44.8664219Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:44.8674682Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:44.8685575Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:44.8695246Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:44.8705485Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:44.8716372Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:44.8727544Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:44.8737683Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:44.8748921Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:44.8759709Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:44.8772499Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:44.8782993Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:44.8793259Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:44.8805167Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:44.8815543Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:44.8827624Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:41890
2026-02-12T19:32:44.8838122Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:44.8850179Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:44.8860425Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:44.8870554Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:44.8882519Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:44.8893275Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:44.8904034Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:44.8915208Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:44.8926981Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:44.8939106Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:44.8954898Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:44.8961683Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:44.9025811Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:44.9026668Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:44.9027609Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:44.9028318Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:44.9029179Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:44.9030261Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:44.9039288Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:44.9050362Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:44.9064063Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:44.9071371Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:44.9081592Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:44.9091954Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:44.9103327Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:44.9113970Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:44.9123992Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:41890
2026-02-12T19:32:44.9133522Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] 
2026-02-12T19:32:44.9143806Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] WorkerProc hit an exception.
2026-02-12T19:32:44.9153259Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:44.9164566Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:44.9175041Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:44.9184807Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:44.9194872Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:44.9205558Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:44.9215927Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:44.9226522Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:44.9236599Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:44.9247484Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:44.9258182Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:44.9268179Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:44.9278487Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:44.9289333Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:44.9299515Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:44.9309445Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:44.9320502Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:44.9330718Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:44.9340652Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:44.9351200Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:44.9361409Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:44.9372618Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:44.9382393Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:44.9392435Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:44.9403263Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:44.9412353Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:44.9422966Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:56732
2026-02-12T19:32:44.9434484Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:44.9444327Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:44.9453965Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:44.9464632Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:44.9474186Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:44.9485160Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:44.9495514Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:44.9505739Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:44.9515821Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:44.9526890Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:44.9538164Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:44.9547101Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:44.9556473Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:44.9567299Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:44.9576773Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:44.9586261Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:44.9597354Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:44.9608331Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:44.9618236Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:44.9629028Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:44.9639782Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:44.9650007Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:44.9659700Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:44.9669331Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:44.9681374Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:44.9691703Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:44.9703564Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:56732
2026-02-12T19:32:44.9713290Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] 
2026-02-12T19:32:44.9724333Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] WorkerProc hit an exception.
2026-02-12T19:32:44.9734816Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:44.9745550Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:44.9755455Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:44.9767528Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:44.9779325Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:44.9790937Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:44.9803473Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:44.9814308Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:44.9825296Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:44.9836397Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:44.9849005Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:44.9859459Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:44.9881669Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:44.9883733Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:44.9894554Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:44.9905853Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:44.9917578Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:44.9928463Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:44.9939788Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:44.9951510Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:44.9962526Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:44.9973772Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:44.9983828Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:44.9994551Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.0006494Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:45.0016865Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:45.0028247Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:44449
2026-02-12T19:32:45.0038810Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:45.0050512Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:45.0060647Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:45.0070961Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.0081399Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:45.0091509Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:45.0101712Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.0112568Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:45.0123170Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:45.0133509Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.0143950Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:45.0153836Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.0164930Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.0175430Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:45.0185840Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:45.0196957Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.0209471Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:45.0220176Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:45.0230990Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.0243219Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:45.0255166Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:45.0265386Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:45.0276120Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] WorkerProc hit an exception.
2026-02-12T19:32:45.0287644Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:45.0300641Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:45.0310415Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:45.0321576Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.0333223Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:45.0344442Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:45.0355229Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.0367239Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:45.0377563Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:45.0388716Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.0400164Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:45.0410661Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.0420958Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.0432650Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:45.0443083Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:45.0453764Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.0465100Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:45.0475670Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:45.0486147Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.0496564Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:45.0506325Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:45.0517509Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:45.0527411Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.0537731Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.0549067Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:45.0559031Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:45.0569787Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:403
2026-02-12T19:32:45.0579856Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:45.0590431Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:45.0600682Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:45.0611090Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.0621849Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:45.0632114Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:45.0643048Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.0653994Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:45.0664620Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:45.0675074Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.0686481Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:45.0696490Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.0707785Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.0718150Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:45.0728971Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:45.0738513Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.0748899Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:45.0759590Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:45.0771419Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.0783408Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:45.0793638Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:45.0806205Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:45.0816660Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.0826811Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.0838779Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:45.0850400Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:45.0867970Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:44449
2026-02-12T19:32:45.0934560Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] 
2026-02-12T19:32:45.0935284Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.0935906Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.0936778Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:45.0937574Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:45.0938401Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:403
2026-02-12T19:32:45.0949225Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] 
2026-02-12T19:32:45.0961200Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] WorkerProc hit an exception.
2026-02-12T19:32:45.0972758Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:45.0983703Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:45.0994910Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:45.1006313Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.1017972Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:45.1028806Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:45.1040130Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.1051671Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:45.1063328Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:45.1073648Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.1084608Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:45.1094941Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.1105930Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.1116619Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:45.1127571Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:45.1138283Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.1149350Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:45.1160399Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:45.1171281Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.1182081Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:45.1191745Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:45.1203283Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:45.1213004Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.1223100Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.1233910Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:45.1244487Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:45.1255853Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:17824
2026-02-12T19:32:45.1265422Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:45.1275776Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:45.1285759Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:45.1297350Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.1307421Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:45.1316905Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:45.1328265Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.1338931Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:45.1349322Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:45.1362234Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.1376968Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:45.1410640Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.1420295Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.1430707Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:45.1441010Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:45.1451273Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.1462467Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:45.1472841Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:45.1483111Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.1493827Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:45.1504081Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:45.1514699Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:45.1525046Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.1535115Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.1545963Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:45.1555473Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:45.1566717Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:17824
2026-02-12T19:32:45.1576294Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] 
2026-02-12T19:32:45.1586488Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] WorkerProc hit an exception.
2026-02-12T19:32:45.1596688Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:45.1607553Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:45.1617610Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:45.1627078Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.1638324Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:45.1649389Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:45.1658826Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.1669733Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:45.1680320Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:45.1691556Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.1703262Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:45.1713598Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.1724641Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.1735771Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:45.1747092Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:45.1757801Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.1775801Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:45.1787052Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:45.1799232Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.1812077Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:45.1823749Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:45.1835822Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:45.1846962Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.1857892Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.1870770Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:45.1881780Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:45.1894858Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:35734
2026-02-12T19:32:45.1906494Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:45.1917978Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:45.1929065Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:45.1940009Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.1952571Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:45.1963813Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:45.1975540Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.1986883Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:45.1997944Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:45.2009439Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.2021592Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:45.2032317Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.2043287Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.2055130Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:45.2066552Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:45.2076592Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.2088956Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:45.2104218Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:45.2142451Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.2143349Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:45.2144259Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:45.2145131Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:45.2153262Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.2163469Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.2175053Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:45.2185256Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:45.2196787Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:35734
2026-02-12T19:32:45.2207321Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] 
2026-02-12T19:32:45.2217999Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] WorkerProc hit an exception.
2026-02-12T19:32:45.2228909Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:45.2240216Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:45.2251414Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:45.2261392Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.2273062Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:45.2283302Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:45.2294401Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.2305436Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:45.2316458Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:45.2327886Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.2338953Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:45.2348790Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.2405954Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.2406766Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:45.2407690Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:45.2408368Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.2409283Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:45.2415602Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:45.2426437Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.2439087Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:45.2448862Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:45.2459698Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:45.2470197Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.2481323Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.2491835Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:45.2501379Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:45.2513228Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:57756
2026-02-12T19:32:45.2523511Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:45.2534928Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:45.2544958Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:45.2555220Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.2567140Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:45.2577636Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:45.2588219Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.2599671Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:45.2610842Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:45.2621556Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.2634992Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:45.2643743Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.2654414Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.2665498Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:45.2676057Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:45.2688810Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.2698787Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:45.2709352Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:45.2720781Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.2732085Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:45.2743090Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:45.2753805Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:45.2770725Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.2776823Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.2789718Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:45.2800831Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:45.2813098Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:57756
2026-02-12T19:32:45.2822943Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] 
2026-02-12T19:32:45.2860387Z [0;36m(EngineCore_DP0 pid=168)[0;0m ERROR 02-12 19:32:44 [dump_input.py:72] Dumping input data for V1 LLM engine (v0.15.0) with config: model='/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8', speculative_config=SpeculativeConfig(method='mtp', model='/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8', num_spec_tokens=2), tokenizer='/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8', skip_tokenizer_init=False, tokenizer_mode=deepseek_v32, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=8, pipeline_parallel_size=1, data_parallel_size=4, disable_custom_all_reduce=True, quantization=ascend, enforce_eager=False, enable_return_routed_experts=False, kv_cache_dtype=bfloat16, device_config=npu, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='deepseek_v3', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01, cudagraph_metrics=False, enable_layerwise_nvtx_tracing=False, enable_mfu_metrics=False, enable_mm_processor_stats=False, enable_logging_iteration_details=False), seed=1024, served_model_name=/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'vllm_ascend.compilation.compiler_interface.AscendCompiler', 'custom_ops': ['all'], 'splitting_ops': [], 'compile_mm_encoder': False, 'compile_sizes': [], 'compile_ranges_split_points': [4096], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_DECODE_ONLY: (2, 0)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [24, 48], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': True, 'fuse_act_quant': True, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 48, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>, 'evaluate_guards': False, 'assume_32_bit_indexing': True}, 'local_cache_dir': None}, 
2026-02-12T19:32:45.2873902Z [0;36m(EngineCore_DP0 pid=168)[0;0m ERROR 02-12 19:32:44 [dump_input.py:79] Dumping scheduler output for model execution: SchedulerOutput(scheduled_new_reqs=[], scheduled_cached_reqs=CachedRequestData(req_ids=['chatcmpl-be88e34741dd5dcb-97a275ff', 'chatcmpl-815ec0f1bc965621-9c6bb9b7'],resumed_req_ids=set(),new_token_ids_lens=[],all_token_ids_lens={},new_block_ids=[None, None],num_computed_tokens=[463, 457],num_output_tokens=[355, 355]), num_scheduled_tokens={chatcmpl-be88e34741dd5dcb-97a275ff: 3, chatcmpl-815ec0f1bc965621-9c6bb9b7: 3}, total_num_scheduled_tokens=6, scheduled_spec_decode_tokens={chatcmpl-815ec0f1bc965621-9c6bb9b7: [-1, -1], chatcmpl-be88e34741dd5dcb-97a275ff: [-1, -1]}, scheduled_encoder_inputs={}, num_common_prefix_blocks=[0], finished_req_ids=[], free_encoder_mm_hashes=[], preempted_req_ids=[], has_structured_output_requests=false, pending_structured_output_tokens=false, num_invalid_spec_tokens=null, kv_connector_metadata=null, ec_connector_metadata=null)
2026-02-12T19:32:45.2883377Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] WorkerProc hit an exception.
2026-02-12T19:32:45.2894658Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:45.2906712Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:45.2919066Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:45.2930912Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.2943166Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:45.2954543Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:45.2966390Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.3137818Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:45.3138746Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:45.3139616Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.3140520Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:45.3141356Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.3142076Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.3142940Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:45.3143776Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:45.3144491Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.3145396Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:45.3146413Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:45.3147211Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.3148090Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:45.3149092Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:45.3149980Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:45.3150813Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.3153577Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.3164019Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:45.3173213Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:45.3184238Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:34739
2026-02-12T19:32:45.3194428Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:45.3205691Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:45.3215552Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:45.3225159Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.3235802Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:45.3248683Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:45.3258990Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.3269677Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:45.3280662Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:45.3291326Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.3302462Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:45.3311882Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.3322765Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.3333720Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:45.3343756Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:45.3353848Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.3365457Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:45.3375984Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:45.3386395Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.3397293Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:45.3407440Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:45.3418533Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:45.3428336Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.3439179Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.3450788Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:45.3460098Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:45.3470884Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:34739
2026-02-12T19:32:45.3480800Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] 
2026-02-12T19:32:45.3490507Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] WorkerProc hit an exception.
2026-02-12T19:32:45.3500629Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:45.3511450Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:45.3521011Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:45.3531474Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.3542716Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:45.3552176Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:45.3562710Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.3573935Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:45.3583826Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:45.3594224Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.3605292Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:45.3615308Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.3625402Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.3635885Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:45.3646409Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:45.3656855Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.3667571Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:45.3678034Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:45.3688788Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.3699545Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:45.3709352Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:45.3720759Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:45.3730381Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.3741054Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.3751447Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:45.3761693Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:45.3773881Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:46498
2026-02-12T19:32:45.3784804Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:45.3795679Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:45.3805685Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:45.3816399Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.3828587Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:45.3839541Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:45.3850995Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.3862416Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:45.3873521Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:45.3885116Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.3896437Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:45.3907040Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.3917720Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.3929283Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:45.3940204Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:45.3951261Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.3963644Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:45.3976074Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:45.3987089Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.4003511Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:45.4017830Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:45.4033957Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:45.4047091Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.4057768Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.4069755Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:45.4092699Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:45.4094212Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:46498
2026-02-12T19:32:45.4102233Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] 
2026-02-12T19:32:45.4115992Z [0;36m(EngineCore_DP0 pid=168)[0;0m ERROR 02-12 19:32:44 [dump_input.py:81] Dumping scheduler stats: SchedulerStats(num_running_reqs=2, num_waiting_reqs=0, step_counter=0, current_wave=0, kv_cache_usage=0.0050093926111458575, prefix_cache_stats=PrefixCacheStats(reset=False, requests=0, queries=0, hits=0, preempted_requests=0, preempted_queries=0, preempted_hits=0), connector_prefix_cache_stats=None, kv_cache_eviction_events=[], spec_decoding_stats=None, kv_connector_stats=None, waiting_lora_adapters={}, running_lora_adapters={}, cudagraph_stats=None, perf_stats=None)
2026-02-12T19:32:45.4125602Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] WorkerProc hit an exception.
2026-02-12T19:32:45.4136103Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:45.4146594Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:45.4156801Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:45.4167671Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.4178359Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:45.4187976Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:45.4198845Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.4209969Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:45.4220441Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:45.4231122Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.4242695Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:45.4253248Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.4263550Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.4273509Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:45.4283669Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:45.4294570Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.4305809Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:45.4315986Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:45.4326889Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.4338093Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:45.4347717Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:45.4358856Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:45.4369215Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.4379657Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.4390813Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:45.4400673Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:45.4412358Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:58789
2026-02-12T19:32:45.4421899Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:45.4433194Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:45.4443058Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:45.4453404Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.4465021Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:45.4474428Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:45.4484651Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.4495047Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:45.4505501Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:45.4515353Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.4527015Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:45.4536662Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.4546154Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.4557169Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:45.4568139Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:45.4577816Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.4589274Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:45.4803745Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:45.4804526Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.4805353Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:45.4806273Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:45.4807183Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:45.4807944Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.4808683Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.4809507Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:45.4810271Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:45.4811046Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:58789
2026-02-12T19:32:45.4811808Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] 
2026-02-12T19:32:45.4812592Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] WorkerProc hit an exception.
2026-02-12T19:32:45.4813176Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:45.4813972Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:45.4814695Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:45.4815254Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.4815951Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:45.4816679Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:45.4817325Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.4818069Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:45.4822567Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:45.4833327Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.4845422Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:45.4856100Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.4867394Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.4879610Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:45.4889692Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:45.4901301Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.4913522Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:45.4924045Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:45.4935238Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.4947031Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:45.4957536Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:45.4968830Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:45.4979878Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.4991352Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.5003344Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:45.5016371Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:45.5027782Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:44449
2026-02-12T19:32:45.5035321Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:45.5046538Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:45.5057548Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:45.5069004Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.5079746Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:45.5090355Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:45.5100726Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.5111829Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:45.5122843Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:45.5133680Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.5144072Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:45.5153894Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.5164918Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.5175711Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:45.5185570Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:45.5195897Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.5207837Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:45.5217901Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:45.5228523Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.5239763Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:45.5250544Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:45.5262149Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:45.5272104Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] WorkerProc hit an exception.
2026-02-12T19:32:45.5282989Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:45.5293881Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:45.5304200Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:45.5314612Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.5325937Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:45.5336632Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:45.5347537Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.5393789Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:45.5394643Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:45.5395479Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.5396321Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:45.5402256Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.5413057Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.5423648Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:45.5433539Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:45.5444088Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.5456546Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:45.5466312Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:45.5476524Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.5488984Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:45.5499475Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:45.5511544Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:45.5521310Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.5532149Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.5543937Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:45.5553538Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:45.5564927Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:403
2026-02-12T19:32:45.5574494Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:45.5585861Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:45.5595491Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:45.5606353Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.5617134Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:45.5626999Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:45.5637577Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.5648046Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:45.5658237Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:45.5668867Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.5679909Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:45.5689912Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.5700792Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.5711052Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:45.5721033Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:45.5730978Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.5741862Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:45.5752518Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:45.5763980Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.5775641Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:45.5786520Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:45.5798683Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:45.5809158Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.5820309Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.5831831Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:45.5842986Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:45.5854192Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:44449
2026-02-12T19:32:45.5864620Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] 
2026-02-12T19:32:45.5877051Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.5886471Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.5898950Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:45.5909474Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:45.5928021Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:403
2026-02-12T19:32:45.5931793Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] 
2026-02-12T19:32:45.5943470Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] WorkerProc hit an exception.
2026-02-12T19:32:45.5953539Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:45.5965342Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:45.6011198Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:45.6011769Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.6012644Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:45.6013439Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:45.6019357Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.6032573Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:45.6041474Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:45.6051539Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.6062287Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:45.6072186Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.6113324Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.6114083Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:45.6114850Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:45.6115543Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.6126174Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:45.6136477Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:45.6147158Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.6158295Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:45.6169421Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:45.6180161Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:45.6190310Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.6201272Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.6213070Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:45.6223053Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:45.6233855Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:41890
2026-02-12T19:32:45.6244571Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:45.6255285Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:45.6264848Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:45.6275261Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.6286821Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:45.6296118Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:45.6306524Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.6317688Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:45.6328249Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:45.6338650Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.6349360Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:45.6359071Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.6368820Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.6379700Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:45.6389859Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:45.6400586Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.6411764Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:45.6421959Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:45.6432265Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.6443628Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:45.6453105Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:45.6463987Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:45.6473523Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.6484805Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.6496209Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:45.6505500Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:45.6516555Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:41890
2026-02-12T19:32:45.6528218Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] 
2026-02-12T19:32:45.6537826Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] WorkerProc hit an exception.
2026-02-12T19:32:45.6548281Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:45.6558972Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:45.6569405Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:45.6579388Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.6590377Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:45.6602266Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:45.6610783Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.6621659Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:45.6632266Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:45.6643308Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.6654141Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:45.6664028Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.6674341Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.6686002Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:45.6695458Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:45.6705767Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.6716525Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:45.6727591Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:45.6737983Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.6748326Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:45.6759145Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:45.6770502Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:45.6780843Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.6791619Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.6805312Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:45.6816850Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:45.6829141Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:55702
2026-02-12T19:32:45.6839767Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:45.6850899Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:45.6861769Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:45.6873022Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.6885055Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:45.6895766Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:45.6906638Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.6918314Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:45.6929117Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:45.6940382Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.6951805Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:45.6962986Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.6974369Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.6985742Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:45.6996727Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:45.7008086Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.7019574Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:45.7030702Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:45.7043047Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.7054634Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:45.7065104Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:45.7084480Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:45.7087105Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.7097121Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.7109860Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:45.7120337Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:45.7131726Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:55702
2026-02-12T19:32:45.7142218Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] 
2026-02-12T19:32:45.7151795Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] WorkerProc hit an exception.
2026-02-12T19:32:45.7162585Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:45.7176750Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:45.7187942Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:45.7199440Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.7211375Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:45.7223790Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:45.7234795Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.7246707Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:45.7257456Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:45.7269281Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.7280853Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:45.7291635Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.7301777Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.7312702Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:45.7323504Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:45.7333932Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.7345053Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:45.7355298Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:45.7366247Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.7377280Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:45.7387546Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:45.7398584Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:45.7408823Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.7419090Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.7429896Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:45.7439399Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:45.7450802Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:56732
2026-02-12T19:32:45.7461022Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:45.7472141Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:45.7483348Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:45.7493243Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.7503549Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:45.7514266Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:45.7524313Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.7535113Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:45.7545009Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:45.7555561Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.7567209Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:45.7577041Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.7586968Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.7598509Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:45.7608878Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:45.7619238Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.7630202Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:45.7640909Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:45.7652419Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.7663231Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:45.7673531Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:45.7685026Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:45.7695181Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.7705745Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.7716983Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:45.7727319Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:45.7738188Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:56732
2026-02-12T19:32:45.7747841Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] 
2026-02-12T19:32:45.7758003Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] WorkerProc hit an exception.
2026-02-12T19:32:45.7769609Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:45.7781318Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:45.7791839Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:45.7803287Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.7814560Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:45.7825878Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:45.7836824Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.7848626Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:45.7859606Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:45.7871646Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.7883566Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:45.7894412Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.7905776Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.7917471Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:45.7928688Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:45.7939872Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.7952169Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:45.7963424Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:45.7975132Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.7986703Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:45.7999427Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:45.8010946Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:45.8022283Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.8032043Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.8043422Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:45.8053272Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:45.8065160Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:35734
2026-02-12T19:32:45.8074593Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:45.8086133Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:45.8095753Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:45.8105639Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.8117672Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:45.8128037Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:45.8138258Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.8149110Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:45.8159824Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:45.8170442Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.8181428Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:45.8190890Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.8201641Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.8213120Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:45.8222894Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:45.8233330Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.8245087Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:45.8255630Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:45.8266254Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.8277580Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:45.8288119Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:45.8299088Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:45.8309106Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.8319145Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.8330657Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:45.8340526Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:45.8351558Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:35734
2026-02-12T19:32:45.8361700Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] 
2026-02-12T19:32:45.8371530Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] WorkerProc hit an exception.
2026-02-12T19:32:45.8381741Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:45.8393741Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:45.8407543Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:45.8417956Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.8428996Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:45.8440416Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:45.8450996Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.8461247Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:45.8472439Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:45.8484020Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.8495186Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:45.8504868Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.8514776Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.8526540Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:45.8536102Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:45.8546428Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.8557891Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:45.8568890Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:45.8579369Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.8590656Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:45.8600829Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:45.8611286Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:45.8621063Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.8630980Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.8644121Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:45.8654637Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:45.8665793Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:57756
2026-02-12T19:32:45.8675512Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:45.8686397Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:45.8696239Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:45.8706327Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.8717051Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:45.8727149Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:45.8737119Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.8748739Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:45.8759486Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:45.8771334Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.8782857Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:45.8793109Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.8803894Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.8815879Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:45.8826662Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:45.8837694Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.8849045Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:45.8859925Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:45.8871776Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.8883234Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:45.8894603Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:45.8906142Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:45.8916708Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.8928148Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.8939849Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:45.8950084Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:45.8962076Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:57756
2026-02-12T19:32:45.8972799Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] 
2026-02-12T19:32:45.8984927Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] WorkerProc hit an exception.
2026-02-12T19:32:45.8994186Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:45.9005949Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:45.9016993Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:45.9027311Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.9038709Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:45.9048922Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:45.9059783Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.9071070Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:45.9081742Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:45.9092329Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.9106467Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:45.9113707Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.9124725Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.9135411Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:45.9145104Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:45.9155071Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.9166839Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:45.9177006Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:45.9187370Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.9198322Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:45.9208094Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:45.9218544Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:45.9228252Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.9238771Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.9250043Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:45.9260275Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:45.9271636Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:50564
2026-02-12T19:32:45.9282604Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:45.9293650Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:45.9303452Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:45.9313667Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.9324886Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:45.9334964Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:45.9345206Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.9355744Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:45.9366428Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:45.9377485Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.9387258Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:45.9397333Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.9407442Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.9418180Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:45.9428432Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:45.9438873Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.9449424Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:45.9460194Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:45.9471283Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.9481656Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:45.9492618Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:45.9503373Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:45.9513107Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.9523434Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.9533799Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:45.9544026Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:45.9554371Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:50564
2026-02-12T19:32:45.9564663Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] 
2026-02-12T19:32:45.9574854Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] WorkerProc hit an exception.
2026-02-12T19:32:45.9584988Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:45.9595579Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:45.9606142Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:45.9615591Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.9625558Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:45.9635866Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:45.9648208Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.9658954Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:45.9669361Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:45.9679902Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.9690217Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:45.9699952Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.9710083Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.9721100Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:45.9731521Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:45.9741747Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.9752371Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:45.9764126Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:45.9774935Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.9786864Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:45.9798235Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:45.9810099Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:45.9820630Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:45.9831312Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.9843461Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:45.9853971Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:45.9865581Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:34739
2026-02-12T19:32:45.9875913Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:45.9887774Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:45.9898658Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:45.9909555Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.9921071Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:45.9932230Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:45.9943154Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:45.9954712Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:45.9966373Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:45.9977883Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.0024292Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:46.0025088Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.0025630Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.0026504Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:46.0031837Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:46.0042815Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.0054021Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:46.0064125Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:46.0074344Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.0085869Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:46.0096046Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:46.0154543Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:46.0155317Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.0155884Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.0156680Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:46.0157417Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:46.0160526Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:34739
2026-02-12T19:32:46.0171548Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] 
2026-02-12T19:32:46.0181173Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] WorkerProc hit an exception.
2026-02-12T19:32:46.0190655Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:46.0203600Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:46.0214229Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:46.0224576Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.0235832Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:46.0246412Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:46.0263444Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.0279323Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:46.0291206Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:46.0303664Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.0317150Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:46.0327255Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.0337926Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.0349654Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:46.0360454Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:46.0371878Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.0384115Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:46.0394671Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:46.0406576Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.0418191Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:46.0428725Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:46.0442390Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:46.0452854Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.0463337Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.0475619Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:46.0485681Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:46.0497481Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:57770
2026-02-12T19:32:46.0508081Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:46.0519786Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:46.0530002Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:46.0540705Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.0552053Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:46.0562999Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:46.0573858Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.0584940Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:46.0595708Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:46.0606944Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.0617838Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:46.0628307Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.0638785Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.0649166Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:46.0659505Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:46.0669902Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.0681391Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:46.0692209Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:46.0702805Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.0713639Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:46.0724057Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:46.0735000Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:46.0745045Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] WorkerProc hit an exception.
2026-02-12T19:32:46.0755609Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:46.0769598Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:46.0780648Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:46.0792097Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.0804601Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:46.0815844Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:46.0827096Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.0838783Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:46.0849968Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:46.0862323Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.0874246Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:46.0885394Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.0896466Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.0909814Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:46.0919389Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:46.0929966Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.0942241Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:46.0953191Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:46.0965019Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.1036695Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:46.1037497Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:46.1038338Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:46.1039196Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.1039738Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.1040539Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:46.1041605Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:46.1052561Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:20362
2026-02-12T19:32:46.1062190Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:46.1073193Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:46.1083293Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:46.1094284Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.1122381Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:46.1123176Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:46.1127449Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.1138054Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:46.1148696Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:46.1159657Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.1171544Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:46.1181766Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.1192142Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.1203637Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:46.1213939Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:46.1224437Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.1235843Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:46.1246774Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:46.1261650Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.1269480Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:46.1280293Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:46.1292268Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:46.1303059Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.1312906Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.1326136Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:46.1335857Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:46.1346694Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:57770
2026-02-12T19:32:46.1357287Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] 
2026-02-12T19:32:46.1368049Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.1378128Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.1389544Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:46.1399654Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:46.1411451Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:20362
2026-02-12T19:32:46.1420932Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] 
2026-02-12T19:32:46.1432364Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] WorkerProc hit an exception.
2026-02-12T19:32:46.1444502Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:46.1453978Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:46.1463954Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:46.1474594Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.1486638Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:46.1496807Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:46.1507806Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.1519678Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:46.1529913Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:46.1541147Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.1552421Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:46.1563455Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.1574008Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.1585555Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:46.1596160Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:46.1607634Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.1619386Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:46.1630788Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:46.1640819Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.1653103Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:46.1663226Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:46.1674432Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:46.1685011Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.1695401Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.1705912Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:46.1715899Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:46.1727271Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:17824
2026-02-12T19:32:46.1737175Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:46.1747291Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:46.1757029Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:46.1767420Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.1778767Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:46.1789777Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:46.1800730Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.1812501Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:46.1823113Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:46.1834550Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.1847434Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:46.1857318Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.1868123Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.1880417Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:46.1891513Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:46.1902720Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.1913500Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:46.1925032Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:46.1935822Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.1947308Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:46.1958202Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:46.1969826Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:46.2034687Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.2035248Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.2036073Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:46.2036815Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:46.2037583Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:17824
2026-02-12T19:32:46.2038259Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] 
2026-02-12T19:32:46.2045596Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] WorkerProc hit an exception.
2026-02-12T19:32:46.2056027Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:46.2066377Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:46.2075876Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:46.2086086Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.2096821Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:46.2106909Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:46.2116526Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.2127193Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:46.2138404Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:46.2147628Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.2158522Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:46.2168198Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.2178367Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.2189162Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:46.2199751Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:46.2209885Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.2220673Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:46.2231065Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:46.2242825Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.2253372Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:46.2263477Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:46.2274858Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:46.2284826Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.2294457Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.2305055Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:46.2314927Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:46.2326735Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:2991
2026-02-12T19:32:46.2335888Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:46.2347158Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:46.2357879Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:46.2368900Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.2380044Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:46.2389681Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:46.2400735Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.2410841Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:46.2421088Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:46.2430943Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.2442269Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:46.2452988Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.2462464Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.2473091Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:46.2484730Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:46.2495228Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.2506382Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:46.2516786Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:46.2527211Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.2537927Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:46.2548217Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:46.2558641Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:46.2568373Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.2578359Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.2589745Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:46.2599560Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:46.2611510Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:2991
2026-02-12T19:32:46.2620519Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] 
2026-02-12T19:32:46.2630666Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] WorkerProc hit an exception.
2026-02-12T19:32:46.2641329Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:46.2652425Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:46.2662204Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:46.2672244Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.2683126Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:46.2693838Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:46.2703453Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.2714679Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:46.2725452Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:46.2735424Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.2745696Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:46.2755572Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.2766759Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.2790265Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:46.2791045Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:46.2800517Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.2812715Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:46.2824451Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:46.2840126Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.2851634Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:46.2862170Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:46.2873660Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:46.2884836Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.2895746Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.2907389Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:46.2917657Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:46.2929088Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:46498
2026-02-12T19:32:46.2939514Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:46.2951111Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:46.2961838Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:46.2975071Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.2984882Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:46.2994711Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:46.3005885Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.3017077Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:46.3076211Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:46.3076974Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.3077823Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:46.3078840Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.3079387Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.3082714Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:46.3093671Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:46.3103528Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.3115026Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:46.3125865Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:46.3136656Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.3147095Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:46.3157772Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:46.3169322Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:46.3178901Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.3188786Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.3200135Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:46.3209930Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:46.3220970Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:46498
2026-02-12T19:32:46.3230459Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] 
2026-02-12T19:32:46.3241687Z [0;36m(EngineCore_DP0 pid=168)[0;0m ERROR 02-12 19:32:44 [core.py:948] EngineCore encountered a fatal error.
2026-02-12T19:32:46.3251606Z [0;36m(EngineCore_DP0 pid=168)[0;0m ERROR 02-12 19:32:44 [core.py:948] Traceback (most recent call last):
2026-02-12T19:32:46.3262278Z [0;36m(EngineCore_DP0 pid=168)[0;0m ERROR 02-12 19:32:44 [core.py:948]   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 939, in run_engine_core
2026-02-12T19:32:46.3272404Z [0;36m(EngineCore_DP0 pid=168)[0;0m ERROR 02-12 19:32:44 [core.py:948]     engine_core.run_busy_loop()
2026-02-12T19:32:46.3284684Z [0;36m(EngineCore_DP0 pid=168)[0;0m ERROR 02-12 19:32:44 [core.py:948]   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 1357, in run_busy_loop
2026-02-12T19:32:46.3295508Z [0;36m(EngineCore_DP0 pid=168)[0;0m ERROR 02-12 19:32:44 [core.py:948]     executed = self._process_engine_step()
2026-02-12T19:32:46.3306821Z [0;36m(EngineCore_DP0 pid=168)[0;0m ERROR 02-12 19:32:44 [core.py:948]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.3317339Z [0;36m(EngineCore_DP0 pid=168)[0;0m ERROR 02-12 19:32:44 [core.py:948]   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 999, in _process_engine_step
2026-02-12T19:32:46.3330681Z [0;36m(EngineCore_DP0 pid=168)[0;0m ERROR 02-12 19:32:44 [core.py:948]     outputs, model_executed = self.step_fn()
2026-02-12T19:32:46.3344015Z [0;36m(EngineCore_DP0 pid=168)[0;0m ERROR 02-12 19:32:44 [core.py:948]                               ^^^^^^^^^^^^^^
2026-02-12T19:32:46.3358406Z [0;36m(EngineCore_DP0 pid=168)[0;0m ERROR 02-12 19:32:44 [core.py:948]   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 490, in step_with_batch_queue
2026-02-12T19:32:46.3372250Z [0;36m(EngineCore_DP0 pid=168)[0;0m ERROR 02-12 19:32:44 [core.py:948]     exec_model_fut.result()
2026-02-12T19:32:46.3383588Z [0;36m(EngineCore_DP0 pid=168)[0;0m ERROR 02-12 19:32:44 [core.py:948]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 80, in result
2026-02-12T19:32:46.3393938Z [0;36m(EngineCore_DP0 pid=168)[0;0m ERROR 02-12 19:32:44 [core.py:948]     return super().result()
2026-02-12T19:32:46.3404990Z [0;36m(EngineCore_DP0 pid=168)[0;0m ERROR 02-12 19:32:44 [core.py:948]            ^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.3417022Z [0;36m(EngineCore_DP0 pid=168)[0;0m ERROR 02-12 19:32:44 [core.py:948]   File "/usr/local/python3.11.14/lib/python3.11/concurrent/futures/_base.py", line 449, in result
2026-02-12T19:32:46.3426287Z [0;36m(EngineCore_DP0 pid=168)[0;0m ERROR 02-12 19:32:44 [core.py:948]     return self.__get_result()
2026-02-12T19:32:46.3435861Z [0;36m(EngineCore_DP0 pid=168)[0;0m ERROR 02-12 19:32:44 [core.py:948]            ^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.3447239Z [0;36m(EngineCore_DP0 pid=168)[0;0m ERROR 02-12 19:32:44 [core.py:948]   File "/usr/local/python3.11.14/lib/python3.11/concurrent/futures/_base.py", line 401, in __get_result
2026-02-12T19:32:46.3457393Z [0;36m(EngineCore_DP0 pid=168)[0;0m ERROR 02-12 19:32:44 [core.py:948]     raise self._exception
2026-02-12T19:32:46.3468443Z [0;36m(EngineCore_DP0 pid=168)[0;0m ERROR 02-12 19:32:44 [core.py:948]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 84, in wait_for_response
2026-02-12T19:32:46.3478987Z [0;36m(EngineCore_DP0 pid=168)[0;0m ERROR 02-12 19:32:44 [core.py:948]     response = self.aggregate(get_response())
2026-02-12T19:32:46.3489527Z [0;36m(EngineCore_DP0 pid=168)[0;0m ERROR 02-12 19:32:44 [core.py:948]                               ^^^^^^^^^^^^^^
2026-02-12T19:32:46.3500656Z [0;36m(EngineCore_DP0 pid=168)[0;0m ERROR 02-12 19:32:44 [core.py:948]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 357, in get_response
2026-02-12T19:32:46.3510493Z [0;36m(EngineCore_DP0 pid=168)[0;0m ERROR 02-12 19:32:44 [core.py:948]     raise RuntimeError(
2026-02-12T19:32:46.3523332Z [0;36m(EngineCore_DP0 pid=168)[0;0m ERROR 02-12 19:32:44 [core.py:948] RuntimeError: Worker failed with error '[/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:41890', please check the stack trace above for the root cause
2026-02-12T19:32:46.3558303Z [0;36m(EngineCore_DP1 pid=187)[0;0m ERROR 02-12 19:32:44 [dump_input.py:72] Dumping input data for V1 LLM engine (v0.15.0) with config: model='/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8', speculative_config=SpeculativeConfig(method='mtp', model='/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8', num_spec_tokens=2), tokenizer='/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8', skip_tokenizer_init=False, tokenizer_mode=deepseek_v32, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=8, pipeline_parallel_size=1, data_parallel_size=4, disable_custom_all_reduce=True, quantization=ascend, enforce_eager=False, enable_return_routed_experts=False, kv_cache_dtype=bfloat16, device_config=npu, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='deepseek_v3', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01, cudagraph_metrics=False, enable_layerwise_nvtx_tracing=False, enable_mfu_metrics=False, enable_mm_processor_stats=False, enable_logging_iteration_details=False), seed=1024, served_model_name=/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'vllm_ascend.compilation.compiler_interface.AscendCompiler', 'custom_ops': ['all'], 'splitting_ops': [], 'compile_mm_encoder': False, 'compile_sizes': [], 'compile_ranges_split_points': [4096], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_DECODE_ONLY: (2, 0)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [24, 48], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': True, 'fuse_act_quant': True, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 48, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>, 'evaluate_guards': False, 'assume_32_bit_indexing': True}, 'local_cache_dir': None}, 
2026-02-12T19:32:46.3567426Z [0;36m(EngineCore_DP1 pid=187)[0;0m ERROR 02-12 19:32:44 [dump_input.py:79] Dumping scheduler output for model execution: SchedulerOutput(scheduled_new_reqs=[], scheduled_cached_reqs=CachedRequestData(req_ids=['chatcmpl-93163432e9b73a46-bfa96628'],resumed_req_ids=set(),new_token_ids_lens=[],all_token_ids_lens={},new_block_ids=[None],num_computed_tokens=[446],num_output_tokens=[355]), num_scheduled_tokens={chatcmpl-93163432e9b73a46-bfa96628: 3}, total_num_scheduled_tokens=3, scheduled_spec_decode_tokens={chatcmpl-93163432e9b73a46-bfa96628: [-1, -1]}, scheduled_encoder_inputs={}, num_common_prefix_blocks=[0], finished_req_ids=[], free_encoder_mm_hashes=[], preempted_req_ids=[], has_structured_output_requests=false, pending_structured_output_tokens=false, num_invalid_spec_tokens=null, kv_connector_metadata=null, ec_connector_metadata=null)
2026-02-12T19:32:46.3575395Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] WorkerProc hit an exception.
2026-02-12T19:32:46.3585361Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:46.3596324Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:46.3606647Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:46.3616645Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.3627104Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:46.3637133Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:46.3649595Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.3660019Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:46.3670812Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:46.3681591Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.3692997Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:46.3702389Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.3712912Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.3723867Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:46.3734454Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:46.3744526Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.3755625Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:46.3769718Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:46.3780943Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.3793138Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:46.3803303Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:46.3815489Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:46.3825649Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.3836461Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.3847926Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:46.3856834Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:46.3867118Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:55702
2026-02-12T19:32:46.3877023Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:46.3887243Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:46.3897590Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:46.3905239Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.3915909Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:46.3925814Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:46.3935345Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.3945499Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:46.3955355Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:46.3965536Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.3975299Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:46.3983917Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.3993648Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.4004099Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:46.4014183Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:46.4023683Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.4033773Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:46.4043615Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:46.4053274Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.4063208Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:46.4073282Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:46.4083158Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:46.4092419Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.4102237Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.4113057Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:46.4121884Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:46.4132318Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:55702
2026-02-12T19:32:46.4140683Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] 
2026-02-12T19:32:46.4153111Z [0;36m(EngineCore_DP1 pid=187)[0;0m ERROR 02-12 19:32:44 [dump_input.py:81] Dumping scheduler stats: SchedulerStats(num_running_reqs=1, num_waiting_reqs=0, step_counter=0, current_wave=0, kv_cache_usage=0.0025046963055729288, prefix_cache_stats=PrefixCacheStats(reset=False, requests=0, queries=0, hits=0, preempted_requests=0, preempted_queries=0, preempted_hits=0), connector_prefix_cache_stats=None, kv_cache_eviction_events=[], spec_decoding_stats=None, kv_connector_stats=None, waiting_lora_adapters={}, running_lora_adapters={}, cudagraph_stats=None, perf_stats=None)
2026-02-12T19:32:46.4161266Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] WorkerProc hit an exception.
2026-02-12T19:32:46.4171061Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:46.4180852Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:46.4190623Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:46.4200302Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.4211311Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:46.4221280Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:46.4231344Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.4241362Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:46.4251429Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:46.4260329Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.4270368Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:46.4279995Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.4289825Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.4299945Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:46.4309311Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:46.4319001Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.4329417Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:46.4339011Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:46.4348602Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.4358103Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:46.4368010Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:46.4378101Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:46.4386884Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.4396870Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.4407084Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:46.4416093Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:46.4426400Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:50564
2026-02-12T19:32:46.4435498Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:46.4446381Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:46.4455531Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:46.4464896Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.4474144Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:46.4484221Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:46.4493938Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.4503916Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:46.4513846Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:46.4523751Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.4533661Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:46.4543568Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.4552997Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.4563012Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:46.4572902Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:46.4583454Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.4593224Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:46.4603128Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:46.4613090Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.4622972Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:46.4632496Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:46.4642465Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:46.4652092Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.4661382Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.4671072Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:46.4680663Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:46.4690574Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:50564
2026-02-12T19:32:46.4699795Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] 
2026-02-12T19:32:46.4709352Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] WorkerProc hit an exception.
2026-02-12T19:32:46.4719285Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:46.4729492Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:46.4738592Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:46.4748091Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.4757972Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:46.4768360Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:46.4777970Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.4787370Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:46.4796980Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:46.4807114Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.4817098Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:46.4826124Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.4835839Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.4846584Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:46.4855728Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:46.4865673Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.4875856Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:46.4886299Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:46.4896106Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.4906237Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:46.4915869Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:46.4928757Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:46.4937565Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.4947516Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.4957913Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:46.4967081Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:46.4977109Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:20362
2026-02-12T19:32:46.4986569Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:46.4996334Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:46.5006954Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:46.5016267Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.5043446Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:46.5044179Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:46.5045431Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.5054452Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:46.5064159Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:46.5073283Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.5083988Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:46.5093504Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.5103386Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.5113148Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:46.5123556Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:46.5133279Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.5143819Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:46.5153368Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:46.5163090Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.5173879Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:46.5183323Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:46.5193498Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:46.5202727Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.5212711Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.5223025Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:46.5232218Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:46.5242440Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:20362
2026-02-12T19:32:46.5251785Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] 
2026-02-12T19:32:46.5260895Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] WorkerProc hit an exception.
2026-02-12T19:32:46.5270232Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:46.5281284Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:46.5290081Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:46.5299661Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.5308791Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:46.5319246Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:46.5329083Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.5339055Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:46.5348695Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:46.5358728Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.5368730Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:46.5377678Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.5386966Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.5397074Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:46.5406553Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:46.5415923Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.5425961Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:46.5435839Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:46.5446708Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.5456596Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:46.5465624Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:46.5475508Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:46.5484851Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.5494539Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.5504693Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:46.5514098Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:46.5524019Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:46516
2026-02-12T19:32:46.5533316Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:46.5543476Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:46.5551917Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:46.5561850Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.5572210Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:46.5581375Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:46.5591013Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.5601277Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:46.5611218Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:46.5620789Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.5630773Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:46.5640468Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.5650309Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.5660480Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:46.5669407Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:46.5679064Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.5688924Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:46.5698129Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:46.5707420Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.5717407Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:46.5727156Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:46.5737025Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:46.5746429Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.5755915Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.5766880Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:46.5775950Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:46.5785763Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:46516
2026-02-12T19:32:46.5794989Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] 
2026-02-12T19:32:46.5805721Z [0;36m(EngineCore_DP1 pid=187)[0;0m ERROR 02-12 19:32:44 [core.py:948] EngineCore encountered a fatal error.
2026-02-12T19:32:46.5815625Z [0;36m(EngineCore_DP1 pid=187)[0;0m ERROR 02-12 19:32:44 [core.py:948] Traceback (most recent call last):
2026-02-12T19:32:46.5825389Z [0;36m(EngineCore_DP1 pid=187)[0;0m ERROR 02-12 19:32:44 [core.py:948]   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 939, in run_engine_core
2026-02-12T19:32:46.5835214Z [0;36m(EngineCore_DP1 pid=187)[0;0m ERROR 02-12 19:32:44 [core.py:948]     engine_core.run_busy_loop()
2026-02-12T19:32:46.5845558Z [0;36m(EngineCore_DP1 pid=187)[0;0m ERROR 02-12 19:32:44 [core.py:948]   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 1357, in run_busy_loop
2026-02-12T19:32:46.5854981Z [0;36m(EngineCore_DP1 pid=187)[0;0m ERROR 02-12 19:32:44 [core.py:948]     executed = self._process_engine_step()
2026-02-12T19:32:46.5864838Z [0;36m(EngineCore_DP1 pid=187)[0;0m ERROR 02-12 19:32:44 [core.py:948]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.5875188Z [0;36m(EngineCore_DP1 pid=187)[0;0m ERROR 02-12 19:32:44 [core.py:948]   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 999, in _process_engine_step
2026-02-12T19:32:46.5885288Z [0;36m(EngineCore_DP1 pid=187)[0;0m ERROR 02-12 19:32:44 [core.py:948]     outputs, model_executed = self.step_fn()
2026-02-12T19:32:46.5894865Z [0;36m(EngineCore_DP1 pid=187)[0;0m ERROR 02-12 19:32:44 [core.py:948]                               ^^^^^^^^^^^^^^
2026-02-12T19:32:46.5904592Z [0;36m(EngineCore_DP1 pid=187)[0;0m ERROR 02-12 19:32:44 [core.py:948]   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 490, in step_with_batch_queue
2026-02-12T19:32:46.5913897Z [0;36m(EngineCore_DP1 pid=187)[0;0m ERROR 02-12 19:32:44 [core.py:948]     exec_model_fut.result()
2026-02-12T19:32:46.5924263Z [0;36m(EngineCore_DP1 pid=187)[0;0m ERROR 02-12 19:32:44 [core.py:948]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 80, in result
2026-02-12T19:32:46.5933737Z [0;36m(EngineCore_DP1 pid=187)[0;0m ERROR 02-12 19:32:44 [core.py:948]     return super().result()
2026-02-12T19:32:46.5943235Z [0;36m(EngineCore_DP1 pid=187)[0;0m ERROR 02-12 19:32:44 [core.py:948]            ^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.5953356Z [0;36m(EngineCore_DP1 pid=187)[0;0m ERROR 02-12 19:32:44 [core.py:948]   File "/usr/local/python3.11.14/lib/python3.11/concurrent/futures/_base.py", line 449, in result
2026-02-12T19:32:46.5965079Z [0;36m(EngineCore_DP1 pid=187)[0;0m ERROR 02-12 19:32:44 [core.py:948]     return self.__get_result()
2026-02-12T19:32:46.5972915Z [0;36m(EngineCore_DP1 pid=187)[0;0m ERROR 02-12 19:32:44 [core.py:948]            ^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.5982688Z [0;36m(EngineCore_DP1 pid=187)[0;0m ERROR 02-12 19:32:44 [core.py:948]   File "/usr/local/python3.11.14/lib/python3.11/concurrent/futures/_base.py", line 401, in __get_result
2026-02-12T19:32:46.5991558Z [0;36m(EngineCore_DP1 pid=187)[0;0m ERROR 02-12 19:32:44 [core.py:948]     raise self._exception
2026-02-12T19:32:46.6001757Z [0;36m(EngineCore_DP1 pid=187)[0;0m ERROR 02-12 19:32:44 [core.py:948]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 84, in wait_for_response
2026-02-12T19:32:46.6011375Z [0;36m(EngineCore_DP1 pid=187)[0;0m ERROR 02-12 19:32:44 [core.py:948]     response = self.aggregate(get_response())
2026-02-12T19:32:46.6020638Z [0;36m(EngineCore_DP1 pid=187)[0;0m ERROR 02-12 19:32:44 [core.py:948]                               ^^^^^^^^^^^^^^
2026-02-12T19:32:46.6030636Z [0;36m(EngineCore_DP1 pid=187)[0;0m ERROR 02-12 19:32:44 [core.py:948]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 357, in get_response
2026-02-12T19:32:46.6039609Z [0;36m(EngineCore_DP1 pid=187)[0;0m ERROR 02-12 19:32:44 [core.py:948]     raise RuntimeError(
2026-02-12T19:32:46.6050393Z [0;36m(EngineCore_DP1 pid=187)[0;0m ERROR 02-12 19:32:44 [core.py:948] RuntimeError: Worker failed with error '[/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:57770', please check the stack trace above for the root cause
2026-02-12T19:32:46.6059783Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] WorkerProc hit an exception.
2026-02-12T19:32:46.6068754Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:46.6078882Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:46.6088440Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:46.6098108Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.6107481Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:46.6117462Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:46.6133415Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.6136963Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:46.6146082Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:46.6155612Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.6165930Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:46.6175481Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.6185216Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.6195237Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:46.6205186Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:46.6215134Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.6225194Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:46.6234648Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:46.6244827Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.6254596Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:46.6263992Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:46.6274442Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:46.6284387Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.6293930Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.6303507Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:46.6312826Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:46.6323990Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:57770
2026-02-12T19:32:46.6334964Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:46.6347292Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:46.6356957Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:46.6367009Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.6382766Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:46.6394626Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:46.6405393Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.6421015Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:46.6431420Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:46.6441302Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.6455092Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:46.6466326Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.6476361Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.6487696Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:46.6497893Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:46.6507859Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.6519202Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:46.6529074Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:46.6538590Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.6548142Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:46.6558231Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:46.6567938Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:46.6577665Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.6586713Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.6596944Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:46.6608666Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:46.6619268Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:57770
2026-02-12T19:32:46.6628655Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] 
2026-02-12T19:32:46.6638494Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] WorkerProc hit an exception.
2026-02-12T19:32:46.6650518Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:46.6659669Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:46.6668053Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:46.6731771Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.6732618Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:46.6733374Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:46.6734015Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.6734742Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:46.6735562Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:46.6737372Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.6747936Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:46.6757175Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.6767389Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.6777614Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:46.6787831Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:46.6797571Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.6807844Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:46.6817137Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:46.6827344Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.6839048Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:46.6976627Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:46.6987775Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:46.7000212Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.7007732Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.7017369Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:46.7029421Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:46.7036617Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:2991
2026-02-12T19:32:46.7046295Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:46.7056771Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:46.7103677Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:46.7104233Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.7104923Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:46.7105652Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:46.7107057Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.7116778Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:46.7129628Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:46.7139605Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.7149731Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:46.7159611Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.7170794Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.7179286Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:46.7188922Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:46.7199279Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.7209949Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:46.7219765Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:46.7229684Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.7240349Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:46.7250413Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:46.7260131Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:46.7272480Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.7282950Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.7294484Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:46.7304393Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:46.7314763Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:2991
2026-02-12T19:32:46.7324776Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] 
2026-02-12T19:32:46.7334124Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] WorkerProc hit an exception.
2026-02-12T19:32:46.7343892Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:46.7353706Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:46.7364109Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:46.7373300Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.7383435Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:46.7393030Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:46.7403020Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.7413129Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:46.7422590Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:46.7432522Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.7442450Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:46.7452419Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.7461056Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.7470640Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:46.7480090Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:46.7490054Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.7500305Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:46.7509726Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:46.7519390Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.7529239Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:46.7538655Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:46.7548880Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:46.7558324Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.7568199Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.7578092Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:46.7587494Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:46.7598620Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:46516
2026-02-12T19:32:46.7608197Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] Traceback (most recent call last):
2026-02-12T19:32:46.7617728Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 847, in worker_busy_loop
2026-02-12T19:32:46.7626627Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = func(*args, **kwargs)
2026-02-12T19:32:46.7635632Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.7645913Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm/vllm/v1/worker/worker_base.py", line 365, in execute_model
2026-02-12T19:32:46.7655294Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return self.worker.execute_model(scheduler_output)
2026-02-12T19:32:46.7664875Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.7674800Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 362, in execute_model
2026-02-12T19:32:46.7684773Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     output = self.model_runner.execute_model(scheduler_output, intermediate_tensors)
2026-02-12T19:32:46.7694506Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.7704332Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
2026-02-12T19:32:46.7713421Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.7723281Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.7733525Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1135, in execute_model
2026-02-12T19:32:46.7743063Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     ) = self._determine_batch_execution_and_padding(
2026-02-12T19:32:46.7753728Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.7763366Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1774, in _determine_batch_execution_and_padding
2026-02-12T19:32:46.7773303Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     _, num_tokens_across_dp, synced_cudagraph_mode = self._sync_batch_across_dp(
2026-02-12T19:32:46.7783171Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.7793165Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 1711, in _sync_batch_across_dp
2026-02-12T19:32:46.7803005Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     dist.all_reduce(tensor, group=get_dp_group().cpu_group)
2026-02-12T19:32:46.7813214Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
2026-02-12T19:32:46.7822957Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     return func(*args, **kwargs)
2026-02-12T19:32:46.7832279Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]            ^^^^^^^^^^^^^^^^^^^^^
2026-02-12T19:32:46.7842780Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]   File "/usr/local/python3.11.14/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 2942, in all_reduce
2026-02-12T19:32:46.7851761Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852]     work.wait()
2026-02-12T19:32:46.7861688Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:547] Connection closed by peer [10.0.0.50]:46516
2026-02-12T19:32:46.7871083Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m ERROR 02-12 19:32:44 [multiproc_executor.py:852] 
2026-02-12T19:32:48.8032268Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m INFO 02-12 19:32:48 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-12T19:32:48.8043627Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m INFO 02-12 19:32:48 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-12T19:32:48.8053100Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m INFO 02-12 19:32:48 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-12T19:32:48.8063109Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m INFO 02-12 19:32:48 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-12T19:32:48.8078077Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m INFO 02-12 19:32:48 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-12T19:32:48.8083102Z [0;36m(Worker_DP0_TP5_EP5 pid=695)[0;0m INFO 02-12 19:32:48 [multiproc_executor.py:774] WorkerProc shutting down.
2026-02-12T19:32:48.8093304Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m INFO 02-12 19:32:48 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-12T19:32:48.8103325Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m INFO 02-12 19:32:48 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-12T19:32:48.8114845Z [0;36m(Worker_DP0_TP2_EP2 pid=386)[0;0m INFO 02-12 19:32:48 [multiproc_executor.py:774] WorkerProc shutting down.
2026-02-12T19:32:48.8123559Z [0;36m(Worker_DP0_TP7_EP7 pid=903)[0;0m INFO 02-12 19:32:48 [multiproc_executor.py:774] WorkerProc shutting down.
2026-02-12T19:32:48.8133285Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m INFO 02-12 19:32:48 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-12T19:32:48.8150652Z [0;36m(Worker_DP0_TP3_EP3 pid=490)[0;0m INFO 02-12 19:32:48 [multiproc_executor.py:774] WorkerProc shutting down.
2026-02-12T19:32:48.8154064Z [0;36m(Worker_DP0_TP6_EP6 pid=799)[0;0m INFO 02-12 19:32:48 [multiproc_executor.py:774] WorkerProc shutting down.
2026-02-12T19:32:48.8163686Z [0;36m(Worker_DP0_TP1_EP1 pid=265)[0;0m INFO 02-12 19:32:48 [multiproc_executor.py:774] WorkerProc shutting down.
2026-02-12T19:32:48.8173893Z [0;36m(Worker_DP0_TP0_EP0 pid=216)[0;0m INFO 02-12 19:32:48 [multiproc_executor.py:774] WorkerProc shutting down.
2026-02-12T19:32:48.8184495Z [0;36m(Worker_DP0_TP4_EP4 pid=594)[0;0m INFO 02-12 19:32:48 [multiproc_executor.py:774] WorkerProc shutting down.
2026-02-12T19:32:48.8195364Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m INFO 02-12 19:32:48 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-12T19:32:48.8205440Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m INFO 02-12 19:32:48 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-12T19:32:48.8215260Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m INFO 02-12 19:32:48 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-12T19:32:48.8225318Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m INFO 02-12 19:32:48 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-12T19:32:48.8235264Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m INFO 02-12 19:32:48 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-12T19:32:48.8245460Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m INFO 02-12 19:32:48 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-12T19:32:48.8255509Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m INFO 02-12 19:32:48 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-12T19:32:48.8265246Z [0;36m(Worker_DP1_TP4_EP12 pid=591)[0;0m INFO 02-12 19:32:48 [multiproc_executor.py:774] WorkerProc shutting down.
2026-02-12T19:32:48.8275124Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m INFO 02-12 19:32:48 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-12T19:32:48.8285784Z [0;36m(Worker_DP1_TP1_EP9 pid=266)[0;0m INFO 02-12 19:32:48 [multiproc_executor.py:774] WorkerProc shutting down.
2026-02-12T19:32:48.8295279Z [0;36m(Worker_DP1_TP7_EP15 pid=906)[0;0m INFO 02-12 19:32:48 [multiproc_executor.py:774] WorkerProc shutting down.
2026-02-12T19:32:48.8304970Z [0;36m(Worker_DP1_TP3_EP11 pid=487)[0;0m INFO 02-12 19:32:48 [multiproc_executor.py:774] WorkerProc shutting down.
2026-02-12T19:32:48.8314967Z [0;36m(Worker_DP1_TP5_EP13 pid=698)[0;0m INFO 02-12 19:32:48 [multiproc_executor.py:774] WorkerProc shutting down.
2026-02-12T19:32:48.8324380Z [0;36m(Worker_DP1_TP0_EP8 pid=215)[0;0m INFO 02-12 19:32:48 [multiproc_executor.py:774] WorkerProc shutting down.
2026-02-12T19:32:48.8333892Z [0;36m(Worker_DP1_TP6_EP14 pid=802)[0;0m INFO 02-12 19:32:48 [multiproc_executor.py:774] WorkerProc shutting down.
2026-02-12T19:32:48.8343349Z [0;36m(Worker_DP1_TP2_EP10 pid=383)[0;0m INFO 02-12 19:32:48 [multiproc_executor.py:774] WorkerProc shutting down.
2026-02-12T19:32:54.8647770Z Traceback (most recent call last):
2026-02-12T19:32:54.8657035Z   File "/usr/local/python3.11.14/bin/vllm", line 7, in <module>
2026-02-12T19:32:54.8667022Z     sys.exit(main())
2026-02-12T19:32:54.8675814Z              ^^^^^^
2026-02-12T19:32:54.8686801Z   File "/vllm-workspace/vllm/vllm/entrypoints/cli/main.py", line 73, in main
2026-02-12T19:32:54.8695772Z     args.dispatch_function(args)
2026-02-12T19:32:54.8704701Z   File "/vllm-workspace/vllm/vllm/entrypoints/cli/serve.py", line 108, in cmd
2026-02-12T19:32:54.8714471Z     run_multi_api_server(args)
2026-02-12T19:32:54.8724406Z   File "/vllm-workspace/vllm/vllm/entrypoints/cli/serve.py", line 282, in run_multi_api_server
2026-02-12T19:32:54.8733368Z     wait_for_completion_or_failure(
2026-02-12T19:32:54.8742848Z   File "/vllm-workspace/vllm/vllm/v1/utils.py", line 277, in wait_for_completion_or_failure
2026-02-12T19:32:54.8752253Z     raise RuntimeError(
2026-02-12T19:32:54.8761851Z RuntimeError: Process ApiServer_1 (PID: 199) died with exit code None
2026-02-12T19:32:54.9349671Z [ERROR] 2026-02-12-19:32:54 (PID:138, Device:-1, RankID:-1) ERR99999 UNKNOWN applicaiton exception
2026-02-12T19:32:55.2781263Z sys:1: DeprecationWarning: builtin type swigvarlink has no __module__ attribute
2026-02-12T19:32:57.0114900Z /usr/local/python3.11.14/lib/python3.11/multiprocessing/resource_tracker.py:254: UserWarning: resource_tracker: There appear to be 2 leaked shared_memory objects to clean up at shutdown
2026-02-12T19:32:57.0122891Z   warnings.warn('resource_tracker: There appear to be %d '
2026-02-12T19:33:07.7847558Z 2026-02-12 19:33:07,782 - modelscope - WARNING - We can not confirm the cached file is for revision: master
2026-02-12T19:33:07.8061950Z 2026-02-12 19:33:07,804 - modelscope - WARNING - We can not confirm the cached file is for revision: master
2026-02-12T19:34:04.0688115Z [2026-02-12 19:34:04] ERROR aisbench.py:243: The following aisbench case failed: {'case_type': 'accuracy', 'dataset_path': 'vllm-ascend/gsm8k-lite', 'request_conf': 'vllm_api_general_chat', 'dataset_conf': 'gsm8k/gsm8k_gen_0_shot_cot_chat_prompt', 'max_out_len': 4096, 'batch_size': 64, 'baseline': 95, 'threshold': 5}, reason is Accuracy verification failed. The accuracy of /root/.cache/modelscope/hub/datasets/vllm-ascend/gsm8k-lite is 0.0, which is not within 5 relative to baseline 95.
2026-02-12T19:34:04.0700833Z [2026-02-12 19:34:04] ERROR aisbench.py:243: The following aisbench case failed: {'case_type': 'performance', 'dataset_path': 'vllm-ascend/GSM8K-in3500-bs2800', 'request_conf': 'vllm_api_stream_chat', 'dataset_conf': 'gsm8k/gsm8k_gen_0_shot_cot_str_perf', 'num_prompts': 512, 'max_out_len': 3000, 'batch_size': 512, 'request_rate': 11.2, 'baseline': 1253.8466, 'threshold': 0.97}, reason is Some errors happened to Aisbench runtime, the first error is 02/12 19:34:04 - AISBench - ERROR - /vllm-workspace/vllm-ascend/benchmark/ais_bench/benchmark/calculators/default_perf_metric_calculator.py - _init_datas - 21 - All requests failed, can't calculate performance results. Please check the ERROR log from every responses!
2026-02-12T19:34:04.3100188Z The request config is
2026-02-12T19:34:04.3109043Z  from ais_bench.benchmark.models import VLLMCustomAPIChat
2026-02-12T19:34:04.3119769Z from ais_bench.benchmark.utils.model_postprocessors import extract_non_reasoning_content
2026-02-12T19:34:04.3129868Z 
2026-02-12T19:34:04.3139676Z models = [
2026-02-12T19:34:04.3149447Z     dict(
2026-02-12T19:34:04.3159070Z         attr="service",
2026-02-12T19:34:04.3168060Z         type=VLLMCustomAPIChat,
2026-02-12T19:34:04.3178144Z         abbr='vllm-api-general-chat',
2026-02-12T19:34:04.3187422Z         path="",
2026-02-12T19:34:04.3198206Z         model="vllm-ascend/DeepSeek-V3.2-W8A8",
2026-02-12T19:34:04.3210603Z         request_rate = 0,
2026-02-12T19:34:04.3222881Z         retry = 2,
2026-02-12T19:34:04.3232947Z         host_ip = "10.0.0.210",
2026-02-12T19:34:04.3242985Z         host_port = 8080,
2026-02-12T19:34:04.3252197Z         max_out_len = 4096,
2026-02-12T19:34:04.3263154Z         batch_size = 64,
2026-02-12T19:34:04.3271878Z         trust_remote_code=False,
2026-02-12T19:34:04.3282557Z         generation_kwargs = dict(
2026-02-12T19:34:04.3292084Z             temperature = 0.6,
2026-02-12T19:34:04.3301289Z             ignore_eos = False,
2026-02-12T19:34:04.3311296Z             #top_k = 10,
2026-02-12T19:34:04.3320848Z             top_p = 0.95,
2026-02-12T19:34:04.3331482Z             #seed = None,
2026-02-12T19:34:04.3341317Z             #repetition_penalty = 1.03,
2026-02-12T19:34:04.3350855Z         ),
2026-02-12T19:34:04.3361274Z         pred_postprocessor=dict(type=extract_non_reasoning_content)
2026-02-12T19:34:04.3370715Z     )
2026-02-12T19:34:04.3380838Z ]
2026-02-12T19:34:04.3391014Z 
2026-02-12T19:34:04.3401364Z running aisbench cmd: ais_bench --models vllm_api_general_chat_custom --datasets gsm8k_gen_0_shot_cot_chat_prompt
2026-02-12T19:34:04.3411448Z 02/12 19:31:40 - AISBench - INFO - Loading gsm8k_gen_0_shot_cot_chat_prompt: /vllm-workspace/vllm-ascend/benchmark/ais_bench/benchmark/configs/./datasets/gsm8k/gsm8k_gen_0_shot_cot_chat_prompt.py
2026-02-12T19:34:04.3421356Z 02/12 19:31:40 - AISBench - INFO - Loading vllm_api_general_chat_custom: /vllm-workspace/vllm-ascend/benchmark/ais_bench/benchmark/configs/./models/vllm_api/vllm_api_general_chat_custom.py
2026-02-12T19:34:04.3430737Z 02/12 19:31:40 - AISBench - INFO - Loading example: /vllm-workspace/vllm-ascend/benchmark/ais_bench/benchmark/configs/./summarizers/example.py
2026-02-12T19:34:04.3441252Z 02/12 19:31:40 - AISBench - INFO - Current exp folder: outputs/default/20260212_193140
2026-02-12T19:34:04.3449916Z 02/12 19:31:42 - AISBench - INFO - Starting inference tasks...
2026-02-12T19:34:04.3459603Z 02/12 19:31:42 - AISBench - INFO - Partitioned into 1 tasks.
2026-02-12T19:34:04.3470311Z 02/12 19:31:42 - AISBench - INFO - Continuous batch enable! All the logs and processes for each task should be checked in each infer/.out file.
2026-02-12T19:34:04.3479432Z Launch OpenICLInfer[vllm-api-general-chat/gsm8k] on CPU
2026-02-12T19:34:04.3488421Z Launch OpenICLInfer[vllm-api-general-chat/gsm8k] on CPU
2026-02-12T19:34:04.3497526Z 02/12 19:32:55 - AISBench - INFO - Inference tasks completed.
2026-02-12T19:34:04.3507169Z 02/12 19:32:57 - AISBench - INFO - Starting evaluation tasks...
2026-02-12T19:34:04.3516544Z 02/12 19:32:57 - AISBench - INFO - Partitioned into 1 tasks.
2026-02-12T19:34:04.3526037Z launch OpenICLEval[vllm-api-general-chat/gsm8k] on CPU
2026-02-12T19:34:04.3535422Z 02/12 19:33:07 - AISBench - INFO - Evaluation tasks completed.
2026-02-12T19:34:04.3544822Z 02/12 19:33:07 - AISBench - INFO - Summarizing evaluation results...
2026-02-12T19:34:04.3554322Z dataset    version    metric    mode      vllm-api-general-chat
2026-02-12T19:34:04.3564660Z ---------  ---------  --------  ------  -----------------------
2026-02-12T19:34:04.3574581Z gsm8k      7cd45e     accuracy  gen                        0.00
2026-02-12T19:34:04.3584072Z 02/12 19:33:07 - AISBench - INFO - write summary to /vllm-workspace/vllm-ascend/outputs/default/20260212_193140/summary/summary_20260212_193140.txt
2026-02-12T19:34:04.3593482Z 02/12 19:33:07 - AISBench - INFO - write csv to /vllm-workspace/vllm-ascend/outputs/default/20260212_193140/summary/summary_20260212_193140.csv
2026-02-12T19:34:04.3603354Z Accuracy verification failed. The accuracy of /root/.cache/modelscope/hub/datasets/vllm-ascend/gsm8k-lite is 0.0, which is not within 5 relative to baseline 95.
2026-02-12T19:34:04.3612850Z The request config is
2026-02-12T19:34:04.3621553Z  from ais_bench.benchmark.models import VLLMCustomAPIChatStream
2026-02-12T19:34:04.3631533Z from ais_bench.benchmark.utils.model_postprocessors import extract_non_reasoning_content
2026-02-12T19:34:04.3641510Z 
2026-02-12T19:34:04.3650424Z models = [
2026-02-12T19:34:04.3659164Z     dict(
2026-02-12T19:34:04.3668647Z         attr="service",
2026-02-12T19:34:04.3678181Z         type=VLLMCustomAPIChatStream,
2026-02-12T19:34:04.3687582Z         abbr='vllm-api-stream-chat',
2026-02-12T19:34:04.3697258Z         path="/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8",
2026-02-12T19:34:04.3706370Z         model="vllm-ascend/DeepSeek-V3.2-W8A8",
2026-02-12T19:34:04.3715309Z         request_rate = 11.2,
2026-02-12T19:34:04.3725391Z         retry = 2,
2026-02-12T19:34:04.3734104Z         host_ip = "10.0.0.210",
2026-02-12T19:34:04.3742941Z         host_port = 8080,
2026-02-12T19:34:04.3751879Z         max_out_len = 3000,
2026-02-12T19:34:04.3761608Z         batch_size = 512,
2026-02-12T19:34:04.3771427Z         trust_remote_code=False,
2026-02-12T19:34:04.3780466Z         generation_kwargs = dict(
2026-02-12T19:34:04.3789896Z             temperature = 0,
2026-02-12T19:34:04.3800193Z             ignore_eos = True,
2026-02-12T19:34:04.3808850Z             #top_k = 10,
2026-02-12T19:34:04.3817699Z             #top_p = 0.95,
2026-02-12T19:34:04.3826704Z             #seed = None,
2026-02-12T19:34:04.3836726Z             #repetition_penalty = 1.03,
2026-02-12T19:34:04.3846178Z         ),
2026-02-12T19:34:04.3855594Z         pred_postprocessor=dict(type=extract_non_reasoning_content)
2026-02-12T19:34:04.3864726Z     )
2026-02-12T19:34:04.3872988Z ]
2026-02-12T19:34:04.3881765Z 
2026-02-12T19:34:04.3892384Z running aisbench cmd: ais_bench --models vllm_api_stream_chat_custom --datasets gsm8k_gen_0_shot_cot_str_perf_custom --mode perf --num-prompts 512
2026-02-12T19:34:04.3901929Z 02/12 19:33:15 - AISBench - INFO - Loading gsm8k_gen_0_shot_cot_str_perf_custom: /vllm-workspace/vllm-ascend/benchmark/ais_bench/benchmark/configs/./datasets/gsm8k/gsm8k_gen_0_shot_cot_str_perf_custom.py
2026-02-12T19:34:04.3911453Z 02/12 19:33:15 - AISBench - INFO - Loading vllm_api_stream_chat_custom: /vllm-workspace/vllm-ascend/benchmark/ais_bench/benchmark/configs/./models/vllm_api/vllm_api_stream_chat_custom.py
2026-02-12T19:34:04.3921162Z 02/12 19:33:15 - AISBench - INFO - Loading example: /vllm-workspace/vllm-ascend/benchmark/ais_bench/benchmark/configs/./summarizers/example.py
2026-02-12T19:34:04.3931029Z 02/12 19:33:16 - AISBench - INFO - Current exp folder: outputs/default/20260212_193316
2026-02-12T19:34:04.3940241Z 02/12 19:33:16 - AISBench - INFO - Starting performance evaluation tasks...
2026-02-12T19:34:04.3949695Z 02/12 19:33:16 - AISBench - INFO - Partitioned into 1 tasks.
2026-02-12T19:34:04.3959951Z 02/12 19:33:16 - AISBench - INFO - Continuous batch enable! All the logs and processes for each task should be checked in each infer/.out file.
2026-02-12T19:34:04.3969373Z Launch OpenICLPerf[vllm-api-stream-chat/gsm8k] on CPU
2026-02-12T19:34:04.3978836Z Launch OpenICLPerf[vllm-api-stream-chat/gsm8k] on CPU
2026-02-12T19:34:04.3987931Z 02/12 19:34:04 - AISBench - INFO - Performance evaluation tasks completed.
2026-02-12T19:34:04.3997500Z 02/12 19:34:04 - AISBench - INFO - Loading detail perf data of model='vllm-api-stream-chat' dataset='gsm8kdataset' ...
2026-02-12T19:34:04.4007039Z 02/12 19:34:04 - AISBench - INFO - Starting request timeline processing...
2026-02-12T19:34:04.4017161Z 02/12 19:34:04 - AISBench - WARNING - [Non-streaming scenario] The plot will only show the request concurrency chart!
2026-02-12T19:34:04.4026419Z 02/12 19:34:04 - AISBench - INFO - Data preprocessing completed in 0.0002s
2026-02-12T19:34:04.4035666Z 02/12 19:34:04 - AISBench - INFO - Generating concurrency traces...
2026-02-12T19:34:04.4044673Z 02/12 19:34:04 - AISBench - WARNING - No valid requests for concurrency plot!
2026-02-12T19:34:04.4054792Z 02/12 19:34:04 - AISBench - INFO - Generated concurrency trace chunks in 0.0001s
2026-02-12T19:34:04.4064743Z 02/12 19:34:04 - AISBench - INFO - Creating figure layout...
2026-02-12T19:34:04.4073920Z 02/12 19:34:04 - AISBench - INFO - Figure layout created in 0.0175s
2026-02-12T19:34:04.4084765Z 02/12 19:34:04 - AISBench - INFO - Writing to outputs/default/20260212_193316/performances/vllm-api-stream-chat/gsm8kdataset_plot.html...
2026-02-12T19:34:04.4093707Z 02/12 19:34:04 - AISBench - INFO - HTML written in 0.0113s
2026-02-12T19:34:04.4103104Z 02/12 19:34:04 - AISBench - INFO - Completed! Total execution time: 0.0294s
2026-02-12T19:34:04.4113386Z 02/12 19:34:04 - AISBench - INFO - The gsm8kdataset_plot has been saved in outputs/default/20260212_193316/performances/vllm-api-stream-chat/gsm8kdataset_plot.html
2026-02-12T19:34:04.4124097Z 02/12 19:34:04 - AISBench - ERROR - /vllm-workspace/vllm-ascend/benchmark/ais_bench/benchmark/calculators/default_perf_metric_calculator.py - _init_datas - 21 - All requests failed, can't calculate performance results. Please check the ERROR log from every responses!
2026-02-12T19:34:04.4134930Z Some errors happened to Aisbench runtime, the first error is 02/12 19:34:04 - AISBench - ERROR - /vllm-workspace/vllm-ascend/benchmark/ais_bench/benchmark/calculators/default_perf_metric_calculator.py - _init_datas - 21 - All requests failed, can't calculate performance results. Please check the ERROR log from every responses!
2026-02-12T19:34:05.7819801Z FAILED
2026-02-12T19:34:05.7843339Z 
2026-02-12T19:34:05.7854795Z =================================== FAILURES ===================================
2026-02-12T19:34:05.7864579Z _______________________________ test_multi_node ________________________________
2026-02-12T19:34:05.7873631Z 
2026-02-12T19:34:05.7883485Z     @pytest.mark.asyncio
2026-02-12T19:34:05.7892624Z     async def test_multi_node() -> None:
2026-02-12T19:34:05.7901657Z         config = MultiNodeConfigLoader.from_yaml()
2026-02-12T19:34:05.7911610Z     
2026-02-12T19:34:05.7921315Z         with ProxyLauncher(
2026-02-12T19:34:05.7931236Z                 nodes=config.nodes,
2026-02-12T19:34:05.7940758Z                 disagg_cfg=config.disagg_cfg,
2026-02-12T19:34:05.7949773Z                 envs=config.envs,
2026-02-12T19:34:05.7960059Z                 proxy_port=config.proxy_port,
2026-02-12T19:34:05.7969441Z                 cur_index=config.cur_index,
2026-02-12T19:34:05.7979020Z         ) as proxy:
2026-02-12T19:34:05.7987551Z     
2026-02-12T19:34:05.7997587Z             with RemoteOpenAIServer(
2026-02-12T19:34:05.8007928Z                     model=config.model,
2026-02-12T19:34:05.8016945Z                     vllm_serve_args=config.server_cmd,
2026-02-12T19:34:05.8025899Z                     server_port=config.server_port,
2026-02-12T19:34:05.8035419Z                     server_host=config.master_ip,
2026-02-12T19:34:05.8045291Z                     env_dict=config.envs,
2026-02-12T19:34:05.8054666Z                     auto_port=False,
2026-02-12T19:34:05.8064224Z                     proxy_port=proxy.proxy_port,
2026-02-12T19:34:05.8073072Z                     disaggregated_prefill=config.disagg_cfg,
2026-02-12T19:34:05.8083130Z                     nodes_info=config.nodes,
2026-02-12T19:34:05.8092980Z                     max_wait_seconds=2800,
2026-02-12T19:34:05.8101892Z             ) as server:
2026-02-12T19:34:05.8110923Z     
2026-02-12T19:34:05.8120661Z                 host, port = config.benchmark_endpoint
2026-02-12T19:34:05.8129952Z     
2026-02-12T19:34:05.8139478Z                 if config.is_master:
2026-02-12T19:34:05.8187894Z >                   run_aisbench_cases(
2026-02-12T19:34:05.8188101Z                         model=config.model,
2026-02-12T19:34:05.8188405Z                         port=port,
2026-02-12T19:34:05.8188641Z                         aisbench_cases=[config.acc_cmd, config.perf_cmd],
2026-02-12T19:34:05.8188882Z                         host_ip=host,
2026-02-12T19:34:05.8199898Z                     )
2026-02-12T19:34:05.8209045Z 
2026-02-12T19:34:05.8218686Z tests/e2e/nightly/multi_node/scripts/test_multi_node.py:37: 
2026-02-12T19:34:05.8228044Z _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
2026-02-12T19:34:05.8237033Z 
2026-02-12T19:34:05.8246492Z model = 'vllm-ascend/DeepSeek-V3.2-W8A8', port = '8080'
2026-02-12T19:34:05.8256779Z aisbench_cases = [{'baseline': 95, 'batch_size': 64, 'case_type': 'accuracy', 'dataset_conf': 'gsm8k/gsm8k_gen_0_shot_cot_chat_prompt',... 1253.8466, 'batch_size': 512, 'case_type': 'performance', 'dataset_conf': 'gsm8k/gsm8k_gen_0_shot_cot_str_perf', ...}]
2026-02-12T19:34:05.8265719Z server_args = '', host_ip = '10.0.0.210'
2026-02-12T19:34:05.8274179Z 
2026-02-12T19:34:05.8284593Z     def run_aisbench_cases(model, port, aisbench_cases, server_args="", host_ip="localhost"):
2026-02-12T19:34:05.8293660Z         aisbench_results = []
2026-02-12T19:34:05.8302971Z         aisbench_errors = []
2026-02-12T19:34:05.8312664Z         for aisbench_case in aisbench_cases:
2026-02-12T19:34:05.8321730Z             if not aisbench_case:
2026-02-12T19:34:05.8330983Z                 continue
2026-02-12T19:34:05.8339906Z             try:
2026-02-12T19:34:05.8349580Z                 with AisbenchRunner(model=model, port=port, host_ip=host_ip, aisbench_config=aisbench_case) as aisbench:
2026-02-12T19:34:05.8359035Z                     aisbench_results.append(aisbench.result)
2026-02-12T19:34:05.8369610Z             except Exception as e:
2026-02-12T19:34:05.8381972Z                 aisbench_results.append("")
2026-02-12T19:34:05.8391730Z                 aisbench_errors.append([aisbench_case, e])
2026-02-12T19:34:05.8401764Z                 print(e)
2026-02-12T19:34:05.8412192Z         for failed_case, error_info in aisbench_errors:
2026-02-12T19:34:05.8421904Z             error_msg = f"The following aisbench case failed: {failed_case}, reason is {error_info}"
2026-02-12T19:34:05.8432689Z             if server_args:
2026-02-12T19:34:05.8442763Z                 error_msg += f"\nserver_args are {server_args}"
2026-02-12T19:34:05.8451950Z             logging.error(error_msg)
2026-02-12T19:34:05.8461736Z >       assert not aisbench_errors, "some aisbench cases failed, info were shown above."
2026-02-12T19:34:05.8470940Z                ^^^^^^^^^^^^^^^^^^^
2026-02-12T19:34:05.8521132Z E       AssertionError: some aisbench cases failed, info were shown above.
2026-02-12T19:34:05.8521348Z 
2026-02-12T19:34:05.8521428Z tools/aisbench.py:244: AssertionError
2026-02-12T19:34:05.8521658Z =============================== warnings summary ===============================
2026-02-12T19:34:05.8521894Z <frozen importlib._bootstrap>:241
2026-02-12T19:34:05.8530100Z   <frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyPacked has no __module__ attribute
2026-02-12T19:34:05.8538854Z 
2026-02-12T19:34:05.8548711Z <frozen importlib._bootstrap>:241
2026-02-12T19:34:05.8559086Z   <frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyObject has no __module__ attribute
2026-02-12T19:34:05.8568294Z 
2026-02-12T19:34:05.8578393Z ../../usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647
2026-02-12T19:34:05.8588716Z   /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-12T19:34:05.8597326Z     warnings.warn(
2026-02-12T19:34:05.8606988Z 
2026-02-12T19:34:05.8616556Z ../../usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/__init__.py:8
2026-02-12T19:34:05.8627469Z   /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/__init__.py:8: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html
2026-02-12T19:34:05.8635841Z     import pkg_resources
2026-02-12T19:34:05.8645572Z 
2026-02-12T19:34:05.8655649Z tests/e2e/nightly/multi_node/scripts/test_multi_node.py::test_multi_node
2026-02-12T19:34:05.8665251Z   /usr/local/python3.11.14/lib/python3.11/site-packages/pandas/core/dtypes/cast.py:1641: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.
2026-02-12T19:34:05.8674678Z   See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)
2026-02-12T19:34:05.8684675Z     return np.find_common_type(types, [])
2026-02-12T19:34:05.8694260Z 
2026-02-12T19:34:05.8704270Z -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
2026-02-12T19:34:05.8713360Z =========================== short test summary info ============================
2026-02-12T19:34:05.8723041Z FAILED tests/e2e/nightly/multi_node/scripts/test_multi_node.py::test_multi_node
2026-02-12T19:34:05.8732749Z ================== 1 failed, 5 warnings in 819.17s (0:13:39) ===================
2026-02-12T19:34:06.0607698Z sys:1: DeprecationWarning: builtin type swigvarlink has no __module__ attribute
2026-02-12T19:34:07.4601798Z [0;31mFAIL_TAG_DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml âœ— ERROR: Some tests failed, please check the error stack above for details. If this is insufficient to pinpoint the error, please download and review the logs of all other nodes from the job's summary.[0m
2026-02-12T19:34:07.6957478Z Cleaning up background log streams...
2026-02-12T19:34:07.7624271Z ##[error]Error: failed to run script step: Error: command terminated with non-zero exit code: command terminated with exit code 1
2026-02-12T19:34:07.7664024Z ##[error]Process completed with exit code 1.
2026-02-12T19:34:07.7753734Z ##[error]Executing the custom container implementation failed. Please contact your self hosted runner administrator.
2026-02-12T19:34:07.8148155Z ##[group]Run actions/upload-artifact@v6
2026-02-12T19:34:07.8148357Z with:
2026-02-12T19:34:07.8148553Z   name: DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml-pod-logs
2026-02-12T19:34:07.8148810Z   path: /tmp/vllm*_logs.txt
2026-02-12T19:34:07.8148981Z   retention-days: 7
2026-02-12T19:34:07.8149140Z   if-no-files-found: warn
2026-02-12T19:34:07.8149307Z   compression-level: 6
2026-02-12T19:34:07.8149466Z   overwrite: false
2026-02-12T19:34:07.8149626Z   include-hidden-files: false
2026-02-12T19:34:07.8149792Z env:
2026-02-12T19:34:07.8149975Z   FAIL_TAG: FAIL_TAG_DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-02-12T19:34:07.8150192Z ##[endgroup]
2026-02-12T19:34:07.8173564Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-12T19:34:07.8174259Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-12T19:34:07.8174502Z ##[endgroup]
2026-02-12T19:34:08.1657754Z (node:952) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-12T19:34:08.1658433Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-12T19:34:09.1770030Z With the provided path, there will be 1 file uploaded
2026-02-12T19:34:09.1770834Z Artifact name is valid!
2026-02-12T19:34:09.1771021Z Root directory input is valid!
2026-02-12T19:34:10.4633904Z Beginning upload of artifact content to blob storage
2026-02-12T19:34:12.3029864Z Uploaded bytes 13525
2026-02-12T19:34:12.5707506Z Finished uploading artifact content to blob storage!
2026-02-12T19:34:12.5707955Z SHA256 digest of uploaded artifact zip is b4037a866895f393789da0f460f3d7a0ca72d8fa6ccca3ca0f4ed30944481aa4
2026-02-12T19:34:12.5708332Z Finalizing artifact upload
2026-02-12T19:34:13.5303204Z Artifact DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml-pod-logs.zip successfully finalized. Artifact ID 5488678150
2026-02-12T19:34:13.5303870Z Artifact DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml-pod-logs has been successfully uploaded! Final size is 13525 bytes. Artifact ID is 5488678150
2026-02-12T19:34:13.5308634Z Artifact download URL: https://github.com/vllm-project/vllm-ascend/actions/runs/21955633637/artifacts/5488678150
2026-02-12T19:34:14.0149253Z ##[group]Run kubectl get pods -n "$NAMESPACE" --ignore-not-found=true
2026-02-12T19:34:14.0149640Z [36;1mkubectl get pods -n "$NAMESPACE" --ignore-not-found=true[0m
2026-02-12T19:34:14.0149967Z [36;1mkubectl delete -f ./lws.yaml --ignore-not-found=true || true[0m
2026-02-12T19:34:14.0150294Z shell: bash -el {0}
2026-02-12T19:34:14.0150447Z env:
2026-02-12T19:34:14.0150645Z   FAIL_TAG: FAIL_TAG_DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-02-12T19:34:14.0150879Z ##[endgroup]
2026-02-12T19:34:14.0235675Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-12T19:34:14.0236422Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-12T19:34:14.0236640Z ##[endgroup]
2026-02-12T19:34:14.3750046Z (node:1067) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-12T19:34:14.3750714Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-12T19:34:15.0884612Z NAME                                             READY   STATUS    RESTARTS      AGE
2026-02-12T19:34:15.0885058Z linux-aarch64-a3-0-n4cwm-runner-v5b2h            1/1     Running   0             15m
2026-02-12T19:34:15.0885487Z linux-aarch64-a3-0-n4cwm-runner-v5b2h-workflow   1/1     Running   0             15m
2026-02-12T19:34:15.0885843Z vllm-0                                           1/1     Running   1 (8s ago)    14m
2026-02-12T19:34:15.0886131Z vllm-0-1                                         1/1     Running   1 (85s ago)   14m
2026-02-12T19:34:15.1504575Z leaderworkerset.leaderworkerset.x-k8s.io "vllm" deleted from vllm-project namespace
2026-02-12T19:34:15.1644786Z service "vllm-leader" deleted from vllm-project namespace
2026-02-12T19:34:15.6287003Z Post job cleanup.
2026-02-12T19:34:15.6307102Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-12T19:34:15.6307761Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-12T19:34:15.6307982Z ##[endgroup]
2026-02-12T19:34:16.0238003Z (node:1195) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-12T19:34:16.0238663Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-12T19:34:16.6527735Z [command]/usr/bin/git version
2026-02-12T19:34:16.6703164Z git version 2.34.1
2026-02-12T19:34:16.6734263Z Copying '/root/.gitconfig' to '/__w/_temp/b5ac4ae2-665c-4e8d-911f-5142033ee0c4/.gitconfig'
2026-02-12T19:34:16.6744141Z Temporarily overriding HOME='/__w/_temp/b5ac4ae2-665c-4e8d-911f-5142033ee0c4' before making global git config changes
2026-02-12T19:34:16.6744697Z Adding repository directory to the temporary git global config as a safe directory
2026-02-12T19:34:16.6748948Z [command]/usr/bin/git config --global --add safe.directory /__w/vllm-ascend/vllm-ascend
2026-02-12T19:34:16.6788176Z Removing SSH command configuration
2026-02-12T19:34:16.6792955Z [command]/usr/bin/git config --local --name-only --get-regexp core\.sshCommand
2026-02-12T19:34:16.6848116Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'core\.sshCommand' && git config --local --unset-all 'core.sshCommand' || :"
2026-02-12T19:34:16.7350594Z Removing HTTP extra header
2026-02-12T19:34:16.7353584Z [command]/usr/bin/git config --local --name-only --get-regexp http\.https\:\/\/github\.com\/\.extraheader
2026-02-12T19:34:16.7379643Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'http\.https\:\/\/github\.com\/\.extraheader' && git config --local --unset-all 'http.https://github.com/.extraheader' || :"
2026-02-12T19:34:16.7557908Z Removing includeIf entries pointing to credentials config files
2026-02-12T19:34:16.7562904Z [command]/usr/bin/git config --local --name-only --get-regexp ^includeIf\.gitdir:
2026-02-12T19:34:16.7610342Z includeif.gitdir:/__w/vllm-ascend/vllm-ascend/.git.path
2026-02-12T19:34:16.7610765Z includeif.gitdir:/__w/vllm-ascend/vllm-ascend/.git/worktrees/*.path
2026-02-12T19:34:16.7620142Z includeif.gitdir:/github/workspace/.git.path
2026-02-12T19:34:16.7628410Z includeif.gitdir:/github/workspace/.git/worktrees/*.path
2026-02-12T19:34:16.7640429Z [command]/usr/bin/git config --local --get-all includeif.gitdir:/__w/vllm-ascend/vllm-ascend/.git.path
2026-02-12T19:34:16.7641000Z /__w/_temp/git-credentials-15532928-7e63-408c-ae6b-fbd2a5fd33f0.config
2026-02-12T19:34:16.7642068Z [command]/usr/bin/git config --local --unset includeif.gitdir:/__w/vllm-ascend/vllm-ascend/.git.path /__w/_temp/git-credentials-15532928-7e63-408c-ae6b-fbd2a5fd33f0.config
2026-02-12T19:34:16.7645399Z [command]/usr/bin/git config --local --get-all includeif.gitdir:/__w/vllm-ascend/vllm-ascend/.git/worktrees/*.path
2026-02-12T19:34:16.7662463Z /__w/_temp/git-credentials-15532928-7e63-408c-ae6b-fbd2a5fd33f0.config
2026-02-12T19:34:16.7669149Z [command]/usr/bin/git config --local --unset includeif.gitdir:/__w/vllm-ascend/vllm-ascend/.git/worktrees/*.path /__w/_temp/git-credentials-15532928-7e63-408c-ae6b-fbd2a5fd33f0.config
2026-02-12T19:34:16.7695054Z [command]/usr/bin/git config --local --get-all includeif.gitdir:/github/workspace/.git.path
2026-02-12T19:34:16.7711864Z /github/runner_temp/git-credentials-15532928-7e63-408c-ae6b-fbd2a5fd33f0.config
2026-02-12T19:34:16.7718978Z [command]/usr/bin/git config --local --unset includeif.gitdir:/github/workspace/.git.path /github/runner_temp/git-credentials-15532928-7e63-408c-ae6b-fbd2a5fd33f0.config
2026-02-12T19:34:16.7744082Z [command]/usr/bin/git config --local --get-all includeif.gitdir:/github/workspace/.git/worktrees/*.path
2026-02-12T19:34:16.7761355Z /github/runner_temp/git-credentials-15532928-7e63-408c-ae6b-fbd2a5fd33f0.config
2026-02-12T19:34:16.7767892Z [command]/usr/bin/git config --local --unset includeif.gitdir:/github/workspace/.git/worktrees/*.path /github/runner_temp/git-credentials-15532928-7e63-408c-ae6b-fbd2a5fd33f0.config
2026-02-12T19:34:16.7794117Z [command]/usr/bin/git submodule foreach --recursive git config --local --show-origin --name-only --get-regexp remote.origin.url
2026-02-12T19:34:16.7971085Z Removing credentials config '/__w/_temp/git-credentials-15532928-7e63-408c-ae6b-fbd2a5fd33f0.config'
2026-02-12T19:34:35.1993102Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-12T19:34:35.1993870Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-12T19:34:35.1994104Z ##[endgroup]
2026-02-12T19:34:35.6238900Z Cleaning up orphan processes
