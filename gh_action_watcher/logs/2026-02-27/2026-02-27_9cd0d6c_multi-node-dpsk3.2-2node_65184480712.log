# Run ID: 22494469024
# Commit: 9cd0d6c33d2ef5cb9b6ce20b1ca047e55ab23a12
# Job: multi-node (multi-node-dpsk3.2-2node, DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml, 2) / DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
# Date: 2026-02-27
============================================================

ï»¿2026-02-27T19:09:38.6888170Z Current runner version: '2.330.0'
2026-02-27T19:09:38.6892948Z Runner name: 'linux-aarch64-a3-0-n4cwm-runner-csk5w'
2026-02-27T19:09:38.6893748Z Runner group name: 'Default'
2026-02-27T19:09:38.6894496Z Machine name: 'linux-aarch64-a3-0-n4cwm-runner-csk5w'
2026-02-27T19:09:38.6897772Z ##[group]GITHUB_TOKEN Permissions
2026-02-27T19:09:38.6899596Z Actions: write
2026-02-27T19:09:38.6900046Z ArtifactMetadata: write
2026-02-27T19:09:38.6900445Z Attestations: write
2026-02-27T19:09:38.6901049Z Checks: write
2026-02-27T19:09:38.6901446Z Contents: write
2026-02-27T19:09:38.6901807Z Deployments: write
2026-02-27T19:09:38.6902442Z Discussions: write
2026-02-27T19:09:38.6902845Z Issues: write
2026-02-27T19:09:38.6903191Z Metadata: read
2026-02-27T19:09:38.6903578Z Models: read
2026-02-27T19:09:38.6903913Z Packages: write
2026-02-27T19:09:38.6904314Z Pages: write
2026-02-27T19:09:38.6904692Z PullRequests: write
2026-02-27T19:09:38.6905062Z RepositoryProjects: write
2026-02-27T19:09:38.6905640Z SecurityEvents: write
2026-02-27T19:09:38.6906082Z Statuses: write
2026-02-27T19:09:38.6906467Z ##[endgroup]
2026-02-27T19:09:38.6908199Z Secret source: Actions
2026-02-27T19:09:38.6908707Z Prepare workflow directory
2026-02-27T19:09:38.7622352Z Prepare all required actions
2026-02-27T19:09:38.7655157Z Getting action download info
2026-02-27T19:09:40.0847341Z Download action repository 'actions/checkout@v6' (SHA:de0fac2e4500dabe0009e67214ff5f5447ce83dd)
2026-02-27T19:09:44.7637824Z Download action repository 'actions/upload-artifact@v6' (SHA:b7c566a772e6b6bfb58ed0dc250532a479d7789f)
2026-02-27T19:09:53.3220732Z Uses: vllm-project/vllm-ascend/.github/workflows/_e2e_nightly_multi_node.yaml@refs/heads/main (9cd0d6c33d2ef5cb9b6ce20b1ca047e55ab23a12)
2026-02-27T19:09:53.3224253Z ##[group] Inputs
2026-02-27T19:09:53.3224650Z   soc_version: a3
2026-02-27T19:09:53.3225040Z   runner: linux-aarch64-a3-0
2026-02-27T19:09:53.3225461Z   image: swr.cn-southwest-2.myhuaweicloud.com/base_image/ascend-ci/vllm-ascend:nightly-a3
2026-02-27T19:09:53.3225931Z   config_file_path: DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-02-27T19:09:53.3226236Z   replicas: 1
2026-02-27T19:09:53.3226438Z   size: 2
2026-02-27T19:09:53.3226651Z   vllm_version: v0.16.0
2026-02-27T19:09:53.3227011Z   vllm_ascend_remote_url: https://github.com/vllm-project/vllm-ascend.git
2026-02-27T19:09:53.3227368Z   vllm_ascend_ref: main
2026-02-27T19:09:53.3227617Z ##[endgroup]
2026-02-27T19:09:53.3228114Z Complete job name: multi-node (multi-node-dpsk3.2-2node, DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml, 2) / DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-02-27T19:09:53.3731578Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-27T19:09:53.3734429Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-27T19:09:53.3734989Z ##[endgroup]
2026-02-27T19:10:08.9247791Z (node:71) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-27T19:10:08.9248775Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-27T19:10:10.9455516Z ##[group]Run # Decode and save kubeconfig
2026-02-27T19:10:10.9455942Z [36;1m# Decode and save kubeconfig[0m
2026-02-27T19:10:10.9488873Z [36;1mecho "***" | base64 -d > "$KUBECONFIG"[0m
2026-02-27T19:10:10.9489399Z shell: bash -el {0}
2026-02-27T19:10:10.9489721Z ##[endgroup]
2026-02-27T19:10:10.9624348Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-27T19:10:10.9625214Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-27T19:10:10.9625527Z ##[endgroup]
2026-02-27T19:10:11.3367803Z (node:402) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-27T19:10:11.3368676Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-27T19:10:12.2386138Z ##[group]Run actions/checkout@v6
2026-02-27T19:10:12.2386553Z with:
2026-02-27T19:10:12.2386831Z   repository: vllm-project/vllm-ascend
2026-02-27T19:10:12.2387502Z   token: ***
2026-02-27T19:10:12.2387852Z   ssh-strict: true
2026-02-27T19:10:12.2388085Z   ssh-user: git
2026-02-27T19:10:12.2388290Z   persist-credentials: true
2026-02-27T19:10:12.2388546Z   clean: true
2026-02-27T19:10:12.2388792Z   sparse-checkout-cone-mode: true
2026-02-27T19:10:12.2389042Z   fetch-depth: 1
2026-02-27T19:10:12.2389289Z   fetch-tags: false
2026-02-27T19:10:12.2389514Z   show-progress: true
2026-02-27T19:10:12.2389715Z   lfs: false
2026-02-27T19:10:12.2389936Z   submodules: false
2026-02-27T19:10:12.2390273Z   set-safe-directory: true
2026-02-27T19:10:12.2390530Z ##[endgroup]
2026-02-27T19:10:12.2435262Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-27T19:10:12.2436190Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-27T19:10:12.2436489Z ##[endgroup]
2026-02-27T19:10:12.6114635Z (node:432) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-27T19:10:12.6115443Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-27T19:10:13.4715877Z Syncing repository: vllm-project/vllm-ascend
2026-02-27T19:10:13.4717091Z ##[group]Getting Git version info
2026-02-27T19:10:13.4717439Z Working directory is '/__w/vllm-ascend/vllm-ascend'
2026-02-27T19:10:13.4717945Z [command]/usr/bin/git version
2026-02-27T19:10:13.4862516Z git version 2.34.1
2026-02-27T19:10:13.4878663Z ##[endgroup]
2026-02-27T19:10:13.4886025Z Copying '/root/.gitconfig' to '/__w/_temp/aa11146e-29e6-43ac-b5b9-7e3264be3622/.gitconfig'
2026-02-27T19:10:13.4897020Z Temporarily overriding HOME='/__w/_temp/aa11146e-29e6-43ac-b5b9-7e3264be3622' before making global git config changes
2026-02-27T19:10:13.4897646Z Adding repository directory to the temporary git global config as a safe directory
2026-02-27T19:10:13.4900573Z [command]/usr/bin/git config --global --add safe.directory /__w/vllm-ascend/vllm-ascend
2026-02-27T19:10:13.4936936Z Deleting the contents of '/__w/vllm-ascend/vllm-ascend'
2026-02-27T19:10:13.4939462Z ##[group]Initializing the repository
2026-02-27T19:10:13.4942934Z [command]/usr/bin/git init /__w/vllm-ascend/vllm-ascend
2026-02-27T19:10:13.5064869Z hint: Using 'master' as the name for the initial branch. This default branch name
2026-02-27T19:10:13.5065452Z hint: is subject to change. To configure the initial branch name to use in all
2026-02-27T19:10:13.5065938Z hint: of your new repositories, which will suppress this warning, call:
2026-02-27T19:10:13.5066254Z hint: 
2026-02-27T19:10:13.5066598Z hint: 	git config --global init.defaultBranch <name>
2026-02-27T19:10:13.5066921Z hint: 
2026-02-27T19:10:13.5067177Z hint: Names commonly chosen instead of 'master' are 'main', 'trunk' and
2026-02-27T19:10:13.5067678Z hint: 'development'. The just-created branch can be renamed via this command:
2026-02-27T19:10:13.5068049Z hint: 
2026-02-27T19:10:13.5068242Z hint: 	git branch -m <name>
2026-02-27T19:10:13.5075146Z Initialized empty Git repository in /__w/vllm-ascend/vllm-ascend/.git/
2026-02-27T19:10:13.5082891Z [command]/usr/bin/git remote add origin https://github.com/vllm-project/vllm-ascend
2026-02-27T19:10:13.5131505Z ##[endgroup]
2026-02-27T19:10:13.5131919Z ##[group]Disabling automatic garbage collection
2026-02-27T19:10:13.5134515Z [command]/usr/bin/git config --local gc.auto 0
2026-02-27T19:10:13.5162216Z ##[endgroup]
2026-02-27T19:10:13.5162599Z ##[group]Setting up auth
2026-02-27T19:10:13.5163594Z Removing SSH command configuration
2026-02-27T19:10:13.5168279Z [command]/usr/bin/git config --local --name-only --get-regexp core\.sshCommand
2026-02-27T19:10:13.5221003Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'core\.sshCommand' && git config --local --unset-all 'core.sshCommand' || :"
2026-02-27T19:10:13.5602157Z Removing HTTP extra header
2026-02-27T19:10:13.5603122Z [command]/usr/bin/git config --local --name-only --get-regexp http\.https\:\/\/github\.com\/\.extraheader
2026-02-27T19:10:13.5629409Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'http\.https\:\/\/github\.com\/\.extraheader' && git config --local --unset-all 'http.https://github.com/.extraheader' || :"
2026-02-27T19:10:13.5803958Z Removing includeIf entries pointing to credentials config files
2026-02-27T19:10:13.5807642Z [command]/usr/bin/git config --local --name-only --get-regexp ^includeIf\.gitdir:
2026-02-27T19:10:13.5832488Z [command]/usr/bin/git submodule foreach --recursive git config --local --show-origin --name-only --get-regexp remote.origin.url
2026-02-27T19:10:13.6013753Z [command]/usr/bin/git config --file /__w/_temp/git-credentials-8a7ecfc3-d443-4242-b915-6e36658e5f2b.config http.https://github.com/.extraheader AUTHORIZATION: basic ***
2026-02-27T19:10:13.6056867Z [command]/usr/bin/git config --local includeIf.gitdir:/__w/vllm-ascend/vllm-ascend/.git.path /__w/_temp/git-credentials-8a7ecfc3-d443-4242-b915-6e36658e5f2b.config
2026-02-27T19:10:13.6078932Z [command]/usr/bin/git config --local includeIf.gitdir:/__w/vllm-ascend/vllm-ascend/.git/worktrees/*.path /__w/_temp/git-credentials-8a7ecfc3-d443-4242-b915-6e36658e5f2b.config
2026-02-27T19:10:13.6105473Z [command]/usr/bin/git config --local includeIf.gitdir:/github/workspace/.git.path /github/runner_temp/git-credentials-8a7ecfc3-d443-4242-b915-6e36658e5f2b.config
2026-02-27T19:10:13.6135298Z [command]/usr/bin/git config --local includeIf.gitdir:/github/workspace/.git/worktrees/*.path /github/runner_temp/git-credentials-8a7ecfc3-d443-4242-b915-6e36658e5f2b.config
2026-02-27T19:10:13.6158137Z ##[endgroup]
2026-02-27T19:10:13.6158504Z ##[group]Fetching the repository
2026-02-27T19:10:13.6165626Z [command]/usr/bin/git -c protocol.version=2 fetch --no-tags --prune --no-recurse-submodules --depth=1 origin +9cd0d6c33d2ef5cb9b6ce20b1ca047e55ab23a12:refs/remotes/origin/main
2026-02-27T19:10:15.4962459Z From https://gh-proxy.test.osinfra.cn/https://github.com/vllm-project/vllm-ascend
2026-02-27T19:10:15.4963086Z  * [new ref]         9cd0d6c33d2ef5cb9b6ce20b1ca047e55ab23a12 -> origin/main
2026-02-27T19:10:15.4981045Z [command]/usr/bin/git branch --list --remote origin/main
2026-02-27T19:10:15.5002288Z   origin/main
2026-02-27T19:10:15.5008046Z [command]/usr/bin/git rev-parse refs/remotes/origin/main
2026-02-27T19:10:15.5028431Z 9cd0d6c33d2ef5cb9b6ce20b1ca047e55ab23a12
2026-02-27T19:10:15.5032433Z ##[endgroup]
2026-02-27T19:10:15.5032711Z ##[group]Determining the checkout info
2026-02-27T19:10:15.5033710Z ##[endgroup]
2026-02-27T19:10:15.5036693Z [command]/usr/bin/git sparse-checkout disable
2026-02-27T19:10:15.5103773Z [command]/usr/bin/git config --local --unset-all extensions.worktreeConfig
2026-02-27T19:10:15.5141394Z ##[group]Checking out the ref
2026-02-27T19:10:15.5141808Z [command]/usr/bin/git checkout --progress --force -B main refs/remotes/origin/main
2026-02-27T19:10:15.6011395Z Switched to a new branch 'main'
2026-02-27T19:10:15.6011739Z Branch 'main' set up to track remote branch 'main' from 'origin'.
2026-02-27T19:10:15.6021157Z ##[endgroup]
2026-02-27T19:10:15.6059964Z [command]/usr/bin/git log -1 --format=%H
2026-02-27T19:10:15.6083249Z 9cd0d6c33d2ef5cb9b6ce20b1ca047e55ab23a12
2026-02-27T19:10:16.0448602Z ##[group]Run # prepare for lws entrypoint scripts
2026-02-27T19:10:16.0448913Z [36;1m# prepare for lws entrypoint scripts[0m
2026-02-27T19:10:16.0449259Z [36;1minstall -D tests/e2e/nightly/multi_node/scripts/run.sh /root/.cache/tests/run.sh[0m
2026-02-27T19:10:16.0449696Z shell: bash -el {0}
2026-02-27T19:10:16.0449852Z ##[endgroup]
2026-02-27T19:10:16.0534610Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-27T19:10:16.0535314Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-27T19:10:16.0535568Z ##[endgroup]
2026-02-27T19:10:16.4498897Z (node:473) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-27T19:10:16.4499687Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-27T19:10:17.3398141Z ##[group]Run set -euo pipefail
2026-02-27T19:10:17.3398420Z [36;1mset -euo pipefail[0m
2026-02-27T19:10:17.3398591Z [36;1m[0m
2026-02-27T19:10:17.3398734Z [36;1mCRD_NAME="${CRD_NAME:-vllm}"[0m
2026-02-27T19:10:17.3398938Z [36;1mTIMEOUT=${TIMEOUT:-120}[0m
2026-02-27T19:10:17.3399127Z [36;1mSLEEP_INTERVAL=2[0m
2026-02-27T19:10:17.3399288Z [36;1m[0m
2026-02-27T19:10:17.3399535Z [36;1mecho "Deleting leaderworkerset [$CRD_NAME] in namespace [$NAMESPACE]..."[0m
2026-02-27T19:10:17.3399962Z [36;1mkubectl delete leaderworkerset "$CRD_NAME" -n "$NAMESPACE" --ignore-not-found[0m
2026-02-27T19:10:17.3400279Z [36;1m[0m
2026-02-27T19:10:17.3400494Z [36;1mecho "Waiting for all pods starting with 'vllm' to be deleted..."[0m
2026-02-27T19:10:17.3400767Z [36;1mSTART_TIME=$(date +%s)[0m
2026-02-27T19:10:17.3400942Z [36;1m[0m
2026-02-27T19:10:17.3401079Z [36;1mwhile true; do[0m
2026-02-27T19:10:17.3401240Z [36;1m  NOW=$(date +%s)[0m
2026-02-27T19:10:17.3401551Z [36;1m  ELAPSED=$((NOW - START_TIME))[0m
2026-02-27T19:10:17.3401747Z [36;1m[0m
2026-02-27T19:10:17.3401911Z [36;1m  if [[ $ELAPSED -ge $TIMEOUT ]]; then[0m
2026-02-27T19:10:17.3402315Z [36;1m    echo "Timeout reached ($TIMEOUT seconds), some pods still exist:"[0m
2026-02-27T19:10:17.3402649Z [36;1m    kubectl get pods -n "$NAMESPACE" | grep '^vllm' || true[0m
2026-02-27T19:10:17.3402896Z [36;1m    exit 1[0m
2026-02-27T19:10:17.3403048Z [36;1m  fi[0m
2026-02-27T19:10:17.3403181Z [36;1m[0m
2026-02-27T19:10:17.3403566Z [36;1m  PODS_EXIST=$(kubectl get pods -n "$NAMESPACE" -o jsonpath='{.items[*].metadata.name}' 2>/dev/null | tr ' ' '\n' | grep '^vllm' || true)[0m
2026-02-27T19:10:17.3403984Z [36;1m[0m
2026-02-27T19:10:17.3404171Z [36;1m  if [[ -z "$PODS_EXIST" ]]; then[0m
2026-02-27T19:10:17.3404388Z [36;1m    echo "All vllm pods deleted."[0m
2026-02-27T19:10:17.3404568Z [36;1m    break[0m
2026-02-27T19:10:17.3404714Z [36;1m  else[0m
2026-02-27T19:10:17.3404920Z [36;1m    echo "Waiting for pods to be deleted: $PODS_EXIST"[0m
2026-02-27T19:10:17.3405158Z [36;1m    sleep $SLEEP_INTERVAL[0m
2026-02-27T19:10:17.3405336Z [36;1m  fi[0m
2026-02-27T19:10:17.3405471Z [36;1mdone[0m
2026-02-27T19:10:17.3405765Z shell: bash -el {0}
2026-02-27T19:10:17.3405914Z ##[endgroup]
2026-02-27T19:10:17.3490502Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-27T19:10:17.3491352Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-27T19:10:17.3491679Z ##[endgroup]
2026-02-27T19:10:17.7105836Z (node:527) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-27T19:10:17.7106522Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-27T19:10:18.1973912Z Deleting leaderworkerset [vllm] in namespace [vllm-project]...
2026-02-27T19:10:18.5018736Z Waiting for all pods starting with 'vllm' to be deleted...
2026-02-27T19:10:18.6089525Z All vllm pods deleted.
2026-02-27T19:10:19.0083128Z ##[group]Run set -e
2026-02-27T19:10:19.0083362Z [36;1mset -e[0m
2026-02-27T19:10:19.0083511Z [36;1m[0m
2026-02-27T19:10:19.0083639Z [36;1msize="2"[0m
2026-02-27T19:10:19.0083789Z [36;1mreplicas="1"[0m
2026-02-27T19:10:19.0084121Z [36;1mimage="swr.cn-southwest-2.myhuaweicloud.com/base_image/ascend-ci/vllm-ascend:nightly-a3"[0m
2026-02-27T19:10:19.0084547Z [36;1mconfig_file_path="DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml"[0m
2026-02-27T19:10:19.0084866Z [36;1mfail_tag=FAIL_TAG_"DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml"[0m
2026-02-27T19:10:19.0085151Z [36;1mecho "FAIL_TAG=${fail_tag}" >> "$GITHUB_ENV"[0m
2026-02-27T19:10:19.0085352Z [36;1m[0m
2026-02-27T19:10:19.0085565Z [36;1mrequired_params=("size" "replicas" "image" "config_file_path")[0m
2026-02-27T19:10:19.0085863Z [36;1mfor param in "${required_params[@]}"; do[0m
2026-02-27T19:10:19.0086077Z [36;1m  if [ -z "${!param}" ]; then[0m
2026-02-27T19:10:19.0086547Z [36;1m    echo "Error: Parameter '$param' is required but empty"[0m
2026-02-27T19:10:19.0086784Z [36;1m    exit 1[0m
2026-02-27T19:10:19.0086950Z [36;1m  fi[0m
2026-02-27T19:10:19.0087091Z [36;1mdone[0m
2026-02-27T19:10:19.0087218Z [36;1m[0m
2026-02-27T19:10:19.0087358Z [36;1mif [ "a3" = "a3" ]; then[0m
2026-02-27T19:10:19.0087535Z [36;1m  npu_per_node=16[0m
2026-02-27T19:10:19.0087807Z [36;1m  TEMPLATE_FILE="tests/e2e/nightly/multi_node/scripts/lws.yaml.jinja2"[0m
2026-02-27T19:10:19.0088084Z [36;1melse[0m
2026-02-27T19:10:19.0088220Z [36;1m  npu_per_node=8[0m
2026-02-27T19:10:19.0088484Z [36;1m  TEMPLATE_FILE="tests/e2e/nightly/multi_node/scripts/lws-a2.yaml.jinja2"[0m
2026-02-27T19:10:19.0088772Z [36;1mfi[0m
2026-02-27T19:10:19.0088896Z [36;1m[0m
2026-02-27T19:10:19.0089040Z [36;1mjinja2 $TEMPLATE_FILE \[0m
2026-02-27T19:10:19.0089227Z [36;1m  -D size="$size" \[0m
2026-02-27T19:10:19.0089407Z [36;1m  -D replicas="$replicas" \[0m
2026-02-27T19:10:19.0089599Z [36;1m  -D image="$image" \[0m
2026-02-27T19:10:19.0089807Z [36;1m  -D config_file_path="$config_file_path" \[0m
2026-02-27T19:10:19.0090043Z [36;1m  -D npu_per_node="$npu_per_node" \[0m
2026-02-27T19:10:19.0090248Z [36;1m  -D fail_tag="$fail_tag" \[0m
2026-02-27T19:10:19.0090428Z [36;1m  --outfile lws.yaml[0m
2026-02-27T19:10:19.0090594Z [36;1m[0m
2026-02-27T19:10:19.0090732Z [36;1mkubectl apply -f ./lws.yaml[0m
2026-02-27T19:10:19.0091050Z shell: bash -el {0}
2026-02-27T19:10:19.0091201Z ##[endgroup]
2026-02-27T19:10:19.0171426Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-27T19:10:19.0172476Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-27T19:10:19.0172693Z ##[endgroup]
2026-02-27T19:10:19.3919495Z (node:593) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-27T19:10:19.3920192Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-27T19:10:20.3911199Z leaderworkerset.leaderworkerset.x-k8s.io/vllm created
2026-02-27T19:10:20.4832925Z service/vllm-leader created
2026-02-27T19:10:20.9729501Z ##[group]Run POD_PREFIX="${POD_PREFIX:-vllm-0}"
2026-02-27T19:10:20.9729832Z [36;1mPOD_PREFIX="${POD_PREFIX:-vllm-0}"[0m
2026-02-27T19:10:20.9730033Z [36;1mSIZE="2"[0m
2026-02-27T19:10:20.9730216Z [36;1mTIMEOUT=1200  # default timeout 20 minutes[0m
2026-02-27T19:10:20.9730431Z [36;1m[0m
2026-02-27T19:10:20.9730734Z [36;1mecho "Waiting for Pods in namespace [$NAMESPACE] to become Running and Ready (timeout ${TIMEOUT}s)..."[0m
2026-02-27T19:10:20.9731098Z [36;1m[0m
2026-02-27T19:10:20.9731243Z [36;1mSTART_TIME=$(date +%s)[0m
2026-02-27T19:10:20.9731411Z [36;1m[0m
2026-02-27T19:10:20.9731550Z [36;1mwhile true; do[0m
2026-02-27T19:10:20.9731709Z [36;1m  NOW=$(date +%s)[0m
2026-02-27T19:10:20.9731901Z [36;1m  ELAPSED=$((NOW - START_TIME))[0m
2026-02-27T19:10:20.9732346Z [36;1m  if [[ $ELAPSED -ge $TIMEOUT ]]; then[0m
2026-02-27T19:10:20.9732672Z [36;1m    echo "Timeout reached after ${ELAPSED}s"[0m
2026-02-27T19:10:20.9732962Z [36;1m    echo "Dumping pod status for debugging:"[0m
2026-02-27T19:10:20.9733198Z [36;1m    kubectl get pods -n "$NAMESPACE"[0m
2026-02-27T19:10:20.9733465Z [36;1m    kubectl describe pod "$LEADER_POD" -n "$NAMESPACE"[0m
2026-02-27T19:10:20.9733705Z [36;1m    exit 1[0m
2026-02-27T19:10:20.9733846Z [36;1m  fi[0m
2026-02-27T19:10:20.9733983Z [36;1m[0m
2026-02-27T19:10:20.9734129Z [36;1m  # 1) check follower pods[0m
2026-02-27T19:10:20.9734314Z [36;1m  ALL_FOLLOWERS_READY=true[0m
2026-02-27T19:10:20.9734655Z [36;1m  for ((i=1; i<SIZE; i++)); do[0m
2026-02-27T19:10:20.9734863Z [36;1m    POD="${POD_PREFIX}-${i}"[0m
2026-02-27T19:10:20.9735236Z [36;1m    PHASE=$(kubectl get pod "$POD" -n "$NAMESPACE" -o jsonpath='{.status.phase}' 2>/dev/null || echo "NotFound")[0m
2026-02-27T19:10:20.9735777Z [36;1m    READY=$(kubectl get pod "$POD" -n "$NAMESPACE" -o jsonpath='{.status.containerStatuses[*].ready}' 2>/dev/null)[0m
2026-02-27T19:10:20.9736258Z [36;1m[0m
2026-02-27T19:10:20.9736441Z [36;1m    echo "Follower [$POD] phase=$PHASE ready=$READY"[0m
2026-02-27T19:10:20.9736670Z [36;1m[0m
2026-02-27T19:10:20.9736844Z [36;1m    if [[ "$PHASE" != "Running" || "$READY" != "true" ]]; then[0m
2026-02-27T19:10:20.9737117Z [36;1m      echo "Follower [$POD] not Ready yet..."[0m
2026-02-27T19:10:20.9737347Z [36;1m      ALL_FOLLOWERS_READY=false[0m
2026-02-27T19:10:20.9737532Z [36;1m      break[0m
2026-02-27T19:10:20.9737679Z [36;1m    fi[0m
2026-02-27T19:10:20.9737817Z [36;1m  done[0m
2026-02-27T19:10:20.9737944Z [36;1m[0m
2026-02-27T19:10:20.9738085Z [36;1m  # 2) check leader pod[0m
2026-02-27T19:10:20.9738480Z [36;1m  LEADER_PHASE=$(kubectl get pod "$LEADER_POD" -n "$NAMESPACE" -o jsonpath='{.status.phase}' 2>/dev/null || echo "NotFound")[0m
2026-02-27T19:10:20.9739082Z [36;1m  LEADER_READY=$(kubectl get pod "$LEADER_POD" -n "$NAMESPACE" -o jsonpath='{.status.containerStatuses[*].ready}' 2>/dev/null)[0m
2026-02-27T19:10:20.9739478Z [36;1m[0m
2026-02-27T19:10:20.9739693Z [36;1m  echo "Leader [$LEADER_POD] phase=$LEADER_PHASE ready=$LEADER_READY"[0m
2026-02-27T19:10:20.9739948Z [36;1m[0m
2026-02-27T19:10:20.9740201Z [36;1m  if [[ "$LEADER_PHASE" != "Running" || "$LEADER_READY" != "true" ]]; then[0m
2026-02-27T19:10:20.9740482Z [36;1m    echo "Leader not Ready yet..."[0m
2026-02-27T19:10:20.9740682Z [36;1m    ALL_FOLLOWERS_READY=false[0m
2026-02-27T19:10:20.9740863Z [36;1m  fi[0m
2026-02-27T19:10:20.9740990Z [36;1m[0m
2026-02-27T19:10:20.9741154Z [36;1m  if [[ "$ALL_FOLLOWERS_READY" == "true" ]]; then[0m
2026-02-27T19:10:20.9741473Z [36;1m    echo "All follower pods and leader pod are Running and Ready â€” continuing."[0m
2026-02-27T19:10:20.9741759Z [36;1m    break[0m
2026-02-27T19:10:20.9741903Z [36;1m  fi[0m
2026-02-27T19:10:20.9742160Z [36;1m[0m
2026-02-27T19:10:20.9742285Z [36;1m  sleep 2[0m
2026-02-27T19:10:20.9742482Z [36;1mdone[0m
2026-02-27T19:10:20.9742793Z shell: bash -el {0}
2026-02-27T19:10:20.9742934Z env:
2026-02-27T19:10:20.9743282Z   FAIL_TAG: FAIL_TAG_DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-02-27T19:10:20.9743510Z ##[endgroup]
2026-02-27T19:10:20.9821726Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-27T19:10:20.9822789Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-27T19:10:20.9823022Z ##[endgroup]
2026-02-27T19:10:21.3489868Z (node:672) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-27T19:10:21.3490553Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-27T19:10:21.9278800Z Waiting for Pods in namespace [vllm-project] to become Running and Ready (timeout 1200s)...
2026-02-27T19:10:22.0445054Z Follower [vllm-0-1] phase=Pending ready=
2026-02-27T19:10:22.0445310Z Follower [vllm-0-1] not Ready yet...
2026-02-27T19:10:22.1611183Z Leader [vllm-0] phase=Pending ready=
2026-02-27T19:10:22.1611471Z Leader not Ready yet...
2026-02-27T19:10:24.2736082Z Follower [vllm-0-1] phase=Pending ready=
2026-02-27T19:10:24.2736424Z Follower [vllm-0-1] not Ready yet...
2026-02-27T19:10:24.3861590Z Leader [vllm-0] phase=Pending ready=
2026-02-27T19:10:26.5438094Z Leader not Ready yet...
2026-02-27T19:10:26.5438359Z Follower [vllm-0-1] phase=Pending ready=
2026-02-27T19:10:26.5438573Z Follower [vllm-0-1] not Ready yet...
2026-02-27T19:10:26.6753044Z Leader [vllm-0] phase=Pending ready=
2026-02-27T19:10:26.6753267Z Leader not Ready yet...
2026-02-27T19:10:28.7899110Z Follower [vllm-0-1] phase=Pending ready=
2026-02-27T19:10:28.7899381Z Follower [vllm-0-1] not Ready yet...
2026-02-27T19:10:28.9060980Z Leader [vllm-0] phase=Pending ready=
2026-02-27T19:10:28.9061235Z Leader not Ready yet...
2026-02-27T19:10:31.0360346Z Follower [vllm-0-1] phase=Pending ready=
2026-02-27T19:10:31.0360632Z Follower [vllm-0-1] not Ready yet...
2026-02-27T19:10:31.1607171Z Leader [vllm-0] phase=Pending ready=
2026-02-27T19:10:31.1607955Z Leader not Ready yet...
2026-02-27T19:10:33.2831960Z Follower [vllm-0-1] phase=Pending ready=
2026-02-27T19:10:33.2832374Z Follower [vllm-0-1] not Ready yet...
2026-02-27T19:10:33.3943672Z Leader [vllm-0] phase=Pending ready=false
2026-02-27T19:10:33.3943935Z Leader not Ready yet...
2026-02-27T19:10:35.5248722Z Follower [vllm-0-1] phase=Pending ready=false
2026-02-27T19:10:35.5249048Z Follower [vllm-0-1] not Ready yet...
2026-02-27T19:10:35.6392356Z Leader [vllm-0] phase=Running ready=true
2026-02-27T19:10:37.7554747Z Follower [vllm-0-1] phase=Running ready=true
2026-02-27T19:10:37.8735675Z Leader [vllm-0] phase=Running ready=true
2026-02-27T19:10:37.8736277Z All follower pods and leader pod are Running and Ready â€” continuing.
2026-02-27T19:10:38.3288970Z ##[group]Run set -euo pipefail
2026-02-27T19:10:38.3289251Z [36;1mset -euo pipefail[0m
2026-02-27T19:10:38.3289417Z [36;1m[0m
2026-02-27T19:10:38.3289558Z [36;1msize="2"[0m
2026-02-27T19:10:38.3289702Z [36;1mpids=()[0m
2026-02-27T19:10:38.3289863Z [36;1m[0m
2026-02-27T19:10:38.3289999Z [36;1mcleanup() {[0m
2026-02-27T19:10:38.3290191Z [36;1m  echo "Cleaning up background log streams..."[0m
2026-02-27T19:10:38.3290429Z [36;1m  for pid in "${pids[@]}"; do[0m
2026-02-27T19:10:38.3290639Z [36;1m    kill "$pid" 2>/dev/null || true[0m
2026-02-27T19:10:38.3290828Z [36;1m  done[0m
2026-02-27T19:10:38.3290970Z [36;1m}[0m
2026-02-27T19:10:38.3291103Z [36;1mtrap cleanup EXIT[0m
2026-02-27T19:10:38.3291265Z [36;1m[0m
2026-02-27T19:10:38.3291414Z [36;1mfor i in $(seq 1 $((size - 1))); do[0m
2026-02-27T19:10:38.3291608Z [36;1m  POD="vllm-0-${i}"[0m
2026-02-27T19:10:38.3291770Z [36;1m[0m
2026-02-27T19:10:38.3292166Z [36;1m  echo "==== Collecting logs from worker pod: $POD ===="[0m
2026-02-27T19:10:38.3292459Z [36;1m  kubectl logs -f "$POD" -n "$NAMESPACE" \[0m
2026-02-27T19:10:38.3292685Z [36;1m    > "/tmp/${POD}_logs.txt" 2>&1 &[0m
2026-02-27T19:10:38.3292880Z [36;1m[0m
2026-02-27T19:10:38.3293009Z [36;1m  pids+=($!)[0m
2026-02-27T19:10:38.3293176Z [36;1mdone[0m
2026-02-27T19:10:38.3293317Z [36;1m[0m
2026-02-27T19:10:38.3293507Z [36;1mecho "==== Streaming logs from leader pod: $LEADER_POD ===="[0m
2026-02-27T19:10:38.3293796Z [36;1mecho "Looking for logs containing: $FAIL_TAG"[0m
2026-02-27T19:10:38.3294010Z [36;1m[0m
2026-02-27T19:10:38.3294238Z [36;1mkubectl logs -f "$LEADER_POD" -n "$NAMESPACE" | while IFS= read -r line; do[0m
2026-02-27T19:10:38.3294538Z [36;1m  echo "$line"[0m
2026-02-27T19:10:38.3294732Z [36;1m  if echo "$line" | grep -q "$FAIL_TAG"; then[0m
2026-02-27T19:10:38.3294934Z [36;1m    exit 1[0m
2026-02-27T19:10:38.3295080Z [36;1m  fi[0m
2026-02-27T19:10:38.3295210Z [36;1mdone[0m
2026-02-27T19:10:38.3295520Z shell: bash -el {0}
2026-02-27T19:10:38.3295671Z env:
2026-02-27T19:10:38.3295859Z   FAIL_TAG: FAIL_TAG_DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-02-27T19:10:38.3296093Z ##[endgroup]
2026-02-27T19:10:38.3406611Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-27T19:10:38.3407475Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-27T19:10:38.3407689Z ##[endgroup]
2026-02-27T19:10:38.7005277Z (node:764) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-27T19:10:38.7006271Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-27T19:10:39.2511098Z ==== Collecting logs from worker pod: vllm-0-1 ====
2026-02-27T19:10:39.2511630Z ==== Streaming logs from leader pod: vllm-0 ====
2026-02-27T19:10:39.2511941Z Looking for logs containing: FAIL_TAG_DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-02-27T19:10:39.3308760Z /usr/local/Ascend/ascend-toolkit/set_env.sh: line 31: CMAKE_PREFIX_PATH: unbound variable
2026-02-27T19:10:39.3320234Z ====> Check NPU info
2026-02-27T19:10:39.3335142Z +------------------------------------------------------------------------------------------------+
2026-02-27T19:10:39.3348545Z | npu-smi 25.5.0                   Version: 25.5.0                                               |
2026-02-27T19:10:39.3359766Z +---------------------------+---------------+----------------------------------------------------+
2026-02-27T19:10:39.3369054Z | NPU   Name                | Health        | Power(W)    Temp(C)           Hugepages-Usage(page)|
2026-02-27T19:10:39.3379189Z | Chip  Phy-ID              | Bus-Id        | AICore(%)   Memory-Usage(MB)  HBM-Usage(MB)        |
2026-02-27T19:10:39.3389491Z +===========================+===============+====================================================+
2026-02-27T19:10:39.3400190Z | 0     Ascend910           | OK            | 164.7       36                0    / 0             |
2026-02-27T19:10:39.3409628Z | 0     0                   | 0000:9D:00.0  | 0           0    / 0          3163 / 65536         |
2026-02-27T19:10:39.3421229Z +------------------------------------------------------------------------------------------------+
2026-02-27T19:10:39.3437564Z | 0     Ascend910           | OK            | -           36                0    / 0             |
2026-02-27T19:10:39.3447592Z | 1     1                   | 0000:9F:00.0  | 0           0    / 0          2896 / 65536         |
2026-02-27T19:10:39.3458449Z +===========================+===============+====================================================+
2026-02-27T19:10:39.3468840Z | 1     Ascend910           | OK            | 162.9       35                0    / 0             |
2026-02-27T19:10:39.3481402Z | 0     2                   | 0000:99:00.0  | 0           0    / 0          3170 / 65536         |
2026-02-27T19:10:39.3489814Z +------------------------------------------------------------------------------------------------+
2026-02-27T19:10:39.3499639Z | 1     Ascend910           | OK            | -           34                0    / 0             |
2026-02-27T19:10:39.3509795Z | 1     3                   | 0000:9B:00.0  | 0           0    / 0          2887 / 65536         |
2026-02-27T19:10:39.3520288Z +===========================+===============+====================================================+
2026-02-27T19:10:39.3530110Z | 2     Ascend910           | OK            | 161.1       34                0    / 0             |
2026-02-27T19:10:39.3540131Z | 0     4                   | 0000:95:00.0  | 0           0    / 0          3153 / 65536         |
2026-02-27T19:10:39.3549513Z +------------------------------------------------------------------------------------------------+
2026-02-27T19:10:39.3559912Z | 2     Ascend910           | OK            | -           34                0    / 0             |
2026-02-27T19:10:39.3569130Z | 1     5                   | 0000:97:00.0  | 0           0    / 0          2898 / 65536         |
2026-02-27T19:10:39.3579292Z +===========================+===============+====================================================+
2026-02-27T19:10:39.3589707Z | 3     Ascend910           | OK            | 164.1       34                0    / 0             |
2026-02-27T19:10:39.3599633Z | 0     6                   | 0000:91:00.0  | 0           0    / 0          3162 / 65536         |
2026-02-27T19:10:39.3609868Z +------------------------------------------------------------------------------------------------+
2026-02-27T19:10:39.3619587Z | 3     Ascend910           | OK            | -           33                0    / 0             |
2026-02-27T19:10:39.3628496Z | 1     7                   | 0000:93:00.0  | 0           0    / 0          2881 / 65536         |
2026-02-27T19:10:39.3638074Z +===========================+===============+====================================================+
2026-02-27T19:10:39.3648076Z | 4     Ascend910           | OK            | 166.6       34                0    / 0             |
2026-02-27T19:10:39.3657246Z | 0     8                   | 0000:8D:00.0  | 0           0    / 0          3155 / 65536         |
2026-02-27T19:10:39.3666876Z +------------------------------------------------------------------------------------------------+
2026-02-27T19:10:39.3677373Z | 4     Ascend910           | OK            | -           34                0    / 0             |
2026-02-27T19:10:39.3687752Z | 1     9                   | 0000:8F:00.0  | 0           0    / 0          2895 / 65536         |
2026-02-27T19:10:39.3697770Z +===========================+===============+====================================================+
2026-02-27T19:10:39.3708819Z | 5     Ascend910           | OK            | 166.2       34                0    / 0             |
2026-02-27T19:10:39.3718630Z | 0     10                  | 0000:89:00.0  | 0           0    / 0          3152 / 65536         |
2026-02-27T19:10:39.3728879Z +------------------------------------------------------------------------------------------------+
2026-02-27T19:10:39.3738360Z | 5     Ascend910           | OK            | -           36                0    / 0             |
2026-02-27T19:10:39.3748157Z | 1     11                  | 0000:8B:00.0  | 0           0    / 0          2899 / 65536         |
2026-02-27T19:10:39.3758680Z +===========================+===============+====================================================+
2026-02-27T19:10:39.3768532Z | 6     Ascend910           | OK            | 162.4       35                0    / 0             |
2026-02-27T19:10:39.3779164Z | 0     12                  | 0000:85:00.0  | 0           0    / 0          3152 / 65536         |
2026-02-27T19:10:39.3790941Z +------------------------------------------------------------------------------------------------+
2026-02-27T19:10:39.3802215Z | 6     Ascend910           | OK            | -           36                0    / 0             |
2026-02-27T19:10:39.3812388Z | 1     13                  | 0000:87:00.0  | 0           0    / 0          2898 / 65536         |
2026-02-27T19:10:39.3822169Z +===========================+===============+====================================================+
2026-02-27T19:10:39.3832378Z | 7     Ascend910           | OK            | 157.7       34                0    / 0             |
2026-02-27T19:10:39.3841721Z | 0     14                  | 0000:81:00.0  | 0           0    / 0          3163 / 65536         |
2026-02-27T19:10:39.3852162Z +------------------------------------------------------------------------------------------------+
2026-02-27T19:10:39.3861885Z | 7     Ascend910           | OK            | -           35                0    / 0             |
2026-02-27T19:10:39.3871954Z | 1     15                  | 0000:83:00.0  | 0           0    / 0          2884 / 65536         |
2026-02-27T19:10:39.3882774Z +===========================+===============+====================================================+
2026-02-27T19:10:39.3892951Z +---------------------------+---------------+----------------------------------------------------+
2026-02-27T19:10:39.3902751Z | NPU     Chip              | Process id    | Process name             | Process memory(MB)      |
2026-02-27T19:10:39.3912360Z +===========================+===============+====================================================+
2026-02-27T19:10:39.3922952Z | No running processes found in NPU 0                                                            |
2026-02-27T19:10:39.3932661Z +===========================+===============+====================================================+
2026-02-27T19:10:39.3942421Z | No running processes found in NPU 1                                                            |
2026-02-27T19:10:39.3952577Z +===========================+===============+====================================================+
2026-02-27T19:10:39.3963772Z | No running processes found in NPU 2                                                            |
2026-02-27T19:10:39.3973646Z +===========================+===============+====================================================+
2026-02-27T19:10:39.3983987Z | No running processes found in NPU 3                                                            |
2026-02-27T19:10:39.3994032Z +===========================+===============+====================================================+
2026-02-27T19:10:39.4004720Z | No running processes found in NPU 4                                                            |
2026-02-27T19:10:39.4014567Z +===========================+===============+====================================================+
2026-02-27T19:10:39.4024659Z | No running processes found in NPU 5                                                            |
2026-02-27T19:10:39.4037899Z +===========================+===============+====================================================+
2026-02-27T19:10:39.4048194Z | No running processes found in NPU 6                                                            |
2026-02-27T19:10:39.4057468Z +===========================+===============+====================================================+
2026-02-27T19:10:39.4069275Z | No running processes found in NPU 7                                                            |
2026-02-27T19:10:39.4079368Z +===========================+===============+====================================================+
2026-02-27T19:10:39.4090590Z package_name=Ascend-cann-toolkit
2026-02-27T19:10:39.4100147Z version=8.5.0
2026-02-27T19:10:39.4110498Z innerversion=V100R001C25SPC001B232
2026-02-27T19:10:39.4121199Z compatible_version=[V100R001C15],[V100R001C18],[V100R001C19],[V100R001C20],[V100R001C21],[V100R001C23]
2026-02-27T19:10:39.4131008Z arch=aarch64
2026-02-27T19:10:39.4140180Z os=linux
2026-02-27T19:10:39.4149133Z path=/usr/local/Ascend/cann-8.5.0
2026-02-27T19:10:39.4158823Z ====> Configure mirrors and git proxy
2026-02-27T19:10:39.4168141Z Writing to /root/.config/pip/pip.conf
2026-02-27T19:10:39.4177742Z Installed vLLM-related Python packages:
2026-02-27T19:10:39.4187810Z ais_bench_benchmark               3.0.20250930              /vllm-workspace/vllm-ascend/benchmark
2026-02-27T19:10:39.4198163Z vllm                              0.16.0+empty              /vllm-workspace/vllm
2026-02-27T19:10:39.4207620Z vllm_ascend                       0.15.0rc2.dev4+gb60b99100 /vllm-workspace/vllm-ascend
2026-02-27T19:10:39.4216485Z 
2026-02-27T19:10:39.4226267Z ============================
2026-02-27T19:10:39.4235846Z vLLM Git information
2026-02-27T19:10:39.4245386Z ============================
2026-02-27T19:10:39.4254755Z Branch:      HEAD
2026-02-27T19:10:39.4264401Z Commit hash: 89a77b10846fd96273cce78d86d2556ea582d26e
2026-02-27T19:10:39.4274793Z Author:      Andreas Karatzas <akaratza@amd.com>
2026-02-27T19:10:39.4285046Z Date:        2026-02-12 12:47:34 -0600
2026-02-27T19:10:39.4295109Z Message:     [ROCm][CI] Pin TorchCodec to v0.10.0 for ROCm compatibility (#34447)
2026-02-27T19:10:39.4304723Z Tags:        v0.16.0
2026-02-27T19:10:39.4314655Z Remote:      origin	https://ghfast.top/https://github.com/vllm-project/vllm.git (fetch)
2026-02-27T19:10:39.4324589Z 
2026-02-27T19:10:39.4334097Z 
2026-02-27T19:10:39.4343860Z ============================
2026-02-27T19:10:39.4353459Z vLLM-Ascend Git information
2026-02-27T19:10:39.4363716Z ============================
2026-02-27T19:10:39.4372780Z Branch:      main
2026-02-27T19:10:39.4382807Z Commit hash: b60b9910053f3d8a9ef7d4eea34c553f81f215a3
2026-02-27T19:10:39.4392101Z Author:      wjunLu <135617475+wjunLu@users.noreply.github.com>
2026-02-27T19:10:39.4402242Z Date:        2026-02-27 16:31:02 +0800
2026-02-27T19:10:39.4412190Z Message:     [CI] Add nightly test for Qwen3-235B-A22B with  mooncake layerwise connector (#5441)
2026-02-27T19:10:39.4421373Z Tags:        
2026-02-27T19:10:39.4431106Z Remote:      origin	https://ghfast.top/https://github.com/vllm-project/vllm-ascend (fetch)
2026-02-27T19:10:39.4441367Z 
2026-02-27T19:10:39.4450869Z ====> Check triton ascend info
2026-02-27T19:10:39.4460822Z Ubuntu clang version 15.0.7
2026-02-27T19:10:39.4470648Z Target: aarch64-unknown-linux-gnu
2026-02-27T19:10:39.4480694Z Thread model: posix
2026-02-27T19:10:39.4494195Z InstalledDir: /usr/bin
2026-02-27T19:10:39.4504099Z Found candidate GCC installation: /usr/bin/../lib/gcc/aarch64-linux-gnu/11
2026-02-27T19:10:39.4513430Z Selected GCC installation: /usr/bin/../lib/gcc/aarch64-linux-gnu/11
2026-02-27T19:10:39.4523781Z Candidate multilib: .;@m64
2026-02-27T19:10:39.4533735Z Selected multilib: .;@m64
2026-02-27T19:10:39.4546291Z /usr/local/Ascend/cann-8.5.0/tools/bishengir/bin/bishengir-compile
2026-02-27T19:10:39.4556780Z Name: triton-ascend
2026-02-27T19:10:39.4567094Z Version: 3.2.0
2026-02-27T19:10:39.4576987Z Summary: A language and compiler for custom Deep Learning operations on Ascend hardwares
2026-02-27T19:10:39.4586354Z Home-page: https://gitcode.com/Ascend/triton-ascend/
2026-02-27T19:10:39.4596247Z Author: 
2026-02-27T19:10:39.4606472Z Author-email: 
2026-02-27T19:10:39.4615743Z License: 
2026-02-27T19:10:39.4625425Z Location: /usr/local/python3.11.14/lib/python3.11/site-packages
2026-02-27T19:10:39.4634808Z Requires: 
2026-02-27T19:10:39.4644940Z Required-by: vllm_ascend
2026-02-27T19:10:57.5324771Z INFO 02-27 19:10:57 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T19:10:57.5335559Z INFO 02-27 19:10:57 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T19:10:57.5346418Z INFO 02-27 19:10:57 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T19:10:57.5793641Z INFO 02-27 19:10:57 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T19:11:04.1057754Z ============================= test session starts ==============================
2026-02-27T19:11:04.1058234Z platform linux -- Python 3.11.14, pytest-8.4.2, pluggy-1.6.0 -- /usr/local/python3.11.14/bin/python3
2026-02-27T19:11:04.1064699Z cachedir: .pytest_cache
2026-02-27T19:11:04.1074976Z rootdir: /vllm-workspace/vllm-ascend
2026-02-27T19:11:04.1084566Z configfile: pyproject.toml
2026-02-27T19:11:04.1094657Z plugins: cov-7.0.0, mock-3.15.1, asyncio-1.3.0, anyio-4.12.1
2026-02-27T19:11:04.1104432Z asyncio: mode=Mode.STRICT, debug=False, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function
2026-02-27T19:11:04.9776407Z collecting ... collected 1 item
2026-02-27T19:11:04.9781580Z 
2026-02-27T19:11:04.9793792Z [2026-02-27 19:11:04] INFO multi_node_config.py:294: Loading config yaml: tests/e2e/nightly/multi_node/config/DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-02-27T19:11:04.9854620Z [2026-02-27 19:11:04] INFO multi_node_config.py:351: Resolving cluster IPs via DNS...
2026-02-27T19:11:04.9928407Z [2026-02-27 19:11:04] INFO multi_node_config.py:212: Node 0 envs: {'HCCL_OP_EXPANSION_MODE': 'AIV', 'VLLM_USE_MODELSCOPE': 'True', 'HCCL_BUFFSIZE': '1024', 'SERVER_PORT': '8080', 'OMP_PROC_BIND': 'False', 'OMP_NUM_THREADS': '1', 'PYTORCH_NPU_ALLOC_CONF': 'expandable_segments:True', 'VLLM_ASCEND_ENABLE_MLAPO': '1', 'VLLM_ASCEND_ENABLE_FLASHCOMM1': '1', 'ASCEND_A3_EBA_ENABLE': '1', 'HCCL_IF_IP': '10.0.0.210', 'HCCL_SOCKET_IFNAME': 'eth0', 'GLOO_SOCKET_IFNAME': 'eth0', 'TP_SOCKET_IFNAME': 'eth0', 'LOCAL_IP': '10.0.0.210', 'NIC_NAME': 'eth0', 'MASTER_IP': '10.0.0.210'}
2026-02-27T19:11:04.9946460Z [2026-02-27 19:11:04] INFO multi_node_config.py:137: Not launching proxy on non-master node
2026-02-27T19:11:04.9960407Z [2026-02-27 19:11:04] INFO conftest.py:241: Starting server with command: vllm serve vllm-ascend/DeepSeek-V3.2-W8A8 --host 0.0.0.0 --port 8080 --data-parallel-size 4 --data-parallel-size-local 2 --data-parallel-address 10.0.0.210 --data-parallel-rpc-port 13399 --tensor-parallel-size 8 --quantization ascend --seed 1024 --enable-expert-parallel --max-num-seqs 16 --max-model-len 68000 --max-num-batched-tokens 4096 --no-enable-prefix-caching --gpu-memory-utilization 0.85 --trust-remote-code --speculative-config {"num_speculative_tokens": 3, "method":"deepseek_mtp"} --compilation-config {"cudagraph_capture_sizes": [8, 16, 24, 32, 40, 48], "cudagraph_mode": "FULL_DECODE_ONLY"} --additional-config {"layer_sharding": ["q_b_proj", "o_proj"]} --tokenizer-mode deepseek_v32 --reasoning-parser deepseek_v3
2026-02-27T19:11:09.3745292Z tests/e2e/nightly/multi_node/scripts/test_multi_node.py::test_multi_node INFO 02-27 19:11:09 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T19:11:09.3749128Z INFO 02-27 19:11:09 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T19:11:09.3759516Z INFO 02-27 19:11:09 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T19:11:09.3806294Z INFO 02-27 19:11:09 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T19:11:15.6985622Z 2026-02-27 19:11:15,696 - 138 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.16.0+empty: default 1
2026-02-27T19:11:15.7602804Z INFO 02-27 19:11:15 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-27T19:11:15.9478518Z INFO 02-27 19:11:15 [serve.py:100] Defaulting api_server_count to data_parallel_size (4).
2026-02-27T19:11:15.9496079Z INFO 02-27 19:11:15 [utils.py:287] 
2026-02-27T19:11:15.9504791Z INFO 02-27 19:11:15 [utils.py:287]        â–ˆ     â–ˆ     â–ˆâ–„   â–„â–ˆ
2026-02-27T19:11:15.9513817Z INFO 02-27 19:11:15 [utils.py:287]  â–„â–„ â–„â–ˆ â–ˆ     â–ˆ     â–ˆ â–€â–„â–€ â–ˆ  version 0.16.0
2026-02-27T19:11:15.9524870Z INFO 02-27 19:11:15 [utils.py:287]   â–ˆâ–„â–ˆâ–€ â–ˆ     â–ˆ     â–ˆ     â–ˆ  model   vllm-ascend/DeepSeek-V3.2-W8A8
2026-02-27T19:11:15.9536191Z INFO 02-27 19:11:15 [utils.py:287]    â–€â–€  â–€â–€â–€â–€â–€ â–€â–€â–€â–€â–€ â–€     â–€
2026-02-27T19:11:15.9543739Z INFO 02-27 19:11:15 [utils.py:287] 
2026-02-27T19:11:15.9563171Z INFO 02-27 19:11:15 [utils.py:223] non-default args: {'model_tag': 'vllm-ascend/DeepSeek-V3.2-W8A8', 'api_server_count': 4, 'host': '0.0.0.0', 'port': 8080, 'model': 'vllm-ascend/DeepSeek-V3.2-W8A8', 'tokenizer_mode': 'deepseek_v32', 'trust_remote_code': True, 'seed': 1024, 'max_model_len': 68000, 'quantization': 'ascend', 'reasoning_parser': 'deepseek_v3', 'tensor_parallel_size': 8, 'data_parallel_size': 4, 'data_parallel_size_local': 2, 'data_parallel_address': '10.0.0.210', 'data_parallel_rpc_port': 13399, 'enable_expert_parallel': True, 'gpu_memory_utilization': 0.85, 'enable_prefix_caching': False, 'max_num_batched_tokens': 4096, 'max_num_seqs': 16, 'speculative_config': {'num_speculative_tokens': 3, 'method': 'deepseek_mtp'}, 'compilation_config': {'level': None, 'mode': None, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'vllm_ascend.compilation.compiler_interface.AscendCompiler', 'custom_ops': [], 'splitting_ops': None, 'compile_mm_encoder': False, 'compile_sizes': None, 'compile_ranges_split_points': None, 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_DECODE_ONLY: (2, 0)>, 'cudagraph_num_of_warmups': 0, 'cudagraph_capture_sizes': [8, 16, 24, 32, 40, 48], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': None, 'pass_config': {}, 'max_cudagraph_capture_size': None, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>, 'evaluate_guards': False, 'assume_32_bit_indexing': False}, 'local_cache_dir': None, 'fast_moe_cold_start': None, 'static_all_moe_layers': []}, 'additional_config': {'layer_sharding': ['q_b_proj', 'o_proj']}}
2026-02-27T19:11:15.9904210Z 2026-02-27 19:11:15,988 - modelscope - WARNING - We can not confirm the cached file is for revision: master
2026-02-27T19:11:15.9950984Z INFO 02-27 19:11:15 [arg_utils.py:620] HF_HUB_OFFLINE is True, replace model_id [vllm-ascend/DeepSeek-V3.2-W8A8] to model_path [/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8]
2026-02-27T19:11:15.9969195Z The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T19:11:16.0080155Z The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T19:11:16.0097240Z The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T19:11:16.0108223Z You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-27T19:11:16.0281078Z INFO 02-27 19:11:16 [model.py:529] Resolved architecture: DeepseekV32ForCausalLM
2026-02-27T19:11:16.0290817Z INFO 02-27 19:11:16 [model.py:1549] Using max model len 68000
2026-02-27T19:11:16.2881306Z WARNING 02-27 19:11:16 [speculative.py:293] method `deepseek_mtp` is deprecated and replaced with mtp.
2026-02-27T19:11:16.2898984Z The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T19:11:16.2907998Z The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T19:11:16.2917864Z You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-27T19:11:16.2994387Z INFO 02-27 19:11:16 [model.py:529] Resolved architecture: DeepSeekMTPModel
2026-02-27T19:11:16.3016043Z INFO 02-27 19:11:16 [model.py:1549] Using max model len 163840
2026-02-27T19:11:16.3033052Z WARNING 02-27 19:11:16 [speculative.py:411] Enabling num_speculative_tokens > 1 will runmultiple times of forward on same MTP layer,which may result in lower acceptance rate
2026-02-27T19:11:16.3044729Z INFO 02-27 19:11:16 [scheduler.py:224] Chunked prefill is enabled with max_num_batched_tokens=4096.
2026-02-27T19:11:16.8997709Z INFO 02-27 19:11:16 [vllm.py:689] Asynchronous scheduling is enabled.
2026-02-27T19:11:16.9011771Z INFO 02-27 19:11:16 [vllm.py:699] Disabling NCCL for DP synchronization when using async scheduling.
2026-02-27T19:11:16.9036472Z WARNING 02-27 19:11:16 [platform.py:717] Speculative quantization is set but Ascend automatically uses the main model's quantization method. Resetting to None.
2026-02-27T19:11:16.9037327Z WARNING 02-27 19:11:16 [platform.py:758] Ignored parameter 'use_trtllm_ragged_deepseek_prefill'. This is a GPU-specific feature not supported on Ascend. Resetting to False.
2026-02-27T19:11:16.9037890Z INFO 02-27 19:11:16 [ascend_config.py:454] Dynamic EPLB is False
2026-02-27T19:11:16.9045187Z INFO 02-27 19:11:16 [ascend_config.py:455] The number of redundant experts is 0
2026-02-27T19:11:16.9054936Z INFO 02-27 19:11:16 [ascend_config.py:55] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-27T19:11:16.9115629Z INFO 02-27 19:11:16 [platform.py:301] FULL_DECODE_ONLY compilation enabled on NPU. use_inductor not supported - using only ACL Graph mode
2026-02-27T19:11:16.9117255Z WARNING 02-27 19:11:16 [platform.py:318] [91m
2026-02-27T19:11:16.9117611Z WARNING 02-27 19:11:16 [platform.py:318]             **********************************************************************************
2026-02-27T19:11:16.9118088Z WARNING 02-27 19:11:16 [platform.py:318]             * WARNING: You have enabled the *full graph* feature.
2026-02-27T19:11:16.9118580Z WARNING 02-27 19:11:16 [platform.py:318]             * This is an early experimental stage and may involve various unknown issues.
2026-02-27T19:11:16.9119126Z WARNING 02-27 19:11:16 [platform.py:318]             * A known problem is that capturing too many batch sizes can lead to OOM
2026-02-27T19:11:16.9126515Z WARNING 02-27 19:11:16 [platform.py:318]             * (Out of Memory) errors or inference hangs. If you encounter such issues,
2026-02-27T19:11:16.9136387Z WARNING 02-27 19:11:16 [platform.py:318]             * consider reducing `gpu_memory_utilization` or manually specifying a smaller
2026-02-27T19:11:16.9146120Z WARNING 02-27 19:11:16 [platform.py:318]             * batch size for graph capture.
2026-02-27T19:11:16.9155188Z WARNING 02-27 19:11:16 [platform.py:318]             * For more details, please refer to:
2026-02-27T19:11:16.9166421Z WARNING 02-27 19:11:16 [platform.py:318]             * https://docs.vllm.ai/en/stable/configuration/conserving_memory.html#reduce-cuda-graphs
2026-02-27T19:11:16.9176452Z WARNING 02-27 19:11:16 [platform.py:318]             **********************************************************************************[0m
2026-02-27T19:11:16.9187235Z WARNING 02-27 19:11:16 [platform.py:318]             
2026-02-27T19:11:16.9196754Z INFO 02-27 19:11:16 [platform.py:430] Set PYTORCH_NPU_ALLOC_CONF=expandable_segments:True
2026-02-27T19:11:16.9207308Z INFO 02-27 19:11:16 [utils.py:843] Started DP Coordinator process (PID: 151)
2026-02-27T19:11:21.5646485Z INFO 02-27 19:11:21 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T19:11:21.5650271Z INFO 02-27 19:11:21 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T19:11:21.5659088Z INFO 02-27 19:11:21 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T19:11:21.5669998Z INFO 02-27 19:11:21 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T19:11:21.5680174Z INFO 02-27 19:11:21 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T19:11:21.5690415Z INFO 02-27 19:11:21 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T19:11:21.5709264Z INFO 02-27 19:11:21 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T19:11:21.5724858Z INFO 02-27 19:11:21 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T19:11:31.5210814Z INFO 02-27 19:11:31 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T19:11:31.5218031Z INFO 02-27 19:11:31 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T19:11:31.5229536Z INFO 02-27 19:11:31 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T19:11:31.5278587Z INFO 02-27 19:11:31 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T19:11:36.8243763Z INFO 02-27 19:11:36 [utils.py:217] Started 4 API server processes
2026-02-27T19:11:37.2030823Z (EngineCore_DP1 pid=173) 2026-02-27 19:11:37,200 - 173 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.16.0+empty: default 1
2026-02-27T19:11:37.2052754Z (EngineCore_DP0 pid=154) 2026-02-27 19:11:37,201 - 154 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.16.0+empty: default 1
2026-02-27T19:11:37.2078491Z (EngineCore_DP1 pid=173) INFO 02-27 19:11:37 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-27T19:11:37.2088777Z (EngineCore_DP0 pid=154) INFO 02-27 19:11:37 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-27T19:11:37.2120702Z (EngineCore_DP0 pid=154) INFO 02-27 19:11:37 [core.py:97] Initializing a V1 LLM engine (v0.16.0) with config: model='/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8', speculative_config=SpeculativeConfig(method='mtp', model='/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8', num_spec_tokens=3), tokenizer='/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8', skip_tokenizer_init=False, tokenizer_mode=deepseek_v32, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=68000, download_dir=None, load_format=auto, tensor_parallel_size=8, pipeline_parallel_size=1, data_parallel_size=4, disable_custom_all_reduce=True, quantization=ascend, enforce_eager=False, enable_return_routed_experts=False, kv_cache_dtype=bfloat16, device_config=npu, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='deepseek_v3', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01, cudagraph_metrics=False, enable_layerwise_nvtx_tracing=False, enable_mfu_metrics=False, enable_mm_processor_stats=False, enable_logging_iteration_details=False), seed=1024, served_model_name=/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'vllm_ascend.compilation.compiler_interface.AscendCompiler', 'custom_ops': ['all'], 'splitting_ops': [], 'compile_mm_encoder': False, 'compile_sizes': [], 'compile_ranges_split_points': [4112], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_DECODE_ONLY: (2, 0)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [8, 16, 24, 32, 40, 48], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': True, 'fuse_act_quant': True, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False, 'fuse_act_padding': False}, 'max_cudagraph_capture_size': 48, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>, 'evaluate_guards': False, 'assume_32_bit_indexing': False}, 'local_cache_dir': None, 'fast_moe_cold_start': False, 'static_all_moe_layers': []}
2026-02-27T19:11:41.7726821Z INFO 02-27 19:11:41 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T19:11:41.7738597Z INFO 02-27 19:11:41 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T19:11:41.7749202Z INFO 02-27 19:11:41 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T19:11:41.7804310Z INFO 02-27 19:11:41 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T19:11:42.1669662Z INFO 02-27 19:11:42 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T19:11:42.1676029Z INFO 02-27 19:11:42 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T19:11:42.1686536Z INFO 02-27 19:11:42 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T19:11:42.1741033Z INFO 02-27 19:11:42 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T19:11:42.1951569Z INFO 02-27 19:11:42 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T19:11:42.1960773Z INFO 02-27 19:11:42 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T19:11:42.1970706Z INFO 02-27 19:11:42 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T19:11:42.2044013Z INFO 02-27 19:11:42 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T19:11:42.2199567Z INFO 02-27 19:11:42 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T19:11:42.2207692Z INFO 02-27 19:11:42 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T19:11:42.2217025Z INFO 02-27 19:11:42 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T19:11:42.2330960Z INFO 02-27 19:11:42 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T19:11:42.5838143Z INFO 02-27 19:11:42 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T19:11:42.5858413Z INFO 02-27 19:11:42 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T19:11:42.5868896Z INFO 02-27 19:11:42 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T19:11:42.5919976Z INFO 02-27 19:11:42 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T19:11:42.6252271Z INFO 02-27 19:11:42 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T19:11:42.6261488Z INFO 02-27 19:11:42 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T19:11:42.6270998Z INFO 02-27 19:11:42 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T19:11:42.6351136Z INFO 02-27 19:11:42 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T19:11:47.8324939Z (ApiServer_0 pid=184) 2026-02-27 19:11:47,828 - 184 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.16.0+empty: default 1
2026-02-27T19:11:47.8629108Z (ApiServer_0 pid=184) INFO 02-27 19:11:47 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-27T19:11:47.8853310Z (ApiServer_0 pid=184) 2026-02-27 19:11:47,883 - modelscope - WARNING - We can not confirm the cached file is for revision: master
2026-02-27T19:11:47.8900610Z (ApiServer_0 pid=184) INFO 02-27 19:11:47 [arg_utils.py:620] HF_HUB_OFFLINE is True, replace model_id [vllm-ascend/DeepSeek-V3.2-W8A8] to model_path [/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8]
2026-02-27T19:11:47.9890589Z (ApiServer_0 pid=184) The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T19:11:48.0437154Z 2026-02-27 19:11:48,041 - 201 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.16.0+empty: default 1
2026-02-27T19:11:48.0478951Z INFO 02-27 19:11:48 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-27T19:11:48.1122432Z (ApiServer_0 pid=184) The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T19:11:48.1144572Z (ApiServer_0 pid=184) The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T19:11:48.1154224Z (ApiServer_0 pid=184) You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-27T19:11:48.1215660Z (ApiServer_0 pid=184) INFO 02-27 19:11:48 [model.py:529] Resolved architecture: DeepseekV32ForCausalLM
2026-02-27T19:11:48.1237618Z (ApiServer_0 pid=184) INFO 02-27 19:11:48 [model.py:1549] Using max model len 68000
2026-02-27T19:11:48.1804275Z 2026-02-27 19:11:48,178 - 202 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.16.0+empty: default 1
2026-02-27T19:11:48.1844929Z INFO 02-27 19:11:48 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-27T19:11:48.2277375Z (ApiServer_0 pid=184) WARNING 02-27 19:11:48 [speculative.py:293] method `deepseek_mtp` is deprecated and replaced with mtp.
2026-02-27T19:11:48.2301666Z (ApiServer_0 pid=184) The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T19:11:48.2310902Z (ApiServer_0 pid=184) The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T19:11:48.2321212Z (ApiServer_0 pid=184) You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-27T19:11:48.2358598Z (ApiServer_0 pid=184) INFO 02-27 19:11:48 [model.py:529] Resolved architecture: DeepSeekMTPModel
2026-02-27T19:11:48.2379309Z (ApiServer_0 pid=184) INFO 02-27 19:11:48 [model.py:1549] Using max model len 163840
2026-02-27T19:11:48.2390132Z (ApiServer_0 pid=184) WARNING 02-27 19:11:48 [speculative.py:411] Enabling num_speculative_tokens > 1 will runmultiple times of forward on same MTP layer,which may result in lower acceptance rate
2026-02-27T19:11:48.2398883Z (ApiServer_0 pid=184) INFO 02-27 19:11:48 [scheduler.py:224] Chunked prefill is enabled with max_num_batched_tokens=4096.
2026-02-27T19:11:48.3493584Z (ApiServer_0 pid=184) INFO 02-27 19:11:48 [vllm.py:689] Asynchronous scheduling is enabled.
2026-02-27T19:11:48.3501043Z (ApiServer_0 pid=184) INFO 02-27 19:11:48 [vllm.py:699] Disabling NCCL for DP synchronization when using async scheduling.
2026-02-27T19:11:48.3513058Z (ApiServer_0 pid=184) WARNING 02-27 19:11:48 [platform.py:717] Speculative quantization is set but Ascend automatically uses the main model's quantization method. Resetting to None.
2026-02-27T19:11:48.3523222Z (ApiServer_0 pid=184) WARNING 02-27 19:11:48 [platform.py:758] Ignored parameter 'use_trtllm_ragged_deepseek_prefill'. This is a GPU-specific feature not supported on Ascend. Resetting to False.
2026-02-27T19:11:48.3531914Z (ApiServer_0 pid=184) INFO 02-27 19:11:48 [ascend_config.py:454] Dynamic EPLB is False
2026-02-27T19:11:48.3541206Z (ApiServer_0 pid=184) INFO 02-27 19:11:48 [ascend_config.py:455] The number of redundant experts is 0
2026-02-27T19:11:48.3551422Z (ApiServer_0 pid=184) INFO 02-27 19:11:48 [ascend_config.py:55] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-27T19:11:48.3561658Z (ApiServer_0 pid=184) INFO 02-27 19:11:48 [platform.py:301] FULL_DECODE_ONLY compilation enabled on NPU. use_inductor not supported - using only ACL Graph mode
2026-02-27T19:11:48.3570842Z (ApiServer_0 pid=184) WARNING 02-27 19:11:48 [platform.py:318] [91m
2026-02-27T19:11:48.3581030Z (ApiServer_0 pid=184) WARNING 02-27 19:11:48 [platform.py:318]             **********************************************************************************
2026-02-27T19:11:48.3590752Z (ApiServer_0 pid=184) WARNING 02-27 19:11:48 [platform.py:318]             * WARNING: You have enabled the *full graph* feature.
2026-02-27T19:11:48.3600493Z (ApiServer_0 pid=184) WARNING 02-27 19:11:48 [platform.py:318]             * This is an early experimental stage and may involve various unknown issues.
2026-02-27T19:11:48.3610162Z (ApiServer_0 pid=184) WARNING 02-27 19:11:48 [platform.py:318]             * A known problem is that capturing too many batch sizes can lead to OOM
2026-02-27T19:11:48.3619882Z (ApiServer_0 pid=184) WARNING 02-27 19:11:48 [platform.py:318]             * (Out of Memory) errors or inference hangs. If you encounter such issues,
2026-02-27T19:11:48.3628975Z (ApiServer_0 pid=184) WARNING 02-27 19:11:48 [platform.py:318]             * consider reducing `gpu_memory_utilization` or manually specifying a smaller
2026-02-27T19:11:48.3639024Z (ApiServer_0 pid=184) WARNING 02-27 19:11:48 [platform.py:318]             * batch size for graph capture.
2026-02-27T19:11:48.3648949Z (ApiServer_0 pid=184) WARNING 02-27 19:11:48 [platform.py:318]             * For more details, please refer to:
2026-02-27T19:11:48.3659719Z (ApiServer_0 pid=184) WARNING 02-27 19:11:48 [platform.py:318]             * https://docs.vllm.ai/en/stable/configuration/conserving_memory.html#reduce-cuda-graphs
2026-02-27T19:11:48.3669556Z (ApiServer_0 pid=184) WARNING 02-27 19:11:48 [platform.py:318]             **********************************************************************************[0m
2026-02-27T19:11:48.3679641Z (ApiServer_0 pid=184) WARNING 02-27 19:11:48 [platform.py:318]             
2026-02-27T19:11:48.3689265Z (ApiServer_0 pid=184) INFO 02-27 19:11:48 [platform.py:430] Set PYTORCH_NPU_ALLOC_CONF=expandable_segments:True
2026-02-27T19:11:48.3911845Z (ApiServer_1 pid=185) 2026-02-27 19:11:48,389 - 185 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.16.0+empty: default 1
2026-02-27T19:11:48.4252392Z (ApiServer_1 pid=185) INFO 02-27 19:11:48 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-27T19:11:48.4412422Z (ApiServer_1 pid=185) 2026-02-27 19:11:48,439 - modelscope - WARNING - We can not confirm the cached file is for revision: master
2026-02-27T19:11:48.4470458Z (ApiServer_1 pid=185) INFO 02-27 19:11:48 [arg_utils.py:620] HF_HUB_OFFLINE is True, replace model_id [vllm-ascend/DeepSeek-V3.2-W8A8] to model_path [/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8]
2026-02-27T19:11:48.5370270Z (ApiServer_3 pid=187) 2026-02-27 19:11:48,535 - 187 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.16.0+empty: default 1
2026-02-27T19:11:48.5501868Z (ApiServer_1 pid=185) The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T19:11:48.5561423Z (ApiServer_1 pid=185) The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T19:11:48.5579699Z (ApiServer_1 pid=185) The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T19:11:48.5589321Z (ApiServer_1 pid=185) You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-27T19:11:48.5640299Z (ApiServer_1 pid=185) INFO 02-27 19:11:48 [model.py:529] Resolved architecture: DeepseekV32ForCausalLM
2026-02-27T19:11:48.5656482Z (ApiServer_1 pid=185) INFO 02-27 19:11:48 [model.py:1549] Using max model len 68000
2026-02-27T19:11:48.5710887Z (ApiServer_3 pid=187) INFO 02-27 19:11:48 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-27T19:11:48.5840661Z (ApiServer_3 pid=187) 2026-02-27 19:11:48,582 - modelscope - WARNING - We can not confirm the cached file is for revision: master
2026-02-27T19:11:48.5887304Z (ApiServer_3 pid=187) INFO 02-27 19:11:48 [arg_utils.py:620] HF_HUB_OFFLINE is True, replace model_id [vllm-ascend/DeepSeek-V3.2-W8A8] to model_path [/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8]
2026-02-27T19:11:48.6756912Z (ApiServer_1 pid=185) WARNING 02-27 19:11:48 [speculative.py:293] method `deepseek_mtp` is deprecated and replaced with mtp.
2026-02-27T19:11:48.6777813Z (ApiServer_1 pid=185) The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T19:11:48.6788367Z (ApiServer_1 pid=185) The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T19:11:48.6797725Z (ApiServer_1 pid=185) You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-27T19:11:48.6836044Z (ApiServer_1 pid=185) INFO 02-27 19:11:48 [model.py:529] Resolved architecture: DeepSeekMTPModel
2026-02-27T19:11:48.6855532Z (ApiServer_1 pid=185) INFO 02-27 19:11:48 [model.py:1549] Using max model len 163840
2026-02-27T19:11:48.6865625Z (ApiServer_1 pid=185) WARNING 02-27 19:11:48 [speculative.py:411] Enabling num_speculative_tokens > 1 will runmultiple times of forward on same MTP layer,which may result in lower acceptance rate
2026-02-27T19:11:48.6874120Z (ApiServer_1 pid=185) INFO 02-27 19:11:48 [scheduler.py:224] Chunked prefill is enabled with max_num_batched_tokens=4096.
2026-02-27T19:11:48.6912459Z (ApiServer_3 pid=187) The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T19:11:48.6971449Z (ApiServer_3 pid=187) The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T19:11:48.6990115Z (ApiServer_3 pid=187) The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T19:11:48.7000293Z (ApiServer_3 pid=187) You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-27T19:11:48.7053420Z (ApiServer_3 pid=187) INFO 02-27 19:11:48 [model.py:529] Resolved architecture: DeepseekV32ForCausalLM
2026-02-27T19:11:48.7074683Z (ApiServer_3 pid=187) INFO 02-27 19:11:48 [model.py:1549] Using max model len 68000
2026-02-27T19:11:48.8024753Z (ApiServer_1 pid=185) INFO 02-27 19:11:48 [vllm.py:689] Asynchronous scheduling is enabled.
2026-02-27T19:11:48.8032467Z (ApiServer_1 pid=185) INFO 02-27 19:11:48 [vllm.py:699] Disabling NCCL for DP synchronization when using async scheduling.
2026-02-27T19:11:48.8049439Z (ApiServer_1 pid=185) WARNING 02-27 19:11:48 [platform.py:717] Speculative quantization is set but Ascend automatically uses the main model's quantization method. Resetting to None.
2026-02-27T19:11:48.8058827Z (ApiServer_1 pid=185) WARNING 02-27 19:11:48 [platform.py:758] Ignored parameter 'use_trtllm_ragged_deepseek_prefill'. This is a GPU-specific feature not supported on Ascend. Resetting to False.
2026-02-27T19:11:48.8068323Z (ApiServer_1 pid=185) INFO 02-27 19:11:48 [ascend_config.py:454] Dynamic EPLB is False
2026-02-27T19:11:48.8078327Z (ApiServer_1 pid=185) INFO 02-27 19:11:48 [ascend_config.py:455] The number of redundant experts is 0
2026-02-27T19:11:48.8089576Z (ApiServer_1 pid=185) INFO 02-27 19:11:48 [ascend_config.py:55] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-27T19:11:48.8098913Z (ApiServer_1 pid=185) INFO 02-27 19:11:48 [platform.py:301] FULL_DECODE_ONLY compilation enabled on NPU. use_inductor not supported - using only ACL Graph mode
2026-02-27T19:11:48.8108808Z (ApiServer_1 pid=185) WARNING 02-27 19:11:48 [platform.py:318] [91m
2026-02-27T19:11:48.8118138Z (ApiServer_1 pid=185) WARNING 02-27 19:11:48 [platform.py:318]             **********************************************************************************
2026-02-27T19:11:48.8128365Z (ApiServer_1 pid=185) WARNING 02-27 19:11:48 [platform.py:318]             * WARNING: You have enabled the *full graph* feature.
2026-02-27T19:11:48.8138223Z (ApiServer_1 pid=185) WARNING 02-27 19:11:48 [platform.py:318]             * This is an early experimental stage and may involve various unknown issues.
2026-02-27T19:11:48.8147266Z (ApiServer_1 pid=185) WARNING 02-27 19:11:48 [platform.py:318]             * A known problem is that capturing too many batch sizes can lead to OOM
2026-02-27T19:11:48.8156800Z (ApiServer_1 pid=185) WARNING 02-27 19:11:48 [platform.py:318]             * (Out of Memory) errors or inference hangs. If you encounter such issues,
2026-02-27T19:11:48.8166686Z (ApiServer_1 pid=185) WARNING 02-27 19:11:48 [platform.py:318]             * consider reducing `gpu_memory_utilization` or manually specifying a smaller
2026-02-27T19:11:48.8176101Z (ApiServer_1 pid=185) WARNING 02-27 19:11:48 [platform.py:318]             * batch size for graph capture.
2026-02-27T19:11:48.8185680Z (ApiServer_1 pid=185) WARNING 02-27 19:11:48 [platform.py:318]             * For more details, please refer to:
2026-02-27T19:11:48.8196461Z (ApiServer_1 pid=185) WARNING 02-27 19:11:48 [platform.py:318]             * https://docs.vllm.ai/en/stable/configuration/conserving_memory.html#reduce-cuda-graphs
2026-02-27T19:11:48.8206419Z (ApiServer_1 pid=185) WARNING 02-27 19:11:48 [platform.py:318]             **********************************************************************************[0m
2026-02-27T19:11:48.8215539Z (ApiServer_1 pid=185) WARNING 02-27 19:11:48 [platform.py:318]             
2026-02-27T19:11:48.8225375Z (ApiServer_1 pid=185) INFO 02-27 19:11:48 [platform.py:430] Set PYTORCH_NPU_ALLOC_CONF=expandable_segments:True
2026-02-27T19:11:48.8236180Z (ApiServer_3 pid=187) WARNING 02-27 19:11:48 [speculative.py:293] method `deepseek_mtp` is deprecated and replaced with mtp.
2026-02-27T19:11:48.8250151Z (ApiServer_3 pid=187) The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T19:11:48.8264493Z (ApiServer_3 pid=187) The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T19:11:48.8279742Z (ApiServer_3 pid=187) You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-27T19:11:48.8293687Z (ApiServer_3 pid=187) INFO 02-27 19:11:48 [model.py:529] Resolved architecture: DeepSeekMTPModel
2026-02-27T19:11:48.8307087Z (ApiServer_3 pid=187) INFO 02-27 19:11:48 [model.py:1549] Using max model len 163840
2026-02-27T19:11:48.8319217Z (ApiServer_3 pid=187) WARNING 02-27 19:11:48 [speculative.py:411] Enabling num_speculative_tokens > 1 will runmultiple times of forward on same MTP layer,which may result in lower acceptance rate
2026-02-27T19:11:48.8330139Z (ApiServer_3 pid=187) INFO 02-27 19:11:48 [scheduler.py:224] Chunked prefill is enabled with max_num_batched_tokens=4096.
2026-02-27T19:11:48.9444109Z (ApiServer_3 pid=187) INFO 02-27 19:11:48 [vllm.py:689] Asynchronous scheduling is enabled.
2026-02-27T19:11:48.9451209Z (ApiServer_3 pid=187) INFO 02-27 19:11:48 [vllm.py:699] Disabling NCCL for DP synchronization when using async scheduling.
2026-02-27T19:11:48.9471188Z (ApiServer_3 pid=187) WARNING 02-27 19:11:48 [platform.py:717] Speculative quantization is set but Ascend automatically uses the main model's quantization method. Resetting to None.
2026-02-27T19:11:48.9481659Z (ApiServer_3 pid=187) WARNING 02-27 19:11:48 [platform.py:758] Ignored parameter 'use_trtllm_ragged_deepseek_prefill'. This is a GPU-specific feature not supported on Ascend. Resetting to False.
2026-02-27T19:11:48.9490651Z (ApiServer_3 pid=187) INFO 02-27 19:11:48 [ascend_config.py:454] Dynamic EPLB is False
2026-02-27T19:11:48.9500064Z (ApiServer_3 pid=187) INFO 02-27 19:11:48 [ascend_config.py:455] The number of redundant experts is 0
2026-02-27T19:11:48.9510747Z (ApiServer_3 pid=187) INFO 02-27 19:11:48 [ascend_config.py:55] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-27T19:11:48.9520296Z (ApiServer_3 pid=187) INFO 02-27 19:11:48 [platform.py:301] FULL_DECODE_ONLY compilation enabled on NPU. use_inductor not supported - using only ACL Graph mode
2026-02-27T19:11:48.9530016Z (ApiServer_3 pid=187) WARNING 02-27 19:11:48 [platform.py:318] [91m
2026-02-27T19:11:48.9539137Z (ApiServer_3 pid=187) WARNING 02-27 19:11:48 [platform.py:318]             **********************************************************************************
2026-02-27T19:11:48.9548237Z (ApiServer_3 pid=187) WARNING 02-27 19:11:48 [platform.py:318]             * WARNING: You have enabled the *full graph* feature.
2026-02-27T19:11:48.9557687Z (ApiServer_3 pid=187) WARNING 02-27 19:11:48 [platform.py:318]             * This is an early experimental stage and may involve various unknown issues.
2026-02-27T19:11:48.9567864Z (ApiServer_3 pid=187) WARNING 02-27 19:11:48 [platform.py:318]             * A known problem is that capturing too many batch sizes can lead to OOM
2026-02-27T19:11:48.9577288Z (ApiServer_3 pid=187) WARNING 02-27 19:11:48 [platform.py:318]             * (Out of Memory) errors or inference hangs. If you encounter such issues,
2026-02-27T19:11:48.9586812Z (ApiServer_3 pid=187) WARNING 02-27 19:11:48 [platform.py:318]             * consider reducing `gpu_memory_utilization` or manually specifying a smaller
2026-02-27T19:11:48.9596393Z (ApiServer_3 pid=187) WARNING 02-27 19:11:48 [platform.py:318]             * batch size for graph capture.
2026-02-27T19:11:48.9606552Z (ApiServer_3 pid=187) WARNING 02-27 19:11:48 [platform.py:318]             * For more details, please refer to:
2026-02-27T19:11:48.9616017Z (ApiServer_3 pid=187) WARNING 02-27 19:11:48 [platform.py:318]             * https://docs.vllm.ai/en/stable/configuration/conserving_memory.html#reduce-cuda-graphs
2026-02-27T19:11:48.9626583Z (ApiServer_3 pid=187) WARNING 02-27 19:11:48 [platform.py:318]             **********************************************************************************[0m
2026-02-27T19:11:48.9635386Z (ApiServer_3 pid=187) WARNING 02-27 19:11:48 [platform.py:318]             
2026-02-27T19:11:48.9644497Z (ApiServer_3 pid=187) INFO 02-27 19:11:48 [platform.py:430] Set PYTORCH_NPU_ALLOC_CONF=expandable_segments:True
2026-02-27T19:11:49.0710383Z (ApiServer_2 pid=186) 2026-02-27 19:11:49,069 - 186 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.16.0+empty: default 1
2026-02-27T19:11:49.1056379Z (ApiServer_2 pid=186) INFO 02-27 19:11:49 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-27T19:11:49.1183849Z (ApiServer_2 pid=186) 2026-02-27 19:11:49,116 - modelscope - WARNING - We can not confirm the cached file is for revision: master
2026-02-27T19:11:49.1235562Z (ApiServer_2 pid=186) INFO 02-27 19:11:49 [arg_utils.py:620] HF_HUB_OFFLINE is True, replace model_id [vllm-ascend/DeepSeek-V3.2-W8A8] to model_path [/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8]
2026-02-27T19:11:49.2322228Z (ApiServer_2 pid=186) The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T19:11:49.2382787Z (ApiServer_2 pid=186) The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T19:11:49.2398568Z (ApiServer_2 pid=186) The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T19:11:49.2408962Z (ApiServer_2 pid=186) You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-27T19:11:49.2454863Z (ApiServer_2 pid=186) INFO 02-27 19:11:49 [model.py:529] Resolved architecture: DeepseekV32ForCausalLM
2026-02-27T19:11:49.2477481Z (ApiServer_2 pid=186) INFO 02-27 19:11:49 [model.py:1549] Using max model len 68000
2026-02-27T19:11:49.3564051Z (ApiServer_2 pid=186) WARNING 02-27 19:11:49 [speculative.py:293] method `deepseek_mtp` is deprecated and replaced with mtp.
2026-02-27T19:11:49.3577252Z (ApiServer_2 pid=186) The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T19:11:49.3586479Z (ApiServer_2 pid=186) The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T19:11:49.3595960Z (ApiServer_2 pid=186) You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-27T19:11:49.3638815Z (ApiServer_2 pid=186) INFO 02-27 19:11:49 [model.py:529] Resolved architecture: DeepSeekMTPModel
2026-02-27T19:11:49.3657188Z (ApiServer_2 pid=186) INFO 02-27 19:11:49 [model.py:1549] Using max model len 163840
2026-02-27T19:11:49.3667972Z (ApiServer_2 pid=186) WARNING 02-27 19:11:49 [speculative.py:411] Enabling num_speculative_tokens > 1 will runmultiple times of forward on same MTP layer,which may result in lower acceptance rate
2026-02-27T19:11:49.3678420Z (ApiServer_2 pid=186) INFO 02-27 19:11:49 [scheduler.py:224] Chunked prefill is enabled with max_num_batched_tokens=4096.
2026-02-27T19:11:49.4838959Z (ApiServer_2 pid=186) INFO 02-27 19:11:49 [vllm.py:689] Asynchronous scheduling is enabled.
2026-02-27T19:11:49.4849552Z (ApiServer_2 pid=186) INFO 02-27 19:11:49 [vllm.py:699] Disabling NCCL for DP synchronization when using async scheduling.
2026-02-27T19:11:49.4865185Z (ApiServer_2 pid=186) WARNING 02-27 19:11:49 [platform.py:717] Speculative quantization is set but Ascend automatically uses the main model's quantization method. Resetting to None.
2026-02-27T19:11:49.4874965Z (ApiServer_2 pid=186) WARNING 02-27 19:11:49 [platform.py:758] Ignored parameter 'use_trtllm_ragged_deepseek_prefill'. This is a GPU-specific feature not supported on Ascend. Resetting to False.
2026-02-27T19:11:49.4885241Z (ApiServer_2 pid=186) INFO 02-27 19:11:49 [ascend_config.py:454] Dynamic EPLB is False
2026-02-27T19:11:49.4894621Z (ApiServer_2 pid=186) INFO 02-27 19:11:49 [ascend_config.py:455] The number of redundant experts is 0
2026-02-27T19:11:49.4906242Z (ApiServer_2 pid=186) INFO 02-27 19:11:49 [ascend_config.py:55] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-27T19:11:49.4914940Z (ApiServer_2 pid=186) INFO 02-27 19:11:49 [platform.py:301] FULL_DECODE_ONLY compilation enabled on NPU. use_inductor not supported - using only ACL Graph mode
2026-02-27T19:11:49.4924609Z (ApiServer_2 pid=186) WARNING 02-27 19:11:49 [platform.py:318] [91m
2026-02-27T19:11:49.4933882Z (ApiServer_2 pid=186) WARNING 02-27 19:11:49 [platform.py:318]             **********************************************************************************
2026-02-27T19:11:49.4943216Z (ApiServer_2 pid=186) WARNING 02-27 19:11:49 [platform.py:318]             * WARNING: You have enabled the *full graph* feature.
2026-02-27T19:11:49.4952492Z (ApiServer_2 pid=186) WARNING 02-27 19:11:49 [platform.py:318]             * This is an early experimental stage and may involve various unknown issues.
2026-02-27T19:11:49.4962978Z (ApiServer_2 pid=186) WARNING 02-27 19:11:49 [platform.py:318]             * A known problem is that capturing too many batch sizes can lead to OOM
2026-02-27T19:11:49.4972376Z (ApiServer_2 pid=186) WARNING 02-27 19:11:49 [platform.py:318]             * (Out of Memory) errors or inference hangs. If you encounter such issues,
2026-02-27T19:11:49.4981833Z (ApiServer_2 pid=186) WARNING 02-27 19:11:49 [platform.py:318]             * consider reducing `gpu_memory_utilization` or manually specifying a smaller
2026-02-27T19:11:49.4991360Z (ApiServer_2 pid=186) WARNING 02-27 19:11:49 [platform.py:318]             * batch size for graph capture.
2026-02-27T19:11:49.5001257Z (ApiServer_2 pid=186) WARNING 02-27 19:11:49 [platform.py:318]             * For more details, please refer to:
2026-02-27T19:11:49.5011177Z (ApiServer_2 pid=186) WARNING 02-27 19:11:49 [platform.py:318]             * https://docs.vllm.ai/en/stable/configuration/conserving_memory.html#reduce-cuda-graphs
2026-02-27T19:11:49.5020632Z (ApiServer_2 pid=186) WARNING 02-27 19:11:49 [platform.py:318]             **********************************************************************************[0m
2026-02-27T19:11:49.5029780Z (ApiServer_2 pid=186) WARNING 02-27 19:11:49 [platform.py:318]             
2026-02-27T19:11:49.5039509Z (ApiServer_2 pid=186) INFO 02-27 19:11:49 [platform.py:430] Set PYTORCH_NPU_ALLOC_CONF=expandable_segments:True
2026-02-27T19:11:50.3705528Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-27T19:11:50.3753790Z   warnings.warn(
2026-02-27T19:11:50.3754555Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-27T19:11:50.3755408Z   warnings.warn(
2026-02-27T19:11:52.7052154Z INFO 02-27 19:11:52 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T19:11:52.7058431Z INFO 02-27 19:11:52 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T19:11:52.7068528Z INFO 02-27 19:11:52 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T19:11:52.7126079Z INFO 02-27 19:11:52 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T19:11:53.0219261Z INFO 02-27 19:11:53 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T19:11:53.0223620Z INFO 02-27 19:11:53 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T19:11:53.0233370Z INFO 02-27 19:11:53 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T19:11:53.0288511Z INFO 02-27 19:11:53 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T19:11:53.6807191Z INFO 02-27 19:11:53 [ascend_config.py:454] Dynamic EPLB is False
2026-02-27T19:11:53.6813786Z INFO 02-27 19:11:53 [ascend_config.py:455] The number of redundant experts is 0
2026-02-27T19:11:53.6824596Z INFO 02-27 19:11:53 [ascend_config.py:55] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-27T19:11:53.6835450Z INFO 02-27 19:11:53 [ascend_config.py:454] Dynamic EPLB is False
2026-02-27T19:11:53.6851956Z INFO 02-27 19:11:53 [ascend_config.py:455] The number of redundant experts is 0
2026-02-27T19:11:53.6863292Z INFO 02-27 19:11:53 [ascend_config.py:55] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-27T19:11:54.0424300Z INFO 02-27 19:11:54 [parallel_state.py:1234] world_size=32 rank=0 local_rank=0 distributed_init_method=tcp://10.0.0.210:58249 backend=hccl
2026-02-27T19:11:54.4068095Z INFO 02-27 19:11:54 [parallel_state.py:1234] world_size=32 rank=8 local_rank=0 distributed_init_method=tcp://10.0.0.210:58249 backend=hccl
2026-02-27T19:11:57.7490515Z 2026-02-27 19:11:57,746 - 251 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.16.0+empty: default 1
2026-02-27T19:11:57.7526030Z INFO 02-27 19:11:57 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-27T19:11:57.9105220Z 2026-02-27 19:11:57,908 - 253 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.16.0+empty: default 1
2026-02-27T19:11:57.9140145Z INFO 02-27 19:11:57 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-27T19:11:59.3921278Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-27T19:11:59.3928162Z   warnings.warn(
2026-02-27T19:11:59.5336278Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-27T19:11:59.5341884Z   warnings.warn(
2026-02-27T19:12:01.1903397Z INFO 02-27 19:12:01 [ascend_config.py:454] Dynamic EPLB is False
2026-02-27T19:12:01.1928094Z INFO 02-27 19:12:01 [ascend_config.py:455] The number of redundant experts is 0
2026-02-27T19:12:01.1928909Z INFO 02-27 19:12:01 [ascend_config.py:55] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-27T19:12:01.3284634Z INFO 02-27 19:12:01 [ascend_config.py:454] Dynamic EPLB is False
2026-02-27T19:12:01.3292183Z INFO 02-27 19:12:01 [ascend_config.py:455] The number of redundant experts is 0
2026-02-27T19:12:01.3303504Z INFO 02-27 19:12:01 [ascend_config.py:55] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-27T19:12:01.9998523Z INFO 02-27 19:12:01 [parallel_state.py:1234] world_size=32 rank=9 local_rank=1 distributed_init_method=tcp://10.0.0.210:58249 backend=hccl
2026-02-27T19:12:02.1053899Z INFO 02-27 19:12:02 [parallel_state.py:1234] world_size=32 rank=1 local_rank=1 distributed_init_method=tcp://10.0.0.210:58249 backend=hccl
2026-02-27T19:12:02.4300723Z INFO 02-27 19:12:02 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T19:12:02.4310228Z INFO 02-27 19:12:02 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T19:12:02.4321179Z INFO 02-27 19:12:02 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T19:12:02.4375574Z INFO 02-27 19:12:02 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T19:12:02.5879916Z INFO 02-27 19:12:02 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T19:12:02.5885887Z INFO 02-27 19:12:02 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T19:12:02.5895980Z INFO 02-27 19:12:02 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T19:12:02.5956097Z INFO 02-27 19:12:02 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T19:12:07.4680236Z 2026-02-27 19:12:07,465 - 369 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.16.0+empty: default 1
2026-02-27T19:12:07.4751206Z INFO 02-27 19:12:07 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-27T19:12:07.6845777Z 2026-02-27 19:12:07,682 - 372 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.16.0+empty: default 1
2026-02-27T19:12:07.6884112Z INFO 02-27 19:12:07 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-27T19:12:09.0798673Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-27T19:12:09.0806443Z   warnings.warn(
2026-02-27T19:12:09.3871245Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-27T19:12:09.3877894Z   warnings.warn(
2026-02-27T19:12:10.9183875Z INFO 02-27 19:12:10 [ascend_config.py:454] Dynamic EPLB is False
2026-02-27T19:12:10.9190460Z INFO 02-27 19:12:10 [ascend_config.py:455] The number of redundant experts is 0
2026-02-27T19:12:10.9202056Z INFO 02-27 19:12:10 [ascend_config.py:55] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-27T19:12:11.1820421Z INFO 02-27 19:12:11 [ascend_config.py:454] Dynamic EPLB is False
2026-02-27T19:12:11.1826428Z INFO 02-27 19:12:11 [ascend_config.py:455] The number of redundant experts is 0
2026-02-27T19:12:11.1837271Z INFO 02-27 19:12:11 [ascend_config.py:55] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-27T19:12:11.7025750Z INFO 02-27 19:12:11 [parallel_state.py:1234] world_size=32 rank=10 local_rank=2 distributed_init_method=tcp://10.0.0.210:58249 backend=hccl
2026-02-27T19:12:11.9957954Z INFO 02-27 19:12:11 [parallel_state.py:1234] world_size=32 rank=2 local_rank=2 distributed_init_method=tcp://10.0.0.210:58249 backend=hccl
2026-02-27T19:12:12.2042168Z INFO 02-27 19:12:12 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T19:12:12.2048485Z INFO 02-27 19:12:12 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T19:12:12.2059316Z INFO 02-27 19:12:12 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T19:12:12.2113760Z INFO 02-27 19:12:12 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T19:12:12.3686373Z INFO 02-27 19:12:12 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T19:12:12.3693009Z INFO 02-27 19:12:12 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T19:12:12.3701694Z INFO 02-27 19:12:12 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T19:12:12.3761569Z INFO 02-27 19:12:12 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T19:12:17.2223917Z 2026-02-27 19:12:17,220 - 473 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.16.0+empty: default 1
2026-02-27T19:12:17.2257145Z INFO 02-27 19:12:17 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-27T19:12:17.3855863Z 2026-02-27 19:12:17,383 - 476 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.16.0+empty: default 1
2026-02-27T19:12:17.3892657Z INFO 02-27 19:12:17 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-27T19:12:18.8264942Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-27T19:12:18.8270093Z   warnings.warn(
2026-02-27T19:12:19.0421521Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-27T19:12:19.0427214Z   warnings.warn(
2026-02-27T19:12:20.6124694Z INFO 02-27 19:12:20 [ascend_config.py:454] Dynamic EPLB is False
2026-02-27T19:12:20.6132830Z INFO 02-27 19:12:20 [ascend_config.py:455] The number of redundant experts is 0
2026-02-27T19:12:20.6143795Z INFO 02-27 19:12:20 [ascend_config.py:55] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-27T19:12:20.9731434Z INFO 02-27 19:12:20 [ascend_config.py:454] Dynamic EPLB is False
2026-02-27T19:12:20.9738010Z INFO 02-27 19:12:20 [ascend_config.py:455] The number of redundant experts is 0
2026-02-27T19:12:20.9747702Z INFO 02-27 19:12:20 [ascend_config.py:55] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-27T19:12:21.4064510Z INFO 02-27 19:12:21 [parallel_state.py:1234] world_size=32 rank=11 local_rank=3 distributed_init_method=tcp://10.0.0.210:58249 backend=hccl
2026-02-27T19:12:21.7451067Z INFO 02-27 19:12:21 [parallel_state.py:1234] world_size=32 rank=3 local_rank=3 distributed_init_method=tcp://10.0.0.210:58249 backend=hccl
2026-02-27T19:12:21.9399061Z INFO 02-27 19:12:21 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T19:12:21.9406287Z INFO 02-27 19:12:21 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T19:12:21.9416383Z INFO 02-27 19:12:21 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T19:12:21.9472072Z INFO 02-27 19:12:21 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T19:12:22.1639304Z INFO 02-27 19:12:22 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T19:12:22.1646371Z INFO 02-27 19:12:22 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T19:12:22.1656776Z INFO 02-27 19:12:22 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T19:12:22.1710093Z INFO 02-27 19:12:22 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T19:12:27.0942292Z 2026-02-27 19:12:27,091 - 577 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.16.0+empty: default 1
2026-02-27T19:12:27.0976737Z INFO 02-27 19:12:27 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-27T19:12:27.2114667Z 2026-02-27 19:12:27,209 - 579 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.16.0+empty: default 1
2026-02-27T19:12:27.2152386Z INFO 02-27 19:12:27 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-27T19:12:28.6437455Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-27T19:12:28.6444222Z   warnings.warn(
2026-02-27T19:12:28.8291201Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-27T19:12:28.8295251Z   warnings.warn(
2026-02-27T19:12:30.4444222Z INFO 02-27 19:12:30 [ascend_config.py:454] Dynamic EPLB is False
2026-02-27T19:12:30.4451049Z INFO 02-27 19:12:30 [ascend_config.py:455] The number of redundant experts is 0
2026-02-27T19:12:30.4462211Z INFO 02-27 19:12:30 [ascend_config.py:55] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-27T19:12:30.7006134Z INFO 02-27 19:12:30 [ascend_config.py:454] Dynamic EPLB is False
2026-02-27T19:12:30.7014414Z INFO 02-27 19:12:30 [ascend_config.py:455] The number of redundant experts is 0
2026-02-27T19:12:30.7027037Z INFO 02-27 19:12:30 [ascend_config.py:55] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-27T19:12:31.2062636Z INFO 02-27 19:12:31 [parallel_state.py:1234] world_size=32 rank=12 local_rank=4 distributed_init_method=tcp://10.0.0.210:58249 backend=hccl
2026-02-27T19:12:31.4770206Z INFO 02-27 19:12:31 [parallel_state.py:1234] world_size=32 rank=4 local_rank=4 distributed_init_method=tcp://10.0.0.210:58249 backend=hccl
2026-02-27T19:12:31.8409138Z INFO 02-27 19:12:31 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T19:12:31.8415257Z INFO 02-27 19:12:31 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T19:12:31.8425153Z INFO 02-27 19:12:31 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T19:12:31.8483620Z INFO 02-27 19:12:31 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T19:12:31.9541303Z INFO 02-27 19:12:31 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T19:12:31.9549635Z INFO 02-27 19:12:31 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T19:12:31.9559323Z INFO 02-27 19:12:31 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T19:12:31.9611380Z INFO 02-27 19:12:31 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T19:12:36.8535633Z 2026-02-27 19:12:36,850 - 681 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.16.0+empty: default 1
2026-02-27T19:12:36.8565303Z INFO 02-27 19:12:36 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-27T19:12:36.9441666Z 2026-02-27 19:12:36,942 - 682 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.16.0+empty: default 1
2026-02-27T19:12:36.9476348Z INFO 02-27 19:12:36 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-27T19:12:38.4382304Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-27T19:12:38.4387504Z   warnings.warn(
2026-02-27T19:12:38.5164014Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-27T19:12:38.5170259Z   warnings.warn(
2026-02-27T19:12:40.2069608Z INFO 02-27 19:12:40 [ascend_config.py:454] Dynamic EPLB is False
2026-02-27T19:12:40.2078528Z INFO 02-27 19:12:40 [ascend_config.py:455] The number of redundant experts is 0
2026-02-27T19:12:40.2089760Z INFO 02-27 19:12:40 [ascend_config.py:55] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-27T19:12:40.2814637Z INFO 02-27 19:12:40 [ascend_config.py:454] Dynamic EPLB is False
2026-02-27T19:12:40.2823201Z INFO 02-27 19:12:40 [ascend_config.py:455] The number of redundant experts is 0
2026-02-27T19:12:40.2833386Z INFO 02-27 19:12:40 [ascend_config.py:55] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-27T19:12:41.0063074Z INFO 02-27 19:12:41 [parallel_state.py:1234] world_size=32 rank=13 local_rank=5 distributed_init_method=tcp://10.0.0.210:58249 backend=hccl
2026-02-27T19:12:41.0992993Z INFO 02-27 19:12:41 [parallel_state.py:1234] world_size=32 rank=5 local_rank=5 distributed_init_method=tcp://10.0.0.210:58249 backend=hccl
2026-02-27T19:12:41.5918221Z INFO 02-27 19:12:41 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T19:12:41.5925305Z INFO 02-27 19:12:41 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T19:12:41.5935919Z INFO 02-27 19:12:41 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T19:12:41.6005920Z INFO 02-27 19:12:41 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T19:12:41.7084526Z INFO 02-27 19:12:41 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T19:12:41.7091595Z INFO 02-27 19:12:41 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T19:12:41.7101263Z INFO 02-27 19:12:41 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T19:12:41.7159184Z INFO 02-27 19:12:41 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T19:12:46.8335796Z 2026-02-27 19:12:46,831 - 785 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.16.0+empty: default 1
2026-02-27T19:12:46.8369957Z INFO 02-27 19:12:46 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-27T19:12:46.9003697Z 2026-02-27 19:12:46,898 - 786 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.16.0+empty: default 1
2026-02-27T19:12:46.9045191Z INFO 02-27 19:12:46 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-27T19:12:48.4869604Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-27T19:12:48.4875457Z   warnings.warn(
2026-02-27T19:12:48.5300687Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-27T19:12:48.5307455Z   warnings.warn(
2026-02-27T19:12:50.2849617Z INFO 02-27 19:12:50 [ascend_config.py:454] Dynamic EPLB is False
2026-02-27T19:12:50.2856986Z INFO 02-27 19:12:50 [ascend_config.py:455] The number of redundant experts is 0
2026-02-27T19:12:50.2867442Z INFO 02-27 19:12:50 [ascend_config.py:55] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-27T19:12:50.5241744Z INFO 02-27 19:12:50 [ascend_config.py:454] Dynamic EPLB is False
2026-02-27T19:12:50.5248543Z INFO 02-27 19:12:50 [ascend_config.py:455] The number of redundant experts is 0
2026-02-27T19:12:50.5259298Z INFO 02-27 19:12:50 [ascend_config.py:55] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-27T19:12:51.0778971Z INFO 02-27 19:12:51 [parallel_state.py:1234] world_size=32 rank=14 local_rank=6 distributed_init_method=tcp://10.0.0.210:58249 backend=hccl
2026-02-27T19:12:51.3209900Z INFO 02-27 19:12:51 [parallel_state.py:1234] world_size=32 rank=6 local_rank=6 distributed_init_method=tcp://10.0.0.210:58249 backend=hccl
2026-02-27T19:12:51.3967724Z INFO 02-27 19:12:51 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T19:12:51.3976410Z INFO 02-27 19:12:51 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T19:12:51.3986416Z INFO 02-27 19:12:51 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T19:12:51.4042363Z INFO 02-27 19:12:51 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T19:12:51.4088805Z INFO 02-27 19:12:51 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T19:12:51.4098802Z INFO 02-27 19:12:51 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T19:12:51.4108990Z INFO 02-27 19:12:51 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T19:12:51.4140769Z INFO 02-27 19:12:51 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T19:12:56.4707177Z 2026-02-27 19:12:56,464 - 889 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.16.0+empty: default 1
2026-02-27T19:12:56.4709778Z INFO 02-27 19:12:56 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-27T19:12:56.5029767Z 2026-02-27 19:12:56,500 - 890 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.16.0+empty: default 1
2026-02-27T19:12:56.5057688Z INFO 02-27 19:12:56 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-27T19:12:58.0492716Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-27T19:12:58.0497459Z   warnings.warn(
2026-02-27T19:12:58.0630850Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-27T19:12:58.0639133Z   warnings.warn(
2026-02-27T19:12:59.8244310Z INFO 02-27 19:12:59 [ascend_config.py:454] Dynamic EPLB is False
2026-02-27T19:12:59.8253877Z INFO 02-27 19:12:59 [ascend_config.py:455] The number of redundant experts is 0
2026-02-27T19:12:59.8265211Z INFO 02-27 19:12:59 [ascend_config.py:55] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-27T19:12:59.8420380Z INFO 02-27 19:12:59 [ascend_config.py:454] Dynamic EPLB is False
2026-02-27T19:12:59.8430743Z INFO 02-27 19:12:59 [ascend_config.py:455] The number of redundant experts is 0
2026-02-27T19:12:59.8441283Z INFO 02-27 19:12:59 [ascend_config.py:55] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-27T19:13:00.6400083Z INFO 02-27 19:13:00 [parallel_state.py:1234] world_size=32 rank=15 local_rank=7 distributed_init_method=tcp://10.0.0.210:58249 backend=hccl
2026-02-27T19:13:00.6472317Z INFO 02-27 19:13:00 [parallel_state.py:1234] world_size=32 rank=7 local_rank=7 distributed_init_method=tcp://10.0.0.210:58249 backend=hccl
2026-02-27T19:13:00.6849317Z [Gloo] Rank 0 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-27T19:13:00.6862103Z [Gloo] Rank 7 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-27T19:13:00.6871362Z [Gloo] Rank 6 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-27T19:13:00.6881467Z [Gloo] Rank 4 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-27T19:13:00.6890361Z [Gloo] Rank 15 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-27T19:13:00.6900961Z [Gloo] Rank 5 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-27T19:13:00.6913990Z [Gloo] Rank 3 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-27T19:13:00.6922873Z [Gloo] Rank 2 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-27T19:13:00.7536686Z [Gloo] Rank 1 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-27T19:13:00.7559144Z [Gloo] Rank 9 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-27T19:13:00.7571635Z [Gloo] Rank 10 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-27T19:13:00.7579947Z [Gloo] Rank 13 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-27T19:13:00.7588131Z [Gloo] Rank 14 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-27T19:13:00.7851459Z [Gloo] Rank 8 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-27T19:13:00.7891861Z [Gloo] Rank 12 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-27T19:13:00.7911477Z [Gloo] Rank 11 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-27T19:13:00.9564036Z [Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-27T19:13:00.9581182Z [Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-27T19:13:00.9590520Z [Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-27T19:13:00.9599670Z [Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-27T19:13:00.9609238Z [Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-27T19:13:00.9618933Z [Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-27T19:13:00.9627848Z [Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-27T19:13:00.9637645Z [Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-27T19:13:00.9647385Z [Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-27T19:13:00.9656836Z [Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-27T19:13:00.9666960Z [Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-27T19:13:00.9676684Z [Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-27T19:13:00.9686877Z [Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-27T19:13:00.9695915Z [Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-27T19:13:00.9705455Z [Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-27T19:13:00.9714539Z [Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-27T19:13:00.9744818Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T19:13:00.9771288Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T19:13:00.9771852Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T19:13:00.9774432Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T19:13:00.9784175Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T19:13:00.9794479Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T19:13:00.9805068Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T19:13:00.9815115Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T19:13:00.9826291Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T19:13:00.9836394Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T19:13:00.9847283Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T19:13:00.9857246Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T19:13:00.9867320Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T19:13:00.9877483Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T19:13:00.9898140Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T19:13:00.9927433Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T19:13:00.9935976Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T19:13:00.9945594Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T19:13:00.9956266Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T19:13:00.9966058Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T19:13:00.9975477Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T19:13:00.9985097Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T19:13:00.9995321Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T19:13:01.0005882Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T19:13:01.0257586Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T19:13:01.0321254Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T19:13:01.0322080Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T19:13:01.0322646Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T19:13:01.0328471Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T19:13:01.0338443Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T19:13:01.0347903Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T19:13:01.0377785Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T19:13:01.0378211Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T19:13:01.0378703Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T19:13:01.0385269Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T19:13:01.0394706Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T19:13:01.0404964Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T19:13:01.0415185Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T19:13:01.0424828Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T19:13:01.0434716Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T19:13:01.0445479Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T19:13:01.0455065Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T19:13:01.0464394Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T19:13:01.0473752Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T19:13:01.0483378Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T19:13:01.0493250Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T19:13:01.0503120Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T19:13:01.0512658Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T19:13:01.0522319Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-27T19:13:01.0532198Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-27T19:13:01.0541942Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-27T19:13:01.0551617Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-27T19:13:01.0610720Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-27T19:13:01.0619587Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-27T19:13:01.0628755Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-27T19:13:01.0638646Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-27T19:13:01.0648369Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-27T19:13:01.0657741Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-27T19:13:01.0668773Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-27T19:13:01.0676892Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-27T19:13:01.0686918Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-27T19:13:01.0696707Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-27T19:13:01.0705978Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-27T19:13:01.0715164Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-27T19:13:01.0779897Z [Gloo] Rank 0 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-27T19:13:01.0806102Z INFO 02-27 19:13:01 [parallel_state.py:1445] rank 0 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
2026-02-27T19:13:01.1623362Z [Gloo] Rank 4 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-27T19:13:01.1640992Z [Gloo] Rank 9 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-27T19:13:01.1649428Z [Gloo] Rank 12 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-27T19:13:01.1660516Z INFO 02-27 19:13:01 [parallel_state.py:1445] rank 4 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 4, EP rank 4
2026-02-27T19:13:01.1668393Z [Gloo] Rank 8 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-27T19:13:01.1678632Z INFO 02-27 19:13:01 [parallel_state.py:1445] rank 9 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 1, EP rank 9
2026-02-27T19:13:01.1688160Z INFO 02-27 19:13:01 [parallel_state.py:1445] rank 12 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 4, EP rank 12
2026-02-27T19:13:01.1697711Z INFO 02-27 19:13:01 [parallel_state.py:1445] rank 8 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 0, EP rank 8
2026-02-27T19:13:01.1707323Z [Gloo] Rank 14 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-27T19:13:01.1716408Z INFO 02-27 19:13:01 [parallel_state.py:1445] rank 14 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 6, EP rank 14
2026-02-27T19:13:01.1726937Z [Gloo] Rank 6 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-27T19:13:01.1736579Z [Gloo] Rank 5 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-27T19:13:01.1784251Z [Gloo] Rank 1 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-27T19:13:01.1784876Z INFO 02-27 19:13:01 [parallel_state.py:1445] rank 6 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 6, EP rank 6
2026-02-27T19:13:01.1785509Z [Gloo] Rank 13 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-27T19:13:01.1786091Z INFO 02-27 19:13:01 [parallel_state.py:1445] rank 1 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 1, EP rank 1
2026-02-27T19:13:01.1791012Z INFO 02-27 19:13:01 [parallel_state.py:1445] rank 5 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 5, EP rank 5
2026-02-27T19:13:01.1800786Z INFO 02-27 19:13:01 [parallel_state.py:1445] rank 13 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 5, EP rank 13
2026-02-27T19:13:01.2265831Z [Gloo] Rank 2 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-27T19:13:01.2285079Z INFO 02-27 19:13:01 [parallel_state.py:1445] rank 2 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 2, EP rank 2
2026-02-27T19:13:01.2303618Z [Gloo] Rank 11 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-27T19:13:01.2313012Z [Gloo] Rank 3 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-27T19:13:01.2322259Z [Gloo] Rank 15 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-27T19:13:01.2332270Z [Gloo] Rank 7 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-27T19:13:01.2341638Z INFO 02-27 19:13:01 [parallel_state.py:1445] rank 11 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 3, EP rank 11
2026-02-27T19:13:01.2350764Z INFO 02-27 19:13:01 [parallel_state.py:1445] rank 3 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 3, EP rank 3
2026-02-27T19:13:01.2360324Z INFO 02-27 19:13:01 [parallel_state.py:1445] rank 15 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 7, EP rank 15
2026-02-27T19:13:01.2370604Z INFO 02-27 19:13:01 [parallel_state.py:1445] rank 7 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 7, EP rank 7
2026-02-27T19:13:01.2458780Z [Gloo] Rank 10 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-27T19:13:01.2479115Z INFO 02-27 19:13:01 [parallel_state.py:1445] rank 10 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 2, EP rank 10
2026-02-27T19:13:01.2656992Z [Gloo] Rank 0 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-27T19:13:01.2679031Z [Gloo] Rank 9 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-27T19:13:01.2688225Z [Gloo] Rank 2 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-27T19:13:01.2697212Z [Gloo] Rank 8 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-27T19:13:01.2706650Z [Gloo] Rank 5 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-27T19:13:01.2715599Z [Gloo] Rank 1 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-27T19:13:01.2725695Z [Gloo] Rank 11 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-27T19:13:01.2734937Z [Gloo] Rank 15 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-27T19:13:01.2744628Z [Gloo] Rank 14 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-27T19:13:01.2754872Z [Gloo] Rank 13 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-27T19:13:01.2764597Z [Gloo] Rank 6 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-27T19:13:01.2774286Z [Gloo] Rank 10 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-27T19:13:01.2783805Z [Gloo] Rank 3 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-27T19:13:01.2793636Z [Gloo] Rank 4 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-27T19:13:01.2803245Z [Gloo] Rank 7 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-27T19:13:01.2813685Z [Gloo] Rank 12 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-27T19:13:01.2848403Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-27T19:13:01.2858695Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-27T19:13:01.2868261Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-27T19:13:01.2878360Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-27T19:13:01.2888244Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-27T19:13:01.2898363Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-27T19:13:01.2907783Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-27T19:13:01.2917339Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-27T19:13:01.2927592Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-27T19:13:01.2937529Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-27T19:13:01.2947084Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-27T19:13:01.2956877Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-27T19:13:01.2967538Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-27T19:13:01.2977328Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-27T19:13:01.2987119Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-27T19:13:01.2997095Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-27T19:13:04.5535524Z INFO 02-27 19:13:04 [cpu_binding.py:297] The CPU allocation plan is as follows:
2026-02-27T19:13:04.5545654Z INFO 02-27 19:13:04 [cpu_binding.py:302] NPU0: main=[2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37]  acl=[38]  release=[[39]]
2026-02-27T19:13:04.6164100Z INFO 02-27 19:13:04 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T19:13:04.6726341Z WARNING 02-27 19:13:04 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T19:13:04.7113242Z WARNING 02-27 19:13:04 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T19:13:04.7428261Z INFO 02-27 19:13:04 [cpu_binding.py:297] The CPU allocation plan is as follows:
2026-02-27T19:13:04.7437682Z INFO 02-27 19:13:04 [cpu_binding.py:302] NPU8: main=[2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37]  acl=[38]  release=[[39]]
2026-02-27T19:13:04.7637818Z (Worker_DP0_TP0_EP0 pid=202) INFO 02-27 19:13:04 [model_runner_v1.py:2352] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-27T19:13:04.8018490Z INFO 02-27 19:13:04 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T19:13:04.8482402Z WARNING 02-27 19:13:04 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T19:13:04.8658192Z WARNING 02-27 19:13:04 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T19:13:04.8702599Z (Worker_DP1_TP0_EP8 pid=201) INFO 02-27 19:13:04 [model_runner_v1.py:2352] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-27T19:13:04.9046532Z INFO 02-27 19:13:04 [cpu_binding.py:297] The CPU allocation plan is as follows:
2026-02-27T19:13:04.9055388Z INFO 02-27 19:13:04 [cpu_binding.py:302] NPU2: main=[82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117]  acl=[118]  release=[[119]]
2026-02-27T19:13:04.9590586Z INFO 02-27 19:13:04 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T19:13:04.9621643Z INFO 02-27 19:13:04 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T19:13:05.0031740Z WARNING 02-27 19:13:05 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T19:13:05.0213911Z WARNING 02-27 19:13:05 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T19:13:05.0259709Z (Worker_DP0_TP2_EP2 pid=372) INFO 02-27 19:13:05 [model_runner_v1.py:2352] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-27T19:13:05.1189741Z INFO 02-27 19:13:05 [cpu_binding.py:297] The CPU allocation plan is as follows:
2026-02-27T19:13:05.1198921Z INFO 02-27 19:13:05 [cpu_binding.py:302] NPU12: main=[162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197]  acl=[198]  release=[[199]]
2026-02-27T19:13:05.1748664Z INFO 02-27 19:13:05 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T19:13:05.1768917Z INFO 02-27 19:13:05 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T19:13:05.2150865Z WARNING 02-27 19:13:05 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T19:13:05.2389591Z WARNING 02-27 19:13:05 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T19:13:05.2458080Z (Worker_DP1_TP4_EP12 pid=577) INFO 02-27 19:13:05 [model_runner_v1.py:2352] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-27T19:13:05.2536907Z (Worker_DP1_TP0_EP8 pid=201) [2026-02-27 19:13:05] INFO modelslim_config.py:296: Using the vLLM Ascend modelslim Quantization now!
2026-02-27T19:13:05.3185811Z INFO 02-27 19:13:05 [cpu_binding.py:297] The CPU allocation plan is as follows:
2026-02-27T19:13:05.3194817Z INFO 02-27 19:13:05 [cpu_binding.py:302] NPU14: main=[242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277]  acl=[278]  release=[[279]]
2026-02-27T19:13:05.3687123Z INFO 02-27 19:13:05 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T19:13:05.3709807Z INFO 02-27 19:13:05 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T19:13:05.4065685Z WARNING 02-27 19:13:05 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T19:13:05.4229118Z (Worker_DP1_TP0_EP8 pid=201) INFO 02-27 19:13:05 [layer.py:481] [EP Rank 8/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->64, 1->65, 2->66, 3->67, 4->68, 5->69, 6->70, 7->71.
2026-02-27T19:13:05.4261513Z WARNING 02-27 19:13:05 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T19:13:05.4304683Z (Worker_DP1_TP6_EP14 pid=785) INFO 02-27 19:13:05 [model_runner_v1.py:2352] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-27T19:13:05.4515747Z INFO 02-27 19:13:05 [cpu_binding.py:297] The CPU allocation plan is as follows:
2026-02-27T19:13:05.4526691Z INFO 02-27 19:13:05 [cpu_binding.py:302] NPU1: main=[42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77]  acl=[78]  release=[[79]]
2026-02-27T19:13:05.4797359Z (Worker_DP0_TP0_EP0 pid=202) [2026-02-27 19:13:05] INFO modelslim_config.py:296: Using the vLLM Ascend modelslim Quantization now!
2026-02-27T19:13:05.5091053Z INFO 02-27 19:13:05 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T19:13:05.5120089Z INFO 02-27 19:13:05 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T19:13:05.5473162Z WARNING 02-27 19:13:05 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T19:13:05.5645313Z WARNING 02-27 19:13:05 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T19:13:05.5693531Z (Worker_DP0_TP1_EP1 pid=253) INFO 02-27 19:13:05 [model_runner_v1.py:2352] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-27T19:13:05.6218339Z (Worker_DP0_TP0_EP0 pid=202) INFO 02-27 19:13:05 [layer.py:481] [EP Rank 0/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->0, 1->1, 2->2, 3->3, 4->4, 5->5, 6->6, 7->7.
2026-02-27T19:13:05.6884927Z (Worker_DP0_TP2_EP2 pid=372) [2026-02-27 19:13:05] INFO modelslim_config.py:296: Using the vLLM Ascend modelslim Quantization now!
2026-02-27T19:13:05.6910186Z INFO 02-27 19:13:05 [cpu_binding.py:297] The CPU allocation plan is as follows:
2026-02-27T19:13:05.6920358Z INFO 02-27 19:13:05 [cpu_binding.py:302] NPU13: main=[202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237]  acl=[238]  release=[[239]]
2026-02-27T19:13:05.7488494Z INFO 02-27 19:13:05 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T19:13:05.7513925Z INFO 02-27 19:13:05 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T19:13:05.7888101Z (Worker_DP1_TP6_EP14 pid=785) [2026-02-27 19:13:05] INFO modelslim_config.py:296: Using the vLLM Ascend modelslim Quantization now!
2026-02-27T19:13:05.8053619Z (Worker_DP0_TP2_EP2 pid=372) INFO 02-27 19:13:05 [layer.py:481] [EP Rank 2/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->16, 1->17, 2->18, 3->19, 4->20, 5->21, 6->22, 7->23.
2026-02-27T19:13:05.8077858Z WARNING 02-27 19:13:05 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T19:13:05.8360761Z WARNING 02-27 19:13:05 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T19:13:05.8469403Z (Worker_DP1_TP5_EP13 pid=681) INFO 02-27 19:13:05 [model_runner_v1.py:2352] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-27T19:13:05.9049379Z (Worker_DP1_TP6_EP14 pid=785) INFO 02-27 19:13:05 [layer.py:481] [EP Rank 14/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->112, 1->113, 2->114, 3->115, 4->116, 5->117, 6->118, 7->119.
2026-02-27T19:13:05.9289199Z (Worker_DP1_TP4_EP12 pid=577) [2026-02-27 19:13:05] INFO modelslim_config.py:296: Using the vLLM Ascend modelslim Quantization now!
2026-02-27T19:13:05.9479055Z (Worker_DP0_TP1_EP1 pid=253) [2026-02-27 19:13:05] INFO modelslim_config.py:296: Using the vLLM Ascend modelslim Quantization now!
2026-02-27T19:13:06.0448376Z (Worker_DP1_TP4_EP12 pid=577) INFO 02-27 19:13:06 [layer.py:481] [EP Rank 12/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->96, 1->97, 2->98, 3->99, 4->100, 5->101, 6->102, 7->103.
2026-02-27T19:13:06.0566514Z (Worker_DP0_TP1_EP1 pid=253) INFO 02-27 19:13:06 [layer.py:481] [EP Rank 1/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->8, 1->9, 2->10, 3->11, 4->12, 5->13, 6->14, 7->15.
2026-02-27T19:13:06.2222688Z INFO 02-27 19:13:06 [cpu_binding.py:297] The CPU allocation plan is as follows:
2026-02-27T19:13:06.2230333Z INFO 02-27 19:13:06 [cpu_binding.py:302] NPU9: main=[42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77]  acl=[78]  release=[[79]]
2026-02-27T19:13:06.2689565Z INFO 02-27 19:13:06 [cpu_binding.py:297] The CPU allocation plan is as follows:
2026-02-27T19:13:06.2698704Z INFO 02-27 19:13:06 [cpu_binding.py:302] NPU7: main=[282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317]  acl=[318]  release=[[319]]
2026-02-27T19:13:06.2783506Z INFO 02-27 19:13:06 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T19:13:06.2810892Z INFO 02-27 19:13:06 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T19:13:06.3007196Z INFO 02-27 19:13:06 [cpu_binding.py:297] The CPU allocation plan is as follows:
2026-02-27T19:13:06.3016579Z INFO 02-27 19:13:06 [cpu_binding.py:302] NPU5: main=[202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237]  acl=[238]  release=[[239]]
2026-02-27T19:13:06.3179972Z WARNING 02-27 19:13:06 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T19:13:06.3371697Z INFO 02-27 19:13:06 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T19:13:06.3393305Z WARNING 02-27 19:13:06 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T19:13:06.3414720Z INFO 02-27 19:13:06 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T19:13:06.3432958Z (Worker_DP1_TP1_EP9 pid=251) INFO 02-27 19:13:06 [model_runner_v1.py:2352] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-27T19:13:06.3675238Z INFO 02-27 19:13:06 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T19:13:06.3705377Z INFO 02-27 19:13:06 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T19:13:06.3815035Z WARNING 02-27 19:13:06 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T19:13:06.3834473Z INFO 02-27 19:13:06 [cpu_binding.py:297] The CPU allocation plan is as follows:
2026-02-27T19:13:06.3845499Z INFO 02-27 19:13:06 [cpu_binding.py:302] NPU10: main=[82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117]  acl=[118]  release=[[119]]
2026-02-27T19:13:06.4051288Z WARNING 02-27 19:13:06 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T19:13:06.4105953Z (Worker_DP0_TP7_EP7 pid=890) INFO 02-27 19:13:06 [model_runner_v1.py:2352] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-27T19:13:06.4213161Z WARNING 02-27 19:13:06 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T19:13:06.4305497Z INFO 02-27 19:13:06 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T19:13:06.4325629Z INFO 02-27 19:13:06 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T19:13:06.4459305Z WARNING 02-27 19:13:06 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T19:13:06.4523193Z (Worker_DP0_TP5_EP5 pid=682) INFO 02-27 19:13:06 [model_runner_v1.py:2352] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-27T19:13:06.4673921Z WARNING 02-27 19:13:06 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T19:13:06.4855143Z WARNING 02-27 19:13:06 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T19:13:06.4895684Z (Worker_DP1_TP2_EP10 pid=369) INFO 02-27 19:13:06 [model_runner_v1.py:2352] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-27T19:13:06.6623970Z (Worker_DP1_TP5_EP13 pid=681) [2026-02-27 19:13:06] INFO modelslim_config.py:296: Using the vLLM Ascend modelslim Quantization now!
2026-02-27T19:13:06.7517666Z (Worker_DP1_TP1_EP9 pid=251) [2026-02-27 19:13:06] INFO modelslim_config.py:296: Using the vLLM Ascend modelslim Quantization now!
2026-02-27T19:13:06.7830761Z (Worker_DP1_TP5_EP13 pid=681) INFO 02-27 19:13:06 [layer.py:481] [EP Rank 13/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->104, 1->105, 2->106, 3->107, 4->108, 5->109, 6->110, 7->111.
2026-02-27T19:13:06.8762256Z (Worker_DP1_TP1_EP9 pid=251) INFO 02-27 19:13:06 [layer.py:481] [EP Rank 9/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->72, 1->73, 2->74, 3->75, 4->76, 5->77, 6->78, 7->79.
2026-02-27T19:13:06.9643893Z INFO 02-27 19:13:06 [cpu_binding.py:297] The CPU allocation plan is as follows:
2026-02-27T19:13:06.9651860Z INFO 02-27 19:13:06 [cpu_binding.py:302] NPU11: main=[122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157]  acl=[158]  release=[[159]]
2026-02-27T19:13:06.9801517Z INFO 02-27 19:13:06 [cpu_binding.py:297] The CPU allocation plan is as follows:
2026-02-27T19:13:06.9811085Z INFO 02-27 19:13:06 [cpu_binding.py:302] NPU4: main=[162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197]  acl=[198]  release=[[199]]
2026-02-27T19:13:07.0132139Z INFO 02-27 19:13:07 [cpu_binding.py:297] The CPU allocation plan is as follows:
2026-02-27T19:13:07.0141974Z INFO 02-27 19:13:07 [cpu_binding.py:302] NPU6: main=[242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277]  acl=[278]  release=[[279]]
2026-02-27T19:13:07.0286085Z INFO 02-27 19:13:07 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T19:13:07.0312756Z INFO 02-27 19:13:07 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T19:13:07.0620602Z INFO 02-27 19:13:07 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T19:13:07.0642396Z INFO 02-27 19:13:07 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T19:13:07.0661342Z WARNING 02-27 19:13:07 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T19:13:07.0680994Z (Worker_DP1_TP2_EP10 pid=369) [2026-02-27 19:13:07] INFO modelslim_config.py:296: Using the vLLM Ascend modelslim Quantization now!
2026-02-27T19:13:07.0718435Z INFO 02-27 19:13:07 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T19:13:07.0738846Z INFO 02-27 19:13:07 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T19:13:07.0844623Z WARNING 02-27 19:13:07 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T19:13:07.0894183Z (Worker_DP1_TP3_EP11 pid=473) INFO 02-27 19:13:07 [model_runner_v1.py:2352] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-27T19:13:07.1068032Z WARNING 02-27 19:13:07 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T19:13:07.1278684Z WARNING 02-27 19:13:07 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T19:13:07.1317033Z (Worker_DP0_TP4_EP4 pid=579) INFO 02-27 19:13:07 [model_runner_v1.py:2352] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-27T19:13:07.1519927Z WARNING 02-27 19:13:07 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T19:13:07.1723998Z WARNING 02-27 19:13:07 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T19:13:07.1771892Z (Worker_DP0_TP6_EP6 pid=786) INFO 02-27 19:13:07 [model_runner_v1.py:2352] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-27T19:13:07.1876963Z (Worker_DP1_TP2_EP10 pid=369) INFO 02-27 19:13:07 [layer.py:481] [EP Rank 10/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->80, 1->81, 2->82, 3->83, 4->84, 5->85, 6->86, 7->87.
2026-02-27T19:13:07.3316941Z INFO 02-27 19:13:07 [cpu_binding.py:297] The CPU allocation plan is as follows:
2026-02-27T19:13:07.3325386Z INFO 02-27 19:13:07 [cpu_binding.py:302] NPU3: main=[122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157]  acl=[158]  release=[[159]]
2026-02-27T19:13:07.3528794Z INFO 02-27 19:13:07 [cpu_binding.py:297] The CPU allocation plan is as follows:
2026-02-27T19:13:07.3536278Z INFO 02-27 19:13:07 [cpu_binding.py:302] NPU15: main=[282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317]  acl=[318]  release=[[319]]
2026-02-27T19:13:07.4076830Z INFO 02-27 19:13:07 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T19:13:07.4102126Z INFO 02-27 19:13:07 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T19:13:07.4155112Z INFO 02-27 19:13:07 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T19:13:07.4179544Z INFO 02-27 19:13:07 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T19:13:07.4547603Z WARNING 02-27 19:13:07 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T19:13:07.4730831Z WARNING 02-27 19:13:07 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T19:13:07.4775419Z (Worker_DP0_TP3_EP3 pid=476) INFO 02-27 19:13:07 [model_runner_v1.py:2352] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-27T19:13:07.4823696Z WARNING 02-27 19:13:07 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T19:13:07.4860474Z (Worker_DP0_TP5_EP5 pid=682) [2026-02-27 19:13:07] INFO modelslim_config.py:296: Using the vLLM Ascend modelslim Quantization now!
2026-02-27T19:13:07.5050602Z WARNING 02-27 19:13:07 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T19:13:07.5103419Z (Worker_DP1_TP7_EP15 pid=889) INFO 02-27 19:13:07 [model_runner_v1.py:2352] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-27T19:13:07.5453557Z (Worker_DP0_TP7_EP7 pid=890) [2026-02-27 19:13:07] INFO modelslim_config.py:296: Using the vLLM Ascend modelslim Quantization now!
2026-02-27T19:13:07.5973552Z (Worker_DP0_TP5_EP5 pid=682) INFO 02-27 19:13:07 [layer.py:481] [EP Rank 5/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->40, 1->41, 2->42, 3->43, 4->44, 5->45, 6->46, 7->47.
2026-02-27T19:13:07.6738806Z (Worker_DP0_TP7_EP7 pid=890) INFO 02-27 19:13:07 [layer.py:481] [EP Rank 7/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->56, 1->57, 2->58, 3->59, 4->60, 5->61, 6->62, 7->63.
2026-02-27T19:13:07.7210495Z (Worker_DP0_TP4_EP4 pid=579) [2026-02-27 19:13:07] INFO modelslim_config.py:296: Using the vLLM Ascend modelslim Quantization now!
2026-02-27T19:13:07.7752352Z (Worker_DP1_TP3_EP11 pid=473) [2026-02-27 19:13:07] INFO modelslim_config.py:296: Using the vLLM Ascend modelslim Quantization now!
2026-02-27T19:13:07.8223908Z (Worker_DP0_TP6_EP6 pid=786) [2026-02-27 19:13:07] INFO modelslim_config.py:296: Using the vLLM Ascend modelslim Quantization now!
2026-02-27T19:13:07.8281158Z (Worker_DP0_TP4_EP4 pid=579) INFO 02-27 19:13:07 [layer.py:481] [EP Rank 4/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->32, 1->33, 2->34, 3->35, 4->36, 5->37, 6->38, 7->39.
2026-02-27T19:13:07.8919557Z (Worker_DP1_TP3_EP11 pid=473) INFO 02-27 19:13:07 [layer.py:481] [EP Rank 11/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->88, 1->89, 2->90, 3->91, 4->92, 5->93, 6->94, 7->95.
2026-02-27T19:13:07.9346354Z (Worker_DP0_TP6_EP6 pid=786) INFO 02-27 19:13:07 [layer.py:481] [EP Rank 6/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->48, 1->49, 2->50, 3->51, 4->52, 5->53, 6->54, 7->55.
2026-02-27T19:13:08.1264163Z (Worker_DP0_TP3_EP3 pid=476) [2026-02-27 19:13:08] INFO modelslim_config.py:296: Using the vLLM Ascend modelslim Quantization now!
2026-02-27T19:13:08.2380952Z (Worker_DP0_TP3_EP3 pid=476) INFO 02-27 19:13:08 [layer.py:481] [EP Rank 3/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->24, 1->25, 2->26, 3->27, 4->28, 5->29, 6->30, 7->31.
2026-02-27T19:13:08.2837378Z (Worker_DP1_TP7_EP15 pid=889) [2026-02-27 19:13:08] INFO modelslim_config.py:296: Using the vLLM Ascend modelslim Quantization now!
2026-02-27T19:13:08.3946833Z (Worker_DP1_TP7_EP15 pid=889) INFO 02-27 19:13:08 [layer.py:481] [EP Rank 15/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->120, 1->121, 2->122, 3->123, 4->124, 5->125, 6->126, 7->127.
2026-02-27T19:13:09.0376330Z (Worker_DP1_TP1_EP9 pid=251) /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-02-27T19:13:09.0381047Z (Worker_DP1_TP1_EP9 pid=251)   return func(*args, **kwargs)
2026-02-27T19:13:09.0400779Z (Worker_DP0_TP1_EP1 pid=253) /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-02-27T19:13:09.0409144Z (Worker_DP0_TP1_EP1 pid=253)   return func(*args, **kwargs)
2026-02-27T19:13:09.0425065Z (Worker_DP0_TP7_EP7 pid=890) /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-02-27T19:13:09.0433931Z (Worker_DP0_TP7_EP7 pid=890)   return func(*args, **kwargs)
2026-02-27T19:13:09.0445061Z (Worker_DP0_TP2_EP2 pid=372) /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-02-27T19:13:09.0453806Z (Worker_DP0_TP2_EP2 pid=372)   return func(*args, **kwargs)
2026-02-27T19:13:09.0464547Z (Worker_DP1_TP3_EP11 pid=473) /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-02-27T19:13:09.0472948Z (Worker_DP1_TP3_EP11 pid=473)   return func(*args, **kwargs)
2026-02-27T19:13:09.0563061Z (Worker_DP1_TP4_EP12 pid=577) /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-02-27T19:13:09.0570579Z (Worker_DP1_TP4_EP12 pid=577)   return func(*args, **kwargs)
2026-02-27T19:13:09.0862376Z (Worker_DP1_TP0_EP8 pid=201) /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-02-27T19:13:09.0869271Z (Worker_DP1_TP0_EP8 pid=201)   return func(*args, **kwargs)
2026-02-27T19:13:09.0954441Z (Worker_DP0_TP6_EP6 pid=786) /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-02-27T19:13:09.0962797Z (Worker_DP0_TP6_EP6 pid=786)   return func(*args, **kwargs)
2026-02-27T19:13:09.1008657Z (Worker_DP1_TP7_EP15 pid=889) /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-02-27T19:13:09.1017339Z (Worker_DP1_TP7_EP15 pid=889)   return func(*args, **kwargs)
2026-02-27T19:13:09.1120611Z (Worker_DP0_TP7_EP7 pid=890) INFO 02-27 19:13:09 [fused_moe.py:293] [EP Rank 7/32] Expert parallelism is enabled. Local/global number of experts: 8/256. Experts local to global index map: 0->56, 1->57, 2->58, 3->59, 4->60, 5->61, 6->62, 7->63.
2026-02-27T19:13:09.1139830Z (Worker_DP1_TP3_EP11 pid=473) INFO 02-27 19:13:09 [fused_moe.py:293] [EP Rank 11/32] Expert parallelism is enabled. Local/global number of experts: 8/256. Experts local to global index map: 0->88, 1->89, 2->90, 3->91, 4->92, 5->93, 6->94, 7->95.
2026-02-27T19:13:09.1296134Z (Worker_DP1_TP1_EP9 pid=251) INFO 02-27 19:13:09 [fused_moe.py:293] [EP Rank 9/32] Expert parallelism is enabled. Local/global number of experts: 8/256. Experts local to global index map: 0->72, 1->73, 2->74, 3->75, 4->76, 5->77, 6->78, 7->79.
2026-02-27T19:13:09.1347034Z (Worker_DP0_TP1_EP1 pid=253) INFO 02-27 19:13:09 [fused_moe.py:293] [EP Rank 1/32] Expert parallelism is enabled. Local/global number of experts: 8/256. Experts local to global index map: 0->8, 1->9, 2->10, 3->11, 4->12, 5->13, 6->14, 7->15.
2026-02-27T19:13:09.1370611Z (Worker_DP0_TP0_EP0 pid=202) /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-02-27T19:13:09.1380099Z (Worker_DP0_TP0_EP0 pid=202)   return func(*args, **kwargs)
2026-02-27T19:13:09.1418760Z (Worker_DP1_TP0_EP8 pid=201) INFO 02-27 19:13:09 [fused_moe.py:293] [EP Rank 8/32] Expert parallelism is enabled. Local/global number of experts: 8/256. Experts local to global index map: 0->64, 1->65, 2->66, 3->67, 4->68, 5->69, 6->70, 7->71.
2026-02-27T19:13:09.1512413Z (Worker_DP0_TP5_EP5 pid=682) /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-02-27T19:13:09.1520739Z (Worker_DP0_TP5_EP5 pid=682)   return func(*args, **kwargs)
2026-02-27T19:13:09.1564879Z (Worker_DP0_TP6_EP6 pid=786) INFO 02-27 19:13:09 [fused_moe.py:293] [EP Rank 6/32] Expert parallelism is enabled. Local/global number of experts: 8/256. Experts local to global index map: 0->48, 1->49, 2->50, 3->51, 4->52, 5->53, 6->54, 7->55.
2026-02-27T19:13:09.1575667Z (Worker_DP1_TP6_EP14 pid=785) /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-02-27T19:13:09.1583823Z (Worker_DP1_TP6_EP14 pid=785)   return func(*args, **kwargs)
2026-02-27T19:13:09.1594722Z (Worker_DP1_TP7_EP15 pid=889) INFO 02-27 19:13:09 [fused_moe.py:293] [EP Rank 15/32] Expert parallelism is enabled. Local/global number of experts: 8/256. Experts local to global index map: 0->120, 1->121, 2->122, 3->123, 4->124, 5->125, 6->126, 7->127.
2026-02-27T19:13:09.1644652Z (Worker_DP0_TP2_EP2 pid=372) INFO 02-27 19:13:09 [fused_moe.py:293] [EP Rank 2/32] Expert parallelism is enabled. Local/global number of experts: 8/256. Experts local to global index map: 0->16, 1->17, 2->18, 3->19, 4->20, 5->21, 6->22, 7->23.
2026-02-27T19:13:09.1654929Z (Worker_DP0_TP3_EP3 pid=476) /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-02-27T19:13:09.1663021Z (Worker_DP0_TP3_EP3 pid=476)   return func(*args, **kwargs)
2026-02-27T19:13:09.1673347Z (Worker_DP1_TP4_EP12 pid=577) INFO 02-27 19:13:09 [fused_moe.py:293] [EP Rank 12/32] Expert parallelism is enabled. Local/global number of experts: 8/256. Experts local to global index map: 0->96, 1->97, 2->98, 3->99, 4->100, 5->101, 6->102, 7->103.
2026-02-27T19:13:09.1684012Z (Worker_DP1_TP5_EP13 pid=681) /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-02-27T19:13:09.1694350Z (Worker_DP1_TP5_EP13 pid=681)   return func(*args, **kwargs)
2026-02-27T19:13:09.1716098Z (Worker_DP1_TP2_EP10 pid=369) /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-02-27T19:13:09.1725142Z (Worker_DP1_TP2_EP10 pid=369)   return func(*args, **kwargs)
2026-02-27T19:13:09.1913746Z (Worker_DP0_TP0_EP0 pid=202) INFO 02-27 19:13:09 [fused_moe.py:293] [EP Rank 0/32] Expert parallelism is enabled. Local/global number of experts: 8/256. Experts local to global index map: 0->0, 1->1, 2->2, 3->3, 4->4, 5->5, 6->6, 7->7.
2026-02-27T19:13:09.2026142Z (Worker_DP0_TP4_EP4 pid=579) /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-02-27T19:13:09.2034490Z (Worker_DP0_TP4_EP4 pid=579)   return func(*args, **kwargs)
2026-02-27T19:13:09.2116786Z (Worker_DP0_TP5_EP5 pid=682) INFO 02-27 19:13:09 [fused_moe.py:293] [EP Rank 5/32] Expert parallelism is enabled. Local/global number of experts: 8/256. Experts local to global index map: 0->40, 1->41, 2->42, 3->43, 4->44, 5->45, 6->46, 7->47.
2026-02-27T19:13:09.2149008Z (Worker_DP1_TP6_EP14 pid=785) INFO 02-27 19:13:09 [fused_moe.py:293] [EP Rank 14/32] Expert parallelism is enabled. Local/global number of experts: 8/256. Experts local to global index map: 0->112, 1->113, 2->114, 3->115, 4->116, 5->117, 6->118, 7->119.
2026-02-27T19:13:09.2192276Z (Worker_DP0_TP3_EP3 pid=476) INFO 02-27 19:13:09 [fused_moe.py:293] [EP Rank 3/32] Expert parallelism is enabled. Local/global number of experts: 8/256. Experts local to global index map: 0->24, 1->25, 2->26, 3->27, 4->28, 5->29, 6->30, 7->31.
2026-02-27T19:13:09.2256636Z (Worker_DP1_TP5_EP13 pid=681) INFO 02-27 19:13:09 [fused_moe.py:293] [EP Rank 13/32] Expert parallelism is enabled. Local/global number of experts: 8/256. Experts local to global index map: 0->104, 1->105, 2->106, 3->107, 4->108, 5->109, 6->110, 7->111.
2026-02-27T19:13:09.2362407Z (Worker_DP1_TP2_EP10 pid=369) INFO 02-27 19:13:09 [fused_moe.py:293] [EP Rank 10/32] Expert parallelism is enabled. Local/global number of experts: 8/256. Experts local to global index map: 0->80, 1->81, 2->82, 3->83, 4->84, 5->85, 6->86, 7->87.
2026-02-27T19:13:09.2655700Z (Worker_DP0_TP4_EP4 pid=579) INFO 02-27 19:13:09 [fused_moe.py:293] [EP Rank 4/32] Expert parallelism is enabled. Local/global number of experts: 8/256. Experts local to global index map: 0->32, 1->33, 2->34, 3->35, 4->36, 5->37, 6->38, 7->39.
2026-02-27T19:13:09.4897306Z (Worker_DP1_TP4_EP12 pid=577) INFO 02-27 19:13:09 [fused_moe.py:532] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-02-27T19:13:09.4919806Z (Worker_DP0_TP2_EP2 pid=372) INFO 02-27 19:13:09 [fused_moe.py:532] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-02-27T19:13:09.4929472Z (Worker_DP1_TP7_EP15 pid=889) INFO 02-27 19:13:09 [fused_moe.py:532] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-02-27T19:13:09.4939642Z (Worker_DP0_TP7_EP7 pid=890) INFO 02-27 19:13:09 [fused_moe.py:532] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-02-27T19:13:09.4951555Z (Worker_DP0_TP1_EP1 pid=253) INFO 02-27 19:13:09 [fused_moe.py:532] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-02-27T19:13:09.4959903Z (Worker_DP1_TP0_EP8 pid=201) INFO 02-27 19:13:09 [fused_moe.py:532] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-02-27T19:13:09.5070545Z (Worker_DP1_TP3_EP11 pid=473) INFO 02-27 19:13:09 [fused_moe.py:532] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-02-27T19:13:09.5145544Z (Worker_DP0_TP6_EP6 pid=786) INFO 02-27 19:13:09 [fused_moe.py:532] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-02-27T19:13:09.5154827Z (Worker_DP0_TP5_EP5 pid=682) INFO 02-27 19:13:09 [fused_moe.py:532] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-02-27T19:13:09.5164550Z (Worker_DP1_TP6_EP14 pid=785) INFO 02-27 19:13:09 [fused_moe.py:532] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-02-27T19:13:09.5297971Z (Worker_DP1_TP2_EP10 pid=369) INFO 02-27 19:13:09 [fused_moe.py:532] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-02-27T19:13:09.5631703Z (Worker_DP0_TP3_EP3 pid=476) INFO 02-27 19:13:09 [fused_moe.py:532] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-02-27T19:13:09.5650960Z (Worker_DP1_TP5_EP13 pid=681) INFO 02-27 19:13:09 [fused_moe.py:532] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-02-27T19:13:09.5661595Z (Worker_DP1_TP1_EP9 pid=251) INFO 02-27 19:13:09 [fused_moe.py:532] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-02-27T19:13:09.5976869Z (Worker_DP0_TP4_EP4 pid=579) INFO 02-27 19:13:09 [fused_moe.py:532] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-02-27T19:13:09.6322567Z (Worker_DP0_TP0_EP0 pid=202) INFO 02-27 19:13:09 [fused_moe.py:532] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-02-27T19:13:12.8457802Z (Worker_DP1_TP3_EP11 pid=473) INFO 02-27 19:13:12 [compilation.py:903] Using OOT custom backend for compilation.
2026-02-27T19:13:12.8634765Z (Worker_DP1_TP2_EP10 pid=369) INFO 02-27 19:13:12 [compilation.py:903] Using OOT custom backend for compilation.
2026-02-27T19:13:12.8716790Z (Worker_DP0_TP5_EP5 pid=682) INFO 02-27 19:13:12 [compilation.py:903] Using OOT custom backend for compilation.
2026-02-27T19:13:12.9596027Z (Worker_DP0_TP2_EP2 pid=372) INFO 02-27 19:13:12 [compilation.py:903] Using OOT custom backend for compilation.
2026-02-27T19:13:12.9613985Z (Worker_DP0_TP4_EP4 pid=579) INFO 02-27 19:13:12 [compilation.py:903] Using OOT custom backend for compilation.
2026-02-27T19:13:12.9653754Z (Worker_DP1_TP5_EP13 pid=681) INFO 02-27 19:13:12 [compilation.py:903] Using OOT custom backend for compilation.
2026-02-27T19:13:12.9681072Z (Worker_DP1_TP4_EP12 pid=577) INFO 02-27 19:13:12 [compilation.py:903] Using OOT custom backend for compilation.
2026-02-27T19:13:12.9733162Z (Worker_DP0_TP7_EP7 pid=890) INFO 02-27 19:13:12 [compilation.py:903] Using OOT custom backend for compilation.
2026-02-27T19:13:12.9773182Z (Worker_DP0_TP3_EP3 pid=476) INFO 02-27 19:13:12 [compilation.py:903] Using OOT custom backend for compilation.
2026-02-27T19:13:12.9783497Z (Worker_DP1_TP0_EP8 pid=201) INFO 02-27 19:13:12 [compilation.py:903] Using OOT custom backend for compilation.
2026-02-27T19:13:13.0485178Z (Worker_DP0_TP1_EP1 pid=253) INFO 02-27 19:13:13 [compilation.py:903] Using OOT custom backend for compilation.
2026-02-27T19:13:13.0544064Z (Worker_DP0_TP0_EP0 pid=202) INFO 02-27 19:13:13 [compilation.py:903] Using OOT custom backend for compilation.
2026-02-27T19:13:13.0606609Z (Worker_DP1_TP1_EP9 pid=251) INFO 02-27 19:13:13 [compilation.py:903] Using OOT custom backend for compilation.
2026-02-27T19:13:13.0717747Z (Worker_DP0_TP6_EP6 pid=786) INFO 02-27 19:13:13 [compilation.py:903] Using OOT custom backend for compilation.
2026-02-27T19:13:13.1284083Z (Worker_DP1_TP6_EP14 pid=785) INFO 02-27 19:13:13 [compilation.py:903] Using OOT custom backend for compilation.
2026-02-27T19:13:13.1608421Z (Worker_DP1_TP7_EP15 pid=889) INFO 02-27 19:13:13 [compilation.py:903] Using OOT custom backend for compilation.
2026-02-27T19:13:13.1735479Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:13:13.1736429Z Loading safetensors checkpoint shards:   0% Completed | 0/163 [00:00<?, ?it/s]
2026-02-27T19:13:19.2311371Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:13:19.2312101Z Loading safetensors checkpoint shards:   1% Completed | 1/163 [00:06<16:20,  6.05s/it]
2026-02-27T19:13:21.1442460Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:13:21.1443036Z Loading safetensors checkpoint shards:   1% Completed | 2/163 [00:07<09:42,  3.62s/it]
2026-02-27T19:13:22.6583073Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:13:22.6583651Z Loading safetensors checkpoint shards:   2% Completed | 3/163 [00:09<07:05,  2.66s/it]
2026-02-27T19:13:25.9898527Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:13:25.9899376Z Loading safetensors checkpoint shards:   2% Completed | 4/163 [00:12<07:44,  2.92s/it]
2026-02-27T19:13:27.2167661Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:13:27.2168286Z Loading safetensors checkpoint shards:   3% Completed | 5/163 [00:14<06:05,  2.31s/it]
2026-02-27T19:13:29.3457883Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:13:29.3458346Z Loading safetensors checkpoint shards:   4% Completed | 6/163 [00:16<05:53,  2.25s/it]
2026-02-27T19:13:30.8301140Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:13:30.8301613Z Loading safetensors checkpoint shards:   4% Completed | 7/163 [00:17<05:11,  2.00s/it]
2026-02-27T19:13:32.9115574Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:13:32.9116004Z Loading safetensors checkpoint shards:   5% Completed | 8/163 [00:19<05:13,  2.03s/it]
2026-02-27T19:13:35.4061913Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:13:35.4062643Z Loading safetensors checkpoint shards:   6% Completed | 9/163 [00:22<05:34,  2.17s/it]
2026-02-27T19:13:37.0116227Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:13:37.0117000Z Loading safetensors checkpoint shards:   6% Completed | 10/163 [00:23<05:05,  2.00s/it]
2026-02-27T19:13:38.6768591Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:13:38.6769155Z Loading safetensors checkpoint shards:   7% Completed | 11/163 [00:25<04:48,  1.90s/it]
2026-02-27T19:13:41.8645640Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:13:41.8646170Z Loading safetensors checkpoint shards:   7% Completed | 12/163 [00:28<05:45,  2.29s/it]
2026-02-27T19:13:43.1040598Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:13:43.1041159Z Loading safetensors checkpoint shards:   8% Completed | 13/163 [00:29<04:55,  1.97s/it]
2026-02-27T19:13:45.0239833Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:13:45.0240286Z Loading safetensors checkpoint shards:   9% Completed | 14/163 [00:31<04:51,  1.96s/it]
2026-02-27T19:13:48.1244199Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:13:48.1244682Z Loading safetensors checkpoint shards:   9% Completed | 15/163 [00:34<05:40,  2.30s/it]
2026-02-27T19:13:49.3427431Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:13:49.3427931Z Loading safetensors checkpoint shards:  10% Completed | 16/163 [00:36<04:50,  1.97s/it]
2026-02-27T19:13:51.5615232Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:13:51.5615793Z Loading safetensors checkpoint shards:  10% Completed | 17/163 [00:38<04:59,  2.05s/it]
2026-02-27T19:13:53.2110509Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:13:53.2110974Z Loading safetensors checkpoint shards:  11% Completed | 18/163 [00:40<04:39,  1.93s/it]
2026-02-27T19:13:55.0466330Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:13:55.0466905Z Loading safetensors checkpoint shards:  12% Completed | 19/163 [00:41<04:33,  1.90s/it]
2026-02-27T19:13:57.9548405Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:13:57.9549011Z Loading safetensors checkpoint shards:  12% Completed | 20/163 [00:44<05:15,  2.20s/it]
2026-02-27T19:13:59.1771094Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:13:59.1771567Z Loading safetensors checkpoint shards:  13% Completed | 21/163 [00:46<04:31,  1.91s/it]
2026-02-27T19:14:00.7263735Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:14:00.7264270Z Loading safetensors checkpoint shards:  13% Completed | 22/163 [00:47<04:13,  1.80s/it]
2026-02-27T19:14:04.1544167Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:14:04.1544697Z Loading safetensors checkpoint shards:  14% Completed | 23/163 [00:50<05:20,  2.29s/it]
2026-02-27T19:14:05.4076149Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:14:05.4076606Z Loading safetensors checkpoint shards:  15% Completed | 24/163 [00:52<04:34,  1.98s/it]
2026-02-27T19:14:07.5060363Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:14:07.5060833Z Loading safetensors checkpoint shards:  15% Completed | 25/163 [00:54<04:37,  2.01s/it]
2026-02-27T19:14:08.8853956Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:14:08.8854382Z Loading safetensors checkpoint shards:  16% Completed | 26/163 [00:55<04:09,  1.82s/it]
2026-02-27T19:14:10.8723286Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:14:10.8723755Z Loading safetensors checkpoint shards:  17% Completed | 27/163 [00:57<04:14,  1.87s/it]
2026-02-27T19:14:13.7419065Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:14:13.7419643Z Loading safetensors checkpoint shards:  17% Completed | 28/163 [01:00<04:53,  2.17s/it]
2026-02-27T19:14:15.3160041Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:14:15.3160583Z Loading safetensors checkpoint shards:  18% Completed | 29/163 [01:02<04:26,  1.99s/it]
2026-02-27T19:14:16.9476644Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:14:16.9477220Z Loading safetensors checkpoint shards:  18% Completed | 30/163 [01:03<04:10,  1.88s/it]
2026-02-27T19:14:20.0805557Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:14:20.0806036Z Loading safetensors checkpoint shards:  19% Completed | 31/163 [01:06<04:58,  2.26s/it]
2026-02-27T19:14:21.4639402Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:14:23.5606599Z Loading safetensors checkpoint shards:  20% Completed | 32/163 [01:08<04:21,  2.00s/it]
2026-02-27T19:14:23.5607209Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:14:23.5607555Z Loading safetensors checkpoint shards:  20% Completed | 33/163 [01:10<04:23,  2.03s/it]
2026-02-27T19:14:25.4110346Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:14:25.4110777Z Loading safetensors checkpoint shards:  21% Completed | 34/163 [01:12<04:14,  1.97s/it]
2026-02-27T19:14:27.1941059Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:14:27.1941573Z Loading safetensors checkpoint shards:  21% Completed | 35/163 [01:14<04:05,  1.92s/it]
2026-02-27T19:14:29.6481348Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:14:29.6481829Z Loading safetensors checkpoint shards:  22% Completed | 36/163 [01:16<04:23,  2.08s/it]
2026-02-27T19:14:31.2566614Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:14:31.2567075Z Loading safetensors checkpoint shards:  23% Completed | 37/163 [01:18<04:04,  1.94s/it]
2026-02-27T19:14:33.0096948Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:14:33.0097425Z Loading safetensors checkpoint shards:  23% Completed | 38/163 [01:19<03:55,  1.88s/it]
2026-02-27T19:14:36.1272309Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:14:36.1272952Z Loading safetensors checkpoint shards:  24% Completed | 39/163 [01:22<04:39,  2.25s/it]
2026-02-27T19:14:37.6660892Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:14:37.6661487Z Loading safetensors checkpoint shards:  25% Completed | 40/163 [01:24<04:10,  2.04s/it]
2026-02-27T19:14:38.9650376Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:14:38.9650851Z Loading safetensors checkpoint shards:  25% Completed | 41/163 [01:25<03:41,  1.82s/it]
2026-02-27T19:14:42.2818611Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:14:42.2819080Z Loading safetensors checkpoint shards:  26% Completed | 42/163 [01:29<04:34,  2.27s/it]
2026-02-27T19:14:43.4995017Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:14:43.4995481Z Loading safetensors checkpoint shards:  26% Completed | 43/163 [01:30<03:54,  1.95s/it]
2026-02-27T19:14:45.6851430Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:14:47.0327460Z Loading safetensors checkpoint shards:  27% Completed | 44/163 [01:32<04:00,  2.02s/it]
2026-02-27T19:14:47.0328019Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:14:47.0328460Z Loading safetensors checkpoint shards:  28% Completed | 45/163 [01:33<03:34,  1.82s/it]
2026-02-27T19:14:48.7955796Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:14:48.7956456Z Loading safetensors checkpoint shards:  28% Completed | 46/163 [01:35<03:30,  1.80s/it]
2026-02-27T19:14:51.7362664Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:14:51.7363095Z Loading safetensors checkpoint shards:  29% Completed | 47/163 [01:38<04:08,  2.14s/it]
2026-02-27T19:14:52.8903212Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:14:52.8903814Z Loading safetensors checkpoint shards:  29% Completed | 48/163 [01:39<03:32,  1.85s/it]
2026-02-27T19:14:54.5556949Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:14:54.5557423Z Loading safetensors checkpoint shards:  30% Completed | 49/163 [01:41<03:24,  1.79s/it]
2026-02-27T19:14:57.8912500Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:14:57.8913000Z Loading safetensors checkpoint shards:  31% Completed | 50/163 [01:44<04:14,  2.26s/it]
2026-02-27T19:14:59.2292277Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:14:59.2293154Z Loading safetensors checkpoint shards:  31% Completed | 51/163 [01:46<03:41,  1.98s/it]
2026-02-27T19:15:01.3419979Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:15:01.3420526Z Loading safetensors checkpoint shards:  32% Completed | 52/163 [01:48<03:44,  2.02s/it]
2026-02-27T19:15:02.8622179Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:15:02.8622646Z Loading safetensors checkpoint shards:  33% Completed | 53/163 [01:49<03:25,  1.87s/it]
2026-02-27T19:15:04.9378942Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:15:04.9379376Z Loading safetensors checkpoint shards:  33% Completed | 54/163 [01:51<03:30,  1.93s/it]
2026-02-27T19:15:07.4296620Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:15:07.4297292Z Loading safetensors checkpoint shards:  34% Completed | 55/163 [01:54<03:46,  2.10s/it]
2026-02-27T19:15:09.0157040Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:15:09.0157625Z Loading safetensors checkpoint shards:  34% Completed | 56/163 [01:55<03:28,  1.95s/it]
2026-02-27T19:15:10.6922260Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:15:10.6923032Z Loading safetensors checkpoint shards:  35% Completed | 57/163 [01:57<03:17,  1.86s/it]
2026-02-27T19:15:13.8027550Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:15:13.8028001Z Loading safetensors checkpoint shards:  36% Completed | 58/163 [02:00<03:55,  2.24s/it]
2026-02-27T19:15:14.9789792Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:15:14.9790340Z Loading safetensors checkpoint shards:  36% Completed | 59/163 [02:01<03:19,  1.92s/it]
2026-02-27T19:15:17.2305217Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:15:17.2305703Z Loading safetensors checkpoint shards:  37% Completed | 60/163 [02:04<03:28,  2.02s/it]
2026-02-27T19:15:20.1328567Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:15:20.1328989Z Loading safetensors checkpoint shards:  37% Completed | 61/163 [02:06<03:52,  2.28s/it]
2026-02-27T19:15:21.2616640Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:15:21.2617098Z Loading safetensors checkpoint shards:  38% Completed | 62/163 [02:08<03:15,  1.94s/it]
2026-02-27T19:15:23.4497315Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:15:23.4497772Z Loading safetensors checkpoint shards:  39% Completed | 63/163 [02:10<03:21,  2.01s/it]
2026-02-27T19:15:25.1086917Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:15:25.1087462Z Loading safetensors checkpoint shards:  39% Completed | 64/163 [02:11<03:08,  1.91s/it]
2026-02-27T19:15:26.8224987Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:15:26.8225566Z Loading safetensors checkpoint shards:  40% Completed | 65/163 [02:13<03:01,  1.85s/it]
2026-02-27T19:15:29.5700646Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:15:29.5701268Z Loading safetensors checkpoint shards:  40% Completed | 66/163 [02:16<03:25,  2.12s/it]
2026-02-27T19:15:30.8672775Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:15:30.8673410Z Loading safetensors checkpoint shards:  41% Completed | 67/163 [02:17<02:59,  1.87s/it]
2026-02-27T19:15:32.3526687Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:15:32.3527265Z Loading safetensors checkpoint shards:  42% Completed | 68/163 [02:19<02:46,  1.76s/it]
2026-02-27T19:15:35.7658507Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:15:35.7658962Z Loading safetensors checkpoint shards:  42% Completed | 69/163 [02:22<03:31,  2.25s/it]
2026-02-27T19:15:37.0219333Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:15:37.0220461Z Loading safetensors checkpoint shards:  43% Completed | 70/163 [02:23<03:01,  1.95s/it]
2026-02-27T19:15:39.1627887Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:15:39.1628341Z Loading safetensors checkpoint shards:  44% Completed | 71/163 [02:25<03:04,  2.01s/it]
2026-02-27T19:15:40.6772092Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:15:40.6772553Z Loading safetensors checkpoint shards:  44% Completed | 72/163 [02:27<02:49,  1.86s/it]
2026-02-27T19:15:42.6126259Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:15:42.6126688Z Loading safetensors checkpoint shards:  45% Completed | 73/163 [02:29<02:49,  1.88s/it]
2026-02-27T19:15:45.3720462Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:15:45.3721370Z Loading safetensors checkpoint shards:  45% Completed | 74/163 [02:32<03:11,  2.15s/it]
2026-02-27T19:15:46.9294969Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:15:46.9295578Z Loading safetensors checkpoint shards:  46% Completed | 75/163 [02:33<02:53,  1.97s/it]
2026-02-27T19:15:48.4756626Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:15:48.4757308Z Loading safetensors checkpoint shards:  47% Completed | 76/163 [02:35<02:40,  1.84s/it]
2026-02-27T19:15:51.6042953Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:15:51.6043627Z Loading safetensors checkpoint shards:  47% Completed | 77/163 [02:38<03:11,  2.23s/it]
2026-02-27T19:15:53.0377701Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:15:53.0378282Z Loading safetensors checkpoint shards:  48% Completed | 78/163 [02:39<02:49,  1.99s/it]
2026-02-27T19:15:54.9823907Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:15:54.9824394Z Loading safetensors checkpoint shards:  48% Completed | 79/163 [02:41<02:46,  1.98s/it]
2026-02-27T19:15:56.4696794Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:15:56.4697300Z Loading safetensors checkpoint shards:  49% Completed | 80/163 [02:43<02:31,  1.83s/it]
2026-02-27T19:15:58.5922981Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:15:58.5923466Z Loading safetensors checkpoint shards:  50% Completed | 81/163 [02:45<02:37,  1.92s/it]
2026-02-27T19:16:01.1416643Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:16:01.1417159Z Loading safetensors checkpoint shards:  50% Completed | 82/163 [02:47<02:50,  2.11s/it]
2026-02-27T19:16:02.6291359Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:16:02.6291810Z Loading safetensors checkpoint shards:  51% Completed | 83/163 [02:49<02:33,  1.92s/it]
2026-02-27T19:16:04.1926123Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:16:04.1926730Z Loading safetensors checkpoint shards:  52% Completed | 84/163 [02:51<02:23,  1.81s/it]
2026-02-27T19:16:07.3563161Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:16:07.3563725Z Loading safetensors checkpoint shards:  52% Completed | 85/163 [02:54<02:53,  2.22s/it]
2026-02-27T19:16:08.7279278Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:16:08.7279842Z Loading safetensors checkpoint shards:  53% Completed | 86/163 [02:55<02:31,  1.96s/it]
2026-02-27T19:16:10.2726215Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:16:10.2726808Z Loading safetensors checkpoint shards:  53% Completed | 87/163 [02:57<02:19,  1.84s/it]
2026-02-27T19:16:13.5686891Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:16:13.5687343Z Loading safetensors checkpoint shards:  54% Completed | 88/163 [03:00<02:50,  2.28s/it]
2026-02-27T19:16:14.8465786Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:16:14.8466242Z Loading safetensors checkpoint shards:  55% Completed | 89/163 [03:01<02:26,  1.98s/it]
2026-02-27T19:16:16.9535261Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:16:16.9535839Z Loading safetensors checkpoint shards:  55% Completed | 90/163 [03:03<02:27,  2.02s/it]
2026-02-27T19:16:18.3894011Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:16:18.3894467Z Loading safetensors checkpoint shards:  56% Completed | 91/163 [03:05<02:12,  1.84s/it]
2026-02-27T19:16:20.2213376Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:16:20.2213863Z Loading safetensors checkpoint shards:  56% Completed | 92/163 [03:07<02:10,  1.84s/it]
2026-02-27T19:16:23.1882250Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:16:23.1882838Z Loading safetensors checkpoint shards:  57% Completed | 93/163 [03:10<02:32,  2.18s/it]
2026-02-27T19:16:24.6866353Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:16:24.6866975Z Loading safetensors checkpoint shards:  58% Completed | 94/163 [03:11<02:16,  1.97s/it]
2026-02-27T19:16:26.2020946Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:16:26.2021564Z Loading safetensors checkpoint shards:  58% Completed | 95/163 [03:13<02:04,  1.84s/it]
2026-02-27T19:16:29.4151868Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:16:29.4152502Z Loading safetensors checkpoint shards:  59% Completed | 96/163 [03:16<02:30,  2.25s/it]
2026-02-27T19:16:30.7583776Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:16:30.7584467Z Loading safetensors checkpoint shards:  60% Completed | 97/163 [03:17<02:10,  1.98s/it]
2026-02-27T19:16:32.7334883Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:16:32.7335548Z Loading safetensors checkpoint shards:  60% Completed | 98/163 [03:19<02:08,  1.98s/it]
2026-02-27T19:16:34.2846275Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:16:34.2846768Z Loading safetensors checkpoint shards:  61% Completed | 99/163 [03:21<01:58,  1.85s/it]
2026-02-27T19:16:36.2856988Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:16:36.2857430Z Loading safetensors checkpoint shards:  61% Completed | 100/163 [03:23<01:59,  1.89s/it]
2026-02-27T19:16:38.8181389Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:16:38.8181829Z Loading safetensors checkpoint shards:  62% Completed | 101/163 [03:25<02:09,  2.09s/it]
2026-02-27T19:16:40.3717455Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:16:40.3717972Z Loading safetensors checkpoint shards:  63% Completed | 102/163 [03:27<01:57,  1.93s/it]
2026-02-27T19:16:41.8500033Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:16:41.8500494Z Loading safetensors checkpoint shards:  63% Completed | 103/163 [03:28<01:47,  1.79s/it]
2026-02-27T19:16:44.8308501Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:16:44.8309147Z Loading safetensors checkpoint shards:  64% Completed | 104/163 [03:31<02:06,  2.15s/it]
2026-02-27T19:16:46.1625374Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:16:46.1625921Z Loading safetensors checkpoint shards:  64% Completed | 105/163 [03:32<01:50,  1.90s/it]
2026-02-27T19:16:48.2891691Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:16:48.2892489Z Loading safetensors checkpoint shards:  65% Completed | 106/163 [03:35<01:52,  1.97s/it]
2026-02-27T19:16:50.7402938Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:16:50.7403589Z Loading safetensors checkpoint shards:  66% Completed | 107/163 [03:37<01:58,  2.11s/it]
2026-02-27T19:16:52.2698089Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:16:52.2698499Z Loading safetensors checkpoint shards:  66% Completed | 108/163 [03:39<01:46,  1.94s/it]
2026-02-27T19:16:54.4318550Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:16:54.4319034Z Loading safetensors checkpoint shards:  67% Completed | 109/163 [03:41<01:48,  2.00s/it]
2026-02-27T19:16:55.9158485Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:16:55.9158945Z Loading safetensors checkpoint shards:  67% Completed | 110/163 [03:42<01:38,  1.85s/it]
2026-02-27T19:16:57.6235222Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:16:57.6235699Z Loading safetensors checkpoint shards:  68% Completed | 111/163 [03:44<01:33,  1.81s/it]
2026-02-27T19:17:00.5543388Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:17:00.5543831Z Loading safetensors checkpoint shards:  69% Completed | 112/163 [03:47<01:49,  2.14s/it]
2026-02-27T19:17:01.8340338Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:17:01.8340859Z Loading safetensors checkpoint shards:  69% Completed | 113/163 [03:48<01:34,  1.89s/it]
2026-02-27T19:17:03.3318481Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:17:03.3318937Z Loading safetensors checkpoint shards:  70% Completed | 114/163 [03:50<01:26,  1.77s/it]
2026-02-27T19:17:06.7688394Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:17:06.7689016Z Loading safetensors checkpoint shards:  71% Completed | 115/163 [03:53<01:48,  2.27s/it]
2026-02-27T19:17:08.1393765Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:17:08.1394172Z Loading safetensors checkpoint shards:  71% Completed | 116/163 [03:54<01:33,  2.00s/it]
2026-02-27T19:17:10.0960730Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:17:10.0961181Z Loading safetensors checkpoint shards:  72% Completed | 117/163 [03:56<01:31,  1.99s/it]
2026-02-27T19:17:11.6407347Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:17:11.6407800Z Loading safetensors checkpoint shards:  72% Completed | 118/163 [03:58<01:23,  1.85s/it]
2026-02-27T19:17:13.6060518Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:17:13.6060999Z Loading safetensors checkpoint shards:  73% Completed | 119/163 [04:00<01:23,  1.89s/it]
2026-02-27T19:17:16.1753450Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:17:16.1753857Z Loading safetensors checkpoint shards:  74% Completed | 120/163 [04:03<01:29,  2.09s/it]
2026-02-27T19:17:17.5852881Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:17:17.5853416Z Loading safetensors checkpoint shards:  74% Completed | 121/163 [04:04<01:19,  1.89s/it]
2026-02-27T19:17:19.2394871Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:17:19.2395314Z Loading safetensors checkpoint shards:  75% Completed | 122/163 [04:06<01:14,  1.82s/it]
2026-02-27T19:17:22.3944725Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:17:22.3945163Z Loading safetensors checkpoint shards:  75% Completed | 123/163 [04:09<01:28,  2.22s/it]
2026-02-27T19:17:23.7867930Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:17:23.7868370Z Loading safetensors checkpoint shards:  76% Completed | 124/163 [04:10<01:16,  1.97s/it]
2026-02-27T19:17:25.7892877Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:17:25.7893331Z Loading safetensors checkpoint shards:  77% Completed | 125/163 [04:12<01:15,  1.98s/it]
2026-02-27T19:17:27.2735585Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:17:27.2736083Z Loading safetensors checkpoint shards:  77% Completed | 126/163 [04:14<01:07,  1.83s/it]
2026-02-27T19:17:29.3187197Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:17:29.3187629Z Loading safetensors checkpoint shards:  78% Completed | 127/163 [04:16<01:08,  1.90s/it]
2026-02-27T19:17:31.8350334Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:17:31.8350822Z Loading safetensors checkpoint shards:  79% Completed | 128/163 [04:18<01:12,  2.08s/it]
2026-02-27T19:17:33.2961254Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:17:33.2961816Z Loading safetensors checkpoint shards:  79% Completed | 129/163 [04:20<01:04,  1.90s/it]
2026-02-27T19:17:34.9759230Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:17:34.9759887Z Loading safetensors checkpoint shards:  80% Completed | 130/163 [04:21<01:00,  1.83s/it]
2026-02-27T19:17:38.1026715Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:17:38.1027332Z Loading safetensors checkpoint shards:  80% Completed | 131/163 [04:24<01:11,  2.22s/it]
2026-02-27T19:17:39.5672929Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:17:39.5673627Z Loading safetensors checkpoint shards:  81% Completed | 132/163 [04:26<01:01,  1.99s/it]
2026-02-27T19:17:41.3214211Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:17:41.3214851Z Loading safetensors checkpoint shards:  82% Completed | 133/163 [04:28<00:57,  1.92s/it]
2026-02-27T19:17:44.3190371Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:17:44.3190852Z Loading safetensors checkpoint shards:  82% Completed | 134/163 [04:31<01:05,  2.24s/it]
2026-02-27T19:17:45.5985170Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:17:45.5985706Z Loading safetensors checkpoint shards:  83% Completed | 135/163 [04:32<00:54,  1.95s/it]
2026-02-27T19:17:47.7806864Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:17:47.7807273Z Loading safetensors checkpoint shards:  83% Completed | 136/163 [04:34<00:54,  2.02s/it]
2026-02-27T19:17:49.4669535Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:17:49.4670062Z Loading safetensors checkpoint shards:  84% Completed | 137/163 [04:36<00:49,  1.92s/it]
2026-02-27T19:17:51.2952706Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:17:51.2953172Z Loading safetensors checkpoint shards:  85% Completed | 138/163 [04:38<00:47,  1.89s/it]
2026-02-27T19:17:54.0166186Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:17:54.0166642Z Loading safetensors checkpoint shards:  85% Completed | 139/163 [04:40<00:51,  2.14s/it]
2026-02-27T19:17:55.5326998Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:17:55.5327474Z Loading safetensors checkpoint shards:  86% Completed | 140/163 [04:42<00:44,  1.95s/it]
2026-02-27T19:17:56.9844816Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:17:56.9845263Z Loading safetensors checkpoint shards:  87% Completed | 141/163 [04:43<00:39,  1.80s/it]
2026-02-27T19:18:00.2117355Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:18:00.2118058Z Loading safetensors checkpoint shards:  87% Completed | 142/163 [04:47<00:46,  2.23s/it]
2026-02-27T19:18:01.5643976Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:18:01.5644547Z Loading safetensors checkpoint shards:  88% Completed | 143/163 [04:48<00:39,  1.97s/it]
2026-02-27T19:18:03.7881764Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:18:03.7882675Z Loading safetensors checkpoint shards:  88% Completed | 144/163 [04:50<00:38,  2.04s/it]
2026-02-27T19:18:05.3010771Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:18:05.3011316Z Loading safetensors checkpoint shards:  89% Completed | 145/163 [04:52<00:33,  1.88s/it]
2026-02-27T19:18:07.2981315Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:18:07.2981747Z Loading safetensors checkpoint shards:  90% Completed | 146/163 [04:54<00:32,  1.92s/it]
2026-02-27T19:18:09.9128117Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:18:09.9128538Z Loading safetensors checkpoint shards:  90% Completed | 147/163 [04:56<00:34,  2.13s/it]
2026-02-27T19:18:11.4551704Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:18:11.4552335Z Loading safetensors checkpoint shards:  91% Completed | 148/163 [04:58<00:29,  1.95s/it]
2026-02-27T19:18:13.1191004Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:18:13.1191463Z Loading safetensors checkpoint shards:  91% Completed | 149/163 [04:59<00:26,  1.87s/it]
2026-02-27T19:18:16.3321371Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:18:16.3321838Z Loading safetensors checkpoint shards:  92% Completed | 150/163 [05:03<00:29,  2.27s/it]
2026-02-27T19:18:17.6380850Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:18:17.6381272Z Loading safetensors checkpoint shards:  93% Completed | 151/163 [05:04<00:23,  1.98s/it]
2026-02-27T19:18:19.7916416Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:18:19.7916946Z Loading safetensors checkpoint shards:  93% Completed | 152/163 [05:06<00:22,  2.03s/it]
2026-02-27T19:18:21.5036116Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:18:21.5036570Z Loading safetensors checkpoint shards:  94% Completed | 153/163 [05:08<00:19,  1.92s/it]
2026-02-27T19:18:23.3047773Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:18:23.3048269Z Loading safetensors checkpoint shards:  94% Completed | 154/163 [05:10<00:17,  1.90s/it]
2026-02-27T19:18:25.8131120Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:18:25.8131582Z Loading safetensors checkpoint shards:  95% Completed | 155/163 [05:12<00:16,  2.08s/it]
2026-02-27T19:18:27.4398657Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:18:27.4399129Z Loading safetensors checkpoint shards:  96% Completed | 156/163 [05:14<00:13,  1.95s/it]
2026-02-27T19:18:29.0493555Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:18:29.0494049Z Loading safetensors checkpoint shards:  96% Completed | 157/163 [05:15<00:11,  1.85s/it]
2026-02-27T19:18:30.0625127Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:18:30.0625595Z Loading safetensors checkpoint shards:  97% Completed | 158/163 [05:16<00:07,  1.60s/it]
2026-02-27T19:18:30.9455805Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:18:30.9456278Z Loading safetensors checkpoint shards:  98% Completed | 159/163 [05:17<00:05,  1.38s/it]
2026-02-27T19:18:31.8908980Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:18:31.8909466Z Loading safetensors checkpoint shards:  98% Completed | 160/163 [05:18<00:03,  1.25s/it]
2026-02-27T19:18:33.5002224Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:18:33.5002802Z Loading safetensors checkpoint shards:  99% Completed | 162/163 [05:20<00:01,  1.04s/it]
2026-02-27T19:18:36.5912763Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:18:36.5913235Z Loading safetensors checkpoint shards: 100% Completed | 163/163 [05:23<00:00,  1.55s/it]
2026-02-27T19:18:36.5940288Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:18:36.5940746Z Loading safetensors checkpoint shards: 100% Completed | 163/163 [05:23<00:00,  1.98s/it]
2026-02-27T19:18:36.5949639Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:18:36.6015503Z (Worker_DP1_TP0_EP8 pid=201) INFO 02-27 19:18:36 [default_loader.py:293] Loading weights took 323.49 seconds
2026-02-27T19:18:36.6443248Z (Worker_DP0_TP0_EP0 pid=202) INFO 02-27 19:18:36 [default_loader.py:293] Loading weights took 323.46 seconds
2026-02-27T19:18:50.7023398Z INFO 02-27 19:18:50 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T19:18:50.7033467Z INFO 02-27 19:18:50 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T19:18:50.7044473Z INFO 02-27 19:18:50 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T19:18:50.7055063Z INFO 02-27 19:18:50 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T19:18:50.7065332Z INFO 02-27 19:18:50 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T19:18:50.7076666Z INFO 02-27 19:18:50 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T19:18:50.7086933Z INFO 02-27 19:18:50 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T19:18:50.7096836Z INFO 02-27 19:18:50 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T19:18:50.7107903Z INFO 02-27 19:18:50 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T19:18:50.7118745Z INFO 02-27 19:18:50 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T19:18:50.7128752Z INFO 02-27 19:18:50 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T19:18:50.7138928Z INFO 02-27 19:18:50 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T19:18:50.7148842Z INFO 02-27 19:18:50 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T19:18:50.7158099Z INFO 02-27 19:18:50 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T19:18:50.7168742Z INFO 02-27 19:18:50 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T19:18:50.7178461Z INFO 02-27 19:18:50 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T19:18:50.7187916Z INFO 02-27 19:18:50 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T19:18:50.7198150Z INFO 02-27 19:18:50 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T19:18:50.7208027Z INFO 02-27 19:18:50 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T19:18:50.7218462Z INFO 02-27 19:18:50 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T19:18:50.7228604Z INFO 02-27 19:18:50 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T19:18:50.7239444Z INFO 02-27 19:18:50 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T19:18:50.7249525Z INFO 02-27 19:18:50 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T19:18:50.7259613Z INFO 02-27 19:18:50 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T19:18:50.7269558Z INFO 02-27 19:18:50 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T19:18:50.7279299Z INFO 02-27 19:18:50 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T19:18:50.7289490Z INFO 02-27 19:18:50 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T19:18:50.7299356Z INFO 02-27 19:18:50 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T19:18:50.7309408Z INFO 02-27 19:18:50 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T19:18:50.7319852Z INFO 02-27 19:18:50 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T19:18:50.7330458Z INFO 02-27 19:18:50 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T19:18:50.7340561Z INFO 02-27 19:18:50 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T19:18:50.7350278Z INFO 02-27 19:18:50 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T19:18:50.7360328Z INFO 02-27 19:18:50 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T19:18:50.7370380Z INFO 02-27 19:18:50 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T19:18:50.7380467Z INFO 02-27 19:18:50 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T19:18:50.7390178Z INFO 02-27 19:18:50 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T19:18:50.7400745Z INFO 02-27 19:18:50 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T19:18:50.7411660Z INFO 02-27 19:18:50 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T19:18:50.7421314Z INFO 02-27 19:18:50 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T19:18:50.7429740Z INFO 02-27 19:18:50 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T19:18:50.7439738Z INFO 02-27 19:18:50 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T19:18:50.7449996Z INFO 02-27 19:18:50 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T19:18:50.7460237Z INFO 02-27 19:18:50 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T19:18:50.7469842Z INFO 02-27 19:18:50 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T19:18:50.7479787Z INFO 02-27 19:18:50 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T19:18:50.7489496Z INFO 02-27 19:18:50 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T19:18:50.7499470Z INFO 02-27 19:18:50 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T19:18:50.7959909Z INFO 02-27 19:18:50 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T19:18:50.7968163Z INFO 02-27 19:18:50 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T19:18:50.7977452Z INFO 02-27 19:18:50 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T19:18:50.8018350Z INFO 02-27 19:18:50 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T19:18:50.8026406Z INFO 02-27 19:18:50 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T19:18:50.8035732Z INFO 02-27 19:18:50 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T19:18:50.8044925Z INFO 02-27 19:18:50 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T19:18:50.8115544Z INFO 02-27 19:18:50 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T19:18:50.8898742Z INFO 02-27 19:18:50 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T19:18:50.8910488Z INFO 02-27 19:18:50 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T19:18:50.8922885Z INFO 02-27 19:18:50 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T19:18:50.8932339Z INFO 02-27 19:18:50 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T19:18:50.8943375Z INFO 02-27 19:18:50 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T19:18:50.8954199Z INFO 02-27 19:18:50 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T19:18:50.8988565Z INFO 02-27 19:18:50 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T19:18:50.8999598Z INFO 02-27 19:18:50 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T19:19:16.4442074Z (Worker_DP1_TP1_EP9 pid=251) WARNING 02-27 19:19:16 [sfa_v1.py:497] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-02-27T19:19:16.4551552Z (Worker_DP0_TP1_EP1 pid=253) WARNING 02-27 19:19:16 [sfa_v1.py:497] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-02-27T19:19:16.4653636Z (Worker_DP1_TP6_EP14 pid=785) WARNING 02-27 19:19:16 [sfa_v1.py:497] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-02-27T19:19:16.4811486Z (Worker_DP0_TP7_EP7 pid=890) WARNING 02-27 19:19:16 [sfa_v1.py:497] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-02-27T19:19:16.4995040Z (Worker_DP1_TP1_EP9 pid=251) INFO 02-27 19:19:16 [model_runner_v1.py:2359] Loading drafter model...
2026-02-27T19:19:16.5030627Z (Worker_DP1_TP0_EP8 pid=201) WARNING 02-27 19:19:16 [sfa_v1.py:497] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-02-27T19:19:16.5060925Z (Worker_DP0_TP1_EP1 pid=253) INFO 02-27 19:19:16 [model_runner_v1.py:2359] Loading drafter model...
2026-02-27T19:19:16.5141495Z (Worker_DP1_TP6_EP14 pid=785) INFO 02-27 19:19:16 [model_runner_v1.py:2359] Loading drafter model...
2026-02-27T19:19:16.5267298Z (Worker_DP0_TP7_EP7 pid=890) INFO 02-27 19:19:16 [model_runner_v1.py:2359] Loading drafter model...
2026-02-27T19:19:16.5465417Z (Worker_DP1_TP0_EP8 pid=201) INFO 02-27 19:19:16 [model_runner_v1.py:2359] Loading drafter model...
2026-02-27T19:19:16.5669435Z (Worker_DP1_TP5_EP13 pid=681) WARNING 02-27 19:19:16 [sfa_v1.py:497] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-02-27T19:19:16.5849482Z (Worker_DP0_TP5_EP5 pid=682) WARNING 02-27 19:19:16 [sfa_v1.py:497] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-02-27T19:19:16.6000503Z (Worker_DP1_TP4_EP12 pid=577) WARNING 02-27 19:19:16 [sfa_v1.py:497] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-02-27T19:19:16.6149994Z (Worker_DP1_TP7_EP15 pid=889) WARNING 02-27 19:19:16 [sfa_v1.py:497] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-02-27T19:19:16.6173600Z (Worker_DP1_TP5_EP13 pid=681) INFO 02-27 19:19:16 [model_runner_v1.py:2359] Loading drafter model...
2026-02-27T19:19:16.6328862Z (Worker_DP0_TP5_EP5 pid=682) INFO 02-27 19:19:16 [model_runner_v1.py:2359] Loading drafter model...
2026-02-27T19:19:16.6461000Z (Worker_DP1_TP4_EP12 pid=577) INFO 02-27 19:19:16 [model_runner_v1.py:2359] Loading drafter model...
2026-02-27T19:19:16.6645543Z (Worker_DP1_TP7_EP15 pid=889) INFO 02-27 19:19:16 [model_runner_v1.py:2359] Loading drafter model...
2026-02-27T19:19:16.7015060Z (Worker_DP0_TP6_EP6 pid=786) WARNING 02-27 19:19:16 [sfa_v1.py:497] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-02-27T19:19:16.7342737Z (Worker_DP0_TP0_EP0 pid=202) WARNING 02-27 19:19:16 [sfa_v1.py:497] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-02-27T19:19:16.7405692Z (Worker_DP0_TP6_EP6 pid=786) INFO 02-27 19:19:16 [model_runner_v1.py:2359] Loading drafter model...
2026-02-27T19:19:16.7779769Z (Worker_DP0_TP0_EP0 pid=202) INFO 02-27 19:19:16 [model_runner_v1.py:2359] Loading drafter model...
2026-02-27T19:19:16.8019519Z (Worker_DP0_TP4_EP4 pid=579) WARNING 02-27 19:19:16 [sfa_v1.py:497] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-02-27T19:19:16.8484272Z (Worker_DP0_TP4_EP4 pid=579) INFO 02-27 19:19:16 [model_runner_v1.py:2359] Loading drafter model...
2026-02-27T19:19:16.8757904Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:19:16.8758355Z Loading safetensors checkpoint shards:   0% Completed | 0/163 [00:00<?, ?it/s]
2026-02-27T19:19:16.9142953Z (Worker_DP0_TP3_EP3 pid=476) WARNING 02-27 19:19:16 [sfa_v1.py:497] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-02-27T19:19:16.9160522Z (Worker_DP1_TP3_EP11 pid=473) WARNING 02-27 19:19:16 [sfa_v1.py:497] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-02-27T19:19:16.9651739Z (Worker_DP1_TP3_EP11 pid=473) INFO 02-27 19:19:16 [model_runner_v1.py:2359] Loading drafter model...
2026-02-27T19:19:16.9683295Z (Worker_DP0_TP3_EP3 pid=476) INFO 02-27 19:19:16 [model_runner_v1.py:2359] Loading drafter model...
2026-02-27T19:19:16.9723332Z (Worker_DP0_TP2_EP2 pid=372) WARNING 02-27 19:19:16 [sfa_v1.py:497] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-02-27T19:19:17.0118671Z (Worker_DP1_TP2_EP10 pid=369) WARNING 02-27 19:19:17 [sfa_v1.py:497] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-02-27T19:19:17.0178304Z (Worker_DP0_TP2_EP2 pid=372) INFO 02-27 19:19:17 [model_runner_v1.py:2359] Loading drafter model...
2026-02-27T19:19:17.0898459Z (Worker_DP1_TP2_EP10 pid=369) INFO 02-27 19:19:17 [model_runner_v1.py:2359] Loading drafter model...
2026-02-27T19:19:17.1018163Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:19:17.1020664Z Loading safetensors checkpoint shards:   1% Completed | 1/163 [00:00<00:35,  4.53it/s]
2026-02-27T19:19:17.7946586Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:19:17.7947037Z Loading safetensors checkpoint shards:   1% Completed | 2/163 [00:00<01:20,  1.99it/s]
2026-02-27T19:19:18.5886454Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:19:18.5886946Z Loading safetensors checkpoint shards:   2% Completed | 3/163 [00:01<01:41,  1.57it/s]
2026-02-27T19:19:19.3962302Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:19:19.3962730Z Loading safetensors checkpoint shards:   2% Completed | 4/163 [00:02<01:51,  1.42it/s]
2026-02-27T19:19:20.2032656Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:19:20.2033090Z Loading safetensors checkpoint shards:   3% Completed | 5/163 [00:03<01:57,  1.35it/s]
2026-02-27T19:19:21.2350164Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:19:21.2350762Z Loading safetensors checkpoint shards:   4% Completed | 6/163 [00:04<02:11,  1.19it/s]
2026-02-27T19:19:22.1042909Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:19:22.1043561Z Loading safetensors checkpoint shards:   4% Completed | 7/163 [00:05<02:12,  1.18it/s]
2026-02-27T19:19:22.8889417Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:19:22.8889981Z Loading safetensors checkpoint shards:   5% Completed | 8/163 [00:06<02:08,  1.21it/s]
2026-02-27T19:19:23.7602698Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:19:23.7603245Z Loading safetensors checkpoint shards:   6% Completed | 9/163 [00:06<02:09,  1.19it/s]
2026-02-27T19:19:24.5216339Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:19:24.5216832Z Loading safetensors checkpoint shards:   6% Completed | 10/163 [00:07<02:05,  1.22it/s]
2026-02-27T19:19:25.3975787Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:19:25.3976218Z Loading safetensors checkpoint shards:   7% Completed | 11/163 [00:08<02:06,  1.20it/s]
2026-02-27T19:19:26.1148041Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:19:26.1148510Z Loading safetensors checkpoint shards:   7% Completed | 12/163 [00:09<02:00,  1.25it/s]
2026-02-27T19:19:26.9714615Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:19:26.9715098Z Loading safetensors checkpoint shards:   8% Completed | 13/163 [00:10<02:02,  1.22it/s]
2026-02-27T19:19:27.8559647Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:19:27.8560137Z Loading safetensors checkpoint shards:   9% Completed | 14/163 [00:10<02:04,  1.19it/s]
2026-02-27T19:19:28.8202204Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:19:28.8202790Z Loading safetensors checkpoint shards:   9% Completed | 15/163 [00:11<02:09,  1.14it/s]
2026-02-27T19:19:29.6646031Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:19:29.6646683Z Loading safetensors checkpoint shards:  10% Completed | 16/163 [00:12<02:07,  1.15it/s]
2026-02-27T19:19:30.5190787Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:19:30.5191228Z Loading safetensors checkpoint shards:  10% Completed | 17/163 [00:13<02:05,  1.16it/s]
2026-02-27T19:19:31.3446295Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:19:31.3447234Z Loading safetensors checkpoint shards:  11% Completed | 18/163 [00:14<02:03,  1.17it/s]
2026-02-27T19:19:32.2200490Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:19:32.2201042Z Loading safetensors checkpoint shards:  12% Completed | 19/163 [00:15<02:03,  1.16it/s]
2026-02-27T19:19:33.3076639Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:19:33.3077135Z Loading safetensors checkpoint shards:  12% Completed | 20/163 [00:16<02:12,  1.08it/s]
2026-02-27T19:19:34.4767693Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:19:34.4768221Z Loading safetensors checkpoint shards:  13% Completed | 21/163 [00:17<02:21,  1.00it/s]
2026-02-27T19:19:35.6214035Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:19:35.6214926Z Loading safetensors checkpoint shards:  13% Completed | 22/163 [00:18<02:27,  1.04s/it]
2026-02-27T19:19:36.6969115Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:19:36.6969573Z Loading safetensors checkpoint shards:  14% Completed | 23/163 [00:19<02:27,  1.05s/it]
2026-02-27T19:19:37.8442205Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:19:37.8442768Z Loading safetensors checkpoint shards:  15% Completed | 24/163 [00:20<02:30,  1.08s/it]
2026-02-27T19:19:38.9831851Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:19:38.9832400Z Loading safetensors checkpoint shards:  15% Completed | 25/163 [00:22<02:31,  1.10s/it]
2026-02-27T19:19:40.1348255Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:19:40.1348691Z Loading safetensors checkpoint shards:  16% Completed | 26/163 [00:23<02:32,  1.11s/it]
2026-02-27T19:19:41.3180748Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:19:41.3181290Z Loading safetensors checkpoint shards:  17% Completed | 27/163 [00:24<02:34,  1.14s/it]
2026-02-27T19:19:42.3586952Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:19:42.3587681Z Loading safetensors checkpoint shards:  17% Completed | 28/163 [00:25<02:29,  1.11s/it]
2026-02-27T19:19:43.5001250Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:19:43.5001712Z Loading safetensors checkpoint shards:  18% Completed | 29/163 [00:26<02:29,  1.12s/it]
2026-02-27T19:19:44.6706477Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:19:44.6706907Z Loading safetensors checkpoint shards:  18% Completed | 30/163 [00:27<02:30,  1.13s/it]
2026-02-27T19:19:45.7707345Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:19:45.7707842Z Loading safetensors checkpoint shards:  19% Completed | 31/163 [00:28<02:28,  1.12s/it]
2026-02-27T19:19:46.9903529Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:19:46.9904013Z Loading safetensors checkpoint shards:  20% Completed | 32/163 [00:30<02:30,  1.15s/it]
2026-02-27T19:19:48.0762140Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:19:48.0762618Z Loading safetensors checkpoint shards:  20% Completed | 33/163 [00:31<02:27,  1.13s/it]
2026-02-27T19:19:49.1923561Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:19:49.1924090Z Loading safetensors checkpoint shards:  21% Completed | 34/163 [00:32<02:25,  1.13s/it]
2026-02-27T19:19:50.3421726Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:19:50.3422291Z Loading safetensors checkpoint shards:  21% Completed | 35/163 [00:33<02:25,  1.13s/it]
2026-02-27T19:19:51.4250043Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:19:51.4250506Z Loading safetensors checkpoint shards:  22% Completed | 36/163 [00:34<02:22,  1.12s/it]
2026-02-27T19:19:52.5501349Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:19:52.5501780Z Loading safetensors checkpoint shards:  23% Completed | 37/163 [00:35<02:21,  1.12s/it]
2026-02-27T19:19:53.7499547Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:19:53.7500052Z Loading safetensors checkpoint shards:  23% Completed | 38/163 [00:36<02:23,  1.14s/it]
2026-02-27T19:19:54.8296109Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:19:54.8296607Z Loading safetensors checkpoint shards:  24% Completed | 39/163 [00:37<02:19,  1.13s/it]
2026-02-27T19:19:56.0022197Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:19:57.1473522Z Loading safetensors checkpoint shards:  25% Completed | 40/163 [00:39<02:20,  1.14s/it]
2026-02-27T19:19:57.1474012Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:19:57.1474399Z Loading safetensors checkpoint shards:  25% Completed | 41/163 [00:40<02:19,  1.14s/it]
2026-02-27T19:19:58.2500689Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:19:58.2501128Z Loading safetensors checkpoint shards:  26% Completed | 42/163 [00:41<02:16,  1.13s/it]
2026-02-27T19:19:59.4280420Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:19:59.4280866Z Loading safetensors checkpoint shards:  26% Completed | 43/163 [00:42<02:17,  1.14s/it]
2026-02-27T19:20:00.5842652Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:00.5843254Z Loading safetensors checkpoint shards:  27% Completed | 44/163 [00:43<02:16,  1.15s/it]
2026-02-27T19:20:01.7344742Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:01.7345192Z Loading safetensors checkpoint shards:  28% Completed | 45/163 [00:44<02:15,  1.15s/it]
2026-02-27T19:20:02.9564350Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:02.9564804Z Loading safetensors checkpoint shards:  28% Completed | 46/163 [00:46<02:16,  1.17s/it]
2026-02-27T19:20:04.0816608Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:04.0817350Z Loading safetensors checkpoint shards:  29% Completed | 47/163 [00:47<02:14,  1.16s/it]
2026-02-27T19:20:05.2560723Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:05.2561335Z Loading safetensors checkpoint shards:  29% Completed | 48/163 [00:48<02:13,  1.16s/it]
2026-02-27T19:20:06.3959193Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:06.3959727Z Loading safetensors checkpoint shards:  30% Completed | 49/163 [00:49<02:11,  1.16s/it]
2026-02-27T19:20:07.5193812Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:07.5194264Z Loading safetensors checkpoint shards:  31% Completed | 50/163 [00:50<02:09,  1.15s/it]
2026-02-27T19:20:08.7877639Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:08.7878123Z Loading safetensors checkpoint shards:  31% Completed | 51/163 [00:51<02:12,  1.18s/it]
2026-02-27T19:20:09.9755339Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:09.9755813Z Loading safetensors checkpoint shards:  32% Completed | 52/163 [00:53<02:11,  1.18s/it]
2026-02-27T19:20:11.0248820Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:11.0249326Z Loading safetensors checkpoint shards:  33% Completed | 53/163 [00:54<02:05,  1.14s/it]
2026-02-27T19:20:12.1697461Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:12.1697875Z Loading safetensors checkpoint shards:  33% Completed | 54/163 [00:55<02:04,  1.14s/it]
2026-02-27T19:20:13.3766912Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:13.3767443Z Loading safetensors checkpoint shards:  34% Completed | 55/163 [00:56<02:05,  1.16s/it]
2026-02-27T19:20:14.5296740Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:14.5297284Z Loading safetensors checkpoint shards:  34% Completed | 56/163 [00:57<02:04,  1.16s/it]
2026-02-27T19:20:15.6739534Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:15.6740128Z Loading safetensors checkpoint shards:  35% Completed | 57/163 [00:58<02:02,  1.16s/it]
2026-02-27T19:20:16.8170290Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:16.8170845Z Loading safetensors checkpoint shards:  36% Completed | 58/163 [00:59<02:00,  1.15s/it]
2026-02-27T19:20:17.9841819Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:17.9842466Z Loading safetensors checkpoint shards:  36% Completed | 59/163 [01:01<02:00,  1.16s/it]
2026-02-27T19:20:19.1259977Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:19.1260603Z Loading safetensors checkpoint shards:  37% Completed | 60/163 [01:02<01:58,  1.15s/it]
2026-02-27T19:20:19.2581465Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:19.2581876Z Loading safetensors checkpoint shards:  39% Completed | 63/163 [01:02<00:52,  1.89it/s]
2026-02-27T19:20:19.3705068Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:19.3705524Z Loading safetensors checkpoint shards:  40% Completed | 66/163 [01:02<00:30,  3.23it/s]
2026-02-27T19:20:19.4783154Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:19.4783738Z Loading safetensors checkpoint shards:  42% Completed | 69/163 [01:02<00:19,  4.92it/s]
2026-02-27T19:20:19.5866593Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:19.5866973Z Loading safetensors checkpoint shards:  44% Completed | 72/163 [01:02<00:13,  6.96it/s]
2026-02-27T19:20:19.6939694Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:19.6940149Z Loading safetensors checkpoint shards:  46% Completed | 75/163 [01:02<00:09,  9.33it/s]
2026-02-27T19:20:19.8023019Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:19.8023684Z Loading safetensors checkpoint shards:  48% Completed | 78/163 [01:02<00:07, 11.89it/s]
2026-02-27T19:20:19.9107032Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:19.9107438Z Loading safetensors checkpoint shards:  50% Completed | 81/163 [01:03<00:05, 14.53it/s]
2026-02-27T19:20:20.0236886Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:20.0237263Z Loading safetensors checkpoint shards:  52% Completed | 84/163 [01:03<00:04, 16.92it/s]
2026-02-27T19:20:20.1336800Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:20.1337220Z Loading safetensors checkpoint shards:  53% Completed | 87/163 [01:03<00:03, 19.17it/s]
2026-02-27T19:20:20.2407882Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:20.2408419Z Loading safetensors checkpoint shards:  55% Completed | 90/163 [01:03<00:03, 21.21it/s]
2026-02-27T19:20:20.3483489Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:20.3484024Z Loading safetensors checkpoint shards:  57% Completed | 93/163 [01:03<00:03, 22.87it/s]
2026-02-27T19:20:21.4580897Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:21.4581478Z Loading safetensors checkpoint shards:  59% Completed | 96/163 [01:04<00:09,  7.02it/s]
2026-02-27T19:20:24.3202665Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:24.3203130Z Loading safetensors checkpoint shards:  60% Completed | 98/163 [01:07<00:28,  2.32it/s]
2026-02-27T19:20:27.0707567Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:27.0708151Z Loading safetensors checkpoint shards:  61% Completed | 100/163 [01:10<00:41,  1.52it/s]
2026-02-27T19:20:29.3767809Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:29.3768241Z Loading safetensors checkpoint shards:  63% Completed | 102/163 [01:12<00:47,  1.27it/s]
2026-02-27T19:20:30.6713834Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:30.6714312Z Loading safetensors checkpoint shards:  63% Completed | 103/163 [01:13<00:51,  1.16it/s]
2026-02-27T19:20:32.0904162Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:32.0904660Z Loading safetensors checkpoint shards:  64% Completed | 104/163 [01:15<00:56,  1.04it/s]
2026-02-27T19:20:33.3309899Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:33.3310378Z Loading safetensors checkpoint shards:  64% Completed | 105/163 [01:16<00:59,  1.02s/it]
2026-02-27T19:20:34.5607014Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:34.5607593Z Loading safetensors checkpoint shards:  65% Completed | 106/163 [01:17<01:00,  1.07s/it]
2026-02-27T19:20:35.8076932Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:35.8077466Z Loading safetensors checkpoint shards:  66% Completed | 107/163 [01:18<01:02,  1.11s/it]
2026-02-27T19:20:37.1087325Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:37.1087783Z Loading safetensors checkpoint shards:  66% Completed | 108/163 [01:20<01:03,  1.16s/it]
2026-02-27T19:20:38.2580329Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:38.2580829Z Loading safetensors checkpoint shards:  67% Completed | 109/163 [01:21<01:02,  1.16s/it]
2026-02-27T19:20:39.4823977Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:39.4824436Z Loading safetensors checkpoint shards:  67% Completed | 110/163 [01:22<01:02,  1.18s/it]
2026-02-27T19:20:40.8907893Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:40.8908350Z Loading safetensors checkpoint shards:  68% Completed | 111/163 [01:24<01:04,  1.24s/it]
2026-02-27T19:20:42.0599733Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:42.0600200Z Loading safetensors checkpoint shards:  69% Completed | 112/163 [01:25<01:02,  1.22s/it]
2026-02-27T19:20:43.3472948Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:43.3473460Z Loading safetensors checkpoint shards:  69% Completed | 113/163 [01:26<01:02,  1.24s/it]
2026-02-27T19:20:44.6619446Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:44.6620123Z Loading safetensors checkpoint shards:  70% Completed | 114/163 [01:27<01:01,  1.26s/it]
2026-02-27T19:20:45.8140637Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:45.8141225Z Loading safetensors checkpoint shards:  71% Completed | 115/163 [01:28<00:59,  1.23s/it]
2026-02-27T19:20:47.0964181Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:47.0964889Z Loading safetensors checkpoint shards:  71% Completed | 116/163 [01:30<00:58,  1.25s/it]
2026-02-27T19:20:48.3525430Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:48.3526079Z Loading safetensors checkpoint shards:  72% Completed | 117/163 [01:31<00:57,  1.25s/it]
2026-02-27T19:20:49.6594608Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:49.6595277Z Loading safetensors checkpoint shards:  72% Completed | 118/163 [01:32<00:56,  1.27s/it]
2026-02-27T19:20:50.8416681Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:50.8417576Z Loading safetensors checkpoint shards:  73% Completed | 119/163 [01:33<00:54,  1.24s/it]
2026-02-27T19:20:51.9050997Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:51.9051458Z Loading safetensors checkpoint shards:  74% Completed | 120/163 [01:35<00:51,  1.19s/it]
2026-02-27T19:20:53.0572719Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:53.0573255Z Loading safetensors checkpoint shards:  74% Completed | 121/163 [01:36<00:49,  1.18s/it]
2026-02-27T19:20:54.1619001Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:54.1619487Z Loading safetensors checkpoint shards:  75% Completed | 122/163 [01:37<00:47,  1.16s/it]
2026-02-27T19:20:55.2717313Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:55.2717882Z Loading safetensors checkpoint shards:  75% Completed | 123/163 [01:38<00:45,  1.14s/it]
2026-02-27T19:20:56.4370109Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:56.4370735Z Loading safetensors checkpoint shards:  76% Completed | 124/163 [01:39<00:44,  1.15s/it]
2026-02-27T19:20:57.5934285Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:57.5934731Z Loading safetensors checkpoint shards:  77% Completed | 125/163 [01:40<00:43,  1.15s/it]
2026-02-27T19:20:58.7622462Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:58.7623060Z Loading safetensors checkpoint shards:  77% Completed | 126/163 [01:41<00:42,  1.16s/it]
2026-02-27T19:20:59.9333223Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:20:59.9333779Z Loading safetensors checkpoint shards:  78% Completed | 127/163 [01:43<00:41,  1.16s/it]
2026-02-27T19:21:01.0309892Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:21:01.0310470Z Loading safetensors checkpoint shards:  79% Completed | 128/163 [01:44<00:39,  1.14s/it]
2026-02-27T19:21:02.2298422Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:21:02.2299025Z Loading safetensors checkpoint shards:  79% Completed | 129/163 [01:45<00:39,  1.16s/it]
2026-02-27T19:21:03.3583165Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:21:03.3583573Z Loading safetensors checkpoint shards:  80% Completed | 130/163 [01:46<00:37,  1.15s/it]
2026-02-27T19:21:04.4775980Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:21:04.4776402Z Loading safetensors checkpoint shards:  80% Completed | 131/163 [01:47<00:36,  1.14s/it]
2026-02-27T19:21:05.6447286Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:21:05.6447788Z Loading safetensors checkpoint shards:  81% Completed | 132/163 [01:48<00:35,  1.15s/it]
2026-02-27T19:21:06.8532072Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:21:06.8532609Z Loading safetensors checkpoint shards:  82% Completed | 133/163 [01:49<00:34,  1.17s/it]
2026-02-27T19:21:07.9587977Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:21:07.9588420Z Loading safetensors checkpoint shards:  82% Completed | 134/163 [01:51<00:33,  1.15s/it]
2026-02-27T19:21:09.1448429Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:21:09.1449049Z Loading safetensors checkpoint shards:  83% Completed | 135/163 [01:52<00:32,  1.16s/it]
2026-02-27T19:21:10.2525965Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:21:10.2526628Z Loading safetensors checkpoint shards:  83% Completed | 136/163 [01:53<00:30,  1.14s/it]
2026-02-27T19:21:11.6350481Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:21:11.6351078Z Loading safetensors checkpoint shards:  84% Completed | 137/163 [01:54<00:31,  1.22s/it]
2026-02-27T19:21:12.7730080Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:21:12.7731051Z Loading safetensors checkpoint shards:  85% Completed | 138/163 [01:55<00:29,  1.19s/it]
2026-02-27T19:21:13.8998624Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:21:13.8999088Z Loading safetensors checkpoint shards:  85% Completed | 139/163 [01:57<00:28,  1.17s/it]
2026-02-27T19:21:15.0723983Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:21:15.0724479Z Loading safetensors checkpoint shards:  86% Completed | 140/163 [01:58<00:26,  1.17s/it]
2026-02-27T19:21:16.2149803Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:21:16.2150313Z Loading safetensors checkpoint shards:  87% Completed | 141/163 [01:59<00:25,  1.16s/it]
2026-02-27T19:21:17.3449050Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:21:17.3449924Z Loading safetensors checkpoint shards:  87% Completed | 142/163 [02:00<00:24,  1.15s/it]
2026-02-27T19:21:18.5055302Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:21:18.5055767Z Loading safetensors checkpoint shards:  88% Completed | 143/163 [02:01<00:23,  1.16s/it]
2026-02-27T19:21:19.6714437Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:21:19.6714919Z Loading safetensors checkpoint shards:  88% Completed | 144/163 [02:02<00:22,  1.16s/it]
2026-02-27T19:21:20.8396923Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:21:20.8397408Z Loading safetensors checkpoint shards:  89% Completed | 145/163 [02:03<00:20,  1.16s/it]
2026-02-27T19:21:22.0008024Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:21:22.0008455Z Loading safetensors checkpoint shards:  90% Completed | 146/163 [02:05<00:19,  1.16s/it]
2026-02-27T19:21:23.1192967Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:21:23.1193586Z Loading safetensors checkpoint shards:  90% Completed | 147/163 [02:06<00:18,  1.15s/it]
2026-02-27T19:21:24.3196072Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:21:24.3196516Z Loading safetensors checkpoint shards:  91% Completed | 148/163 [02:07<00:17,  1.16s/it]
2026-02-27T19:21:25.5125281Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:21:25.5125777Z Loading safetensors checkpoint shards:  91% Completed | 149/163 [02:08<00:16,  1.17s/it]
2026-02-27T19:21:26.6251135Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:21:26.6251612Z Loading safetensors checkpoint shards:  92% Completed | 150/163 [02:09<00:15,  1.15s/it]
2026-02-27T19:21:27.7860437Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:21:27.7860953Z Loading safetensors checkpoint shards:  93% Completed | 151/163 [02:10<00:13,  1.16s/it]
2026-02-27T19:21:28.9303887Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:21:28.9304331Z Loading safetensors checkpoint shards:  93% Completed | 152/163 [02:12<00:12,  1.15s/it]
2026-02-27T19:21:30.1053700Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:21:30.1054130Z Loading safetensors checkpoint shards:  94% Completed | 153/163 [02:13<00:11,  1.15s/it]
2026-02-27T19:21:31.2837540Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:21:31.2838007Z Loading safetensors checkpoint shards:  94% Completed | 154/163 [02:14<00:10,  1.17s/it]
2026-02-27T19:21:32.4390980Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:21:32.4391398Z Loading safetensors checkpoint shards:  95% Completed | 155/163 [02:15<00:09,  1.16s/it]
2026-02-27T19:21:33.5416846Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:21:33.5417395Z Loading safetensors checkpoint shards:  96% Completed | 156/163 [02:16<00:08,  1.15s/it]
2026-02-27T19:21:34.7291427Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:21:34.7292070Z Loading safetensors checkpoint shards:  96% Completed | 157/163 [02:17<00:06,  1.16s/it]
2026-02-27T19:21:37.6022153Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:21:37.6022803Z Loading safetensors checkpoint shards:  97% Completed | 158/163 [02:20<00:08,  1.67s/it]
2026-02-27T19:21:38.8670940Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:21:38.8671539Z Loading safetensors checkpoint shards:  98% Completed | 159/163 [02:21<00:06,  1.55s/it]
2026-02-27T19:21:40.2637061Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:21:40.2637519Z Loading safetensors checkpoint shards:  98% Completed | 160/163 [02:23<00:04,  1.50s/it]
2026-02-27T19:21:44.2115741Z (Worker_DP0_TP2_EP2 pid=372) INFO 02-27 19:21:44 [eagle_proposer.py:237] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-02-27T19:21:44.2265485Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:21:44.2265965Z Loading safetensors checkpoint shards:  99% Completed | 161/163 [02:27<00:04,  2.24s/it]
2026-02-27T19:21:44.2292812Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:21:44.2293195Z Loading safetensors checkpoint shards: 100% Completed | 163/163 [02:27<00:00,  1.11it/s]
2026-02-27T19:21:44.2302866Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:21:44.2400007Z (Worker_DP1_TP4_EP12 pid=577) INFO 02-27 19:21:44 [eagle_proposer.py:237] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-02-27T19:21:44.2411272Z (Worker_DP0_TP7_EP7 pid=890) INFO 02-27 19:21:44 [eagle_proposer.py:237] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-02-27T19:21:44.2422540Z (Worker_DP0_TP6_EP6 pid=786) INFO 02-27 19:21:44 [eagle_proposer.py:237] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-02-27T19:21:44.2495975Z (Worker_DP1_TP2_EP10 pid=369) INFO 02-27 19:21:44 [eagle_proposer.py:237] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-02-27T19:21:44.2563266Z (Worker_DP1_TP1_EP9 pid=251) INFO 02-27 19:21:44 [eagle_proposer.py:237] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-02-27T19:21:44.2581461Z (Worker_DP0_TP5_EP5 pid=682) INFO 02-27 19:21:44 [eagle_proposer.py:237] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-02-27T19:21:44.2591234Z (Worker_DP1_TP0_EP8 pid=201) INFO 02-27 19:21:44 [default_loader.py:293] Loading weights took 147.59 seconds
2026-02-27T19:21:44.2691685Z (Worker_DP0_TP4_EP4 pid=579) INFO 02-27 19:21:44 [eagle_proposer.py:237] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-02-27T19:21:44.2738393Z (Worker_DP1_TP7_EP15 pid=889) INFO 02-27 19:21:44 [eagle_proposer.py:237] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-02-27T19:21:44.2759438Z (Worker_DP0_TP3_EP3 pid=476) INFO 02-27 19:21:44 [eagle_proposer.py:237] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-02-27T19:21:44.2780364Z (Worker_DP1_TP6_EP14 pid=785) INFO 02-27 19:21:44 [eagle_proposer.py:237] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-02-27T19:21:44.2909705Z (Worker_DP0_TP1_EP1 pid=253) INFO 02-27 19:21:44 [eagle_proposer.py:237] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-02-27T19:21:44.2938550Z (Worker_DP1_TP0_EP8 pid=201) INFO 02-27 19:21:44 [eagle_proposer.py:237] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-02-27T19:21:44.2990039Z (Worker_DP1_TP5_EP13 pid=681) INFO 02-27 19:21:44 [eagle_proposer.py:237] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-02-27T19:21:44.3223546Z (Worker_DP1_TP3_EP11 pid=473) INFO 02-27 19:21:44 [eagle_proposer.py:237] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-02-27T19:21:44.4189491Z (Worker_DP0_TP0_EP0 pid=202) INFO 02-27 19:21:44 [default_loader.py:293] Loading weights took 147.55 seconds
2026-02-27T19:21:44.4552561Z (Worker_DP0_TP0_EP0 pid=202) INFO 02-27 19:21:44 [eagle_proposer.py:237] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-02-27T19:21:45.4630813Z (Worker_DP1_TP0_EP8 pid=201) INFO 02-27 19:21:45 [model_runner_v1.py:2368] Loading model weights took 30.8109 GB
2026-02-27T19:21:45.9826934Z (Worker_DP1_TP5_EP13 pid=681) INFO 02-27 19:21:45 [model_runner_v1.py:2368] Loading model weights took 30.8109 GB
2026-02-27T19:21:46.1870702Z (Worker_DP0_TP7_EP7 pid=890) INFO 02-27 19:21:46 [model_runner_v1.py:2368] Loading model weights took 30.8109 GB
2026-02-27T19:21:47.1759632Z (Worker_DP1_TP4_EP12 pid=577) INFO 02-27 19:21:47 [model_runner_v1.py:2368] Loading model weights took 30.8109 GB
2026-02-27T19:21:47.2666673Z (Worker_DP0_TP5_EP5 pid=682) INFO 02-27 19:21:47 [model_runner_v1.py:2368] Loading model weights took 30.8109 GB
2026-02-27T19:21:47.3081868Z (Worker_DP1_TP7_EP15 pid=889) INFO 02-27 19:21:47 [model_runner_v1.py:2368] Loading model weights took 30.8109 GB
2026-02-27T19:21:47.4450820Z (Worker_DP0_TP1_EP1 pid=253) INFO 02-27 19:21:47 [model_runner_v1.py:2368] Loading model weights took 30.8109 GB
2026-02-27T19:21:47.5169516Z (Worker_DP0_TP6_EP6 pid=786) INFO 02-27 19:21:47 [model_runner_v1.py:2368] Loading model weights took 30.8109 GB
2026-02-27T19:21:47.5961279Z (Worker_DP0_TP3_EP3 pid=476) INFO 02-27 19:21:47 [model_runner_v1.py:2368] Loading model weights took 30.8109 GB
2026-02-27T19:21:47.6351316Z (Worker_DP1_TP1_EP9 pid=251) INFO 02-27 19:21:47 [model_runner_v1.py:2368] Loading model weights took 30.8109 GB
2026-02-27T19:21:47.6739972Z (Worker_DP1_TP2_EP10 pid=369) INFO 02-27 19:21:47 [model_runner_v1.py:2368] Loading model weights took 30.8109 GB
2026-02-27T19:21:47.7034247Z (Worker_DP0_TP4_EP4 pid=579) INFO 02-27 19:21:47 [model_runner_v1.py:2368] Loading model weights took 30.8109 GB
2026-02-27T19:21:47.8281422Z (Worker_DP1_TP6_EP14 pid=785) INFO 02-27 19:21:47 [model_runner_v1.py:2368] Loading model weights took 30.8109 GB
2026-02-27T19:21:47.8722186Z (Worker_DP1_TP3_EP11 pid=473) INFO 02-27 19:21:47 [model_runner_v1.py:2368] Loading model weights took 30.8109 GB
2026-02-27T19:21:47.8927256Z (Worker_DP0_TP2_EP2 pid=372) INFO 02-27 19:21:47 [model_runner_v1.py:2368] Loading model weights took 30.8109 GB
2026-02-27T19:21:47.8985737Z (Worker_DP0_TP0_EP0 pid=202) INFO 02-27 19:21:47 [model_runner_v1.py:2368] Loading model weights took 30.8109 GB
2026-02-27T19:21:53.7734913Z (Worker_DP1_TP0_EP8 pid=201) INFO 02-27 19:21:53 [backends.py:916] Using cache directory: /root/.cache/vllm/torch_compile_cache/498d9dba1e/rank_0_1/backbone for vLLM's torch.compile
2026-02-27T19:21:53.7886104Z (Worker_DP1_TP0_EP8 pid=201) INFO 02-27 19:21:53 [backends.py:976] Dynamo bytecode transform time: 5.42 s
2026-02-27T19:21:53.8181317Z (Worker_DP0_TP0_EP0 pid=202) INFO 02-27 19:21:53 [backends.py:916] Using cache directory: /root/.cache/vllm/torch_compile_cache/498d9dba1e/rank_0_0/backbone for vLLM's torch.compile
2026-02-27T19:21:53.8264830Z (Worker_DP0_TP0_EP0 pid=202) INFO 02-27 19:21:53 [backends.py:976] Dynamo bytecode transform time: 5.46 s
2026-02-27T19:22:00.6069718Z (Worker_DP1_TP0_EP8 pid=201) /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in reduce-overhead mode: config.experimental_config.enable_view_optimize:True, set_dim_gears, dynamo_export, scope, npu_print
2026-02-27T19:22:00.6080553Z (Worker_DP1_TP0_EP8 pid=201)   warnings.warn(
2026-02-27T19:22:00.6142679Z (Worker_DP1_TP6_EP14 pid=785) /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in reduce-overhead mode: config.experimental_config.enable_view_optimize:True, set_dim_gears, dynamo_export, scope, npu_print
2026-02-27T19:22:00.6152845Z (Worker_DP1_TP6_EP14 pid=785)   warnings.warn(
2026-02-27T19:22:00.6183593Z (Worker_DP1_TP4_EP12 pid=577) /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in reduce-overhead mode: config.experimental_config.enable_view_optimize:True, set_dim_gears, dynamo_export, scope, npu_print
2026-02-27T19:22:00.6193784Z (Worker_DP1_TP4_EP12 pid=577)   warnings.warn(
2026-02-27T19:22:00.6215853Z (Worker_DP0_TP0_EP0 pid=202) /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in reduce-overhead mode: config.experimental_config.enable_view_optimize:True, set_dim_gears, dynamo_export, scope, npu_print
2026-02-27T19:22:00.6227032Z (Worker_DP0_TP0_EP0 pid=202)   warnings.warn(
2026-02-27T19:22:00.6238711Z (Worker_DP1_TP5_EP13 pid=681) /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in reduce-overhead mode: config.experimental_config.enable_view_optimize:True, set_dim_gears, dynamo_export, scope, npu_print
2026-02-27T19:22:00.6248568Z (Worker_DP1_TP5_EP13 pid=681)   warnings.warn(
2026-02-27T19:22:00.6269028Z (Worker_DP1_TP3_EP11 pid=473) /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in reduce-overhead mode: config.experimental_config.enable_view_optimize:True, set_dim_gears, dynamo_export, scope, npu_print
2026-02-27T19:22:00.6279292Z (Worker_DP1_TP3_EP11 pid=473)   warnings.warn(
2026-02-27T19:22:00.6332768Z (Worker_DP0_TP6_EP6 pid=786) /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in reduce-overhead mode: config.experimental_config.enable_view_optimize:True, set_dim_gears, dynamo_export, scope, npu_print
2026-02-27T19:22:00.6333917Z (Worker_DP0_TP6_EP6 pid=786)   warnings.warn(
2026-02-27T19:22:00.6334969Z (Worker_DP0_TP5_EP5 pid=682) /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in reduce-overhead mode: config.experimental_config.enable_view_optimize:True, set_dim_gears, dynamo_export, scope, npu_print
2026-02-27T19:22:00.6340669Z (Worker_DP0_TP5_EP5 pid=682)   warnings.warn(
2026-02-27T19:22:00.6352859Z (Worker_DP1_TP2_EP10 pid=369) /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in reduce-overhead mode: config.experimental_config.enable_view_optimize:True, set_dim_gears, dynamo_export, scope, npu_print
2026-02-27T19:22:00.6361874Z (Worker_DP1_TP2_EP10 pid=369)   warnings.warn(
2026-02-27T19:22:00.6373580Z (Worker_DP0_TP4_EP4 pid=579) /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in reduce-overhead mode: config.experimental_config.enable_view_optimize:True, set_dim_gears, dynamo_export, scope, npu_print
2026-02-27T19:22:00.6382975Z (Worker_DP0_TP4_EP4 pid=579)   warnings.warn(
2026-02-27T19:22:00.6393944Z (Worker_DP0_TP7_EP7 pid=890) /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in reduce-overhead mode: config.experimental_config.enable_view_optimize:True, set_dim_gears, dynamo_export, scope, npu_print
2026-02-27T19:22:00.6402551Z (Worker_DP0_TP7_EP7 pid=890)   warnings.warn(
2026-02-27T19:22:00.6414340Z (Worker_DP1_TP7_EP15 pid=889) /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in reduce-overhead mode: config.experimental_config.enable_view_optimize:True, set_dim_gears, dynamo_export, scope, npu_print
2026-02-27T19:22:00.6423129Z (Worker_DP1_TP7_EP15 pid=889)   warnings.warn(
2026-02-27T19:22:00.6490816Z (Worker_DP0_TP2_EP2 pid=372) /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in reduce-overhead mode: config.experimental_config.enable_view_optimize:True, set_dim_gears, dynamo_export, scope, npu_print
2026-02-27T19:22:00.6506552Z (Worker_DP0_TP2_EP2 pid=372)   warnings.warn(
2026-02-27T19:22:00.6751772Z (Worker_DP0_TP3_EP3 pid=476) /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in reduce-overhead mode: config.experimental_config.enable_view_optimize:True, set_dim_gears, dynamo_export, scope, npu_print
2026-02-27T19:22:00.6761068Z (Worker_DP0_TP3_EP3 pid=476)   warnings.warn(
2026-02-27T19:22:00.6841606Z (Worker_DP0_TP1_EP1 pid=253) /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in reduce-overhead mode: config.experimental_config.enable_view_optimize:True, set_dim_gears, dynamo_export, scope, npu_print
2026-02-27T19:22:00.6851103Z (Worker_DP0_TP1_EP1 pid=253)   warnings.warn(
2026-02-27T19:22:00.7644763Z (Worker_DP1_TP1_EP9 pid=251) /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in reduce-overhead mode: config.experimental_config.enable_view_optimize:True, set_dim_gears, dynamo_export, scope, npu_print
2026-02-27T19:22:00.7651762Z (Worker_DP1_TP1_EP9 pid=251)   warnings.warn(
2026-02-27T19:22:13.3762323Z (Worker_DP1_TP0_EP8 pid=201) INFO 02-27 19:22:13 [backends.py:368] Compiling a graph for compile range (1, 4112) takes 12.84 s
2026-02-27T19:22:13.3774117Z (Worker_DP1_TP0_EP8 pid=201) INFO 02-27 19:22:13 [monitor.py:34] torch.compile takes 18.26 s in total
2026-02-27T19:22:13.5343950Z (Worker_DP0_TP0_EP0 pid=202) INFO 02-27 19:22:13 [backends.py:368] Compiling a graph for compile range (1, 4112) takes 12.99 s
2026-02-27T19:22:13.5375418Z (Worker_DP0_TP0_EP0 pid=202) INFO 02-27 19:22:13 [monitor.py:34] torch.compile takes 18.45 s in total
2026-02-27T19:22:18.5479455Z (Worker_DP0_TP0_EP0 pid=202) INFO 02-27 19:22:18 [worker.py:359] Available KV cache memory: 16.97 GiB
2026-02-27T19:22:18.5587776Z (EngineCore_DP0 pid=154) INFO 02-27 19:22:18 [kv_cache_utils.py:1307] GPU KV cache size: 208,640 tokens
2026-02-27T19:22:18.5600204Z (EngineCore_DP0 pid=154) INFO 02-27 19:22:18 [kv_cache_utils.py:1312] Maximum concurrency for 68,000 tokens per request: 3.06x
2026-02-27T19:22:18.5652375Z (Worker_DP1_TP0_EP8 pid=201) INFO 02-27 19:22:18 [worker.py:359] Available KV cache memory: 16.98 GiB
2026-02-27T19:22:18.5784454Z (EngineCore_DP1 pid=173) INFO 02-27 19:22:18 [kv_cache_utils.py:1307] GPU KV cache size: 208,768 tokens
2026-02-27T19:22:18.5796070Z (EngineCore_DP1 pid=173) INFO 02-27 19:22:18 [kv_cache_utils.py:1312] Maximum concurrency for 68,000 tokens per request: 3.07x
2026-02-27T19:22:35.8164557Z (Worker_DP0_TP0_EP0 pid=202) 
2026-02-27T19:22:35.8165512Z Capturing CUDA graphs (decode, FULL):   0%|          | 0/6 [00:00<?, ?it/s][rank5]:[W227 19:22:35.769020751 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-02-27T19:22:35.8172541Z [rank6]:[W227 19:22:35.769044311 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-02-27T19:22:35.8184268Z [rank7]:[W227 19:22:35.769053301 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-02-27T19:22:35.8196689Z [rank4]:[W227 19:22:35.769054091 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-02-27T19:22:35.8207073Z [rank11]:[W227 19:22:35.769059501 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-02-27T19:22:35.8216457Z [rank3]:[W227 19:22:35.769056871 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-02-27T19:22:35.8227132Z [rank12]:[W227 19:22:35.769064831 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-02-27T19:22:35.8238331Z [rank14]:[W227 19:22:35.769066361 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-02-27T19:22:35.8248841Z [rank13]:[W227 19:22:35.769064741 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-02-27T19:22:35.8259941Z [rank15]:[W227 19:22:35.769069211 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-02-27T19:22:35.8270591Z [rank8]:[W227 19:22:35.769082211 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-02-27T19:22:35.8280657Z [rank10]:[W227 19:22:35.769101101 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-02-27T19:22:35.8290511Z [rank9]:[W227 19:22:35.769540484 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-02-27T19:22:35.8301019Z [rank2]:[W227 19:22:35.770052518 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-02-27T19:22:35.8311746Z [rank0]:[W227 19:22:35.770107408 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-02-27T19:22:35.8322189Z [rank1]:[W227 19:22:35.771954310 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-02-27T19:22:38.5228747Z [rank2]:[W227 19:22:38.476037333 compiler_depend.ts:3667] Warning: Tensor not is not allocated by NPUCachingAllocator, skip eraseStream. (function operator())
2026-02-27T19:22:38.5234975Z [rank5]:[W227 19:22:38.476044093 compiler_depend.ts:3667] Warning: Tensor not is not allocated by NPUCachingAllocator, skip eraseStream. (function operator())
2026-02-27T19:22:38.5244495Z [rank6]:[W227 19:22:38.476059224 compiler_depend.ts:3667] Warning: Tensor not is not allocated by NPUCachingAllocator, skip eraseStream. (function operator())
2026-02-27T19:22:38.5253962Z [rank4]:[W227 19:22:38.476069284 compiler_depend.ts:3667] Warning: Tensor not is not allocated by NPUCachingAllocator, skip eraseStream. (function operator())
2026-02-27T19:22:38.5264473Z [rank7]:[W227 19:22:38.476613487 compiler_depend.ts:3667] Warning: Tensor not is not allocated by NPUCachingAllocator, skip eraseStream. (function operator())
2026-02-27T19:22:38.5275475Z [rank1]:[W227 19:22:38.477760585 compiler_depend.ts:3667] Warning: Tensor not is not allocated by NPUCachingAllocator, skip eraseStream. (function operator())
2026-02-27T19:22:38.5286374Z [rank3]:[W227 19:22:38.478040577 compiler_depend.ts:3667] Warning: Tensor not is not allocated by NPUCachingAllocator, skip eraseStream. (function operator())
2026-02-27T19:22:38.5297449Z [rank0]:[W227 19:22:38.478614601 compiler_depend.ts:3667] Warning: Tensor not is not allocated by NPUCachingAllocator, skip eraseStream. (function operator())
2026-02-27T19:22:38.5674871Z [rank12]:[W227 19:22:38.521242354 compiler_depend.ts:3667] Warning: Tensor not is not allocated by NPUCachingAllocator, skip eraseStream. (function operator())
2026-02-27T19:22:38.5714544Z [rank11]:[W227 19:22:38.524356635 compiler_depend.ts:3667] Warning: Tensor not is not allocated by NPUCachingAllocator, skip eraseStream. (function operator())
2026-02-27T19:22:38.5733511Z [rank13]:[W227 19:22:38.524617277 compiler_depend.ts:3667] Warning: Tensor not is not allocated by NPUCachingAllocator, skip eraseStream. (function operator())
2026-02-27T19:22:38.5743988Z [rank9]:[W227 19:22:38.525084140 compiler_depend.ts:3667] Warning: Tensor not is not allocated by NPUCachingAllocator, skip eraseStream. (function operator())
2026-02-27T19:22:38.5754430Z [rank8]:[W227 19:22:38.525457392 compiler_depend.ts:3667] Warning: Tensor not is not allocated by NPUCachingAllocator, skip eraseStream. (function operator())
2026-02-27T19:22:38.5765100Z [rank10]:[W227 19:22:38.525768554 compiler_depend.ts:3667] Warning: Tensor not is not allocated by NPUCachingAllocator, skip eraseStream. (function operator())
2026-02-27T19:22:38.5775568Z [rank15]:[W227 19:22:38.526071706 compiler_depend.ts:3667] Warning: Tensor not is not allocated by NPUCachingAllocator, skip eraseStream. (function operator())
2026-02-27T19:22:38.5796789Z [rank14]:[W227 19:22:38.526465539 compiler_depend.ts:3667] Warning: Tensor not is not allocated by NPUCachingAllocator, skip eraseStream. (function operator())
2026-02-27T19:22:57.4852276Z 
2026-02-27T19:22:57.4853319Z Capturing CUDA graphs (decode, FULL):  17%|â–ˆâ–‹        | 1/6 [00:17<01:28, 17.74s/it]
2026-02-27T19:22:57.4853883Z Capturing CUDA graphs (decode, FULL):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [00:20<00:36,  9.03s/it]
2026-02-27T19:22:57.4854362Z Capturing CUDA graphs (decode, FULL):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:23<00:18,  6.31s/it]
2026-02-27T19:22:57.4855124Z Capturing CUDA graphs (decode, FULL):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [00:26<00:10,  5.02s/it]
2026-02-27T19:22:57.4855661Z Capturing CUDA graphs (decode, FULL):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:29<00:04,  4.34s/it]
2026-02-27T19:22:57.4856116Z Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:36<00:00,  5.15s/it]
2026-02-27T19:22:57.4856699Z Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:36<00:00,  6.11s/it]
2026-02-27T19:22:57.9774686Z (Worker_DP1_TP0_EP8 pid=201) INFO 02-27 19:22:57 [gpu_model_runner.py:5246] Graph capturing finished in 38 secs, took 0.33 GiB
2026-02-27T19:22:57.9881428Z (EngineCore_DP1 pid=173) INFO 02-27 19:22:57 [core.py:278] init engine (profile, create kv cache, warmup model) took 70.11 seconds
2026-02-27T19:22:57.9906089Z (Worker_DP0_TP0_EP0 pid=202) INFO 02-27 19:22:57 [gpu_model_runner.py:5246] Graph capturing finished in 38 secs, took 0.33 GiB
2026-02-27T19:22:58.0050640Z (EngineCore_DP0 pid=154) INFO 02-27 19:22:58 [core.py:278] init engine (profile, create kv cache, warmup model) took 70.10 seconds
2026-02-27T19:22:58.9199541Z (ApiServer_0 pid=184) WARNING 02-27 19:22:58 [loggers.py:1264] AsyncLLM created with api_server_count more than 1; disabling stats logging to avoid incomplete stats.
2026-02-27T19:22:58.9207716Z (ApiServer_2 pid=186) WARNING 02-27 19:22:58 [loggers.py:1264] AsyncLLM created with api_server_count more than 1; disabling stats logging to avoid incomplete stats.
2026-02-27T19:22:58.9218114Z (ApiServer_1 pid=185) WARNING 02-27 19:22:58 [loggers.py:1264] AsyncLLM created with api_server_count more than 1; disabling stats logging to avoid incomplete stats.
2026-02-27T19:22:58.9227530Z INFO 02-27 19:22:58 [coordinator.py:200] All engine subscriptions received by DP coordinator
2026-02-27T19:22:58.9238871Z (ApiServer_3 pid=187) WARNING 02-27 19:22:58 [loggers.py:1264] AsyncLLM created with api_server_count more than 1; disabling stats logging to avoid incomplete stats.
2026-02-27T19:22:58.9247706Z (EngineCore_DP0 pid=154) INFO 02-27 19:22:58 [vllm.py:689] Asynchronous scheduling is enabled.
2026-02-27T19:22:58.9256796Z (EngineCore_DP1 pid=173) INFO 02-27 19:22:58 [vllm.py:689] Asynchronous scheduling is enabled.
2026-02-27T19:22:58.9267330Z INFO 02-27 19:22:58 [utils.py:248] Waiting for API servers to complete ...
2026-02-27T19:22:58.9277197Z (EngineCore_DP1 pid=173) INFO 02-27 19:22:58 [ascend_config.py:454] Dynamic EPLB is False
2026-02-27T19:22:58.9287392Z (EngineCore_DP0 pid=154) INFO 02-27 19:22:58 [ascend_config.py:454] Dynamic EPLB is False
2026-02-27T19:22:58.9297024Z (EngineCore_DP1 pid=173) INFO 02-27 19:22:58 [ascend_config.py:455] The number of redundant experts is 0
2026-02-27T19:22:58.9306964Z (EngineCore_DP0 pid=154) INFO 02-27 19:22:58 [ascend_config.py:455] The number of redundant experts is 0
2026-02-27T19:22:58.9318928Z (EngineCore_DP1 pid=173) INFO 02-27 19:22:58 [ascend_config.py:55] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-27T19:22:58.9329559Z (EngineCore_DP0 pid=154) INFO 02-27 19:22:58 [ascend_config.py:55] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-27T19:22:58.9339735Z (EngineCore_DP1 pid=173) INFO 02-27 19:22:58 [platform.py:301] FULL_DECODE_ONLY compilation enabled on NPU. use_inductor not supported - using only ACL Graph mode
2026-02-27T19:22:58.9349188Z (EngineCore_DP0 pid=154) INFO 02-27 19:22:58 [platform.py:301] FULL_DECODE_ONLY compilation enabled on NPU. use_inductor not supported - using only ACL Graph mode
2026-02-27T19:22:58.9359378Z (EngineCore_DP0 pid=154) WARNING 02-27 19:22:58 [platform.py:318] [91m
2026-02-27T19:22:58.9369433Z (EngineCore_DP0 pid=154) WARNING 02-27 19:22:58 [platform.py:318]             **********************************************************************************
2026-02-27T19:22:58.9381029Z (EngineCore_DP0 pid=154) WARNING 02-27 19:22:58 [platform.py:318]             * WARNING: You have enabled the *full graph* feature.
2026-02-27T19:22:58.9390330Z (EngineCore_DP0 pid=154) WARNING 02-27 19:22:58 [platform.py:318]             * This is an early experimental stage and may involve various unknown issues.
2026-02-27T19:22:58.9400853Z (EngineCore_DP0 pid=154) WARNING 02-27 19:22:58 [platform.py:318]             * A known problem is that capturing too many batch sizes can lead to OOM
2026-02-27T19:22:58.9410553Z (EngineCore_DP0 pid=154) WARNING 02-27 19:22:58 [platform.py:318]             * (Out of Memory) errors or inference hangs. If you encounter such issues,
2026-02-27T19:22:58.9420360Z (EngineCore_DP0 pid=154) WARNING 02-27 19:22:58 [platform.py:318]             * consider reducing `gpu_memory_utilization` or manually specifying a smaller
2026-02-27T19:22:58.9429880Z (EngineCore_DP0 pid=154) WARNING 02-27 19:22:58 [platform.py:318]             * batch size for graph capture.
2026-02-27T19:22:58.9440122Z (EngineCore_DP0 pid=154) WARNING 02-27 19:22:58 [platform.py:318]             * For more details, please refer to:
2026-02-27T19:22:58.9450942Z (EngineCore_DP0 pid=154) WARNING 02-27 19:22:58 [platform.py:318]             * https://docs.vllm.ai/en/stable/configuration/conserving_memory.html#reduce-cuda-graphs
2026-02-27T19:22:58.9462161Z (EngineCore_DP0 pid=154) WARNING 02-27 19:22:58 [platform.py:318]             **********************************************************************************[0m
2026-02-27T19:22:58.9471587Z (EngineCore_DP0 pid=154) WARNING 02-27 19:22:58 [platform.py:318]             
2026-02-27T19:22:58.9482156Z (EngineCore_DP1 pid=173) WARNING 02-27 19:22:58 [platform.py:318] [91m
2026-02-27T19:22:58.9492242Z (EngineCore_DP1 pid=173) WARNING 02-27 19:22:58 [platform.py:318]             **********************************************************************************
2026-02-27T19:22:58.9502152Z (EngineCore_DP1 pid=173) WARNING 02-27 19:22:58 [platform.py:318]             * WARNING: You have enabled the *full graph* feature.
2026-02-27T19:22:58.9511213Z (EngineCore_DP1 pid=173) WARNING 02-27 19:22:58 [platform.py:318]             * This is an early experimental stage and may involve various unknown issues.
2026-02-27T19:22:58.9524353Z (EngineCore_DP1 pid=173) WARNING 02-27 19:22:58 [platform.py:318]             * A known problem is that capturing too many batch sizes can lead to OOM
2026-02-27T19:22:58.9532145Z (EngineCore_DP1 pid=173) WARNING 02-27 19:22:58 [platform.py:318]             * (Out of Memory) errors or inference hangs. If you encounter such issues,
2026-02-27T19:22:58.9540831Z (EngineCore_DP1 pid=173) WARNING 02-27 19:22:58 [platform.py:318]             * consider reducing `gpu_memory_utilization` or manually specifying a smaller
2026-02-27T19:22:58.9550197Z (EngineCore_DP1 pid=173) WARNING 02-27 19:22:58 [platform.py:318]             * batch size for graph capture.
2026-02-27T19:22:58.9560030Z (EngineCore_DP1 pid=173) WARNING 02-27 19:22:58 [platform.py:318]             * For more details, please refer to:
2026-02-27T19:22:58.9570135Z (EngineCore_DP1 pid=173) WARNING 02-27 19:22:58 [platform.py:318]             * https://docs.vllm.ai/en/stable/configuration/conserving_memory.html#reduce-cuda-graphs
2026-02-27T19:22:58.9579857Z (EngineCore_DP1 pid=173) WARNING 02-27 19:22:58 [platform.py:318]             **********************************************************************************[0m
2026-02-27T19:22:58.9588474Z (EngineCore_DP1 pid=173) WARNING 02-27 19:22:58 [platform.py:318]             
2026-02-27T19:22:58.9599100Z (EngineCore_DP0 pid=154) INFO 02-27 19:22:58 [platform.py:430] Set PYTORCH_NPU_ALLOC_CONF=expandable_segments:True
2026-02-27T19:22:58.9609328Z (EngineCore_DP1 pid=173) INFO 02-27 19:22:58 [platform.py:430] Set PYTORCH_NPU_ALLOC_CONF=expandable_segments:True
2026-02-27T19:22:58.9918356Z (ApiServer_0 pid=184) INFO 02-27 19:22:58 [api_server.py:481] Supported tasks: ['generate']
2026-02-27T19:22:58.9930103Z (ApiServer_3 pid=187) INFO 02-27 19:22:58 [api_server.py:481] Supported tasks: ['generate']
2026-02-27T19:22:58.9941660Z (ApiServer_2 pid=186) INFO 02-27 19:22:58 [api_server.py:481] Supported tasks: ['generate']
2026-02-27T19:22:58.9953059Z (ApiServer_1 pid=185) INFO 02-27 19:22:58 [api_server.py:481] Supported tasks: ['generate']
2026-02-27T19:22:59.4155208Z (ApiServer_0 pid=184) WARNING 02-27 19:22:59 [model.py:1350] Default vLLM sampling parameters have been overridden by the model's `generation_config.json`: `{'top_p': 0.95}`. If this is not intended, please relaunch vLLM instance with `--generation-config vllm`.
2026-02-27T19:22:59.4164896Z (ApiServer_3 pid=187) WARNING 02-27 19:22:59 [model.py:1350] Default vLLM sampling parameters have been overridden by the model's `generation_config.json`: `{'top_p': 0.95}`. If this is not intended, please relaunch vLLM instance with `--generation-config vllm`.
2026-02-27T19:22:59.4174304Z (ApiServer_1 pid=185) WARNING 02-27 19:22:59 [model.py:1350] Default vLLM sampling parameters have been overridden by the model's `generation_config.json`: `{'top_p': 0.95}`. If this is not intended, please relaunch vLLM instance with `--generation-config vllm`.
2026-02-27T19:22:59.4183834Z (ApiServer_0 pid=184) INFO 02-27 19:22:59 [serving.py:188] Warming up chat template processing...
2026-02-27T19:22:59.4193675Z (ApiServer_3 pid=187) INFO 02-27 19:22:59 [serving.py:188] Warming up chat template processing...
2026-02-27T19:22:59.4204819Z (ApiServer_1 pid=185) INFO 02-27 19:22:59 [serving.py:188] Warming up chat template processing...
2026-02-27T19:22:59.4439089Z (ApiServer_3 pid=187) INFO 02-27 19:22:59 [serving.py:213] Chat template warmup completed in 27.5ms
2026-02-27T19:22:59.4448228Z (ApiServer_0 pid=184) INFO 02-27 19:22:59 [serving.py:213] Chat template warmup completed in 27.5ms
2026-02-27T19:22:59.4458404Z (ApiServer_1 pid=185) INFO 02-27 19:22:59 [serving.py:213] Chat template warmup completed in 27.5ms
2026-02-27T19:22:59.4468429Z (ApiServer_0 pid=184) INFO 02-27 19:22:59 [api_server.py:486] Starting vLLM API server 0 on http://0.0.0.0:8080
2026-02-27T19:22:59.4479142Z (ApiServer_3 pid=187) INFO 02-27 19:22:59 [api_server.py:486] Starting vLLM API server 3 on http://0.0.0.0:8080
2026-02-27T19:22:59.4489698Z (ApiServer_0 pid=184) INFO 02-27 19:22:59 [launcher.py:38] Available routes are:
2026-02-27T19:22:59.4501391Z (ApiServer_3 pid=187) INFO 02-27 19:22:59 [launcher.py:38] Available routes are:
2026-02-27T19:22:59.4511715Z (ApiServer_0 pid=184) INFO 02-27 19:22:59 [launcher.py:47] Route: /openapi.json, Methods: GET, HEAD
2026-02-27T19:22:59.4522408Z (ApiServer_3 pid=187) INFO 02-27 19:22:59 [launcher.py:47] Route: /openapi.json, Methods: GET, HEAD
2026-02-27T19:22:59.4537355Z (ApiServer_0 pid=184) INFO 02-27 19:22:59 [launcher.py:47] Route: /docs, Methods: GET, HEAD
2026-02-27T19:22:59.4550176Z (ApiServer_3 pid=187) INFO 02-27 19:22:59 [launcher.py:47] Route: /docs, Methods: GET, HEAD
2026-02-27T19:22:59.4564585Z (ApiServer_0 pid=184) INFO 02-27 19:22:59 [launcher.py:47] Route: /docs/oauth2-redirect, Methods: GET, HEAD
2026-02-27T19:22:59.4576690Z (ApiServer_3 pid=187) INFO 02-27 19:22:59 [launcher.py:47] Route: /docs/oauth2-redirect, Methods: GET, HEAD
2026-02-27T19:22:59.4588255Z (ApiServer_0 pid=184) INFO 02-27 19:22:59 [launcher.py:47] Route: /redoc, Methods: GET, HEAD
2026-02-27T19:22:59.4604871Z (ApiServer_1 pid=185) INFO 02-27 19:22:59 [api_server.py:486] Starting vLLM API server 1 on http://0.0.0.0:8080
2026-02-27T19:22:59.4615584Z (ApiServer_3 pid=187) INFO 02-27 19:22:59 [launcher.py:47] Route: /redoc, Methods: GET, HEAD
2026-02-27T19:22:59.4625601Z (ApiServer_0 pid=184) INFO 02-27 19:22:59 [launcher.py:47] Route: /load, Methods: GET
2026-02-27T19:22:59.4636971Z (ApiServer_3 pid=187) INFO 02-27 19:22:59 [launcher.py:47] Route: /load, Methods: GET
2026-02-27T19:22:59.4647379Z (ApiServer_0 pid=184) INFO 02-27 19:22:59 [launcher.py:47] Route: /version, Methods: GET
2026-02-27T19:22:59.4658055Z (ApiServer_3 pid=187) INFO 02-27 19:22:59 [launcher.py:47] Route: /version, Methods: GET
2026-02-27T19:22:59.4668952Z (ApiServer_0 pid=184) INFO 02-27 19:22:59 [launcher.py:47] Route: /scale_elastic_ep, Methods: POST
2026-02-27T19:22:59.4682408Z (ApiServer_1 pid=185) INFO 02-27 19:22:59 [launcher.py:38] Available routes are:
2026-02-27T19:22:59.4690811Z (ApiServer_3 pid=187) INFO 02-27 19:22:59 [launcher.py:47] Route: /scale_elastic_ep, Methods: POST
2026-02-27T19:22:59.4701054Z (ApiServer_0 pid=184) INFO 02-27 19:22:59 [launcher.py:47] Route: /is_scaling_elastic_ep, Methods: POST
2026-02-27T19:22:59.4711958Z (ApiServer_1 pid=185) INFO 02-27 19:22:59 [launcher.py:47] Route: /openapi.json, Methods: HEAD, GET
2026-02-27T19:22:59.4722830Z (ApiServer_0 pid=184) INFO 02-27 19:22:59 [launcher.py:47] Route: /tokenize, Methods: POST
2026-02-27T19:22:59.4733270Z (ApiServer_3 pid=187) INFO 02-27 19:22:59 [launcher.py:47] Route: /is_scaling_elastic_ep, Methods: POST
2026-02-27T19:22:59.4743494Z (ApiServer_1 pid=185) INFO 02-27 19:22:59 [launcher.py:47] Route: /docs, Methods: HEAD, GET
2026-02-27T19:22:59.4754057Z (ApiServer_0 pid=184) INFO 02-27 19:22:59 [launcher.py:47] Route: /detokenize, Methods: POST
2026-02-27T19:22:59.4764761Z (ApiServer_3 pid=187) INFO 02-27 19:22:59 [launcher.py:47] Route: /tokenize, Methods: POST
2026-02-27T19:22:59.4775524Z (ApiServer_1 pid=185) INFO 02-27 19:22:59 [launcher.py:47] Route: /docs/oauth2-redirect, Methods: HEAD, GET
2026-02-27T19:22:59.4785897Z (ApiServer_0 pid=184) INFO 02-27 19:22:59 [launcher.py:47] Route: /inference/v1/generate, Methods: POST
2026-02-27T19:22:59.4796275Z (ApiServer_3 pid=187) INFO 02-27 19:22:59 [launcher.py:47] Route: /detokenize, Methods: POST
2026-02-27T19:22:59.4807327Z (ApiServer_0 pid=184) INFO 02-27 19:22:59 [launcher.py:47] Route: /metrics, Methods: GET
2026-02-27T19:22:59.4818592Z (ApiServer_1 pid=185) INFO 02-27 19:22:59 [launcher.py:47] Route: /redoc, Methods: HEAD, GET
2026-02-27T19:22:59.4828669Z (ApiServer_3 pid=187) INFO 02-27 19:22:59 [launcher.py:47] Route: /inference/v1/generate, Methods: POST
2026-02-27T19:22:59.4838278Z (ApiServer_3 pid=187) INFO 02-27 19:22:59 [launcher.py:47] Route: /metrics, Methods: GET
2026-02-27T19:22:59.4848633Z (ApiServer_1 pid=185) INFO 02-27 19:22:59 [launcher.py:47] Route: /load, Methods: GET
2026-02-27T19:22:59.4858590Z (ApiServer_0 pid=184) INFO 02-27 19:22:59 [launcher.py:47] Route: /health, Methods: GET
2026-02-27T19:22:59.4868173Z (ApiServer_3 pid=187) INFO 02-27 19:22:59 [launcher.py:47] Route: /health, Methods: GET
2026-02-27T19:22:59.4878767Z (ApiServer_1 pid=185) INFO 02-27 19:22:59 [launcher.py:47] Route: /version, Methods: GET
2026-02-27T19:22:59.4889535Z (ApiServer_0 pid=184) INFO 02-27 19:22:59 [launcher.py:47] Route: /v1/models, Methods: GET
2026-02-27T19:22:59.4899770Z (ApiServer_3 pid=187) INFO 02-27 19:22:59 [launcher.py:47] Route: /v1/models, Methods: GET
2026-02-27T19:22:59.4909211Z (ApiServer_0 pid=184) INFO 02-27 19:22:59 [launcher.py:47] Route: /ping, Methods: GET
2026-02-27T19:22:59.4919431Z (ApiServer_1 pid=185) INFO 02-27 19:22:59 [launcher.py:47] Route: /scale_elastic_ep, Methods: POST
2026-02-27T19:22:59.4929281Z (ApiServer_0 pid=184) INFO 02-27 19:22:59 [launcher.py:47] Route: /ping, Methods: POST
2026-02-27T19:22:59.4938931Z (ApiServer_3 pid=187) INFO 02-27 19:22:59 [launcher.py:47] Route: /ping, Methods: GET
2026-02-27T19:22:59.4949589Z (ApiServer_1 pid=185) INFO 02-27 19:22:59 [launcher.py:47] Route: /is_scaling_elastic_ep, Methods: POST
2026-02-27T19:22:59.4959987Z (ApiServer_0 pid=184) INFO 02-27 19:22:59 [launcher.py:47] Route: /invocations, Methods: POST
2026-02-27T19:22:59.4970420Z (ApiServer_3 pid=187) INFO 02-27 19:22:59 [launcher.py:47] Route: /ping, Methods: POST
2026-02-27T19:22:59.4981093Z (ApiServer_1 pid=185) INFO 02-27 19:22:59 [launcher.py:47] Route: /tokenize, Methods: POST
2026-02-27T19:22:59.4991147Z (ApiServer_3 pid=187) INFO 02-27 19:22:59 [launcher.py:47] Route: /invocations, Methods: POST
2026-02-27T19:22:59.5001933Z (ApiServer_0 pid=184) INFO 02-27 19:22:59 [launcher.py:47] Route: /v1/chat/completions, Methods: POST
2026-02-27T19:22:59.5012383Z (ApiServer_1 pid=185) INFO 02-27 19:22:59 [launcher.py:47] Route: /detokenize, Methods: POST
2026-02-27T19:22:59.5021885Z (ApiServer_3 pid=187) INFO 02-27 19:22:59 [launcher.py:47] Route: /v1/chat/completions, Methods: POST
2026-02-27T19:22:59.5031747Z (ApiServer_0 pid=184) INFO 02-27 19:22:59 [launcher.py:47] Route: /v1/chat/completions/render, Methods: POST
2026-02-27T19:22:59.5044056Z (ApiServer_1 pid=185) INFO 02-27 19:22:59 [launcher.py:47] Route: /inference/v1/generate, Methods: POST
2026-02-27T19:22:59.5052265Z (ApiServer_0 pid=184) INFO 02-27 19:22:59 [launcher.py:47] Route: /v1/responses, Methods: POST
2026-02-27T19:22:59.5062891Z (ApiServer_3 pid=187) INFO 02-27 19:22:59 [launcher.py:47] Route: /v1/chat/completions/render, Methods: POST
2026-02-27T19:22:59.5072450Z (ApiServer_1 pid=185) INFO 02-27 19:22:59 [launcher.py:47] Route: /metrics, Methods: GET
2026-02-27T19:22:59.5083310Z (ApiServer_3 pid=187) INFO 02-27 19:22:59 [launcher.py:47] Route: /v1/responses, Methods: POST
2026-02-27T19:22:59.5094537Z (ApiServer_0 pid=184) INFO 02-27 19:22:59 [launcher.py:47] Route: /v1/responses/{response_id}, Methods: GET
2026-02-27T19:22:59.5103948Z (ApiServer_1 pid=185) INFO 02-27 19:22:59 [launcher.py:47] Route: /health, Methods: GET
2026-02-27T19:22:59.5114359Z (ApiServer_3 pid=187) INFO 02-27 19:22:59 [launcher.py:47] Route: /v1/responses/{response_id}, Methods: GET
2026-02-27T19:22:59.5124834Z (ApiServer_0 pid=184) INFO 02-27 19:22:59 [launcher.py:47] Route: /v1/responses/{response_id}/cancel, Methods: POST
2026-02-27T19:22:59.5135447Z (ApiServer_1 pid=185) INFO 02-27 19:22:59 [launcher.py:47] Route: /v1/models, Methods: GET
2026-02-27T19:22:59.5144885Z (ApiServer_0 pid=184) INFO 02-27 19:22:59 [launcher.py:47] Route: /v1/completions, Methods: POST
2026-02-27T19:22:59.5155363Z (ApiServer_3 pid=187) INFO 02-27 19:22:59 [launcher.py:47] Route: /v1/responses/{response_id}/cancel, Methods: POST
2026-02-27T19:22:59.5165560Z (ApiServer_1 pid=185) INFO 02-27 19:22:59 [launcher.py:47] Route: /ping, Methods: GET
2026-02-27T19:22:59.5175957Z (ApiServer_0 pid=184) INFO 02-27 19:22:59 [launcher.py:47] Route: /v1/completions/render, Methods: POST
2026-02-27T19:22:59.5185481Z (ApiServer_3 pid=187) INFO 02-27 19:22:59 [launcher.py:47] Route: /v1/completions, Methods: POST
2026-02-27T19:22:59.5196007Z (ApiServer_1 pid=185) INFO 02-27 19:22:59 [launcher.py:47] Route: /ping, Methods: POST
2026-02-27T19:22:59.5207341Z (ApiServer_0 pid=184) INFO 02-27 19:22:59 [launcher.py:47] Route: /v1/messages, Methods: POST
2026-02-27T19:22:59.5219468Z (ApiServer_3 pid=187) INFO 02-27 19:22:59 [launcher.py:47] Route: /v1/completions/render, Methods: POST
2026-02-27T19:22:59.5233185Z (ApiServer_1 pid=185) INFO 02-27 19:22:59 [launcher.py:47] Route: /invocations, Methods: POST
2026-02-27T19:22:59.5243396Z (ApiServer_3 pid=187) INFO 02-27 19:22:59 [launcher.py:47] Route: /v1/messages, Methods: POST
2026-02-27T19:22:59.5254327Z (ApiServer_1 pid=185) INFO 02-27 19:22:59 [launcher.py:47] Route: /v1/chat/completions, Methods: POST
2026-02-27T19:22:59.5264633Z (ApiServer_1 pid=185) INFO 02-27 19:22:59 [launcher.py:47] Route: /v1/chat/completions/render, Methods: POST
2026-02-27T19:22:59.5274963Z (ApiServer_1 pid=185) INFO 02-27 19:22:59 [launcher.py:47] Route: /v1/responses, Methods: POST
2026-02-27T19:22:59.5285727Z (ApiServer_1 pid=185) INFO 02-27 19:22:59 [launcher.py:47] Route: /v1/responses/{response_id}, Methods: GET
2026-02-27T19:22:59.5295722Z (ApiServer_1 pid=185) INFO 02-27 19:22:59 [launcher.py:47] Route: /v1/responses/{response_id}/cancel, Methods: POST
2026-02-27T19:22:59.5305614Z (ApiServer_1 pid=185) INFO 02-27 19:22:59 [launcher.py:47] Route: /v1/completions, Methods: POST
2026-02-27T19:22:59.5316056Z (ApiServer_1 pid=185) INFO 02-27 19:22:59 [launcher.py:47] Route: /v1/completions/render, Methods: POST
2026-02-27T19:22:59.5326526Z (ApiServer_1 pid=185) INFO 02-27 19:22:59 [launcher.py:47] Route: /v1/messages, Methods: POST
2026-02-27T19:22:59.5338501Z (ApiServer_3 pid=187) WARNING 02-27 19:22:59 [warnings.py:110] /usr/local/python3.11.14/lib/python3.11/site-packages/websockets/legacy/__init__.py:6: DeprecationWarning: websockets.legacy is deprecated; see https://websockets.readthedocs.io/en/stable/howto/upgrade.html for upgrade instructions
2026-02-27T19:22:59.5348436Z (ApiServer_1 pid=185) WARNING 02-27 19:22:59 [warnings.py:110] /usr/local/python3.11.14/lib/python3.11/site-packages/websockets/legacy/__init__.py:6: DeprecationWarning: websockets.legacy is deprecated; see https://websockets.readthedocs.io/en/stable/howto/upgrade.html for upgrade instructions
2026-02-27T19:22:59.5358989Z (ApiServer_0 pid=184) WARNING 02-27 19:22:59 [warnings.py:110] /usr/local/python3.11.14/lib/python3.11/site-packages/websockets/legacy/__init__.py:6: DeprecationWarning: websockets.legacy is deprecated; see https://websockets.readthedocs.io/en/stable/howto/upgrade.html for upgrade instructions
2026-02-27T19:22:59.5369794Z (ApiServer_3 pid=187) WARNING 02-27 19:22:59 [warnings.py:110] /usr/local/python3.11.14/lib/python3.11/site-packages/uvicorn/protocols/websockets/websockets_impl.py:17: DeprecationWarning: websockets.server.WebSocketServerProtocol is deprecated
2026-02-27T19:22:59.5380482Z (ApiServer_1 pid=185) WARNING 02-27 19:22:59 [warnings.py:110] /usr/local/python3.11.14/lib/python3.11/site-packages/uvicorn/protocols/websockets/websockets_impl.py:17: DeprecationWarning: websockets.server.WebSocketServerProtocol is deprecated
2026-02-27T19:22:59.5390722Z (ApiServer_0 pid=184) WARNING 02-27 19:22:59 [warnings.py:110] /usr/local/python3.11.14/lib/python3.11/site-packages/uvicorn/protocols/websockets/websockets_impl.py:17: DeprecationWarning: websockets.server.WebSocketServerProtocol is deprecated
2026-02-27T19:22:59.5400100Z (ApiServer_3 pid=187) INFO:     Started server process [187]
2026-02-27T19:22:59.5410735Z (ApiServer_1 pid=185) INFO:     Started server process [185]
2026-02-27T19:22:59.5420911Z (ApiServer_3 pid=187) INFO:     Waiting for application startup.
2026-02-27T19:22:59.5431086Z (ApiServer_1 pid=185) INFO:     Waiting for application startup.
2026-02-27T19:22:59.5441270Z (ApiServer_0 pid=184) INFO:     Started server process [184]
2026-02-27T19:22:59.5450869Z (ApiServer_0 pid=184) INFO:     Waiting for application startup.
2026-02-27T19:22:59.8014379Z (ApiServer_3 pid=187) INFO:     Application startup complete.
2026-02-27T19:22:59.8164726Z (ApiServer_1 pid=185) INFO:     Application startup complete.
2026-02-27T19:22:59.8225330Z (ApiServer_2 pid=186) WARNING 02-27 19:22:59 [model.py:1350] Default vLLM sampling parameters have been overridden by the model's `generation_config.json`: `{'top_p': 0.95}`. If this is not intended, please relaunch vLLM instance with `--generation-config vllm`.
2026-02-27T19:22:59.8246558Z (ApiServer_2 pid=186) INFO 02-27 19:22:59 [serving.py:188] Warming up chat template processing...
2026-02-27T19:22:59.8425528Z (ApiServer_0 pid=184) INFO:     Application startup complete.
2026-02-27T19:22:59.8455758Z (ApiServer_2 pid=186) INFO 02-27 19:22:59 [serving.py:213] Chat template warmup completed in 21.7ms
2026-02-27T19:22:59.8476513Z (ApiServer_2 pid=186) INFO 02-27 19:22:59 [api_server.py:486] Starting vLLM API server 2 on http://0.0.0.0:8080
2026-02-27T19:22:59.8585362Z (ApiServer_2 pid=186) INFO 02-27 19:22:59 [launcher.py:38] Available routes are:
2026-02-27T19:22:59.8595039Z (ApiServer_2 pid=186) INFO 02-27 19:22:59 [launcher.py:47] Route: /openapi.json, Methods: GET, HEAD
2026-02-27T19:22:59.8605318Z (ApiServer_2 pid=186) INFO 02-27 19:22:59 [launcher.py:47] Route: /docs, Methods: GET, HEAD
2026-02-27T19:22:59.8664650Z (ApiServer_2 pid=186) INFO 02-27 19:22:59 [launcher.py:47] Route: /docs/oauth2-redirect, Methods: GET, HEAD
2026-02-27T19:22:59.8665206Z (ApiServer_2 pid=186) INFO 02-27 19:22:59 [launcher.py:47] Route: /redoc, Methods: GET, HEAD
2026-02-27T19:22:59.8665679Z (ApiServer_2 pid=186) INFO 02-27 19:22:59 [launcher.py:47] Route: /load, Methods: GET
2026-02-27T19:22:59.8666208Z (ApiServer_2 pid=186) INFO 02-27 19:22:59 [launcher.py:47] Route: /version, Methods: GET
2026-02-27T19:22:59.8666684Z (ApiServer_2 pid=186) INFO 02-27 19:22:59 [launcher.py:47] Route: /scale_elastic_ep, Methods: POST
2026-02-27T19:22:59.8669274Z (ApiServer_2 pid=186) INFO 02-27 19:22:59 [launcher.py:47] Route: /is_scaling_elastic_ep, Methods: POST
2026-02-27T19:22:59.8673080Z (ApiServer_2 pid=186) INFO 02-27 19:22:59 [launcher.py:47] Route: /tokenize, Methods: POST
2026-02-27T19:22:59.8682469Z (ApiServer_2 pid=186) INFO 02-27 19:22:59 [launcher.py:47] Route: /detokenize, Methods: POST
2026-02-27T19:22:59.8692647Z (ApiServer_2 pid=186) INFO 02-27 19:22:59 [launcher.py:47] Route: /inference/v1/generate, Methods: POST
2026-02-27T19:22:59.8702903Z (ApiServer_2 pid=186) INFO 02-27 19:22:59 [launcher.py:47] Route: /metrics, Methods: GET
2026-02-27T19:22:59.8713448Z (ApiServer_2 pid=186) INFO 02-27 19:22:59 [launcher.py:47] Route: /health, Methods: GET
2026-02-27T19:22:59.8733243Z (ApiServer_2 pid=186) INFO 02-27 19:22:59 [launcher.py:47] Route: /v1/models, Methods: GET
2026-02-27T19:22:59.8733703Z (ApiServer_2 pid=186) INFO 02-27 19:22:59 [launcher.py:47] Route: /ping, Methods: GET
2026-02-27T19:22:59.8741506Z (ApiServer_2 pid=186) INFO 02-27 19:22:59 [launcher.py:47] Route: /ping, Methods: POST
2026-02-27T19:22:59.8752375Z (ApiServer_2 pid=186) INFO 02-27 19:22:59 [launcher.py:47] Route: /invocations, Methods: POST
2026-02-27T19:22:59.8762968Z (ApiServer_2 pid=186) INFO 02-27 19:22:59 [launcher.py:47] Route: /v1/chat/completions, Methods: POST
2026-02-27T19:22:59.8773773Z (ApiServer_2 pid=186) INFO 02-27 19:22:59 [launcher.py:47] Route: /v1/chat/completions/render, Methods: POST
2026-02-27T19:22:59.8784565Z (ApiServer_2 pid=186) INFO 02-27 19:22:59 [launcher.py:47] Route: /v1/responses, Methods: POST
2026-02-27T19:22:59.8801876Z (ApiServer_2 pid=186) INFO 02-27 19:22:59 [launcher.py:47] Route: /v1/responses/{response_id}, Methods: GET
2026-02-27T19:22:59.8805198Z (ApiServer_2 pid=186) INFO 02-27 19:22:59 [launcher.py:47] Route: /v1/responses/{response_id}/cancel, Methods: POST
2026-02-27T19:22:59.8815628Z (ApiServer_2 pid=186) INFO 02-27 19:22:59 [launcher.py:47] Route: /v1/completions, Methods: POST
2026-02-27T19:22:59.8824527Z (ApiServer_2 pid=186) INFO 02-27 19:22:59 [launcher.py:47] Route: /v1/completions/render, Methods: POST
2026-02-27T19:22:59.8834558Z (ApiServer_2 pid=186) INFO 02-27 19:22:59 [launcher.py:47] Route: /v1/messages, Methods: POST
2026-02-27T19:22:59.8847531Z (ApiServer_2 pid=186) WARNING 02-27 19:22:59 [warnings.py:110] /usr/local/python3.11.14/lib/python3.11/site-packages/websockets/legacy/__init__.py:6: DeprecationWarning: websockets.legacy is deprecated; see https://websockets.readthedocs.io/en/stable/howto/upgrade.html for upgrade instructions
2026-02-27T19:22:59.8856299Z (ApiServer_2 pid=186) WARNING 02-27 19:22:59 [warnings.py:110] /usr/local/python3.11.14/lib/python3.11/site-packages/uvicorn/protocols/websockets/websockets_impl.py:17: DeprecationWarning: websockets.server.WebSocketServerProtocol is deprecated
2026-02-27T19:22:59.8866895Z (ApiServer_2 pid=186) INFO:     Started server process [186]
2026-02-27T19:22:59.8874823Z (ApiServer_2 pid=186) INFO:     Waiting for application startup.
2026-02-27T19:23:00.1959163Z (ApiServer_0 pid=184) INFO:     10.0.0.210:39062 - "GET /health HTTP/1.1" 200 OK
2026-02-27T19:23:00.1965970Z [2026-02-27 19:23:00] INFO conftest.py:390: [READY] Node 10.0.0.210 is ready.
2026-02-27T19:23:00.2254382Z 2026-02-27 19:23:00,223 - modelscope - WARNING - We can not confirm the cached file is for revision: master
2026-02-27T19:23:00.2555426Z 2026-02-27 19:23:00,253 - modelscope - WARNING - We can not confirm the cached file is for revision: master
2026-02-27T19:23:00.5447790Z (ApiServer_2 pid=186) INFO:     Application startup complete.
2026-02-27T19:23:01.4660549Z (ApiServer_2 pid=186) INFO:     10.0.0.111:50576 - "GET /health HTTP/1.1" 200 OK
2026-02-27T19:23:01.4667182Z (ApiServer_1 pid=185) INFO:     10.0.0.111:50580 - "GET /health HTTP/1.1" 200 OK
2026-02-27T19:23:06.4696627Z (ApiServer_2 pid=186) INFO:     10.0.0.111:34588 - "GET /health HTTP/1.1" 200 OK
2026-02-27T19:23:11.4709656Z (ApiServer_2 pid=186) INFO:     10.0.0.111:34600 - "GET /health HTTP/1.1" 200 OK
2026-02-27T19:23:16.4749115Z (ApiServer_0 pid=184) INFO:     10.0.0.111:35746 - "GET /health HTTP/1.1" 200 OK
2026-02-27T19:23:16.5735741Z (ApiServer_1 pid=185) WARNING 02-27 19:23:16 [warnings.py:110] /vllm-workspace/vllm/vllm/entrypoints/openai/chat_completion/protocol.py:377: DeprecationWarning: max_tokens is deprecated in favor of the max_completion_tokens field
2026-02-27T19:23:16.5757954Z (ApiServer_2 pid=186) WARNING 02-27 19:23:16 [warnings.py:110] /vllm-workspace/vllm/vllm/entrypoints/openai/chat_completion/protocol.py:377: DeprecationWarning: max_tokens is deprecated in favor of the max_completion_tokens field
2026-02-27T19:23:16.5768894Z (ApiServer_0 pid=184) WARNING 02-27 19:23:16 [warnings.py:110] /vllm-workspace/vllm/vllm/entrypoints/openai/chat_completion/protocol.py:377: DeprecationWarning: max_tokens is deprecated in favor of the max_completion_tokens field
2026-02-27T19:23:16.5787071Z (ApiServer_3 pid=187) WARNING 02-27 19:23:16 [warnings.py:110] /vllm-workspace/vllm/vllm/entrypoints/openai/chat_completion/protocol.py:377: DeprecationWarning: max_tokens is deprecated in favor of the max_completion_tokens field
2026-02-27T19:23:16.5790001Z (ApiServer_1 pid=185) WARNING 02-27 19:23:16 [warnings.py:110] /vllm-workspace/vllm/vllm/entrypoints/openai/chat_completion/serving.py:393: DeprecationWarning: max_tokens is deprecated in favor of the max_completion_tokens field
2026-02-27T19:23:16.5800770Z (ApiServer_2 pid=186) WARNING 02-27 19:23:16 [warnings.py:110] /vllm-workspace/vllm/vllm/entrypoints/openai/chat_completion/serving.py:393: DeprecationWarning: max_tokens is deprecated in favor of the max_completion_tokens field
2026-02-27T19:23:16.5811244Z (ApiServer_0 pid=184) WARNING 02-27 19:23:16 [warnings.py:110] /vllm-workspace/vllm/vllm/entrypoints/openai/chat_completion/serving.py:393: DeprecationWarning: max_tokens is deprecated in favor of the max_completion_tokens field
2026-02-27T19:23:16.5821391Z (ApiServer_3 pid=187) WARNING 02-27 19:23:16 [warnings.py:110] /vllm-workspace/vllm/vllm/entrypoints/openai/chat_completion/serving.py:393: DeprecationWarning: max_tokens is deprecated in favor of the max_completion_tokens field
2026-02-27T19:23:21.4782382Z ................(ApiServer_2 pid=186) INFO:     10.0.0.111:35756 - "GET /health HTTP/1.1" 200 OK
2026-02-27T19:23:26.4824462Z (ApiServer_2 pid=186) INFO:     10.0.0.111:58600 - "GET /health HTTP/1.1" 200 OK
2026-02-27T19:23:31.4861220Z (ApiServer_2 pid=186) INFO:     10.0.0.111:58606 - "GET /health HTTP/1.1" 200 OK
2026-02-27T19:23:36.4904262Z (ApiServer_2 pid=186) INFO:     10.0.0.111:41002 - "GET /health HTTP/1.1" 200 OK
2026-02-27T19:23:41.1427498Z (Worker_DP1_TP6_EP14 pid=785) INFO 02-27 19:23:41 [acl_graph.py:185] Replaying aclgraph
2026-02-27T19:23:41.1455302Z (Worker_DP0_TP7_EP7 pid=890) INFO 02-27 19:23:41 [acl_graph.py:185] Replaying aclgraph
2026-02-27T19:23:41.1461944Z (Worker_DP0_TP6_EP6 pid=786) INFO 02-27 19:23:41 [acl_graph.py:185] Replaying aclgraph
2026-02-27T19:23:41.1471478Z (Worker_DP0_TP0_EP0 pid=202) INFO 02-27 19:23:41 [acl_graph.py:185] Replaying aclgraph
2026-02-27T19:23:41.1486231Z (Worker_DP1_TP3_EP11 pid=473) INFO 02-27 19:23:41 [acl_graph.py:185] Replaying aclgraph
2026-02-27T19:23:41.1494974Z (Worker_DP1_TP0_EP8 pid=201) INFO 02-27 19:23:41 [acl_graph.py:185] Replaying aclgraph
2026-02-27T19:23:41.1505391Z (Worker_DP1_TP7_EP15 pid=889) INFO 02-27 19:23:41 [acl_graph.py:185] Replaying aclgraph
2026-02-27T19:23:41.1514714Z (Worker_DP1_TP5_EP13 pid=681) INFO 02-27 19:23:41 [acl_graph.py:185] Replaying aclgraph
2026-02-27T19:23:41.1525375Z (Worker_DP0_TP3_EP3 pid=476) INFO 02-27 19:23:41 [acl_graph.py:185] Replaying aclgraph
2026-02-27T19:23:41.1535359Z (Worker_DP1_TP2_EP10 pid=369) INFO 02-27 19:23:41 [acl_graph.py:185] Replaying aclgraph
2026-02-27T19:23:41.1545373Z (Worker_DP0_TP5_EP5 pid=682) INFO 02-27 19:23:41 [acl_graph.py:185] Replaying aclgraph
2026-02-27T19:23:41.1556716Z (Worker_DP1_TP4_EP12 pid=577) INFO 02-27 19:23:41 [acl_graph.py:185] Replaying aclgraph
2026-02-27T19:23:41.1567952Z (Worker_DP0_TP4_EP4 pid=579) INFO 02-27 19:23:41 [acl_graph.py:185] Replaying aclgraph
2026-02-27T19:23:41.1577816Z (Worker_DP0_TP2_EP2 pid=372) INFO 02-27 19:23:41 [acl_graph.py:185] Replaying aclgraph
2026-02-27T19:23:41.1588070Z (Worker_DP1_TP1_EP9 pid=251) INFO 02-27 19:23:41 [acl_graph.py:185] Replaying aclgraph
2026-02-27T19:23:41.1597807Z (Worker_DP0_TP1_EP1 pid=253) INFO 02-27 19:23:41 [acl_graph.py:185] Replaying aclgraph
2026-02-27T19:23:41.4937672Z (ApiServer_2 pid=186) INFO:     10.0.0.111:41012 - "GET /health HTTP/1.1" 200 OK
2026-02-27T19:23:44.5215201Z (ApiServer_2 pid=186) INFO:     10.0.0.210:54176 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-27T19:23:45.1500470Z (ApiServer_3 pid=187) INFO:     10.0.0.210:54196 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-27T19:23:45.1509096Z (ApiServer_3 pid=187) INFO:     10.0.0.210:54374 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-27T19:23:45.7798744Z (ApiServer_1 pid=185) INFO:     10.0.0.210:54366 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-27T19:23:45.8870397Z (ApiServer_1 pid=185) INFO:     10.0.0.210:54430 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-27T19:23:46.1283829Z (ApiServer_2 pid=186) INFO:     10.0.0.210:54312 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-27T19:23:46.3317041Z (ApiServer_1 pid=185) INFO:     10.0.0.210:54162 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-27T19:23:46.4965064Z (ApiServer_0 pid=184) INFO:     10.0.0.111:50844 - "GET /health HTTP/1.1" 200 OK
2026-02-27T19:23:46.5358052Z (ApiServer_0 pid=184) INFO:     10.0.0.210:54220 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-27T19:23:46.8473697Z (ApiServer_3 pid=187) INFO:     10.0.0.210:54250 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-27T19:23:46.8823700Z (ApiServer_3 pid=187) INFO:     10.0.0.210:54402 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-27T19:23:46.9432327Z (ApiServer_0 pid=184) INFO:     10.0.0.210:54202 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-27T19:23:47.0172447Z (ApiServer_3 pid=187) INFO:     10.0.0.210:54238 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-27T19:23:47.0463043Z (ApiServer_3 pid=187) INFO:     10.0.0.210:54236 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-27T19:23:47.2545893Z (ApiServer_2 pid=186) INFO:     10.0.0.210:54388 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-27T19:23:47.2564090Z (ApiServer_2 pid=186) INFO:     10.0.0.210:54354 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-27T19:23:47.3590473Z (ApiServer_1 pid=185) INFO:     10.0.0.210:54320 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-27T19:23:47.4617780Z (ApiServer_1 pid=185) INFO:     10.0.0.210:54296 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-27T19:23:47.4693441Z (ApiServer_0 pid=184) INFO:     10.0.0.210:54328 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-27T19:23:51.5011391Z (ApiServer_2 pid=186) INFO:     10.0.0.111:50846 - "GET /health HTTP/1.1" 200 OK
2026-02-27T19:23:56.5078040Z (ApiServer_0 pid=184) INFO:     10.0.0.111:42954 - "GET /health HTTP/1.1" 200 OK
2026-02-27T19:23:56.6041783Z (ApiServer_2 pid=186) INFO:     10.0.0.210:54282 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-27T19:23:56.6070045Z (ApiServer_2 pid=186) INFO:     10.0.0.210:54436 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-27T19:23:57.2294315Z (ApiServer_0 pid=184) INFO:     10.0.0.210:54414 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-27T19:23:57.3316421Z (ApiServer_1 pid=185) INFO:     10.0.0.210:54392 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-27T19:23:57.4009526Z (ApiServer_3 pid=187) INFO:     10.0.0.210:54462 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-27T19:23:57.4364297Z (ApiServer_0 pid=184) INFO:     10.0.0.210:54446 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-27T19:23:59.0984165Z (ApiServer_3 pid=187) INFO:     10.0.0.210:54344 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-27T19:24:00.3242548Z (ApiServer_2 pid=186) INFO:     10.0.0.210:54214 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-27T19:24:01.5082268Z (ApiServer_2 pid=186) INFO:     10.0.0.111:42968 - "GET /health HTTP/1.1" 200 OK
2026-02-27T19:24:02.8143156Z (ApiServer_3 pid=187) INFO:     10.0.0.210:54232 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-27T19:24:02.9109205Z (ApiServer_3 pid=187) INFO:     10.0.0.210:54228 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-27T19:24:03.3305565Z (ApiServer_0 pid=184) INFO:     10.0.0.210:54352 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-27T19:24:05.2298164Z (ApiServer_0 pid=184) INFO:     10.0.0.210:54262 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-27T19:24:06.4957260Z (ApiServer_0 pid=184) INFO:     10.0.0.210:54278 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-27T19:24:06.5107298Z (ApiServer_0 pid=184) INFO:     10.0.0.111:39660 - "GET /health HTTP/1.1" 200 OK
2026-02-27T19:24:09.2843003Z (ApiServer_0 pid=184) INFO:     10.0.0.210:54188 - "POST /v1/chat/completions HTTP/1.1" 200 OK
2026-02-27T19:24:11.5164922Z (ApiServer_0 pid=184) INFO:     10.0.0.111:39666 - "GET /health HTTP/1.1" 200 OK
2026-02-27T19:24:16.5175933Z (ApiServer_0 pid=184) INFO:     10.0.0.111:60962 - "GET /health HTTP/1.1" 200 OK
2026-02-27T19:24:21.5215072Z (ApiServer_2 pid=186) INFO:     10.0.0.111:60978 - "GET /health HTTP/1.1" 200 OK
2026-02-27T19:24:22.7237433Z INFO 02-27 19:24:22 [utils.py:287] Received KeyboardInterrupt, shutting down API servers...
2026-02-27T19:24:22.7244215Z INFO 02-27 19:24:22 [utils.py:292] Terminating remaining processes ...
2026-02-27T19:24:22.8371814Z (ApiServer_0 pid=184) WARNING 02-27 19:24:22 [launcher.py:116] port 8080 is used by process psutil.Process(pid=186, name='VLLM::APIServer_2', status='running', started='19:11:36') launched with command:
2026-02-27T19:24:22.8376492Z (ApiServer_0 pid=184) WARNING 02-27 19:24:22 [launcher.py:116] VLLM::APIServer_2                                                                                                                                    
2026-02-27T19:24:22.8387271Z (ApiServer_0 pid=184) INFO 02-27 19:24:22 [launcher.py:122] Shutting down FastAPI HTTP server.
2026-02-27T19:24:22.8396492Z (ApiServer_0 pid=184) INFO:     Shutting down
2026-02-27T19:24:22.8519113Z (ApiServer_3 pid=187) WARNING 02-27 19:24:22 [launcher.py:116] port 8080 is used by process psutil.Process(pid=186, name='VLLM::APIServer_2', status='running', started='19:11:36') launched with command:
2026-02-27T19:24:22.8529468Z (ApiServer_3 pid=187) WARNING 02-27 19:24:22 [launcher.py:116] VLLM::APIServer_2                                                                                                                                    
2026-02-27T19:24:22.8538131Z (ApiServer_3 pid=187) INFO 02-27 19:24:22 [launcher.py:122] Shutting down FastAPI HTTP server.
2026-02-27T19:24:22.8547824Z (ApiServer_3 pid=187) INFO:     Shutting down
2026-02-27T19:24:22.8558582Z (ApiServer_1 pid=185) WARNING 02-27 19:24:22 [launcher.py:116] port 8080 is used by process psutil.Process(pid=187, name='VLLM::APIServer_3', status='sleeping', started='19:11:36') launched with command:
2026-02-27T19:24:22.8568547Z (ApiServer_1 pid=185) WARNING 02-27 19:24:22 [launcher.py:116] VLLM::APIServer_3                                                                                                                                    
2026-02-27T19:24:22.8578392Z (ApiServer_1 pid=185) INFO 02-27 19:24:22 [launcher.py:122] Shutting down FastAPI HTTP server.
2026-02-27T19:24:22.8587797Z (ApiServer_1 pid=185) INFO:     Shutting down
2026-02-27T19:24:22.8627973Z (ApiServer_2 pid=186) WARNING 02-27 19:24:22 [launcher.py:116] port 8080 is used by process psutil.Process(pid=187, name='VLLM::APIServer_3', status='sleeping', started='19:11:36') launched with command:
2026-02-27T19:24:22.8637830Z (ApiServer_2 pid=186) WARNING 02-27 19:24:22 [launcher.py:116] VLLM::APIServer_3                                                                                                                                    
2026-02-27T19:24:22.8647011Z (ApiServer_2 pid=186) INFO 02-27 19:24:22 [launcher.py:122] Shutting down FastAPI HTTP server.
2026-02-27T19:24:22.8656489Z (ApiServer_2 pid=186) INFO:     Shutting down
2026-02-27T19:24:22.9375773Z (ApiServer_0 pid=184) INFO:     Waiting for application shutdown.
2026-02-27T19:24:22.9382344Z (ApiServer_0 pid=184) INFO:     Application shutdown complete.
2026-02-27T19:24:22.9555576Z (ApiServer_3 pid=187) INFO:     Waiting for application shutdown.
2026-02-27T19:24:22.9564782Z (ApiServer_3 pid=187) INFO:     Application shutdown complete.
2026-02-27T19:24:22.9574967Z (ApiServer_1 pid=185) INFO:     Waiting for application shutdown.
2026-02-27T19:24:22.9584754Z (ApiServer_1 pid=185) INFO:     Application shutdown complete.
2026-02-27T19:24:22.9664411Z (ApiServer_2 pid=186) INFO:     Waiting for application shutdown.
2026-02-27T19:24:22.9666760Z (ApiServer_2 pid=186) INFO:     Application shutdown complete.
2026-02-27T19:24:23.0084914Z (ApiServer_3 pid=187) sys:1: DeprecationWarning: builtin type swigvarlink has no __module__ attribute
2026-02-27T19:24:23.0110559Z (ApiServer_0 pid=184) sys:1: DeprecationWarning: builtin type swigvarlink has no __module__ attribute
2026-02-27T19:24:23.0138240Z (ApiServer_1 pid=185) sys:1: DeprecationWarning: builtin type swigvarlink has no __module__ attribute
2026-02-27T19:24:23.0190939Z (ApiServer_2 pid=186) sys:1: DeprecationWarning: builtin type swigvarlink has no __module__ attribute
2026-02-27T19:24:24.1071881Z (Worker_DP0_TP1_EP1 pid=253) INFO 02-27 19:24:24 [multiproc_executor.py:732] Parent process exited, terminating worker
2026-02-27T19:24:24.1079703Z (Worker_DP0_TP5_EP5 pid=682) INFO 02-27 19:24:24 [multiproc_executor.py:732] Parent process exited, terminating worker
2026-02-27T19:24:24.1088061Z (Worker_DP1_TP0_EP8 pid=201) INFO 02-27 19:24:24 [multiproc_executor.py:732] Parent process exited, terminating worker
2026-02-27T19:24:24.1096750Z (Worker_DP0_TP2_EP2 pid=372) INFO 02-27 19:24:24 [multiproc_executor.py:732] Parent process exited, terminating worker
2026-02-27T19:24:24.1106681Z (Worker_DP0_TP0_EP0 pid=202) INFO 02-27 19:24:24 [multiproc_executor.py:732] Parent process exited, terminating worker
2026-02-27T19:24:24.1116784Z (Worker_DP1_TP2_EP10 pid=369) INFO 02-27 19:24:24 [multiproc_executor.py:732] Parent process exited, terminating worker
2026-02-27T19:24:24.1126357Z (Worker_DP1_TP3_EP11 pid=473) INFO 02-27 19:24:24 [multiproc_executor.py:732] Parent process exited, terminating worker
2026-02-27T19:24:24.1135805Z (Worker_DP0_TP6_EP6 pid=786) INFO 02-27 19:24:24 [multiproc_executor.py:732] Parent process exited, terminating worker
2026-02-27T19:24:24.1144815Z (Worker_DP0_TP3_EP3 pid=476) INFO 02-27 19:24:24 [multiproc_executor.py:732] Parent process exited, terminating worker
2026-02-27T19:24:24.1154384Z (Worker_DP0_TP7_EP7 pid=890) INFO 02-27 19:24:24 [multiproc_executor.py:732] Parent process exited, terminating worker
2026-02-27T19:24:24.1164502Z (Worker_DP1_TP1_EP9 pid=251) INFO 02-27 19:24:24 [multiproc_executor.py:732] Parent process exited, terminating worker
2026-02-27T19:24:24.1174135Z (Worker_DP1_TP4_EP12 pid=577) INFO 02-27 19:24:24 [multiproc_executor.py:732] Parent process exited, terminating worker
2026-02-27T19:24:24.1184600Z (Worker_DP0_TP4_EP4 pid=579) INFO 02-27 19:24:24 [multiproc_executor.py:732] Parent process exited, terminating worker
2026-02-27T19:24:24.1194441Z (Worker_DP1_TP6_EP14 pid=785) INFO 02-27 19:24:24 [multiproc_executor.py:732] Parent process exited, terminating worker
2026-02-27T19:24:24.1205380Z (Worker_DP1_TP7_EP15 pid=889) INFO 02-27 19:24:24 [multiproc_executor.py:732] Parent process exited, terminating worker
2026-02-27T19:24:24.1215316Z (Worker_DP1_TP5_EP13 pid=681) INFO 02-27 19:24:24 [multiproc_executor.py:732] Parent process exited, terminating worker
2026-02-27T19:24:24.1225111Z (Worker_DP0_TP5_EP5 pid=682) INFO 02-27 19:24:24 [multiproc_executor.py:785] WorkerProc shutting down.
2026-02-27T19:24:24.1235083Z (Worker_DP0_TP1_EP1 pid=253) INFO 02-27 19:24:24 [multiproc_executor.py:785] WorkerProc shutting down.
2026-02-27T19:24:24.1245764Z (Worker_DP0_TP2_EP2 pid=372) INFO 02-27 19:24:24 [multiproc_executor.py:785] WorkerProc shutting down.
2026-02-27T19:24:24.1255100Z (Worker_DP1_TP2_EP10 pid=369) INFO 02-27 19:24:24 [multiproc_executor.py:785] WorkerProc shutting down.
2026-02-27T19:24:24.1265013Z (Worker_DP1_TP3_EP11 pid=473) INFO 02-27 19:24:24 [multiproc_executor.py:785] WorkerProc shutting down.
2026-02-27T19:24:24.1274232Z (Worker_DP0_TP0_EP0 pid=202) INFO 02-27 19:24:24 [multiproc_executor.py:785] WorkerProc shutting down.
2026-02-27T19:24:24.1284226Z (Worker_DP1_TP4_EP12 pid=577) INFO 02-27 19:24:24 [multiproc_executor.py:785] WorkerProc shutting down.
2026-02-27T19:24:24.1294055Z (Worker_DP1_TP0_EP8 pid=201) INFO 02-27 19:24:24 [multiproc_executor.py:785] WorkerProc shutting down.
2026-02-27T19:24:24.1303927Z (Worker_DP0_TP6_EP6 pid=786) INFO 02-27 19:24:24 [multiproc_executor.py:785] WorkerProc shutting down.
2026-02-27T19:24:24.1314649Z (Worker_DP1_TP1_EP9 pid=251) INFO 02-27 19:24:24 [multiproc_executor.py:785] WorkerProc shutting down.
2026-02-27T19:24:24.1324065Z (Worker_DP1_TP6_EP14 pid=785) INFO 02-27 19:24:24 [multiproc_executor.py:785] WorkerProc shutting down.
2026-02-27T19:24:24.1333792Z (Worker_DP0_TP3_EP3 pid=476) INFO 02-27 19:24:24 [multiproc_executor.py:785] WorkerProc shutting down.
2026-02-27T19:24:24.1343787Z (Worker_DP0_TP7_EP7 pid=890) INFO 02-27 19:24:24 [multiproc_executor.py:785] WorkerProc shutting down.
2026-02-27T19:24:24.1353981Z (Worker_DP0_TP4_EP4 pid=579) INFO 02-27 19:24:24 [multiproc_executor.py:785] WorkerProc shutting down.
2026-02-27T19:24:24.1363837Z (Worker_DP1_TP7_EP15 pid=889) INFO 02-27 19:24:24 [multiproc_executor.py:785] WorkerProc shutting down.
2026-02-27T19:24:24.1373847Z (Worker_DP1_TP5_EP13 pid=681) INFO 02-27 19:24:24 [multiproc_executor.py:785] WorkerProc shutting down.
2026-02-27T19:24:29.5565738Z sys:1: DeprecationWarning: builtin type swigvarlink has no __module__ attribute
2026-02-27T19:24:30.7244889Z The request config is
2026-02-27T19:24:30.7256194Z  from ais_bench.benchmark.models import VLLMCustomAPIChat
2026-02-27T19:24:30.7264965Z from ais_bench.benchmark.utils.model_postprocessors import extract_non_reasoning_content
2026-02-27T19:24:30.7274279Z 
2026-02-27T19:24:30.7284861Z models = [
2026-02-27T19:24:30.7294707Z     dict(
2026-02-27T19:24:30.7304997Z         attr="service",
2026-02-27T19:24:30.7314572Z         type=VLLMCustomAPIChat,
2026-02-27T19:24:30.7324985Z         abbr='vllm-api-general-chat',
2026-02-27T19:24:30.7334569Z         path="",
2026-02-27T19:24:30.7344954Z         model="vllm-ascend/DeepSeek-V3.2-W8A8",
2026-02-27T19:24:30.7355533Z         request_rate = 0,
2026-02-27T19:24:30.7366041Z         retry = 2,
2026-02-27T19:24:30.7381652Z         host_ip = "10.0.0.210",
2026-02-27T19:24:30.7391385Z         host_port = 8080,
2026-02-27T19:24:30.7400622Z         max_out_len = 4096,
2026-02-27T19:24:30.7410695Z         batch_size = 64,
2026-02-27T19:24:30.7420076Z         trust_remote_code=False,
2026-02-27T19:24:30.7429948Z         generation_kwargs = dict(
2026-02-27T19:24:30.7440382Z             temperature = 0.6,
2026-02-27T19:24:30.7450573Z             ignore_eos = False,
2026-02-27T19:24:30.7460268Z             #top_k = 10,
2026-02-27T19:24:30.7470911Z             top_p = 0.95,
2026-02-27T19:24:30.7481675Z             #seed = None,
2026-02-27T19:24:30.7493457Z             #repetition_penalty = 1.03,
2026-02-27T19:24:30.7503669Z         ),
2026-02-27T19:24:30.7513314Z         pred_postprocessor=dict(type=extract_non_reasoning_content)
2026-02-27T19:24:30.7523363Z     )
2026-02-27T19:24:30.7533829Z ]
2026-02-27T19:24:30.7542859Z 
2026-02-27T19:24:30.7553476Z running aisbench cmd: ais_bench --models vllm_api_general_chat_custom --datasets gsm8k_gen_0_shot_cot_chat_prompt
2026-02-27T19:24:30.7564747Z 02/27 19:23:14 - AISBench - INFO - Loading gsm8k_gen_0_shot_cot_chat_prompt: /vllm-workspace/vllm-ascend/benchmark/ais_bench/benchmark/configs/./datasets/gsm8k/gsm8k_gen_0_shot_cot_chat_prompt.py
2026-02-27T19:24:30.7574935Z 02/27 19:23:14 - AISBench - INFO - Loading vllm_api_general_chat_custom: /vllm-workspace/vllm-ascend/benchmark/ais_bench/benchmark/configs/./models/vllm_api/vllm_api_general_chat_custom.py
2026-02-27T19:24:30.7584612Z 02/27 19:23:14 - AISBench - INFO - Loading example: /vllm-workspace/vllm-ascend/benchmark/ais_bench/benchmark/configs/./summarizers/example.py
2026-02-27T19:24:30.7594112Z 02/27 19:23:14 - AISBench - INFO - Current exp folder: outputs/default/20260227_192314
2026-02-27T19:24:30.7606787Z 02/27 19:23:16 - AISBench - INFO - Starting inference tasks...
2026-02-27T19:24:30.7616966Z 02/27 19:23:16 - AISBench - INFO - Partitioned into 1 tasks.
2026-02-27T19:24:30.7627010Z 02/27 19:23:16 - AISBench - INFO - Continuous batch enable! All the logs and processes for each task should be checked in each infer/.out file.
2026-02-27T19:24:30.7636084Z Launch OpenICLInfer[vllm-api-general-chat/gsm8k] on CPU
2026-02-27T19:24:30.7646845Z Launch OpenICLInfer[vllm-api-general-chat/gsm8k] on CPU
2026-02-27T19:24:30.7656492Z 02/27 19:24:09 - AISBench - INFO - Inference tasks completed.
2026-02-27T19:24:30.7666574Z 02/27 19:24:11 - AISBench - INFO - Starting evaluation tasks...
2026-02-27T19:24:30.7676519Z 02/27 19:24:11 - AISBench - INFO - Partitioned into 1 tasks.
2026-02-27T19:24:30.7686960Z launch OpenICLEval[vllm-api-general-chat/gsm8k] on CPU
2026-02-27T19:24:30.7696500Z 02/27 19:24:22 - AISBench - INFO - Evaluation tasks completed.
2026-02-27T19:24:30.7707033Z 02/27 19:24:22 - AISBench - INFO - Summarizing evaluation results...
2026-02-27T19:24:30.7716970Z dataset    version    metric    mode      vllm-api-general-chat
2026-02-27T19:24:30.7727744Z ---------  ---------  --------  ------  -----------------------
2026-02-27T19:24:30.7736599Z gsm8k      7cd45e     accuracy  gen                       93.75
2026-02-27T19:24:30.7747122Z 02/27 19:24:22 - AISBench - INFO - write summary to /vllm-workspace/vllm-ascend/outputs/default/20260227_192314/summary/summary_20260227_192314.txt
2026-02-27T19:24:30.7757261Z 02/27 19:24:22 - AISBench - INFO - write csv to /vllm-workspace/vllm-ascend/outputs/default/20260227_192314/summary/summary_20260227_192314.csv
2026-02-27T19:24:30.7961010Z /usr/local/python3.11.14/lib/python3.11/multiprocessing/resource_tracker.py:254: UserWarning: resource_tracker: There appear to be 2 leaked shared_memory objects to clean up at shutdown
2026-02-27T19:24:30.7975889Z   warnings.warn('resource_tracker: There appear to be %d '
2026-02-27T19:24:32.0719286Z PASSED
2026-02-27T19:24:32.0728986Z 
2026-02-27T19:24:32.0741293Z =============================== warnings summary ===============================
2026-02-27T19:24:32.0751436Z <frozen importlib._bootstrap>:241
2026-02-27T19:24:32.0764086Z   <frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyPacked has no __module__ attribute
2026-02-27T19:24:32.0774388Z 
2026-02-27T19:24:32.0785056Z <frozen importlib._bootstrap>:241
2026-02-27T19:24:32.0796449Z   <frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyObject has no __module__ attribute
2026-02-27T19:24:32.0806997Z 
2026-02-27T19:24:32.0819921Z ../../usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647
2026-02-27T19:24:32.0832840Z   /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-27T19:24:32.0843511Z     warnings.warn(
2026-02-27T19:24:32.0853525Z 
2026-02-27T19:24:32.0865557Z ../../usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/__init__.py:8
2026-02-27T19:24:32.0877613Z   /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/__init__.py:8: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html
2026-02-27T19:24:32.0888475Z     import pkg_resources
2026-02-27T19:24:32.0898616Z 
2026-02-27T19:24:32.0909679Z tests/e2e/nightly/multi_node/scripts/test_multi_node.py::test_multi_node
2026-02-27T19:24:32.0921100Z   /usr/local/python3.11.14/lib/python3.11/site-packages/pandas/core/dtypes/cast.py:1641: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.
2026-02-27T19:24:32.0930477Z   See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)
2026-02-27T19:24:32.0940534Z     return np.find_common_type(types, [])
2026-02-27T19:24:32.0949965Z 
2026-02-27T19:24:32.0960841Z -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
2026-02-27T19:24:32.0970644Z ================== 1 passed, 5 warnings in 806.63s (0:13:26) ===================
2026-02-27T19:24:32.3376009Z sys:1: DeprecationWarning: builtin type swigvarlink has no __module__ attribute
2026-02-27T19:24:33.9140614Z [0;32mâœ“ All tests passed![0m
2026-02-27T19:24:34.1606835Z Cleaning up background log streams...
2026-02-27T19:24:34.8911268Z ##[group]Run actions/upload-artifact@v6
2026-02-27T19:24:34.8911573Z with:
2026-02-27T19:24:34.8911824Z   name: DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml-pod-logs
2026-02-27T19:24:34.8912277Z   path: /tmp/vllm*_logs.txt
2026-02-27T19:24:34.8912546Z   retention-days: 7
2026-02-27T19:24:34.8912762Z   if-no-files-found: warn
2026-02-27T19:24:34.8913004Z   compression-level: 6
2026-02-27T19:24:34.8913217Z   overwrite: false
2026-02-27T19:24:34.8913463Z   include-hidden-files: false
2026-02-27T19:24:34.8913708Z env:
2026-02-27T19:24:34.8913953Z   FAIL_TAG: FAIL_TAG_DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-02-27T19:24:34.8914286Z ##[endgroup]
2026-02-27T19:24:34.8942758Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-27T19:24:34.8943511Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-27T19:24:34.8943813Z ##[endgroup]
2026-02-27T19:24:35.2526017Z (node:968) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-27T19:24:35.2526818Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-27T19:24:36.2910264Z With the provided path, there will be 1 file uploaded
2026-02-27T19:24:36.2914184Z Artifact name is valid!
2026-02-27T19:24:36.2914380Z Root directory input is valid!
2026-02-27T19:24:37.3476602Z Beginning upload of artifact content to blob storage
2026-02-27T19:24:38.5642717Z Uploaded bytes 13902
2026-02-27T19:24:38.7976409Z Finished uploading artifact content to blob storage!
2026-02-27T19:24:38.7976892Z SHA256 digest of uploaded artifact zip is 30259c8cc2f5c4328921f96a3132ad1b792c33c3a285a1d21eed1c8de3eb9736
2026-02-27T19:24:38.7977693Z Finalizing artifact upload
2026-02-27T19:24:39.6631614Z Artifact DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml-pod-logs.zip successfully finalized. Artifact ID 5696037447
2026-02-27T19:24:39.6632441Z Artifact DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml-pod-logs has been successfully uploaded! Final size is 13902 bytes. Artifact ID is 5696037447
2026-02-27T19:24:39.6634067Z Artifact download URL: https://github.com/vllm-project/vllm-ascend/actions/runs/22494469024/artifacts/5696037447
2026-02-27T19:24:41.3532157Z ##[group]Run kubectl get pods -n "$NAMESPACE" --ignore-not-found=true
2026-02-27T19:24:41.3532578Z [36;1mkubectl get pods -n "$NAMESPACE" --ignore-not-found=true[0m
2026-02-27T19:24:41.3532913Z [36;1mkubectl delete -f ./lws.yaml --ignore-not-found=true || true[0m
2026-02-27T19:24:41.3533276Z shell: bash -el {0}
2026-02-27T19:24:41.3533430Z env:
2026-02-27T19:24:41.3533624Z   FAIL_TAG: FAIL_TAG_DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-02-27T19:24:41.3533880Z ##[endgroup]
2026-02-27T19:24:41.3619751Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-27T19:24:41.3620394Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-27T19:24:41.3620611Z ##[endgroup]
2026-02-27T19:24:41.7140500Z (node:1133) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-27T19:24:41.7141194Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-27T19:24:42.4232146Z NAME                                             READY   STATUS    RESTARTS     AGE
2026-02-27T19:24:42.4232582Z linux-aarch64-a3-0-n4cwm-runner-csk5w            1/1     Running   0            15m
2026-02-27T19:24:42.4233007Z linux-aarch64-a3-0-n4cwm-runner-csk5w-workflow   1/1     Running   0            14m
2026-02-27T19:24:42.4233370Z vllm-0                                           1/1     Running   1 (9s ago)   14m
2026-02-27T19:24:42.4233661Z vllm-0-1                                         1/1     Running   1 (2s ago)   14m
2026-02-27T19:24:42.5021443Z leaderworkerset.leaderworkerset.x-k8s.io "vllm" deleted from vllm-project namespace
2026-02-27T19:24:42.5455906Z service "vllm-leader" deleted from vllm-project namespace
2026-02-27T19:24:43.1325121Z Post job cleanup.
2026-02-27T19:24:43.1346669Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-27T19:24:43.1347458Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-27T19:24:43.1347732Z ##[endgroup]
2026-02-27T19:24:43.5021145Z (node:1260) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-27T19:24:43.5021852Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-27T19:24:44.2231301Z [command]/usr/bin/git version
2026-02-27T19:24:44.2412971Z git version 2.34.1
2026-02-27T19:24:44.2444455Z Copying '/root/.gitconfig' to '/__w/_temp/8a08a531-a997-49b8-b318-13e5fe05db7f/.gitconfig'
2026-02-27T19:24:44.2452779Z Temporarily overriding HOME='/__w/_temp/8a08a531-a997-49b8-b318-13e5fe05db7f' before making global git config changes
2026-02-27T19:24:44.2453426Z Adding repository directory to the temporary git global config as a safe directory
2026-02-27T19:24:44.2456129Z [command]/usr/bin/git config --global --add safe.directory /__w/vllm-ascend/vllm-ascend
2026-02-27T19:24:44.2493412Z Removing SSH command configuration
2026-02-27T19:24:44.2499585Z [command]/usr/bin/git config --local --name-only --get-regexp core\.sshCommand
2026-02-27T19:24:44.2552113Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'core\.sshCommand' && git config --local --unset-all 'core.sshCommand' || :"
2026-02-27T19:24:44.3028090Z Removing HTTP extra header
2026-02-27T19:24:44.3031690Z [command]/usr/bin/git config --local --name-only --get-regexp http\.https\:\/\/github\.com\/\.extraheader
2026-02-27T19:24:44.3057734Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'http\.https\:\/\/github\.com\/\.extraheader' && git config --local --unset-all 'http.https://github.com/.extraheader' || :"
2026-02-27T19:24:44.3244727Z Removing includeIf entries pointing to credentials config files
2026-02-27T19:24:44.3249172Z [command]/usr/bin/git config --local --name-only --get-regexp ^includeIf\.gitdir:
2026-02-27T19:24:44.3270631Z includeif.gitdir:/__w/vllm-ascend/vllm-ascend/.git.path
2026-02-27T19:24:44.3271046Z includeif.gitdir:/__w/vllm-ascend/vllm-ascend/.git/worktrees/*.path
2026-02-27T19:24:44.3271387Z includeif.gitdir:/github/workspace/.git.path
2026-02-27T19:24:44.3271656Z includeif.gitdir:/github/workspace/.git/worktrees/*.path
2026-02-27T19:24:44.3278467Z [command]/usr/bin/git config --local --get-all includeif.gitdir:/__w/vllm-ascend/vllm-ascend/.git.path
2026-02-27T19:24:44.3299248Z /__w/_temp/git-credentials-8a7ecfc3-d443-4242-b915-6e36658e5f2b.config
2026-02-27T19:24:44.3308022Z [command]/usr/bin/git config --local --unset includeif.gitdir:/__w/vllm-ascend/vllm-ascend/.git.path /__w/_temp/git-credentials-8a7ecfc3-d443-4242-b915-6e36658e5f2b.config
2026-02-27T19:24:44.3340539Z [command]/usr/bin/git config --local --get-all includeif.gitdir:/__w/vllm-ascend/vllm-ascend/.git/worktrees/*.path
2026-02-27T19:24:44.3359467Z /__w/_temp/git-credentials-8a7ecfc3-d443-4242-b915-6e36658e5f2b.config
2026-02-27T19:24:44.3366301Z [command]/usr/bin/git config --local --unset includeif.gitdir:/__w/vllm-ascend/vllm-ascend/.git/worktrees/*.path /__w/_temp/git-credentials-8a7ecfc3-d443-4242-b915-6e36658e5f2b.config
2026-02-27T19:24:44.3396751Z [command]/usr/bin/git config --local --get-all includeif.gitdir:/github/workspace/.git.path
2026-02-27T19:24:44.3415288Z /github/runner_temp/git-credentials-8a7ecfc3-d443-4242-b915-6e36658e5f2b.config
2026-02-27T19:24:44.3422260Z [command]/usr/bin/git config --local --unset includeif.gitdir:/github/workspace/.git.path /github/runner_temp/git-credentials-8a7ecfc3-d443-4242-b915-6e36658e5f2b.config
2026-02-27T19:24:44.3454456Z [command]/usr/bin/git config --local --get-all includeif.gitdir:/github/workspace/.git/worktrees/*.path
2026-02-27T19:24:44.3472426Z /github/runner_temp/git-credentials-8a7ecfc3-d443-4242-b915-6e36658e5f2b.config
2026-02-27T19:24:44.3479215Z [command]/usr/bin/git config --local --unset includeif.gitdir:/github/workspace/.git/worktrees/*.path /github/runner_temp/git-credentials-8a7ecfc3-d443-4242-b915-6e36658e5f2b.config
2026-02-27T19:24:44.3506344Z [command]/usr/bin/git submodule foreach --recursive git config --local --show-origin --name-only --get-regexp remote.origin.url
2026-02-27T19:24:44.3686893Z Removing credentials config '/__w/_temp/git-credentials-8a7ecfc3-d443-4242-b915-6e36658e5f2b.config'
2026-02-27T19:25:03.1548080Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-27T19:25:03.1548800Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-27T19:25:03.1549017Z ##[endgroup]
2026-02-27T19:25:03.5989606Z Cleaning up orphan processes
