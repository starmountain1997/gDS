# Run ID: 22494469024
# Commit: 9cd0d6c33d2ef5cb9b6ce20b1ca047e55ab23a12
# Job: single-node (deepseek3_2-w8a8, linux-aarch64-a3-16, tests/e2e/nightly/single_node/models/test_dee... / tests/e2e/nightly/single_node/models/test_deepseek_v3_2_w8a8.py
# Date: 2026-02-27
============================================================

ï»¿2026-02-27T23:14:30.9060787Z Current runner version: '2.330.0'
2026-02-27T23:14:30.9065700Z Runner name: 'linux-aarch64-a3-16-jl5bl-runner-czqml'
2026-02-27T23:14:30.9066525Z Runner group name: 'Default'
2026-02-27T23:14:30.9067371Z Machine name: 'linux-aarch64-a3-16-jl5bl-runner-czqml'
2026-02-27T23:14:30.9071436Z ##[group]GITHUB_TOKEN Permissions
2026-02-27T23:14:30.9073720Z Actions: write
2026-02-27T23:14:30.9074183Z ArtifactMetadata: write
2026-02-27T23:14:30.9074585Z Attestations: write
2026-02-27T23:14:30.9075071Z Checks: write
2026-02-27T23:14:30.9075557Z Contents: write
2026-02-27T23:14:30.9075936Z Deployments: write
2026-02-27T23:14:30.9076334Z Discussions: write
2026-02-27T23:14:30.9076680Z Issues: write
2026-02-27T23:14:30.9077044Z Metadata: read
2026-02-27T23:14:30.9077426Z Models: read
2026-02-27T23:14:30.9077782Z Packages: write
2026-02-27T23:14:30.9078130Z Pages: write
2026-02-27T23:14:30.9078666Z PullRequests: write
2026-02-27T23:14:30.9079044Z RepositoryProjects: write
2026-02-27T23:14:30.9079654Z SecurityEvents: write
2026-02-27T23:14:30.9080079Z Statuses: write
2026-02-27T23:14:30.9080465Z ##[endgroup]
2026-02-27T23:14:30.9082473Z Secret source: Actions
2026-02-27T23:14:30.9083000Z Prepare workflow directory
2026-02-27T23:14:30.9691245Z Prepare all required actions
2026-02-27T23:14:30.9742399Z Uses: vllm-project/vllm-ascend/.github/workflows/_e2e_nightly_single_node.yaml@refs/heads/main (9cd0d6c33d2ef5cb9b6ce20b1ca047e55ab23a12)
2026-02-27T23:14:30.9746342Z ##[group] Inputs
2026-02-27T23:14:30.9746897Z   runner: linux-aarch64-a3-16
2026-02-27T23:14:30.9747594Z   image: swr.cn-southwest-2.myhuaweicloud.com/base_image/ascend-ci/vllm-ascend:nightly-a3
2026-02-27T23:14:30.9748371Z   tests: tests/e2e/nightly/single_node/models/test_deepseek_v3_2_w8a8.py
2026-02-27T23:14:30.9749149Z   name: deepseek3_2-w8a8
2026-02-27T23:14:30.9749541Z ##[endgroup]
2026-02-27T23:14:30.9750633Z Complete job name: single-node (deepseek3_2-w8a8, linux-aarch64-a3-16, tests/e2e/nightly/single_node/models/test_dee... / tests/e2e/nightly/single_node/models/test_deepseek_v3_2_w8a8.py
2026-02-27T23:14:31.0362988Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-27T23:14:31.0373506Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-27T23:14:31.0374776Z ##[endgroup]
2026-02-27T23:15:03.1112385Z (node:53) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-27T23:15:03.1113783Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-27T23:15:03.7971123Z ##[group]Run npu-smi info
2026-02-27T23:15:03.7971567Z [36;1mnpu-smi info[0m
2026-02-27T23:15:03.7972162Z [36;1mcat /usr/local/Ascend/ascend-toolkit/latest/"$(uname -i)"-linux/ascend_toolkit_install.info[0m
2026-02-27T23:15:03.7972866Z shell: bash -el {0}
2026-02-27T23:15:03.7973108Z env:
2026-02-27T23:15:03.7973376Z   HF_HUB_OFFLINE: 1
2026-02-27T23:15:03.7973626Z   VLLM_USE_MODELSCOPE: true
2026-02-27T23:15:03.7973878Z ##[endgroup]
2026-02-27T23:15:03.8140980Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-27T23:15:03.8141880Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-27T23:15:03.8142352Z ##[endgroup]
2026-02-27T23:15:04.2035323Z (node:79) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-27T23:15:04.2036228Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-27T23:15:06.9699062Z +------------------------------------------------------------------------------------------------+
2026-02-27T23:15:06.9699862Z | npu-smi 25.5.0                   Version: 25.5.0                                               |
2026-02-27T23:15:06.9700381Z +---------------------------+---------------+----------------------------------------------------+
2026-02-27T23:15:06.9700903Z | NPU   Name                | Health        | Power(W)    Temp(C)           Hugepages-Usage(page)|
2026-02-27T23:15:06.9701898Z | Chip  Phy-ID              | Bus-Id        | AICore(%)   Memory-Usage(MB)  HBM-Usage(MB)        |
2026-02-27T23:15:06.9702524Z +===========================+===============+====================================================+
2026-02-27T23:15:06.9703145Z | 0     Ascend910           | OK            | 161.0       36                0    / 0             |
2026-02-27T23:15:06.9703715Z | 0     0                   | 0000:9D:00.0  | 0           0    / 0          3150 / 65536         |
2026-02-27T23:15:06.9704238Z +------------------------------------------------------------------------------------------------+
2026-02-27T23:15:06.9704742Z | 0     Ascend910           | OK            | -           34                0    / 0             |
2026-02-27T23:15:06.9705229Z | 1     1                   | 0000:9F:00.0  | 0           0    / 0          2892 / 65536         |
2026-02-27T23:15:06.9705651Z +===========================+===============+====================================================+
2026-02-27T23:15:06.9706029Z | 1     Ascend910           | OK            | 163.3       36                0    / 0             |
2026-02-27T23:15:06.9706558Z | 0     2                   | 0000:99:00.0  | 0           0    / 0          3159 / 65536         |
2026-02-27T23:15:06.9707018Z +------------------------------------------------------------------------------------------------+
2026-02-27T23:15:06.9707527Z | 1     Ascend910           | OK            | -           35                0    / 0             |
2026-02-27T23:15:06.9707989Z | 1     3                   | 0000:9B:00.0  | 0           0    / 0          2880 / 65536         |
2026-02-27T23:15:06.9708367Z +===========================+===============+====================================================+
2026-02-27T23:15:06.9708885Z | 2     Ascend910           | OK            | 162.7       36                0    / 0             |
2026-02-27T23:15:06.9709328Z | 0     4                   | 0000:95:00.0  | 0           0    / 0          3150 / 65536         |
2026-02-27T23:15:06.9709795Z +------------------------------------------------------------------------------------------------+
2026-02-27T23:15:06.9710243Z | 2     Ascend910           | OK            | -           36                0    / 0             |
2026-02-27T23:15:06.9710660Z | 1     5                   | 0000:97:00.0  | 0           0    / 0          2892 / 65536         |
2026-02-27T23:15:06.9711053Z +===========================+===============+====================================================+
2026-02-27T23:15:06.9711615Z | 3     Ascend910           | OK            | 168.8       36                0    / 0             |
2026-02-27T23:15:06.9712202Z | 0     6                   | 0000:91:00.0  | 0           0    / 0          3159 / 65536         |
2026-02-27T23:15:06.9712678Z +------------------------------------------------------------------------------------------------+
2026-02-27T23:15:06.9713121Z | 3     Ascend910           | OK            | -           35                0    / 0             |
2026-02-27T23:15:06.9713560Z | 1     7                   | 0000:93:00.0  | 0           0    / 0          2883 / 65536         |
2026-02-27T23:15:06.9713948Z +===========================+===============+====================================================+
2026-02-27T23:15:06.9714378Z | 4     Ascend910           | OK            | 165.7       36                0    / 0             |
2026-02-27T23:15:06.9714814Z | 0     8                   | 0000:8D:00.0  | 0           0    / 0          3151 / 65536         |
2026-02-27T23:15:06.9715229Z +------------------------------------------------------------------------------------------------+
2026-02-27T23:15:06.9715694Z | 4     Ascend910           | OK            | -           34                0    / 0             |
2026-02-27T23:15:06.9716119Z | 1     9                   | 0000:8F:00.0  | 0           0    / 0          2893 / 65536         |
2026-02-27T23:15:06.9716490Z +===========================+===============+====================================================+
2026-02-27T23:15:06.9717062Z | 5     Ascend910           | OK            | 162.1       33                0    / 0             |
2026-02-27T23:15:06.9717456Z | 0     10                  | 0000:89:00.0  | 0           0    / 0          3143 / 65536         |
2026-02-27T23:15:06.9717925Z +------------------------------------------------------------------------------------------------+
2026-02-27T23:15:06.9718370Z | 5     Ascend910           | OK            | -           34                0    / 0             |
2026-02-27T23:15:06.9718851Z | 1     11                  | 0000:8B:00.0  | 0           0    / 0          2892 / 65536         |
2026-02-27T23:15:07.2716634Z +===========================+===============+====================================================+
2026-02-27T23:15:07.2717155Z | 6     Ascend910           | OK            | 160.0       36                0    / 0             |
2026-02-27T23:15:07.2717520Z | 0     12                  | 0000:85:00.0  | 0           0    / 0          3148 / 65536         |
2026-02-27T23:15:07.2718086Z +------------------------------------------------------------------------------------------------+
2026-02-27T23:15:07.2718587Z | 6     Ascend910           | OK            | -           34                0    / 0             |
2026-02-27T23:15:07.2718974Z | 1     13                  | 0000:87:00.0  | 0           0    / 0          2893 / 65536         |
2026-02-27T23:15:07.2719356Z +===========================+===============+====================================================+
2026-02-27T23:15:07.2719713Z | 7     Ascend910           | OK            | 164.3       35                0    / 0             |
2026-02-27T23:15:07.2720074Z | 0     14                  | 0000:81:00.0  | 0           0    / 0          3157 / 65536         |
2026-02-27T23:15:07.2720468Z +------------------------------------------------------------------------------------------------+
2026-02-27T23:15:07.2720869Z | 7     Ascend910           | OK            | -           36                0    / 0             |
2026-02-27T23:15:07.2721222Z | 1     15                  | 0000:83:00.0  | 0           0    / 0          2884 / 65536         |
2026-02-27T23:15:07.2722117Z +===========================+===============+====================================================+
2026-02-27T23:15:07.2722519Z +---------------------------+---------------+----------------------------------------------------+
2026-02-27T23:15:07.2723045Z | NPU     Chip              | Process id    | Process name             | Process memory(MB)      |
2026-02-27T23:15:07.2723775Z +===========================+===============+====================================================+
2026-02-27T23:15:07.2724197Z | No running processes found in NPU 0                                                            |
2026-02-27T23:15:07.2724547Z +===========================+===============+====================================================+
2026-02-27T23:15:07.2724997Z | No running processes found in NPU 1                                                            |
2026-02-27T23:15:07.2725385Z +===========================+===============+====================================================+
2026-02-27T23:15:07.2725731Z | No running processes found in NPU 2                                                            |
2026-02-27T23:15:07.2726201Z +===========================+===============+====================================================+
2026-02-27T23:15:07.2726639Z | No running processes found in NPU 3                                                            |
2026-02-27T23:15:07.2727025Z +===========================+===============+====================================================+
2026-02-27T23:15:07.2727469Z | No running processes found in NPU 4                                                            |
2026-02-27T23:15:07.2727823Z +===========================+===============+====================================================+
2026-02-27T23:15:07.2728195Z | No running processes found in NPU 5                                                            |
2026-02-27T23:15:07.2728699Z +===========================+===============+====================================================+
2026-02-27T23:15:07.2729152Z | No running processes found in NPU 6                                                            |
2026-02-27T23:15:07.2729596Z +===========================+===============+====================================================+
2026-02-27T23:15:07.2729988Z | No running processes found in NPU 7                                                            |
2026-02-27T23:15:07.2730385Z +===========================+===============+====================================================+
2026-02-27T23:15:07.2775864Z package_name=Ascend-cann-toolkit
2026-02-27T23:15:07.2776147Z version=8.5.0
2026-02-27T23:15:07.2776398Z innerversion=V100R001C25SPC001B232
2026-02-27T23:15:07.2776759Z compatible_version=[V100R001C15],[V100R001C18],[V100R001C19],[V100R001C20],[V100R001C21],[V100R001C23]
2026-02-27T23:15:07.2777182Z arch=aarch64
2026-02-27T23:15:07.2777369Z os=linux
2026-02-27T23:15:07.2777596Z path=/usr/local/Ascend/cann-8.5.0
2026-02-27T23:15:07.8086741Z ##[group]Run echo "Installed vLLM-related Python packages:"
2026-02-27T23:15:07.8087238Z [36;1mecho "Installed vLLM-related Python packages:"[0m
2026-02-27T23:15:07.8087610Z [36;1mpip list | grep vllm || echo "No vllm packages found."[0m
2026-02-27T23:15:07.8087892Z [36;1m[0m
2026-02-27T23:15:07.8088110Z [36;1mecho ""[0m
2026-02-27T23:15:07.8088342Z [36;1mecho "============================"[0m
2026-02-27T23:15:07.8088590Z [36;1mecho "vLLM Git information"[0m
2026-02-27T23:15:07.8089088Z [36;1mecho "============================"[0m
2026-02-27T23:15:07.8089312Z [36;1mcd vllm[0m
2026-02-27T23:15:07.8089544Z [36;1mif [ -d .git ]; then[0m
2026-02-27T23:15:07.8089833Z [36;1m  echo "Branch:      $(git rev-parse --abbrev-ref HEAD)"[0m
2026-02-27T23:15:07.8090261Z [36;1m  echo "Commit hash: $(git rev-parse HEAD)"[0m
2026-02-27T23:15:07.8090612Z [36;1m  echo "Author:      $(git log -1 --pretty=format:'%an <%ae>')"[0m
2026-02-27T23:15:07.8091056Z [36;1m  echo "Date:        $(git log -1 --pretty=format:'%ad' --date=iso)"[0m
2026-02-27T23:15:07.8091450Z [36;1m  echo "Message:     $(git log -1 --pretty=format:'%s')"[0m
2026-02-27T23:15:07.8091787Z [36;1m  echo "Tags:        $(git tag --points-at HEAD || echo 'None')"[0m
2026-02-27T23:15:07.8092243Z [36;1m  echo "Remote:      $(git remote -v | head -n1)"[0m
2026-02-27T23:15:07.8092523Z [36;1m  echo ""[0m
2026-02-27T23:15:07.8092743Z [36;1melse[0m
2026-02-27T23:15:07.8093035Z [36;1m  echo "No .git directory found in vllm"[0m
2026-02-27T23:15:07.8093311Z [36;1mfi[0m
2026-02-27T23:15:07.8093520Z [36;1mcd ..[0m
2026-02-27T23:15:07.8093693Z [36;1m[0m
2026-02-27T23:15:07.8093915Z [36;1mecho ""[0m
2026-02-27T23:15:07.8094111Z [36;1mecho "============================"[0m
2026-02-27T23:15:07.8094389Z [36;1mecho "vLLM-Ascend Git information"[0m
2026-02-27T23:15:07.8094620Z [36;1mecho "============================"[0m
2026-02-27T23:15:07.8094890Z [36;1mcd vllm-ascend[0m
2026-02-27T23:15:07.8095123Z [36;1mif [ -d .git ]; then[0m
2026-02-27T23:15:07.8095408Z [36;1m  echo "Branch:      $(git rev-parse --abbrev-ref HEAD)"[0m
2026-02-27T23:15:07.8095752Z [36;1m  echo "Commit hash: $(git rev-parse HEAD)"[0m
2026-02-27T23:15:07.8096105Z [36;1m  echo "Author:      $(git log -1 --pretty=format:'%an <%ae>')"[0m
2026-02-27T23:15:07.8096471Z [36;1m  echo "Date:        $(git log -1 --pretty=format:'%ad' --date=iso)"[0m
2026-02-27T23:15:07.8096819Z [36;1m  echo "Message:     $(git log -1 --pretty=format:'%s')"[0m
2026-02-27T23:15:07.8097163Z [36;1m  echo "Tags:        $(git tag --points-at HEAD || echo 'None')"[0m
2026-02-27T23:15:07.8097503Z [36;1m  echo "Remote:      $(git remote -v | head -n1)"[0m
2026-02-27T23:15:07.8097760Z [36;1m  echo ""[0m
2026-02-27T23:15:07.8097970Z [36;1melse[0m
2026-02-27T23:15:07.8098175Z [36;1m  echo "No .git directory found in vllm-ascend"[0m
2026-02-27T23:15:07.8098472Z [36;1mfi[0m
2026-02-27T23:15:07.8098642Z [36;1mcd ..[0m
2026-02-27T23:15:07.8099337Z shell: bash -el {0}
2026-02-27T23:15:07.8099577Z env:
2026-02-27T23:15:07.8099797Z   HF_HUB_OFFLINE: 1
2026-02-27T23:15:07.8100019Z   VLLM_USE_MODELSCOPE: true
2026-02-27T23:15:07.8100245Z ##[endgroup]
2026-02-27T23:15:07.8287475Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-27T23:15:07.8288284Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-27T23:15:07.8288536Z ##[endgroup]
2026-02-27T23:15:08.2093504Z (node:111) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-27T23:15:08.2094279Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-27T23:15:09.0317281Z Installed vLLM-related Python packages:
2026-02-27T23:15:10.1414676Z ais_bench_benchmark               3.0.20250930              /vllm-workspace/vllm-ascend/benchmark
2026-02-27T23:15:10.1415261Z vllm                              0.16.0+empty              /vllm-workspace/vllm
2026-02-27T23:15:10.1416053Z vllm_ascend                       0.15.0rc2.dev4+gb60b99100 /vllm-workspace/vllm-ascend
2026-02-27T23:15:10.1416347Z 
2026-02-27T23:15:10.1416421Z ============================
2026-02-27T23:15:10.1416705Z vLLM Git information
2026-02-27T23:15:10.1416911Z ============================
2026-02-27T23:15:10.1619593Z Branch:      HEAD
2026-02-27T23:15:10.1640426Z Commit hash: 89a77b10846fd96273cce78d86d2556ea582d26e
2026-02-27T23:15:10.1720199Z Author:      Andreas Karatzas <akaratza@amd.com>
2026-02-27T23:15:10.1743238Z Date:        2026-02-12 12:47:34 -0600
2026-02-27T23:15:10.1765939Z Message:     [ROCm][CI] Pin TorchCodec to v0.10.0 for ROCm compatibility (#34447)
2026-02-27T23:15:10.1789653Z Tags:        v0.16.0
2026-02-27T23:15:10.1817803Z Remote:      origin	https://gh-proxy.test.osinfra.cn/https://github.com/vllm-project/vllm.git (fetch)
2026-02-27T23:15:10.1818235Z 
2026-02-27T23:15:10.1818240Z 
2026-02-27T23:15:10.1818352Z ============================
2026-02-27T23:15:10.1818672Z vLLM-Ascend Git information
2026-02-27T23:15:10.1818896Z ============================
2026-02-27T23:15:10.1874681Z Branch:      main
2026-02-27T23:15:10.1894574Z Commit hash: b60b9910053f3d8a9ef7d4eea34c553f81f215a3
2026-02-27T23:15:10.1968101Z Author:      wjunLu <135617475+wjunLu@users.noreply.github.com>
2026-02-27T23:15:10.1992589Z Date:        2026-02-27 16:31:02 +0800
2026-02-27T23:15:10.2019556Z Message:     [CI] Add nightly test for Qwen3-235B-A22B with  mooncake layerwise connector (#5441)
2026-02-27T23:15:10.2288241Z Tags:        
2026-02-27T23:15:10.2316180Z Remote:      origin	https://gh-proxy.test.osinfra.cn/https://github.com/vllm-project/vllm-ascend (fetch)
2026-02-27T23:15:10.2316601Z 
2026-02-27T23:15:10.6266508Z ##[group]Run apt-get update && apt-get -y install clang-15
2026-02-27T23:15:10.6266904Z [36;1mapt-get update && apt-get -y install clang-15[0m
2026-02-27T23:15:10.6267273Z [36;1mupdate-alternatives --install /usr/bin/clang clang /usr/bin/clang-15 20[0m
2026-02-27T23:15:10.6267770Z [36;1mupdate-alternatives --install /usr/bin/clang++ clang++ /usr/bin/clang++-15 20[0m
2026-02-27T23:15:10.6268261Z shell: bash -l {0}
2026-02-27T23:15:10.6268449Z env:
2026-02-27T23:15:10.6268672Z   HF_HUB_OFFLINE: 1
2026-02-27T23:15:10.6268864Z   VLLM_USE_MODELSCOPE: true
2026-02-27T23:15:10.6269103Z ##[endgroup]
2026-02-27T23:15:10.6355717Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-27T23:15:10.6356573Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-27T23:15:10.6356829Z ##[endgroup]
2026-02-27T23:15:10.9909151Z (node:154) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-27T23:15:11.3535104Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-27T23:15:12.4623992Z Get:1 http://ports.ubuntu.com/ubuntu-ports jammy InRelease [270 kB]
2026-02-27T23:15:59.5073332Z Ign:1 http://ports.ubuntu.com/ubuntu-ports jammy InRelease
2026-02-27T23:16:00.0666697Z Get:2 http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease [128 kB]
2026-02-27T23:16:01.3197660Z Get:3 http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease [127 kB]
2026-02-27T23:16:01.7980728Z Get:4 http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease [129 kB]
2026-02-27T23:16:02.2415856Z Get:1 http://ports.ubuntu.com/ubuntu-ports jammy InRelease [270 kB]
2026-02-27T23:16:02.2850826Z Get:5 http://ports.ubuntu.com/ubuntu-ports jammy-updates/universe arm64 Packages [1659 kB]
2026-02-27T23:16:03.2408232Z Get:6 http://ports.ubuntu.com/ubuntu-ports jammy-updates/main arm64 Packages [3890 kB]
2026-02-27T23:16:03.6958969Z Get:7 http://ports.ubuntu.com/ubuntu-ports jammy-updates/multiverse arm64 Packages [47.7 kB]
2026-02-27T23:16:03.6989354Z Get:8 http://ports.ubuntu.com/ubuntu-ports jammy-updates/restricted arm64 Packages [6683 kB]
2026-02-27T23:16:04.2845177Z Get:9 http://ports.ubuntu.com/ubuntu-ports jammy-backports/main arm64 Packages [83.5 kB]
2026-02-27T23:16:04.2874533Z Get:10 http://ports.ubuntu.com/ubuntu-ports jammy-backports/universe arm64 Packages [35.3 kB]
2026-02-27T23:16:04.2892375Z Get:11 http://ports.ubuntu.com/ubuntu-ports jammy-security/universe arm64 Packages [1355 kB]
2026-02-27T23:16:04.4326174Z Get:12 http://ports.ubuntu.com/ubuntu-ports jammy-security/multiverse arm64 Packages [41.2 kB]
2026-02-27T23:16:04.4363720Z Get:13 http://ports.ubuntu.com/ubuntu-ports jammy-security/restricted arm64 Packages [6473 kB]
2026-02-27T23:16:05.0071080Z Get:14 http://ports.ubuntu.com/ubuntu-ports jammy-security/main arm64 Packages [3554 kB]
2026-02-27T23:16:05.3224704Z Get:15 http://ports.ubuntu.com/ubuntu-ports jammy/multiverse arm64 Packages [224 kB]
2026-02-27T23:16:05.3403276Z Get:16 http://ports.ubuntu.com/ubuntu-ports jammy/universe arm64 Packages [17.2 MB]
2026-02-27T23:16:06.8567644Z Get:17 http://ports.ubuntu.com/ubuntu-ports jammy/main arm64 Packages [1758 kB]
2026-02-27T23:16:07.0131966Z Get:18 http://ports.ubuntu.com/ubuntu-ports jammy/restricted arm64 Packages [24.2 kB]
2026-02-27T23:16:07.4808992Z Fetched 43.5 MB in 56s (783 kB/s)
2026-02-27T23:16:08.3684485Z Reading package lists...
2026-02-27T23:16:09.3026049Z Reading package lists...
2026-02-27T23:16:09.5058776Z Building dependency tree...
2026-02-27T23:16:09.5065783Z Reading state information...
2026-02-27T23:16:09.7461889Z clang-15 is already the newest version (1:15.0.7-0ubuntu0.22.04.3).
2026-02-27T23:16:09.7463841Z The following packages were automatically installed and are no longer required:
2026-02-27T23:16:09.7464479Z   autoconf automake autotools-dev file javascript-common libboost-atomic-dev
2026-02-27T23:16:09.7465429Z   libboost-atomic1.74-dev libboost-atomic1.74.0 libboost-chrono-dev
2026-02-27T23:16:09.7465913Z   libboost-chrono1.74-dev libboost-chrono1.74.0 libboost-container-dev
2026-02-27T23:16:09.7466401Z   libboost-container1.74-dev libboost-container1.74.0 libboost-context-dev
2026-02-27T23:16:09.7466816Z   libboost-context1.74-dev libboost-context1.74.0 libboost-coroutine-dev
2026-02-27T23:16:09.7467276Z   libboost-coroutine1.74-dev libboost-coroutine1.74.0 libboost-date-time-dev
2026-02-27T23:16:09.7467674Z   libboost-date-time1.74-dev libboost-date-time1.74.0 libboost-dev
2026-02-27T23:16:09.7468146Z   libboost-exception-dev libboost-exception1.74-dev libboost-fiber-dev
2026-02-27T23:16:09.7468600Z   libboost-fiber1.74-dev libboost-fiber1.74.0 libboost-filesystem-dev
2026-02-27T23:16:09.7469354Z   libboost-filesystem1.74-dev libboost-filesystem1.74.0 libboost-graph-dev
2026-02-27T23:16:09.7469878Z   libboost-graph-parallel-dev libboost-graph-parallel1.74-dev
2026-02-27T23:16:09.7470279Z   libboost-graph-parallel1.74.0 libboost-graph1.74-dev libboost-graph1.74.0
2026-02-27T23:16:09.7470738Z   libboost-iostreams-dev libboost-iostreams1.74-dev libboost-iostreams1.74.0
2026-02-27T23:16:09.7471176Z   libboost-locale-dev libboost-locale1.74-dev libboost-locale1.74.0
2026-02-27T23:16:09.7471567Z   libboost-log-dev libboost-log1.74-dev libboost-log1.74.0 libboost-math-dev
2026-02-27T23:16:09.7472175Z   libboost-math1.74-dev libboost-math1.74.0 libboost-mpi1.74.0
2026-02-27T23:16:09.7472560Z   libboost-nowide-dev libboost-nowide1.74-dev libboost-nowide1.74.0
2026-02-27T23:16:09.7473005Z   libboost-numpy-dev libboost-numpy1.74-dev libboost-numpy1.74.0
2026-02-27T23:16:09.7473358Z   libboost-program-options-dev libboost-program-options1.74-dev
2026-02-27T23:16:09.7473807Z   libboost-program-options1.74.0 libboost-python-dev libboost-python1.74-dev
2026-02-27T23:16:09.7474237Z   libboost-python1.74.0 libboost-random-dev libboost-random1.74-dev
2026-02-27T23:16:09.7474584Z   libboost-random1.74.0 libboost-regex-dev libboost-regex1.74-dev
2026-02-27T23:16:09.7475041Z   libboost-regex1.74.0 libboost-serialization-dev
2026-02-27T23:16:09.7475372Z   libboost-serialization1.74-dev libboost-serialization1.74.0
2026-02-27T23:16:09.7475784Z   libboost-stacktrace-dev libboost-stacktrace1.74-dev
2026-02-27T23:16:09.7476200Z   libboost-stacktrace1.74.0 libboost-system-dev libboost-system1.74-dev
2026-02-27T23:16:09.7476687Z   libboost-system1.74.0 libboost-test-dev libboost-test1.74-dev
2026-02-27T23:16:09.7477063Z   libboost-test1.74.0 libboost-thread-dev libboost-thread1.74-dev
2026-02-27T23:16:09.7477443Z   libboost-thread1.74.0 libboost-timer-dev libboost-timer1.74-dev
2026-02-27T23:16:09.7477844Z   libboost-timer1.74.0 libboost-tools-dev libboost-type-erasure-dev
2026-02-27T23:16:09.7478242Z   libboost-type-erasure1.74-dev libboost-type-erasure1.74.0 libboost-wave-dev
2026-02-27T23:16:09.7478674Z   libboost-wave1.74-dev libboost-wave1.74.0 libboost1.74-dev
2026-02-27T23:16:09.7479091Z   libboost1.74-tools-dev libcaf-openmpi-3 libcoarrays-dev libevent-2.1-7
2026-02-27T23:16:09.7479499Z   libevent-core-2.1-7 libevent-dev libevent-extra-2.1-7 libevent-openssl-2.1-7
2026-02-27T23:16:09.7480015Z   libevent-pthreads-2.1-7 libhwloc-dev libjs-jquery libjs-jquery-ui
2026-02-27T23:16:09.7480399Z   libjs-sphinxdoc libjs-underscore libltdl-dev libltdl7 libmagic-mgc libmagic1
2026-02-27T23:16:09.7480811Z   libopenmpi3 libpmix-dev libpmix2 libsigsegv2 libtool libucx0 m4
2026-02-27T23:16:09.7485665Z   openmpi-common python3-dev python3-distutils python3-lib2to3 python3.10-dev
2026-02-27T23:16:09.7486097Z Use 'apt autoremove' to remove them.
2026-02-27T23:16:09.7783454Z 0 upgraded, 0 newly installed, 0 to remove and 13 not upgraded.
2026-02-27T23:16:10.2506795Z ##[group]Run # ignore test_dispatch_ffn_combine until the test is fixed
2026-02-27T23:16:10.2507355Z [36;1m# ignore test_dispatch_ffn_combine until the test is fixed[0m
2026-02-27T23:16:10.2507776Z [36;1mpytest -sv tests/e2e/nightly/single_node/models/test_deepseek_v3_2_w8a8.py \[0m
2026-02-27T23:16:10.2508243Z [36;1m--ignore=tests/e2e/nightly/single_node/ops/singlecard_ops/test_fused_moe.py[0m
2026-02-27T23:16:10.2508770Z shell: bash -el {0}
2026-02-27T23:16:10.2508963Z env:
2026-02-27T23:16:10.2509175Z   HF_HUB_OFFLINE: 1
2026-02-27T23:16:10.2509365Z   VLLM_USE_MODELSCOPE: true
2026-02-27T23:16:10.2509629Z   VLLM_WORKER_MULTIPROC_METHOD: spawn
2026-02-27T23:16:10.2509927Z   VLLM_CI_RUNNER: linux-aarch64-a3-16
2026-02-27T23:16:10.2510198Z   BENCHMARK_HOME: /vllm-workspace/vllm-ascend/benchmark
2026-02-27T23:16:10.2510499Z ##[endgroup]
2026-02-27T23:16:10.2595239Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-27T23:16:10.2596274Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-27T23:16:10.2596589Z ##[endgroup]
2026-02-27T23:16:10.6257365Z (node:220) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-27T23:16:10.6258195Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-27T23:16:24.8671230Z INFO 02-27 23:16:24 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T23:16:24.8671692Z INFO 02-27 23:16:24 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T23:16:24.8672452Z INFO 02-27 23:16:24 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T23:16:24.9140193Z INFO 02-27 23:16:24 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T23:16:32.0888321Z ============================= test session starts ==============================
2026-02-27T23:16:32.0889086Z platform linux -- Python 3.11.14, pytest-8.4.2, pluggy-1.6.0 -- /usr/local/python3.11.14/bin/python3
2026-02-27T23:16:32.0889491Z cachedir: .pytest_cache
2026-02-27T23:16:32.0889755Z rootdir: /vllm-workspace/vllm-ascend
2026-02-27T23:16:32.0890048Z configfile: pyproject.toml
2026-02-27T23:16:32.0890334Z plugins: asyncio-1.3.0, mock-3.15.1, cov-7.0.0, anyio-4.12.1
2026-02-27T23:16:32.0890840Z asyncio: mode=Mode.STRICT, debug=False, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function
2026-02-27T23:16:32.8635474Z collecting ... collected 1 item
2026-02-27T23:16:32.8635720Z 
2026-02-27T23:16:32.8651648Z [2026-02-27 23:16:32] INFO conftest.py:241: Starting server with command: vllm serve vllm-ascend/DeepSeek-V3.2-W8A8 --enable-expert-parallel --tensor-parallel-size 8 --data-parallel-size 2 --port 58945 --max-model-len 8192 --max-num-batched-tokens 8192 --max-num-seqs 4 --trust-remote-code --quantization ascend --gpu-memory-utilization 0.98 --compilation-config {"cudagraph_capture_sizes":[8, 16, 24, 32, 40, 48], "cudagraph_mode":"FULL_DECODE_ONLY"} --speculative-config {"num_speculative_tokens": 3, "method":"deepseek_mtp"} --additional-config {"layer_sharding": ["q_b_proj", "o_proj"]} --reasoning-parser deepseek_v3 --tokenizer_mode deepseek_v32
2026-02-27T23:16:37.1857771Z tests/e2e/nightly/single_node/models/test_deepseek_v3_2_w8a8.py::test_models[2-8-vllm-ascend/DeepSeek-V3.2-W8A8] INFO 02-27 23:16:37 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T23:16:37.1858570Z INFO 02-27 23:16:37 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T23:16:37.1859050Z INFO 02-27 23:16:37 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T23:16:37.1922778Z INFO 02-27 23:16:37 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T23:16:43.1318689Z 2026-02-27 23:16:43,130 - 979 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.16.0+empty: default 1
2026-02-27T23:16:43.1812785Z INFO 02-27 23:16:43 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-27T23:16:43.3709106Z INFO 02-27 23:16:43 [serve.py:100] Defaulting api_server_count to data_parallel_size (2).
2026-02-27T23:16:43.3709643Z INFO 02-27 23:16:43 [utils.py:287] 
2026-02-27T23:16:43.3785193Z INFO 02-27 23:16:43 [utils.py:287]        â–ˆ     â–ˆ     â–ˆâ–„   â–„â–ˆ
2026-02-27T23:16:43.3785920Z INFO 02-27 23:16:43 [utils.py:287]  â–„â–„ â–„â–ˆ â–ˆ     â–ˆ     â–ˆ â–€â–„â–€ â–ˆ  version 0.16.0
2026-02-27T23:16:43.3786448Z INFO 02-27 23:16:43 [utils.py:287]   â–ˆâ–„â–ˆâ–€ â–ˆ     â–ˆ     â–ˆ     â–ˆ  model   vllm-ascend/DeepSeek-V3.2-W8A8
2026-02-27T23:16:43.3786923Z INFO 02-27 23:16:43 [utils.py:287]    â–€â–€  â–€â–€â–€â–€â–€ â–€â–€â–€â–€â–€ â–€     â–€
2026-02-27T23:16:43.3787221Z INFO 02-27 23:16:43 [utils.py:287] 
2026-02-27T23:16:43.3790987Z INFO 02-27 23:16:43 [utils.py:223] non-default args: {'model_tag': 'vllm-ascend/DeepSeek-V3.2-W8A8', 'api_server_count': 2, 'port': 58945, 'model': 'vllm-ascend/DeepSeek-V3.2-W8A8', 'tokenizer_mode': 'deepseek_v32', 'trust_remote_code': True, 'max_model_len': 8192, 'quantization': 'ascend', 'reasoning_parser': 'deepseek_v3', 'tensor_parallel_size': 8, 'data_parallel_size': 2, 'enable_expert_parallel': True, 'gpu_memory_utilization': 0.98, 'max_num_batched_tokens': 8192, 'max_num_seqs': 4, 'speculative_config': {'num_speculative_tokens': 3, 'method': 'deepseek_mtp'}, 'compilation_config': {'level': None, 'mode': None, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'vllm_ascend.compilation.compiler_interface.AscendCompiler', 'custom_ops': [], 'splitting_ops': None, 'compile_mm_encoder': False, 'compile_sizes': None, 'compile_ranges_split_points': None, 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_DECODE_ONLY: (2, 0)>, 'cudagraph_num_of_warmups': 0, 'cudagraph_capture_sizes': [8, 16, 24, 32, 40, 48], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': None, 'pass_config': {}, 'max_cudagraph_capture_size': None, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>, 'evaluate_guards': False, 'assume_32_bit_indexing': False}, 'local_cache_dir': None, 'fast_moe_cold_start': None, 'static_all_moe_layers': []}, 'additional_config': {'layer_sharding': ['q_b_proj', 'o_proj']}}
2026-02-27T23:16:43.4235383Z 2026-02-27 23:16:43,422 - modelscope - WARNING - We can not confirm the cached file is for revision: master
2026-02-27T23:16:43.4295495Z INFO 02-27 23:16:43 [arg_utils.py:620] HF_HUB_OFFLINE is True, replace model_id [vllm-ascend/DeepSeek-V3.2-W8A8] to model_path [/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8]
2026-02-27T23:16:43.4303124Z The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T23:16:43.4303848Z [2026-02-27 23:16:43] WARNING configuration_utils.py:697: The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T23:16:43.4445392Z The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T23:16:43.4446018Z [2026-02-27 23:16:43] WARNING configuration_utils.py:697: The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T23:16:43.4454571Z The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T23:16:43.4455261Z [2026-02-27 23:16:43] WARNING configuration_utils.py:697: The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T23:16:43.4461859Z You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-27T23:16:43.4463092Z [2026-02-27 23:16:43] WARNING configuration_utils.py:635: You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-27T23:16:43.4680843Z INFO 02-27 23:16:43 [model.py:529] Resolved architecture: DeepseekV32ForCausalLM
2026-02-27T23:16:43.4681198Z INFO 02-27 23:16:43 [model.py:1549] Using max model len 8192
2026-02-27T23:16:43.7460700Z WARNING 02-27 23:16:43 [speculative.py:293] method `deepseek_mtp` is deprecated and replaced with mtp.
2026-02-27T23:16:43.7463787Z The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T23:16:43.7464490Z [2026-02-27 23:16:43] WARNING configuration_utils.py:697: The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T23:16:43.7494591Z The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T23:16:43.7495343Z [2026-02-27 23:16:43] WARNING configuration_utils.py:697: The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T23:16:43.7496186Z You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-27T23:16:43.7497071Z [2026-02-27 23:16:43] WARNING configuration_utils.py:635: You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-27T23:16:43.7572369Z INFO 02-27 23:16:43 [model.py:529] Resolved architecture: DeepSeekMTPModel
2026-02-27T23:16:43.7573149Z INFO 02-27 23:16:43 [model.py:1549] Using max model len 163840
2026-02-27T23:16:43.7573741Z WARNING 02-27 23:16:43 [speculative.py:411] Enabling num_speculative_tokens > 1 will runmultiple times of forward on same MTP layer,which may result in lower acceptance rate
2026-02-27T23:16:43.7575585Z INFO 02-27 23:16:43 [scheduler.py:224] Chunked prefill is enabled with max_num_batched_tokens=8192.
2026-02-27T23:16:44.0656597Z INFO 02-27 23:16:44 [vllm.py:689] Asynchronous scheduling is enabled.
2026-02-27T23:16:44.0657259Z INFO 02-27 23:16:44 [vllm.py:699] Disabling NCCL for DP synchronization when using async scheduling.
2026-02-27T23:16:44.0658296Z WARNING 02-27 23:16:44 [platform.py:717] Speculative quantization is set but Ascend automatically uses the main model's quantization method. Resetting to None.
2026-02-27T23:16:44.0659263Z WARNING 02-27 23:16:44 [platform.py:758] Ignored parameter 'use_trtllm_ragged_deepseek_prefill'. This is a GPU-specific feature not supported on Ascend. Resetting to False.
2026-02-27T23:16:44.0659938Z INFO 02-27 23:16:44 [ascend_config.py:454] Dynamic EPLB is False
2026-02-27T23:16:44.0660321Z INFO 02-27 23:16:44 [ascend_config.py:455] The number of redundant experts is 0
2026-02-27T23:16:44.0661193Z INFO 02-27 23:16:44 [ascend_config.py:55] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-27T23:16:44.0662415Z INFO 02-27 23:16:44 [platform.py:301] FULL_DECODE_ONLY compilation enabled on NPU. use_inductor not supported - using only ACL Graph mode
2026-02-27T23:16:44.0663206Z WARNING 02-27 23:16:44 [platform.py:318] [91m
2026-02-27T23:16:44.0663566Z WARNING 02-27 23:16:44 [platform.py:318]             **********************************************************************************
2026-02-27T23:16:44.0664076Z WARNING 02-27 23:16:44 [platform.py:318]             * WARNING: You have enabled the *full graph* feature.
2026-02-27T23:16:44.0664623Z WARNING 02-27 23:16:44 [platform.py:318]             * This is an early experimental stage and may involve various unknown issues.
2026-02-27T23:16:44.0665522Z WARNING 02-27 23:16:44 [platform.py:318]             * A known problem is that capturing too many batch sizes can lead to OOM
2026-02-27T23:16:44.0666127Z WARNING 02-27 23:16:44 [platform.py:318]             * (Out of Memory) errors or inference hangs. If you encounter such issues,
2026-02-27T23:16:44.0666682Z WARNING 02-27 23:16:44 [platform.py:318]             * consider reducing `gpu_memory_utilization` or manually specifying a smaller
2026-02-27T23:16:44.0667200Z WARNING 02-27 23:16:44 [platform.py:318]             * batch size for graph capture.
2026-02-27T23:16:44.0667629Z WARNING 02-27 23:16:44 [platform.py:318]             * For more details, please refer to:
2026-02-27T23:16:44.0668186Z WARNING 02-27 23:16:44 [platform.py:318]             * https://docs.vllm.ai/en/stable/configuration/conserving_memory.html#reduce-cuda-graphs
2026-02-27T23:16:44.0668865Z WARNING 02-27 23:16:44 [platform.py:318]             **********************************************************************************[0m
2026-02-27T23:16:44.0669282Z WARNING 02-27 23:16:44 [platform.py:318]             
2026-02-27T23:16:44.0669730Z INFO 02-27 23:16:44 [platform.py:430] Set PYTORCH_NPU_ALLOC_CONF=expandable_segments:True
2026-02-27T23:16:44.0678133Z INFO 02-27 23:16:44 [utils.py:843] Started DP Coordinator process (PID: 992)
2026-02-27T23:16:48.7340486Z INFO 02-27 23:16:48 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T23:16:48.7341171Z INFO 02-27 23:16:48 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T23:16:48.7341644Z INFO 02-27 23:16:48 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T23:16:48.7405782Z INFO 02-27 23:16:48 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T23:16:48.8115184Z INFO 02-27 23:16:48 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T23:16:48.8115660Z INFO 02-27 23:16:48 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T23:16:48.8116256Z INFO 02-27 23:16:48 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T23:16:48.8186313Z INFO 02-27 23:16:48 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T23:16:58.5678172Z INFO 02-27 23:16:58 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T23:16:58.5678755Z INFO 02-27 23:16:58 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T23:16:58.5679320Z INFO 02-27 23:16:58 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T23:16:58.5745906Z INFO 02-27 23:16:58 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T23:17:03.7732475Z INFO 02-27 23:17:03 [utils.py:217] Started 2 API server processes
2026-02-27T23:17:03.9812407Z (EngineCore_DP0 pid=995) 2026-02-27 23:17:03,980 - 995 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.16.0+empty: default 1
2026-02-27T23:17:03.9821254Z (EngineCore_DP1 pid=1014) 2026-02-27 23:17:03,981 - 1014 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.16.0+empty: default 1
2026-02-27T23:17:03.9848385Z (EngineCore_DP0 pid=995) INFO 02-27 23:17:03 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-27T23:17:03.9860529Z (EngineCore_DP0 pid=995) INFO 02-27 23:17:03 [core.py:97] Initializing a V1 LLM engine (v0.16.0) with config: model='/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8', speculative_config=SpeculativeConfig(method='mtp', model='/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8', num_spec_tokens=3), tokenizer='/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8', skip_tokenizer_init=False, tokenizer_mode=deepseek_v32, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=8, pipeline_parallel_size=1, data_parallel_size=2, disable_custom_all_reduce=True, quantization=ascend, enforce_eager=False, enable_return_routed_experts=False, kv_cache_dtype=bfloat16, device_config=npu, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='deepseek_v3', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01, cudagraph_metrics=False, enable_layerwise_nvtx_tracing=False, enable_mfu_metrics=False, enable_mm_processor_stats=False, enable_logging_iteration_details=False), seed=0, served_model_name=/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'vllm_ascend.compilation.compiler_interface.AscendCompiler', 'custom_ops': ['all'], 'splitting_ops': [], 'compile_mm_encoder': False, 'compile_sizes': [], 'compile_ranges_split_points': [8196], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_DECODE_ONLY: (2, 0)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [8, 16, 24, 32, 40, 48], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': True, 'fuse_act_quant': True, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False, 'fuse_act_padding': False}, 'max_cudagraph_capture_size': 48, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>, 'evaluate_guards': False, 'assume_32_bit_indexing': False}, 'local_cache_dir': None, 'fast_moe_cold_start': False, 'static_all_moe_layers': []}
2026-02-27T23:17:03.9868099Z (EngineCore_DP1 pid=1014) INFO 02-27 23:17:03 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-27T23:17:08.7554957Z INFO 02-27 23:17:08 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T23:17:08.7555464Z INFO 02-27 23:17:08 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T23:17:08.7555952Z INFO 02-27 23:17:08 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T23:17:08.7556305Z INFO 02-27 23:17:08 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T23:17:08.7556852Z INFO 02-27 23:17:08 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T23:17:08.7557487Z INFO 02-27 23:17:08 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T23:17:08.7629016Z INFO 02-27 23:17:08 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T23:17:08.7629411Z INFO 02-27 23:17:08 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T23:17:09.1595383Z INFO 02-27 23:17:09 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T23:17:09.1595947Z INFO 02-27 23:17:09 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T23:17:09.1596509Z INFO 02-27 23:17:09 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T23:17:09.1689031Z INFO 02-27 23:17:09 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T23:17:09.2009563Z INFO 02-27 23:17:09 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T23:17:09.2010093Z INFO 02-27 23:17:09 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T23:17:09.2010937Z INFO 02-27 23:17:09 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T23:17:09.2089713Z INFO 02-27 23:17:09 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T23:17:14.4766187Z 2026-02-27 23:17:14,475 - 1041 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.16.0+empty: default 1
2026-02-27T23:17:14.4804500Z INFO 02-27 23:17:14 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-27T23:17:14.8565080Z (ApiServer_0 pid=1025) 2026-02-27 23:17:14,855 - 1025 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.16.0+empty: default 1
2026-02-27T23:17:14.8763100Z (ApiServer_1 pid=1026) 2026-02-27 23:17:14,875 - 1026 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.16.0+empty: default 1
2026-02-27T23:17:14.8904799Z (ApiServer_0 pid=1025) INFO 02-27 23:17:14 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-27T23:17:14.9107352Z (ApiServer_1 pid=1026) INFO 02-27 23:17:14 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-27T23:17:14.9162286Z (ApiServer_0 pid=1025) 2026-02-27 23:17:14,915 - modelscope - WARNING - We can not confirm the cached file is for revision: master
2026-02-27T23:17:14.9216435Z (ApiServer_0 pid=1025) INFO 02-27 23:17:14 [arg_utils.py:620] HF_HUB_OFFLINE is True, replace model_id [vllm-ascend/DeepSeek-V3.2-W8A8] to model_path [/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8]
2026-02-27T23:17:14.9812923Z (ApiServer_1 pid=1026) 2026-02-27 23:17:14,980 - modelscope - WARNING - We can not confirm the cached file is for revision: master
2026-02-27T23:17:14.9883461Z (ApiServer_1 pid=1026) INFO 02-27 23:17:14 [arg_utils.py:620] HF_HUB_OFFLINE is True, replace model_id [vllm-ascend/DeepSeek-V3.2-W8A8] to model_path [/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8]
2026-02-27T23:17:15.0250040Z (ApiServer_0 pid=1025) The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T23:17:15.0250888Z (ApiServer_0 pid=1025) [2026-02-27 23:17:15] WARNING configuration_utils.py:697: The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T23:17:15.0911931Z (ApiServer_1 pid=1026) The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T23:17:15.0912792Z (ApiServer_1 pid=1026) [2026-02-27 23:17:15] WARNING configuration_utils.py:697: The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T23:17:15.1487454Z 2026-02-27 23:17:15,147 - 1040 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.16.0+empty: default 1
2026-02-27T23:17:15.1529250Z INFO 02-27 23:17:15 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-27T23:17:15.1913465Z (ApiServer_1 pid=1026) The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T23:17:15.1914296Z (ApiServer_0 pid=1025) The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T23:17:15.1915084Z (ApiServer_1 pid=1026) [2026-02-27 23:17:15] WARNING configuration_utils.py:697: The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T23:17:15.1915995Z (ApiServer_0 pid=1025) [2026-02-27 23:17:15] WARNING configuration_utils.py:697: The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T23:17:15.1922475Z (ApiServer_1 pid=1026) The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T23:17:15.1923468Z (ApiServer_1 pid=1026) [2026-02-27 23:17:15] WARNING configuration_utils.py:697: The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T23:17:15.1924288Z (ApiServer_0 pid=1025) The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T23:17:15.1924988Z (ApiServer_0 pid=1025) [2026-02-27 23:17:15] WARNING configuration_utils.py:697: The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T23:17:15.1929499Z (ApiServer_1 pid=1026) You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-27T23:17:15.1930550Z (ApiServer_1 pid=1026) [2026-02-27 23:17:15] WARNING configuration_utils.py:635: You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-27T23:17:15.1931578Z (ApiServer_0 pid=1025) You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-27T23:17:15.1932702Z (ApiServer_0 pid=1025) [2026-02-27 23:17:15] WARNING configuration_utils.py:635: You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-27T23:17:15.2008363Z (ApiServer_1 pid=1026) INFO 02-27 23:17:15 [model.py:529] Resolved architecture: DeepseekV32ForCausalLM
2026-02-27T23:17:15.2013175Z (ApiServer_1 pid=1026) INFO 02-27 23:17:15 [model.py:1549] Using max model len 8192
2026-02-27T23:17:15.2013627Z (ApiServer_0 pid=1025) INFO 02-27 23:17:15 [model.py:529] Resolved architecture: DeepseekV32ForCausalLM
2026-02-27T23:17:15.2023911Z (ApiServer_0 pid=1025) INFO 02-27 23:17:15 [model.py:1549] Using max model len 8192
2026-02-27T23:17:15.3149690Z (ApiServer_1 pid=1026) WARNING 02-27 23:17:15 [speculative.py:293] method `deepseek_mtp` is deprecated and replaced with mtp.
2026-02-27T23:17:15.3153430Z (ApiServer_1 pid=1026) The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T23:17:15.3154258Z (ApiServer_1 pid=1026) [2026-02-27 23:17:15] WARNING configuration_utils.py:697: The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T23:17:15.3162555Z (ApiServer_1 pid=1026) The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T23:17:15.3163285Z (ApiServer_1 pid=1026) [2026-02-27 23:17:15] WARNING configuration_utils.py:697: The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T23:17:15.3170597Z (ApiServer_1 pid=1026) You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-27T23:17:15.3171612Z (ApiServer_1 pid=1026) [2026-02-27 23:17:15] WARNING configuration_utils.py:635: You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-27T23:17:15.3241355Z (ApiServer_1 pid=1026) INFO 02-27 23:17:15 [model.py:529] Resolved architecture: DeepSeekMTPModel
2026-02-27T23:17:15.3243140Z (ApiServer_1 pid=1026) INFO 02-27 23:17:15 [model.py:1549] Using max model len 163840
2026-02-27T23:17:15.3244545Z (ApiServer_1 pid=1026) WARNING 02-27 23:17:15 [speculative.py:411] Enabling num_speculative_tokens > 1 will runmultiple times of forward on same MTP layer,which may result in lower acceptance rate
2026-02-27T23:17:15.3246452Z (ApiServer_1 pid=1026) INFO 02-27 23:17:15 [scheduler.py:224] Chunked prefill is enabled with max_num_batched_tokens=8192.
2026-02-27T23:17:15.3309590Z (ApiServer_0 pid=1025) WARNING 02-27 23:17:15 [speculative.py:293] method `deepseek_mtp` is deprecated and replaced with mtp.
2026-02-27T23:17:15.3317341Z (ApiServer_0 pid=1025) The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T23:17:15.3318161Z (ApiServer_0 pid=1025) [2026-02-27 23:17:15] WARNING configuration_utils.py:697: The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T23:17:15.3327574Z (ApiServer_0 pid=1025) The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T23:17:15.3331153Z (ApiServer_0 pid=1025) [2026-02-27 23:17:15] WARNING configuration_utils.py:697: The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-27T23:17:15.3370441Z (ApiServer_0 pid=1025) You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-27T23:17:15.3371407Z (ApiServer_0 pid=1025) [2026-02-27 23:17:15] WARNING configuration_utils.py:635: You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-27T23:17:15.3425754Z (ApiServer_0 pid=1025) INFO 02-27 23:17:15 [model.py:529] Resolved architecture: DeepSeekMTPModel
2026-02-27T23:17:15.3426381Z (ApiServer_0 pid=1025) INFO 02-27 23:17:15 [model.py:1549] Using max model len 163840
2026-02-27T23:17:15.3427058Z (ApiServer_0 pid=1025) WARNING 02-27 23:17:15 [speculative.py:411] Enabling num_speculative_tokens > 1 will runmultiple times of forward on same MTP layer,which may result in lower acceptance rate
2026-02-27T23:17:15.3428095Z (ApiServer_0 pid=1025) INFO 02-27 23:17:15 [scheduler.py:224] Chunked prefill is enabled with max_num_batched_tokens=8192.
2026-02-27T23:17:15.4401120Z (ApiServer_1 pid=1026) INFO 02-27 23:17:15 [vllm.py:689] Asynchronous scheduling is enabled.
2026-02-27T23:17:15.4401700Z (ApiServer_1 pid=1026) INFO 02-27 23:17:15 [vllm.py:699] Disabling NCCL for DP synchronization when using async scheduling.
2026-02-27T23:17:15.4404820Z (ApiServer_1 pid=1026) WARNING 02-27 23:17:15 [platform.py:717] Speculative quantization is set but Ascend automatically uses the main model's quantization method. Resetting to None.
2026-02-27T23:17:15.4405795Z (ApiServer_1 pid=1026) WARNING 02-27 23:17:15 [platform.py:758] Ignored parameter 'use_trtllm_ragged_deepseek_prefill'. This is a GPU-specific feature not supported on Ascend. Resetting to False.
2026-02-27T23:17:15.4406498Z (ApiServer_1 pid=1026) INFO 02-27 23:17:15 [ascend_config.py:454] Dynamic EPLB is False
2026-02-27T23:17:15.4407048Z (ApiServer_1 pid=1026) INFO 02-27 23:17:15 [ascend_config.py:455] The number of redundant experts is 0
2026-02-27T23:17:15.4407969Z (ApiServer_1 pid=1026) INFO 02-27 23:17:15 [ascend_config.py:55] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-27T23:17:15.4409040Z (ApiServer_1 pid=1026) INFO 02-27 23:17:15 [platform.py:301] FULL_DECODE_ONLY compilation enabled on NPU. use_inductor not supported - using only ACL Graph mode
2026-02-27T23:17:15.4409967Z (ApiServer_1 pid=1026) WARNING 02-27 23:17:15 [platform.py:318] [91m
2026-02-27T23:17:15.4410436Z (ApiServer_1 pid=1026) WARNING 02-27 23:17:15 [platform.py:318]             **********************************************************************************
2026-02-27T23:17:15.4411028Z (ApiServer_1 pid=1026) WARNING 02-27 23:17:15 [platform.py:318]             * WARNING: You have enabled the *full graph* feature.
2026-02-27T23:17:15.4411690Z (ApiServer_1 pid=1026) WARNING 02-27 23:17:15 [platform.py:318]             * This is an early experimental stage and may involve various unknown issues.
2026-02-27T23:17:15.4412705Z (ApiServer_1 pid=1026) WARNING 02-27 23:17:15 [platform.py:318]             * A known problem is that capturing too many batch sizes can lead to OOM
2026-02-27T23:17:15.4413380Z (ApiServer_1 pid=1026) WARNING 02-27 23:17:15 [platform.py:318]             * (Out of Memory) errors or inference hangs. If you encounter such issues,
2026-02-27T23:17:15.4414155Z (ApiServer_1 pid=1026) WARNING 02-27 23:17:15 [platform.py:318]             * consider reducing `gpu_memory_utilization` or manually specifying a smaller
2026-02-27T23:17:15.4414752Z (ApiServer_1 pid=1026) WARNING 02-27 23:17:15 [platform.py:318]             * batch size for graph capture.
2026-02-27T23:17:15.4415267Z (ApiServer_1 pid=1026) WARNING 02-27 23:17:15 [platform.py:318]             * For more details, please refer to:
2026-02-27T23:17:15.4415970Z (ApiServer_1 pid=1026) WARNING 02-27 23:17:15 [platform.py:318]             * https://docs.vllm.ai/en/stable/configuration/conserving_memory.html#reduce-cuda-graphs
2026-02-27T23:17:15.4416734Z (ApiServer_1 pid=1026) WARNING 02-27 23:17:15 [platform.py:318]             **********************************************************************************[0m
2026-02-27T23:17:15.4417274Z (ApiServer_1 pid=1026) WARNING 02-27 23:17:15 [platform.py:318]             
2026-02-27T23:17:15.4417726Z (ApiServer_1 pid=1026) INFO 02-27 23:17:15 [platform.py:430] Set PYTORCH_NPU_ALLOC_CONF=expandable_segments:True
2026-02-27T23:17:15.4607941Z (ApiServer_0 pid=1025) INFO 02-27 23:17:15 [vllm.py:689] Asynchronous scheduling is enabled.
2026-02-27T23:17:15.4608523Z (ApiServer_0 pid=1025) INFO 02-27 23:17:15 [vllm.py:699] Disabling NCCL for DP synchronization when using async scheduling.
2026-02-27T23:17:15.4614628Z (ApiServer_0 pid=1025) WARNING 02-27 23:17:15 [platform.py:717] Speculative quantization is set but Ascend automatically uses the main model's quantization method. Resetting to None.
2026-02-27T23:17:15.4615608Z (ApiServer_0 pid=1025) WARNING 02-27 23:17:15 [platform.py:758] Ignored parameter 'use_trtllm_ragged_deepseek_prefill'. This is a GPU-specific feature not supported on Ascend. Resetting to False.
2026-02-27T23:17:15.4616349Z (ApiServer_0 pid=1025) INFO 02-27 23:17:15 [ascend_config.py:454] Dynamic EPLB is False
2026-02-27T23:17:15.4616897Z (ApiServer_0 pid=1025) INFO 02-27 23:17:15 [ascend_config.py:455] The number of redundant experts is 0
2026-02-27T23:17:15.4617797Z (ApiServer_0 pid=1025) INFO 02-27 23:17:15 [ascend_config.py:55] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-27T23:17:15.4618849Z (ApiServer_0 pid=1025) INFO 02-27 23:17:15 [platform.py:301] FULL_DECODE_ONLY compilation enabled on NPU. use_inductor not supported - using only ACL Graph mode
2026-02-27T23:17:15.4619504Z (ApiServer_0 pid=1025) WARNING 02-27 23:17:15 [platform.py:318] [91m
2026-02-27T23:17:15.4619958Z (ApiServer_0 pid=1025) WARNING 02-27 23:17:15 [platform.py:318]             **********************************************************************************
2026-02-27T23:17:15.4620583Z (ApiServer_0 pid=1025) WARNING 02-27 23:17:15 [platform.py:318]             * WARNING: You have enabled the *full graph* feature.
2026-02-27T23:17:15.4621206Z (ApiServer_0 pid=1025) WARNING 02-27 23:17:15 [platform.py:318]             * This is an early experimental stage and may involve various unknown issues.
2026-02-27T23:17:15.4621849Z (ApiServer_0 pid=1025) WARNING 02-27 23:17:15 [platform.py:318]             * A known problem is that capturing too many batch sizes can lead to OOM
2026-02-27T23:17:15.4622956Z (ApiServer_0 pid=1025) WARNING 02-27 23:17:15 [platform.py:318]             * (Out of Memory) errors or inference hangs. If you encounter such issues,
2026-02-27T23:17:15.4623634Z (ApiServer_0 pid=1025) WARNING 02-27 23:17:15 [platform.py:318]             * consider reducing `gpu_memory_utilization` or manually specifying a smaller
2026-02-27T23:17:15.4624355Z (ApiServer_0 pid=1025) WARNING 02-27 23:17:15 [platform.py:318]             * batch size for graph capture.
2026-02-27T23:17:15.4624880Z (ApiServer_0 pid=1025) WARNING 02-27 23:17:15 [platform.py:318]             * For more details, please refer to:
2026-02-27T23:17:15.4625583Z (ApiServer_0 pid=1025) WARNING 02-27 23:17:15 [platform.py:318]             * https://docs.vllm.ai/en/stable/configuration/conserving_memory.html#reduce-cuda-graphs
2026-02-27T23:17:15.4626360Z (ApiServer_0 pid=1025) WARNING 02-27 23:17:15 [platform.py:318]             **********************************************************************************[0m
2026-02-27T23:17:15.4626965Z (ApiServer_0 pid=1025) WARNING 02-27 23:17:15 [platform.py:318]             
2026-02-27T23:17:15.4627411Z (ApiServer_0 pid=1025) INFO 02-27 23:17:15 [platform.py:430] Set PYTORCH_NPU_ALLOC_CONF=expandable_segments:True
2026-02-27T23:17:16.8654919Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-27T23:17:16.8655870Z   warnings.warn(
2026-02-27T23:17:16.9328753Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-27T23:17:16.9329747Z   warnings.warn(
2026-02-27T23:17:19.0948990Z INFO 02-27 23:17:19 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T23:17:19.0949833Z INFO 02-27 23:17:19 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T23:17:19.0950337Z INFO 02-27 23:17:19 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T23:17:19.1021873Z INFO 02-27 23:17:19 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T23:17:19.8592961Z INFO 02-27 23:17:19 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T23:17:19.8593507Z INFO 02-27 23:17:19 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T23:17:19.8594043Z INFO 02-27 23:17:19 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T23:17:19.8668888Z INFO 02-27 23:17:19 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T23:17:19.8773766Z INFO 02-27 23:17:19 [ascend_config.py:454] Dynamic EPLB is False
2026-02-27T23:17:19.8774227Z INFO 02-27 23:17:19 [ascend_config.py:455] The number of redundant experts is 0
2026-02-27T23:17:19.8775211Z INFO 02-27 23:17:19 [ascend_config.py:55] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-27T23:17:19.8819909Z INFO 02-27 23:17:19 [ascend_config.py:454] Dynamic EPLB is False
2026-02-27T23:17:19.8820343Z INFO 02-27 23:17:19 [ascend_config.py:455] The number of redundant experts is 0
2026-02-27T23:17:19.8822380Z INFO 02-27 23:17:19 [ascend_config.py:55] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-27T23:17:20.2486254Z INFO 02-27 23:17:20 [parallel_state.py:1234] world_size=16 rank=8 local_rank=0 distributed_init_method=tcp://127.0.0.1:48307 backend=hccl
2026-02-27T23:17:20.5776906Z INFO 02-27 23:17:20 [parallel_state.py:1234] world_size=16 rank=0 local_rank=0 distributed_init_method=tcp://127.0.0.1:48307 backend=hccl
2026-02-27T23:17:24.1373391Z 2026-02-27 23:17:24,136 - 1074 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.16.0+empty: default 1
2026-02-27T23:17:24.1412485Z INFO 02-27 23:17:24 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-27T23:17:25.0054100Z 2026-02-27 23:17:25,004 - 1077 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.16.0+empty: default 1
2026-02-27T23:17:25.0091206Z INFO 02-27 23:17:25 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-27T23:17:25.7582083Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-27T23:17:25.7583389Z   warnings.warn(
2026-02-27T23:17:26.7549041Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-27T23:17:26.7550101Z   warnings.warn(
2026-02-27T23:17:27.6205061Z INFO 02-27 23:17:27 [ascend_config.py:454] Dynamic EPLB is False
2026-02-27T23:17:27.6205555Z INFO 02-27 23:17:27 [ascend_config.py:455] The number of redundant experts is 0
2026-02-27T23:17:27.6206430Z INFO 02-27 23:17:27 [ascend_config.py:55] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-27T23:17:28.4201396Z INFO 02-27 23:17:28 [parallel_state.py:1234] world_size=16 rank=9 local_rank=1 distributed_init_method=tcp://127.0.0.1:48307 backend=hccl
2026-02-27T23:17:28.5171802Z INFO 02-27 23:17:28 [ascend_config.py:454] Dynamic EPLB is False
2026-02-27T23:17:28.5172399Z INFO 02-27 23:17:28 [ascend_config.py:455] The number of redundant experts is 0
2026-02-27T23:17:28.5173321Z INFO 02-27 23:17:28 [ascend_config.py:55] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-27T23:17:28.8334637Z INFO 02-27 23:17:28 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T23:17:28.8335213Z INFO 02-27 23:17:28 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T23:17:28.8335743Z INFO 02-27 23:17:28 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T23:17:28.8430092Z INFO 02-27 23:17:28 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T23:17:29.3043161Z INFO 02-27 23:17:29 [parallel_state.py:1234] world_size=16 rank=1 local_rank=1 distributed_init_method=tcp://127.0.0.1:48307 backend=hccl
2026-02-27T23:17:29.5969835Z INFO 02-27 23:17:29 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T23:17:29.5970282Z INFO 02-27 23:17:29 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T23:17:29.5970901Z INFO 02-27 23:17:29 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T23:17:29.6047656Z INFO 02-27 23:17:29 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T23:17:34.2074094Z 2026-02-27 23:17:34,206 - 1180 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.16.0+empty: default 1
2026-02-27T23:17:34.2111039Z INFO 02-27 23:17:34 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-27T23:17:34.7092969Z 2026-02-27 23:17:34,708 - 1183 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.16.0+empty: default 1
2026-02-27T23:17:34.7130122Z INFO 02-27 23:17:34 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-27T23:17:35.8721155Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-27T23:17:35.8722202Z   warnings.warn(
2026-02-27T23:17:36.2858326Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-27T23:17:36.2859471Z   warnings.warn(
2026-02-27T23:17:37.6847125Z INFO 02-27 23:17:37 [ascend_config.py:454] Dynamic EPLB is False
2026-02-27T23:17:37.6847650Z INFO 02-27 23:17:37 [ascend_config.py:455] The number of redundant experts is 0
2026-02-27T23:17:37.6848514Z INFO 02-27 23:17:37 [ascend_config.py:55] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-27T23:17:38.0500610Z INFO 02-27 23:17:38 [ascend_config.py:454] Dynamic EPLB is False
2026-02-27T23:17:38.0501129Z INFO 02-27 23:17:38 [ascend_config.py:455] The number of redundant experts is 0
2026-02-27T23:17:38.0502139Z INFO 02-27 23:17:38 [ascend_config.py:55] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-27T23:17:38.4765559Z INFO 02-27 23:17:38 [parallel_state.py:1234] world_size=16 rank=10 local_rank=2 distributed_init_method=tcp://127.0.0.1:48307 backend=hccl
2026-02-27T23:17:38.7357661Z INFO 02-27 23:17:38 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T23:17:38.7358236Z INFO 02-27 23:17:38 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T23:17:38.7358794Z INFO 02-27 23:17:38 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T23:17:38.7441937Z INFO 02-27 23:17:38 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T23:17:39.2485861Z INFO 02-27 23:17:39 [parallel_state.py:1234] world_size=16 rank=2 local_rank=2 distributed_init_method=tcp://127.0.0.1:48307 backend=hccl
2026-02-27T23:17:39.4420807Z INFO 02-27 23:17:39 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T23:17:39.4421457Z INFO 02-27 23:17:39 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T23:17:39.4421953Z INFO 02-27 23:17:39 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T23:17:39.4511832Z INFO 02-27 23:17:39 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T23:17:43.7300108Z 2026-02-27 23:17:43,728 - 1284 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.16.0+empty: default 1
2026-02-27T23:17:43.7339551Z INFO 02-27 23:17:43 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-27T23:17:44.4423963Z 2026-02-27 23:17:44,441 - 1287 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.16.0+empty: default 1
2026-02-27T23:17:44.4460453Z INFO 02-27 23:17:44 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-27T23:17:45.3538536Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-27T23:17:45.3539882Z   warnings.warn(
2026-02-27T23:17:46.1084113Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-27T23:17:46.1085136Z   warnings.warn(
2026-02-27T23:17:47.1215291Z INFO 02-27 23:17:47 [ascend_config.py:454] Dynamic EPLB is False
2026-02-27T23:17:47.1215794Z INFO 02-27 23:17:47 [ascend_config.py:455] The number of redundant experts is 0
2026-02-27T23:17:47.1216714Z INFO 02-27 23:17:47 [ascend_config.py:55] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-27T23:17:47.9151273Z INFO 02-27 23:17:47 [parallel_state.py:1234] world_size=16 rank=11 local_rank=3 distributed_init_method=tcp://127.0.0.1:48307 backend=hccl
2026-02-27T23:17:47.9250462Z INFO 02-27 23:17:47 [ascend_config.py:454] Dynamic EPLB is False
2026-02-27T23:17:47.9251011Z INFO 02-27 23:17:47 [ascend_config.py:455] The number of redundant experts is 0
2026-02-27T23:17:47.9251874Z INFO 02-27 23:17:47 [ascend_config.py:55] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-27T23:17:48.3510238Z INFO 02-27 23:17:48 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T23:17:48.3511217Z INFO 02-27 23:17:48 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T23:17:48.3511710Z INFO 02-27 23:17:48 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T23:17:48.3586096Z INFO 02-27 23:17:48 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T23:17:48.7075052Z INFO 02-27 23:17:48 [parallel_state.py:1234] world_size=16 rank=3 local_rank=3 distributed_init_method=tcp://127.0.0.1:48307 backend=hccl
2026-02-27T23:17:49.0229056Z INFO 02-27 23:17:49 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T23:17:49.0229627Z INFO 02-27 23:17:49 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T23:17:49.0230166Z INFO 02-27 23:17:49 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T23:17:49.0304513Z INFO 02-27 23:17:49 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T23:17:53.4535724Z 2026-02-27 23:17:53,452 - 1388 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.16.0+empty: default 1
2026-02-27T23:17:53.4572318Z INFO 02-27 23:17:53 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-27T23:17:54.3228949Z 2026-02-27 23:17:54,321 - 1391 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.16.0+empty: default 1
2026-02-27T23:17:54.3267294Z INFO 02-27 23:17:54 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-27T23:17:55.0605032Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-27T23:17:55.0605985Z   warnings.warn(
2026-02-27T23:17:56.0910797Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-27T23:17:56.0912358Z   warnings.warn(
2026-02-27T23:17:56.9260069Z INFO 02-27 23:17:56 [ascend_config.py:454] Dynamic EPLB is False
2026-02-27T23:17:56.9260495Z INFO 02-27 23:17:56 [ascend_config.py:455] The number of redundant experts is 0
2026-02-27T23:17:56.9261357Z INFO 02-27 23:17:56 [ascend_config.py:55] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-27T23:17:57.9376697Z INFO 02-27 23:17:57 [ascend_config.py:454] Dynamic EPLB is False
2026-02-27T23:17:57.9377204Z INFO 02-27 23:17:57 [ascend_config.py:455] The number of redundant experts is 0
2026-02-27T23:17:57.9378087Z INFO 02-27 23:17:57 [ascend_config.py:55] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-27T23:17:58.0351827Z INFO 02-27 23:17:58 [parallel_state.py:1234] world_size=16 rank=12 local_rank=4 distributed_init_method=tcp://127.0.0.1:48307 backend=hccl
2026-02-27T23:17:58.0384173Z INFO 02-27 23:17:58 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T23:17:58.0384642Z INFO 02-27 23:17:58 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T23:17:58.0385331Z INFO 02-27 23:17:58 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T23:17:58.0461523Z INFO 02-27 23:17:58 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T23:17:58.7341511Z INFO 02-27 23:17:58 [parallel_state.py:1234] world_size=16 rank=4 local_rank=4 distributed_init_method=tcp://127.0.0.1:48307 backend=hccl
2026-02-27T23:17:58.9302644Z INFO 02-27 23:17:58 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T23:17:58.9303294Z INFO 02-27 23:17:58 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T23:17:58.9303837Z INFO 02-27 23:17:58 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T23:17:58.9376993Z INFO 02-27 23:17:58 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T23:18:03.1184117Z 2026-02-27 23:18:03,117 - 1492 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.16.0+empty: default 1
2026-02-27T23:18:03.1220133Z INFO 02-27 23:18:03 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-27T23:18:03.9647074Z 2026-02-27 23:18:03,963 - 1495 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.16.0+empty: default 1
2026-02-27T23:18:03.9684749Z INFO 02-27 23:18:03 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-27T23:18:04.9294323Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-27T23:18:04.9295309Z   warnings.warn(
2026-02-27T23:18:05.6656110Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-27T23:18:05.6657064Z   warnings.warn(
2026-02-27T23:18:06.8111184Z INFO 02-27 23:18:06 [ascend_config.py:454] Dynamic EPLB is False
2026-02-27T23:18:06.8112105Z INFO 02-27 23:18:06 [ascend_config.py:455] The number of redundant experts is 0
2026-02-27T23:18:06.8113431Z INFO 02-27 23:18:06 [ascend_config.py:55] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-27T23:18:07.4544221Z INFO 02-27 23:18:07 [ascend_config.py:454] Dynamic EPLB is False
2026-02-27T23:18:07.4544694Z INFO 02-27 23:18:07 [ascend_config.py:455] The number of redundant experts is 0
2026-02-27T23:18:07.4545635Z INFO 02-27 23:18:07 [ascend_config.py:55] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-27T23:18:07.8665263Z INFO 02-27 23:18:07 [parallel_state.py:1234] world_size=16 rank=13 local_rank=5 distributed_init_method=tcp://127.0.0.1:48307 backend=hccl
2026-02-27T23:18:07.9034132Z INFO 02-27 23:18:07 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T23:18:07.9034720Z INFO 02-27 23:18:07 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T23:18:07.9035255Z INFO 02-27 23:18:07 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T23:18:07.9112516Z INFO 02-27 23:18:07 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T23:18:08.2471484Z INFO 02-27 23:18:08 [parallel_state.py:1234] world_size=16 rank=5 local_rank=5 distributed_init_method=tcp://127.0.0.1:48307 backend=hccl
2026-02-27T23:18:08.5957277Z INFO 02-27 23:18:08 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T23:18:08.5957883Z INFO 02-27 23:18:08 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T23:18:08.5958378Z INFO 02-27 23:18:08 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T23:18:08.6028811Z INFO 02-27 23:18:08 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T23:18:12.9758225Z 2026-02-27 23:18:12,974 - 1596 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.16.0+empty: default 1
2026-02-27T23:18:12.9796286Z INFO 02-27 23:18:12 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-27T23:18:13.7129726Z 2026-02-27 23:18:13,711 - 1599 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.16.0+empty: default 1
2026-02-27T23:18:13.7166824Z INFO 02-27 23:18:13 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-27T23:18:14.7048233Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-27T23:18:14.7049186Z   warnings.warn(
2026-02-27T23:18:15.3657205Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-27T23:18:15.3658191Z   warnings.warn(
2026-02-27T23:18:16.4830238Z INFO 02-27 23:18:16 [ascend_config.py:454] Dynamic EPLB is False
2026-02-27T23:18:16.4830792Z INFO 02-27 23:18:16 [ascend_config.py:455] The number of redundant experts is 0
2026-02-27T23:18:16.4831623Z INFO 02-27 23:18:16 [ascend_config.py:55] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-27T23:18:17.1479536Z INFO 02-27 23:18:17 [ascend_config.py:454] Dynamic EPLB is False
2026-02-27T23:18:17.1480041Z INFO 02-27 23:18:17 [ascend_config.py:455] The number of redundant experts is 0
2026-02-27T23:18:17.1481328Z INFO 02-27 23:18:17 [ascend_config.py:55] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-27T23:18:17.5524030Z INFO 02-27 23:18:17 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T23:18:17.5524539Z INFO 02-27 23:18:17 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T23:18:17.5525172Z INFO 02-27 23:18:17 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T23:18:17.5598798Z INFO 02-27 23:18:17 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T23:18:17.6951839Z INFO 02-27 23:18:17 [parallel_state.py:1234] world_size=16 rank=14 local_rank=6 distributed_init_method=tcp://127.0.0.1:48307 backend=hccl
2026-02-27T23:18:18.3666401Z INFO 02-27 23:18:18 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T23:18:18.3667014Z INFO 02-27 23:18:18 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T23:18:18.3667561Z INFO 02-27 23:18:18 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T23:18:18.3752461Z INFO 02-27 23:18:18 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T23:18:18.5165100Z INFO 02-27 23:18:18 [parallel_state.py:1234] world_size=16 rank=6 local_rank=6 distributed_init_method=tcp://127.0.0.1:48307 backend=hccl
2026-02-27T23:18:22.7358847Z 2026-02-27 23:18:22,734 - 1700 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.16.0+empty: default 1
2026-02-27T23:18:22.7398866Z INFO 02-27 23:18:22 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-27T23:18:23.3897699Z 2026-02-27 23:18:23,388 - 1703 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.16.0+empty: default 1
2026-02-27T23:18:23.3935440Z INFO 02-27 23:18:23 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-27T23:18:24.3131913Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-27T23:18:24.3132986Z   warnings.warn(
2026-02-27T23:18:25.0109894Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-27T23:18:25.0110839Z   warnings.warn(
2026-02-27T23:18:26.0520172Z INFO 02-27 23:18:26 [ascend_config.py:454] Dynamic EPLB is False
2026-02-27T23:18:26.0520705Z INFO 02-27 23:18:26 [ascend_config.py:455] The number of redundant experts is 0
2026-02-27T23:18:26.0521580Z INFO 02-27 23:18:26 [ascend_config.py:55] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-27T23:18:26.7512858Z INFO 02-27 23:18:26 [ascend_config.py:454] Dynamic EPLB is False
2026-02-27T23:18:26.7513612Z INFO 02-27 23:18:26 [ascend_config.py:455] The number of redundant experts is 0
2026-02-27T23:18:26.7514420Z INFO 02-27 23:18:26 [ascend_config.py:55] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-27T23:18:26.9233846Z INFO 02-27 23:18:26 [parallel_state.py:1234] world_size=16 rank=15 local_rank=7 distributed_init_method=tcp://127.0.0.1:48307 backend=hccl
2026-02-27T23:18:27.5327228Z INFO 02-27 23:18:27 [parallel_state.py:1234] world_size=16 rank=7 local_rank=7 distributed_init_method=tcp://127.0.0.1:48307 backend=hccl
2026-02-27T23:18:27.5524703Z [Gloo] Rank 0 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
2026-02-27T23:18:27.5526018Z [Gloo] Rank 8 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
2026-02-27T23:18:27.5527203Z [Gloo] Rank 7 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
2026-02-27T23:18:27.5528878Z [Gloo] Rank 5 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
2026-02-27T23:18:27.5529410Z [Gloo] Rank 6 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
2026-02-27T23:18:27.6026899Z [Gloo] Rank 13 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
2026-02-27T23:18:27.6027455Z [Gloo] Rank 14 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
2026-02-27T23:18:27.6389368Z [Gloo] Rank 2 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
2026-02-27T23:18:27.6426558Z [Gloo] Rank 1 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
2026-02-27T23:18:27.6427758Z [Gloo] Rank 3 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
2026-02-27T23:18:27.6428346Z [Gloo] Rank 10 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
2026-02-27T23:18:27.6428942Z [Gloo] Rank 4 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
2026-02-27T23:18:27.7148466Z [Gloo] Rank 11 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
2026-02-27T23:18:27.7149600Z [Gloo] Rank 9 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
2026-02-27T23:18:27.7269805Z [Gloo] Rank 12 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
2026-02-27T23:18:27.7270353Z [Gloo] Rank 15 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
2026-02-27T23:18:27.7388625Z [Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-27T23:18:27.7389105Z [Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-27T23:18:27.7389963Z [Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-27T23:18:27.7390460Z [Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-27T23:18:27.7390901Z [Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-27T23:18:27.7392296Z [Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-27T23:18:27.7392847Z [Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-27T23:18:27.7393281Z [Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-27T23:18:27.7500187Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T23:18:27.7500676Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T23:18:27.7501182Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T23:18:27.7501642Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T23:18:27.7502224Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T23:18:27.7502696Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T23:18:27.7503139Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T23:18:27.7503600Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T23:18:27.7529437Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T23:18:27.7529884Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T23:18:27.7530367Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T23:18:27.7530802Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T23:18:27.7531338Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T23:18:27.7531801Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T23:18:27.7532360Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T23:18:27.7552585Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T23:18:27.7556576Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T23:18:27.7557012Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T23:18:27.7558789Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T23:18:27.7559223Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T23:18:27.7562257Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T23:18:27.7562864Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T23:18:27.7609788Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T23:18:27.7634351Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T23:18:27.8088366Z [Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-27T23:18:27.8089142Z [Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-27T23:18:27.8089673Z [Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-27T23:18:27.8090114Z [Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-27T23:18:27.8090669Z [Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-27T23:18:27.8091155Z [Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-27T23:18:27.8091592Z [Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-27T23:18:27.8092243Z [Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-27T23:18:27.8164015Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T23:18:27.8175948Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T23:18:27.8176608Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T23:18:27.8177084Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T23:18:27.8177645Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T23:18:27.8178112Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T23:18:27.8178543Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T23:18:27.8179006Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T23:18:27.8197806Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T23:18:27.8204360Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T23:18:27.8205177Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T23:18:27.8205631Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T23:18:27.8206131Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T23:18:27.8206591Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T23:18:27.8207012Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T23:18:27.8213450Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T23:18:27.8214128Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T23:18:27.8228091Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T23:18:27.8228597Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T23:18:27.8229123Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T23:18:27.8229580Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T23:18:27.8230120Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T23:18:27.8233196Z [Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
2026-02-27T23:18:27.8233907Z [Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
2026-02-27T23:18:27.8234505Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T23:18:27.8235158Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-27T23:18:27.8248623Z [Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
2026-02-27T23:18:27.8249252Z [Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
2026-02-27T23:18:27.8249687Z [Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
2026-02-27T23:18:27.8250141Z [Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
2026-02-27T23:18:27.8258455Z [Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
2026-02-27T23:18:27.8258931Z [Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
2026-02-27T23:18:27.8259401Z [Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
2026-02-27T23:18:27.8259999Z [Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
2026-02-27T23:18:27.8260444Z [Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
2026-02-27T23:18:27.8260897Z [Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
2026-02-27T23:18:27.8261362Z [Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
2026-02-27T23:18:27.8261781Z [Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
2026-02-27T23:18:27.8262425Z [Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
2026-02-27T23:18:27.8262986Z [Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
2026-02-27T23:18:27.8347617Z [Gloo] Rank 0 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
2026-02-27T23:18:27.8348159Z [Gloo] Rank 2 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
2026-02-27T23:18:27.8348612Z [Gloo] Rank 1 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
2026-02-27T23:18:27.8353354Z [Gloo] Rank 3 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
2026-02-27T23:18:27.8354616Z [Gloo] Rank 9 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
2026-02-27T23:18:27.8355205Z [Gloo] Rank 4 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
2026-02-27T23:18:27.8355776Z INFO 02-27 23:18:27 [parallel_state.py:1445] rank 2 in world size 16 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 2, EP rank 2
2026-02-27T23:18:27.8356377Z [Gloo] Rank 5 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
2026-02-27T23:18:27.8356821Z [Gloo] Rank 6 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
2026-02-27T23:18:27.8357396Z INFO 02-27 23:18:27 [parallel_state.py:1445] rank 4 in world size 16 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 4, EP rank 4
2026-02-27T23:18:27.8357977Z [Gloo] Rank 7 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
2026-02-27T23:18:27.8358426Z [Gloo] Rank 8 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
2026-02-27T23:18:27.8359047Z INFO 02-27 23:18:27 [parallel_state.py:1445] rank 1 in world size 16 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 1, EP rank 1
2026-02-27T23:18:27.8359608Z [Gloo] Rank 10 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
2026-02-27T23:18:27.8360123Z INFO 02-27 23:18:27 [parallel_state.py:1445] rank 3 in world size 16 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 3, EP rank 3
2026-02-27T23:18:27.8360671Z [Gloo] Rank 11 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
2026-02-27T23:18:27.8361107Z [Gloo] Rank 12 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
2026-02-27T23:18:27.8361786Z INFO 02-27 23:18:27 [parallel_state.py:1445] rank 9 in world size 16 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 1, EP rank 9
2026-02-27T23:18:27.8362462Z [Gloo] Rank 13 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
2026-02-27T23:18:27.8362903Z [Gloo] Rank 14 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
2026-02-27T23:18:27.8363471Z INFO 02-27 23:18:27 [parallel_state.py:1445] rank 5 in world size 16 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 5, EP rank 5
2026-02-27T23:18:27.8364050Z [Gloo] Rank 15 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
2026-02-27T23:18:27.8364621Z INFO 02-27 23:18:27 [parallel_state.py:1445] rank 0 in world size 16 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
2026-02-27T23:18:27.8365262Z INFO 02-27 23:18:27 [parallel_state.py:1445] rank 8 in world size 16 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 0, EP rank 8
2026-02-27T23:18:27.8365867Z INFO 02-27 23:18:27 [parallel_state.py:1445] rank 11 in world size 16 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 3, EP rank 11
2026-02-27T23:18:27.8366499Z INFO 02-27 23:18:27 [parallel_state.py:1445] rank 7 in world size 16 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 7, EP rank 7
2026-02-27T23:18:27.8367148Z INFO 02-27 23:18:27 [parallel_state.py:1445] rank 12 in world size 16 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 4, EP rank 12
2026-02-27T23:18:27.8367784Z INFO 02-27 23:18:27 [parallel_state.py:1445] rank 10 in world size 16 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 2, EP rank 10
2026-02-27T23:18:27.8368518Z INFO 02-27 23:18:27 [parallel_state.py:1445] rank 14 in world size 16 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 6, EP rank 14
2026-02-27T23:18:27.8369223Z INFO 02-27 23:18:27 [parallel_state.py:1445] rank 15 in world size 16 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 7, EP rank 15
2026-02-27T23:18:27.8369813Z INFO 02-27 23:18:27 [parallel_state.py:1445] rank 13 in world size 16 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 5, EP rank 13
2026-02-27T23:18:27.8370445Z INFO 02-27 23:18:27 [parallel_state.py:1445] rank 6 in world size 16 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 6, EP rank 6
2026-02-27T23:18:27.8828405Z [Gloo] Rank 0 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
2026-02-27T23:18:27.9112873Z [Gloo] Rank 4 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
2026-02-27T23:18:27.9113543Z [Gloo] Rank 2 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
2026-02-27T23:18:27.9226022Z [Gloo] Rank 3 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
2026-02-27T23:18:27.9226570Z [Gloo] Rank 6 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
2026-02-27T23:18:27.9229315Z [Gloo] Rank 10 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
2026-02-27T23:18:27.9230566Z [Gloo] Rank 14 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
2026-02-27T23:18:27.9252448Z [Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
2026-02-27T23:18:27.9252927Z [Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
2026-02-27T23:18:27.9255012Z [Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
2026-02-27T23:18:27.9255513Z [Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
2026-02-27T23:18:27.9832809Z [Gloo] Rank 1 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
2026-02-27T23:18:27.9833400Z [Gloo] Rank 7 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
2026-02-27T23:18:27.9834049Z [Gloo] Rank 5 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
2026-02-27T23:18:27.9834905Z [Gloo] Rank 9 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
2026-02-27T23:18:27.9835352Z [Gloo] Rank 8 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
2026-02-27T23:18:27.9835848Z [Gloo] Rank 15 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
2026-02-27T23:18:27.9836420Z [Gloo] Rank 13 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
2026-02-27T23:18:27.9836896Z [Gloo] Rank 11 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
2026-02-27T23:18:27.9837360Z [Gloo] Rank 12 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
2026-02-27T23:18:27.9855761Z [Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
2026-02-27T23:18:27.9856267Z [Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
2026-02-27T23:18:27.9858495Z [Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
2026-02-27T23:18:27.9858982Z [Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
2026-02-27T23:18:27.9859450Z [Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
2026-02-27T23:18:27.9859899Z [Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
2026-02-27T23:18:27.9861877Z [Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
2026-02-27T23:18:27.9862567Z [Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
2026-02-27T23:18:27.9863139Z [Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
2026-02-27T23:18:27.9863919Z [Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
2026-02-27T23:18:27.9869670Z [Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
2026-02-27T23:18:27.9870108Z [Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
2026-02-27T23:18:31.2113798Z INFO 02-27 23:18:31 [cpu_binding.py:297] The CPU allocation plan is as follows:
2026-02-27T23:18:31.2114960Z INFO 02-27 23:18:31 [cpu_binding.py:302] NPU14: main=[242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277]  acl=[278]  release=[[279]]
2026-02-27T23:18:31.2796169Z INFO 02-27 23:18:31 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T23:18:31.2812723Z INFO 02-27 23:18:31 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T23:18:31.3305767Z WARNING 02-27 23:18:31 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T23:18:31.3601612Z INFO 02-27 23:18:31 [cpu_binding.py:297] The CPU allocation plan is as follows:
2026-02-27T23:18:31.3602483Z INFO 02-27 23:18:31 [cpu_binding.py:302] NPU2: main=[82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117]  acl=[118]  release=[[119]]
2026-02-27T23:18:31.3713276Z WARNING 02-27 23:18:31 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T23:18:31.3755988Z (Worker_DP1_TP6_EP14 pid=1596) INFO 02-27 23:18:31 [model_runner_v1.py:2352] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-27T23:18:31.4130186Z INFO 02-27 23:18:31 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T23:18:31.4149256Z INFO 02-27 23:18:31 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T23:18:31.4478554Z WARNING 02-27 23:18:31 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T23:18:31.4668774Z WARNING 02-27 23:18:31 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T23:18:31.4699047Z (Worker_DP0_TP2_EP2 pid=1183) INFO 02-27 23:18:31 [model_runner_v1.py:2352] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-27T23:18:31.6012892Z INFO 02-27 23:18:31 [cpu_binding.py:297] The CPU allocation plan is as follows:
2026-02-27T23:18:31.6013780Z INFO 02-27 23:18:31 [cpu_binding.py:302] NPU10: main=[82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117]  acl=[118]  release=[[119]]
2026-02-27T23:18:31.6553644Z INFO 02-27 23:18:31 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T23:18:31.6573296Z INFO 02-27 23:18:31 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T23:18:31.6926641Z WARNING 02-27 23:18:31 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T23:18:31.7218182Z WARNING 02-27 23:18:31 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T23:18:31.7259261Z (Worker_DP1_TP2_EP10 pid=1180) INFO 02-27 23:18:31 [model_runner_v1.py:2352] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-27T23:18:31.7535708Z INFO 02-27 23:18:31 [cpu_binding.py:297] The CPU allocation plan is as follows:
2026-02-27T23:18:31.7536512Z INFO 02-27 23:18:31 [cpu_binding.py:302] NPU6: main=[242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277]  acl=[278]  release=[[279]]
2026-02-27T23:18:31.8119023Z INFO 02-27 23:18:31 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T23:18:31.8137334Z INFO 02-27 23:18:31 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T23:18:31.8564440Z WARNING 02-27 23:18:31 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T23:18:31.8769783Z WARNING 02-27 23:18:31 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T23:18:31.8805298Z (Worker_DP0_TP6_EP6 pid=1599) INFO 02-27 23:18:31 [model_runner_v1.py:2352] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-27T23:18:31.8837418Z (Worker_DP0_TP2_EP2 pid=1183) [2026-02-27 23:18:31] INFO modelslim_config.py:296: Using the vLLM Ascend modelslim Quantization now!
2026-02-27T23:18:32.0219757Z INFO 02-27 23:18:32 [cpu_binding.py:297] The CPU allocation plan is as follows:
2026-02-27T23:18:32.0220380Z INFO 02-27 23:18:32 [cpu_binding.py:302] NPU8: main=[2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37]  acl=[38]  release=[[39]]
2026-02-27T23:18:32.0441960Z (Worker_DP0_TP2_EP2 pid=1183) INFO 02-27 23:18:32 [layer.py:481] [EP Rank 2/16] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 16/256. Experts local to global index map: 0->32, 1->33, 2->34, 3->35, 4->36, 5->37, 6->38, 7->39, 8->40, 9->41, 10->42, 11->43, 12->44, 13->45, 14->46, 15->47.
2026-02-27T23:18:32.0736501Z INFO 02-27 23:18:32 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T23:18:32.1082862Z WARNING 02-27 23:18:32 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T23:18:32.1276450Z WARNING 02-27 23:18:32 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T23:18:32.1313627Z (Worker_DP1_TP0_EP8 pid=1041) INFO 02-27 23:18:32 [model_runner_v1.py:2352] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-27T23:18:32.2044714Z (Worker_DP1_TP6_EP14 pid=1596) [2026-02-27 23:18:32] INFO modelslim_config.py:296: Using the vLLM Ascend modelslim Quantization now!
2026-02-27T23:18:32.3379311Z (Worker_DP1_TP6_EP14 pid=1596) INFO 02-27 23:18:32 [layer.py:481] [EP Rank 14/16] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 16/256. Experts local to global index map: 0->224, 1->225, 2->226, 3->227, 4->228, 5->229, 6->230, 7->231, 8->232, 9->233, 10->234, 11->235, 12->236, 13->237, 14->238, 15->239.
2026-02-27T23:18:32.3543518Z INFO 02-27 23:18:32 [cpu_binding.py:297] The CPU allocation plan is as follows:
2026-02-27T23:18:32.3544218Z INFO 02-27 23:18:32 [cpu_binding.py:302] NPU7: main=[282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317]  acl=[318]  release=[[319]]
2026-02-27T23:18:32.3648916Z (Worker_DP0_TP6_EP6 pid=1599) [2026-02-27 23:18:32] INFO modelslim_config.py:296: Using the vLLM Ascend modelslim Quantization now!
2026-02-27T23:18:32.3838837Z (Worker_DP1_TP2_EP10 pid=1180) [2026-02-27 23:18:32] INFO modelslim_config.py:296: Using the vLLM Ascend modelslim Quantization now!
2026-02-27T23:18:32.4137800Z INFO 02-27 23:18:32 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T23:18:32.4166997Z INFO 02-27 23:18:32 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T23:18:32.4587110Z WARNING 02-27 23:18:32 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T23:18:32.4809592Z WARNING 02-27 23:18:32 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T23:18:32.4845674Z (Worker_DP0_TP6_EP6 pid=1599) INFO 02-27 23:18:32 [layer.py:481] [EP Rank 6/16] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 16/256. Experts local to global index map: 0->96, 1->97, 2->98, 3->99, 4->100, 5->101, 6->102, 7->103, 8->104, 9->105, 10->106, 11->107, 12->108, 13->109, 14->110, 15->111.
2026-02-27T23:18:32.4846937Z (Worker_DP0_TP7_EP7 pid=1703) INFO 02-27 23:18:32 [model_runner_v1.py:2352] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-27T23:18:32.5003173Z (Worker_DP1_TP2_EP10 pid=1180) INFO 02-27 23:18:32 [layer.py:481] [EP Rank 10/16] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 16/256. Experts local to global index map: 0->160, 1->161, 2->162, 3->163, 4->164, 5->165, 6->166, 7->167, 8->168, 9->169, 10->170, 11->171, 12->172, 13->173, 14->174, 15->175.
2026-02-27T23:18:32.5741559Z INFO 02-27 23:18:32 [cpu_binding.py:297] The CPU allocation plan is as follows:
2026-02-27T23:18:32.5742542Z INFO 02-27 23:18:32 [cpu_binding.py:302] NPU3: main=[122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157]  acl=[158]  release=[[159]]
2026-02-27T23:18:32.6233593Z INFO 02-27 23:18:32 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T23:18:32.6249200Z INFO 02-27 23:18:32 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T23:18:32.6563407Z WARNING 02-27 23:18:32 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T23:18:32.6763435Z WARNING 02-27 23:18:32 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T23:18:32.6792488Z (Worker_DP0_TP3_EP3 pid=1287) INFO 02-27 23:18:32 [model_runner_v1.py:2352] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-27T23:18:32.7619305Z (Worker_DP1_TP0_EP8 pid=1041) [2026-02-27 23:18:32] INFO modelslim_config.py:296: Using the vLLM Ascend modelslim Quantization now!
2026-02-27T23:18:32.8096653Z INFO 02-27 23:18:32 [cpu_binding.py:297] The CPU allocation plan is as follows:
2026-02-27T23:18:32.8097324Z INFO 02-27 23:18:32 [cpu_binding.py:302] NPU4: main=[162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197]  acl=[198]  release=[[199]]
2026-02-27T23:18:32.8712600Z INFO 02-27 23:18:32 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T23:18:32.8736081Z INFO 02-27 23:18:32 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T23:18:32.9158528Z WARNING 02-27 23:18:32 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T23:18:32.9277600Z (Worker_DP1_TP0_EP8 pid=1041) INFO 02-27 23:18:32 [layer.py:481] [EP Rank 8/16] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 16/256. Experts local to global index map: 0->128, 1->129, 2->130, 3->131, 4->132, 5->133, 6->134, 7->135, 8->136, 9->137, 10->138, 11->139, 12->140, 13->141, 14->142, 15->143.
2026-02-27T23:18:32.9375041Z WARNING 02-27 23:18:32 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T23:18:32.9413284Z (Worker_DP0_TP4_EP4 pid=1391) INFO 02-27 23:18:32 [model_runner_v1.py:2352] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-27T23:18:32.9895196Z (Worker_DP0_TP3_EP3 pid=1287) [2026-02-27 23:18:32] INFO modelslim_config.py:296: Using the vLLM Ascend modelslim Quantization now!
2026-02-27T23:18:33.0930566Z (Worker_DP0_TP3_EP3 pid=1287) INFO 02-27 23:18:33 [layer.py:481] [EP Rank 3/16] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 16/256. Experts local to global index map: 0->48, 1->49, 2->50, 3->51, 4->52, 5->53, 6->54, 7->55, 8->56, 9->57, 10->58, 11->59, 12->60, 13->61, 14->62, 15->63.
2026-02-27T23:18:33.1519748Z (Worker_DP0_TP7_EP7 pid=1703) [2026-02-27 23:18:33] INFO modelslim_config.py:296: Using the vLLM Ascend modelslim Quantization now!
2026-02-27T23:18:33.2642652Z (Worker_DP0_TP7_EP7 pid=1703) INFO 02-27 23:18:33 [layer.py:481] [EP Rank 7/16] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 16/256. Experts local to global index map: 0->112, 1->113, 2->114, 3->115, 4->116, 5->117, 6->118, 7->119, 8->120, 9->121, 10->122, 11->123, 12->124, 13->125, 14->126, 15->127.
2026-02-27T23:18:33.4761459Z INFO 02-27 23:18:33 [cpu_binding.py:297] The CPU allocation plan is as follows:
2026-02-27T23:18:33.4762439Z INFO 02-27 23:18:33 [cpu_binding.py:302] NPU15: main=[282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317]  acl=[318]  release=[[319]]
2026-02-27T23:18:33.4929209Z INFO 02-27 23:18:33 [cpu_binding.py:297] The CPU allocation plan is as follows:
2026-02-27T23:18:33.4930004Z INFO 02-27 23:18:33 [cpu_binding.py:302] NPU11: main=[122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157]  acl=[158]  release=[[159]]
2026-02-27T23:18:33.5304670Z (Worker_DP0_TP4_EP4 pid=1391) [2026-02-27 23:18:33] INFO modelslim_config.py:296: Using the vLLM Ascend modelslim Quantization now!
2026-02-27T23:18:33.5305195Z INFO 02-27 23:18:33 [cpu_binding.py:297] The CPU allocation plan is as follows:
2026-02-27T23:18:33.5305885Z INFO 02-27 23:18:33 [cpu_binding.py:302] NPU9: main=[42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77]  acl=[78]  release=[[79]]
2026-02-27T23:18:33.5426322Z INFO 02-27 23:18:33 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T23:18:33.5451179Z INFO 02-27 23:18:33 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T23:18:33.5584213Z INFO 02-27 23:18:33 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T23:18:33.5610048Z INFO 02-27 23:18:33 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T23:18:33.5916374Z INFO 02-27 23:18:33 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T23:18:33.5938558Z INFO 02-27 23:18:33 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T23:18:33.5974803Z WARNING 02-27 23:18:33 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T23:18:33.5988436Z WARNING 02-27 23:18:33 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T23:18:33.6183968Z WARNING 02-27 23:18:33 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T23:18:33.6199100Z WARNING 02-27 23:18:33 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T23:18:33.6215189Z (Worker_DP1_TP3_EP11 pid=1284) INFO 02-27 23:18:33 [model_runner_v1.py:2352] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-27T23:18:33.6241813Z (Worker_DP1_TP7_EP15 pid=1700) INFO 02-27 23:18:33 [model_runner_v1.py:2352] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-27T23:18:33.6342619Z WARNING 02-27 23:18:33 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T23:18:33.6511296Z (Worker_DP0_TP4_EP4 pid=1391) INFO 02-27 23:18:33 [layer.py:481] [EP Rank 4/16] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 16/256. Experts local to global index map: 0->64, 1->65, 2->66, 3->67, 4->68, 5->69, 6->70, 7->71, 8->72, 9->73, 10->74, 11->75, 12->76, 13->77, 14->78, 15->79.
2026-02-27T23:18:33.6561581Z WARNING 02-27 23:18:33 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T23:18:33.6600481Z (Worker_DP1_TP1_EP9 pid=1074) INFO 02-27 23:18:33 [model_runner_v1.py:2352] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-27T23:18:33.9327591Z (Worker_DP1_TP3_EP11 pid=1284) [2026-02-27 23:18:33] INFO modelslim_config.py:296: Using the vLLM Ascend modelslim Quantization now!
2026-02-27T23:18:34.0384101Z (Worker_DP1_TP3_EP11 pid=1284) INFO 02-27 23:18:34 [layer.py:481] [EP Rank 11/16] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 16/256. Experts local to global index map: 0->176, 1->177, 2->178, 3->179, 4->180, 5->181, 6->182, 7->183, 8->184, 9->185, 10->186, 11->187, 12->188, 13->189, 14->190, 15->191.
2026-02-27T23:18:34.1958743Z INFO 02-27 23:18:34 [cpu_binding.py:297] The CPU allocation plan is as follows:
2026-02-27T23:18:34.1959318Z INFO 02-27 23:18:34 [cpu_binding.py:302] NPU0: main=[2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37]  acl=[38]  release=[[39]]
2026-02-27T23:18:34.2528987Z INFO 02-27 23:18:34 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T23:18:34.2647728Z INFO 02-27 23:18:34 [cpu_binding.py:297] The CPU allocation plan is as follows:
2026-02-27T23:18:34.2648385Z INFO 02-27 23:18:34 [cpu_binding.py:302] NPU12: main=[162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197]  acl=[198]  release=[[199]]
2026-02-27T23:18:34.2984407Z WARNING 02-27 23:18:34 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T23:18:34.3201426Z INFO 02-27 23:18:34 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T23:18:34.3207814Z WARNING 02-27 23:18:34 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T23:18:34.3211852Z (Worker_DP1_TP7_EP15 pid=1700) [2026-02-27 23:18:34] INFO modelslim_config.py:296: Using the vLLM Ascend modelslim Quantization now!
2026-02-27T23:18:34.3218185Z INFO 02-27 23:18:34 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T23:18:34.3255049Z (Worker_DP0_TP0_EP0 pid=1040) INFO 02-27 23:18:34 [model_runner_v1.py:2352] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-27T23:18:34.3524453Z (Worker_DP1_TP1_EP9 pid=1074) [2026-02-27 23:18:34] INFO modelslim_config.py:296: Using the vLLM Ascend modelslim Quantization now!
2026-02-27T23:18:34.3606478Z WARNING 02-27 23:18:34 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T23:18:34.3837005Z WARNING 02-27 23:18:34 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T23:18:34.3875367Z (Worker_DP1_TP4_EP12 pid=1388) INFO 02-27 23:18:34 [model_runner_v1.py:2352] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-27T23:18:34.4358790Z (Worker_DP1_TP7_EP15 pid=1700) INFO 02-27 23:18:34 [layer.py:481] [EP Rank 15/16] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 16/256. Experts local to global index map: 0->240, 1->241, 2->242, 3->243, 4->244, 5->245, 6->246, 7->247, 8->248, 9->249, 10->250, 11->251, 12->252, 13->253, 14->254, 15->255.
2026-02-27T23:18:34.4655809Z (Worker_DP1_TP1_EP9 pid=1074) INFO 02-27 23:18:34 [layer.py:481] [EP Rank 9/16] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 16/256. Experts local to global index map: 0->144, 1->145, 2->146, 3->147, 4->148, 5->149, 6->150, 7->151, 8->152, 9->153, 10->154, 11->155, 12->156, 13->157, 14->158, 15->159.
2026-02-27T23:18:34.7893133Z INFO 02-27 23:18:34 [cpu_binding.py:297] The CPU allocation plan is as follows:
2026-02-27T23:18:34.7893843Z INFO 02-27 23:18:34 [cpu_binding.py:302] NPU1: main=[42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77]  acl=[78]  release=[[79]]
2026-02-27T23:18:34.8466815Z INFO 02-27 23:18:34 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T23:18:34.8487854Z INFO 02-27 23:18:34 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T23:18:34.8944095Z INFO 02-27 23:18:34 [cpu_binding.py:297] The CPU allocation plan is as follows:
2026-02-27T23:18:34.8944817Z INFO 02-27 23:18:34 [cpu_binding.py:302] NPU13: main=[202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237]  acl=[238]  release=[[239]]
2026-02-27T23:18:34.8988110Z INFO 02-27 23:18:34 [cpu_binding.py:297] The CPU allocation plan is as follows:
2026-02-27T23:18:34.9081612Z INFO 02-27 23:18:34 [cpu_binding.py:302] NPU5: main=[202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237]  acl=[238]  release=[[239]]
2026-02-27T23:18:34.9082524Z WARNING 02-27 23:18:34 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T23:18:34.9309713Z WARNING 02-27 23:18:34 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T23:18:34.9349226Z (Worker_DP0_TP1_EP1 pid=1077) INFO 02-27 23:18:34 [model_runner_v1.py:2352] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-27T23:18:34.9540397Z INFO 02-27 23:18:34 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T23:18:34.9560638Z INFO 02-27 23:18:34 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T23:18:34.9633827Z INFO 02-27 23:18:34 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T23:18:34.9647480Z INFO 02-27 23:18:34 [cpu_binding.py:306] The 'migratepages' command is not available, skipping memory binding.
2026-02-27T23:18:34.9999291Z WARNING 02-27 23:18:34 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T23:18:35.0003213Z WARNING 02-27 23:18:34 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T23:18:35.0177118Z WARNING 02-27 23:18:35 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T23:18:35.0215881Z (Worker_DP1_TP5_EP13 pid=1492) INFO 02-27 23:18:35 [model_runner_v1.py:2352] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-27T23:18:35.0236877Z WARNING 02-27 23:18:35 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-27T23:18:35.0254825Z (Worker_DP1_TP4_EP12 pid=1388) [2026-02-27 23:18:35] INFO modelslim_config.py:296: Using the vLLM Ascend modelslim Quantization now!
2026-02-27T23:18:35.0274664Z (Worker_DP0_TP5_EP5 pid=1495) INFO 02-27 23:18:35 [model_runner_v1.py:2352] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-27T23:18:35.1371573Z (Worker_DP0_TP0_EP0 pid=1040) [2026-02-27 23:18:35] INFO modelslim_config.py:296: Using the vLLM Ascend modelslim Quantization now!
2026-02-27T23:18:35.1378655Z (Worker_DP1_TP4_EP12 pid=1388) INFO 02-27 23:18:35 [layer.py:481] [EP Rank 12/16] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 16/256. Experts local to global index map: 0->192, 1->193, 2->194, 3->195, 4->196, 5->197, 6->198, 7->199, 8->200, 9->201, 10->202, 11->203, 12->204, 13->205, 14->206, 15->207.
2026-02-27T23:18:35.3041635Z (Worker_DP0_TP0_EP0 pid=1040) INFO 02-27 23:18:35 [layer.py:481] [EP Rank 0/16] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 16/256. Experts local to global index map: 0->0, 1->1, 2->2, 3->3, 4->4, 5->5, 6->6, 7->7, 8->8, 9->9, 10->10, 11->11, 12->12, 13->13, 14->14, 15->15.
2026-02-27T23:18:35.6464242Z (Worker_DP0_TP1_EP1 pid=1077) [2026-02-27 23:18:35] INFO modelslim_config.py:296: Using the vLLM Ascend modelslim Quantization now!
2026-02-27T23:18:35.7520094Z (Worker_DP0_TP5_EP5 pid=1495) [2026-02-27 23:18:35] INFO modelslim_config.py:296: Using the vLLM Ascend modelslim Quantization now!
2026-02-27T23:18:35.7582428Z (Worker_DP0_TP1_EP1 pid=1077) INFO 02-27 23:18:35 [layer.py:481] [EP Rank 1/16] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 16/256. Experts local to global index map: 0->16, 1->17, 2->18, 3->19, 4->20, 5->21, 6->22, 7->23, 8->24, 9->25, 10->26, 11->27, 12->28, 13->29, 14->30, 15->31.
2026-02-27T23:18:35.7592266Z (Worker_DP1_TP5_EP13 pid=1492) [2026-02-27 23:18:35] INFO modelslim_config.py:296: Using the vLLM Ascend modelslim Quantization now!
2026-02-27T23:18:35.8699692Z (Worker_DP1_TP5_EP13 pid=1492) INFO 02-27 23:18:35 [layer.py:481] [EP Rank 13/16] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 16/256. Experts local to global index map: 0->208, 1->209, 2->210, 3->211, 4->212, 5->213, 6->214, 7->215, 8->216, 9->217, 10->218, 11->219, 12->220, 13->221, 14->222, 15->223.
2026-02-27T23:18:35.8761171Z (Worker_DP0_TP5_EP5 pid=1495) INFO 02-27 23:18:35 [layer.py:481] [EP Rank 5/16] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 16/256. Experts local to global index map: 0->80, 1->81, 2->82, 3->83, 4->84, 5->85, 6->86, 7->87, 8->88, 9->89, 10->90, 11->91, 12->92, 13->93, 14->94, 15->95.
2026-02-27T23:18:36.4008570Z (Worker_DP1_TP4_EP12 pid=1388) /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-02-27T23:18:36.4009919Z (Worker_DP1_TP4_EP12 pid=1388)   return func(*args, **kwargs)
2026-02-27T23:18:36.4036004Z (Worker_DP1_TP1_EP9 pid=1074) /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-02-27T23:18:36.4037180Z (Worker_DP1_TP1_EP9 pid=1074)   return func(*args, **kwargs)
2026-02-27T23:18:36.4051088Z (Worker_DP1_TP0_EP8 pid=1041) /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-02-27T23:18:36.4052289Z (Worker_DP1_TP0_EP8 pid=1041)   return func(*args, **kwargs)
2026-02-27T23:18:36.4121572Z (Worker_DP0_TP4_EP4 pid=1391) /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-02-27T23:18:36.4122685Z (Worker_DP0_TP4_EP4 pid=1391)   return func(*args, **kwargs)
2026-02-27T23:18:36.4295980Z (Worker_DP0_TP1_EP1 pid=1077) /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-02-27T23:18:36.4297202Z (Worker_DP0_TP1_EP1 pid=1077)   return func(*args, **kwargs)
2026-02-27T23:18:36.4398422Z (Worker_DP0_TP0_EP0 pid=1040) /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-02-27T23:18:36.4399451Z (Worker_DP0_TP0_EP0 pid=1040)   return func(*args, **kwargs)
2026-02-27T23:18:36.4475631Z (Worker_DP1_TP7_EP15 pid=1700) /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-02-27T23:18:36.4476855Z (Worker_DP1_TP7_EP15 pid=1700)   return func(*args, **kwargs)
2026-02-27T23:18:36.4486174Z (Worker_DP0_TP7_EP7 pid=1703) /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-02-27T23:18:36.4487244Z (Worker_DP0_TP7_EP7 pid=1703)   return func(*args, **kwargs)
2026-02-27T23:18:36.4500809Z (Worker_DP0_TP6_EP6 pid=1599) /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-02-27T23:18:36.4501887Z (Worker_DP0_TP6_EP6 pid=1599)   return func(*args, **kwargs)
2026-02-27T23:18:36.4528046Z (Worker_DP1_TP6_EP14 pid=1596) /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-02-27T23:18:36.4529167Z (Worker_DP1_TP6_EP14 pid=1596)   return func(*args, **kwargs)
2026-02-27T23:18:36.4674430Z (Worker_DP1_TP0_EP8 pid=1041) INFO 02-27 23:18:36 [fused_moe.py:293] [EP Rank 8/16] Expert parallelism is enabled. Local/global number of experts: 16/256. Experts local to global index map: 0->128, 1->129, 2->130, 3->131, 4->132, 5->133, 6->134, 7->135, 8->136, 9->137, 10->138, 11->139, 12->140, 13->141, 14->142, 15->143.
2026-02-27T23:18:36.4676026Z (Worker_DP1_TP2_EP10 pid=1180) /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-02-27T23:18:36.4677190Z (Worker_DP1_TP2_EP10 pid=1180)   return func(*args, **kwargs)
2026-02-27T23:18:36.4683908Z (Worker_DP0_TP2_EP2 pid=1183) /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-02-27T23:18:36.4685006Z (Worker_DP0_TP2_EP2 pid=1183)   return func(*args, **kwargs)
2026-02-27T23:18:36.4700572Z (Worker_DP1_TP3_EP11 pid=1284) /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-02-27T23:18:36.4702231Z (Worker_DP1_TP1_EP9 pid=1074) INFO 02-27 23:18:36 [fused_moe.py:293] [EP Rank 9/16] Expert parallelism is enabled. Local/global number of experts: 16/256. Experts local to global index map: 0->144, 1->145, 2->146, 3->147, 4->148, 5->149, 6->150, 7->151, 8->152, 9->153, 10->154, 11->155, 12->156, 13->157, 14->158, 15->159.
2026-02-27T23:18:36.4703091Z (Worker_DP1_TP3_EP11 pid=1284)   return func(*args, **kwargs)
2026-02-27T23:18:36.4704162Z (Worker_DP0_TP3_EP3 pid=1287) /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-02-27T23:18:36.4705265Z (Worker_DP0_TP3_EP3 pid=1287)   return func(*args, **kwargs)
2026-02-27T23:18:36.4753402Z (Worker_DP0_TP4_EP4 pid=1391) INFO 02-27 23:18:36 [fused_moe.py:293] [EP Rank 4/16] Expert parallelism is enabled. Local/global number of experts: 16/256. Experts local to global index map: 0->64, 1->65, 2->66, 3->67, 4->68, 5->69, 6->70, 7->71, 8->72, 9->73, 10->74, 11->75, 12->76, 13->77, 14->78, 15->79.
2026-02-27T23:18:36.4890958Z (Worker_DP0_TP1_EP1 pid=1077) INFO 02-27 23:18:36 [fused_moe.py:293] [EP Rank 1/16] Expert parallelism is enabled. Local/global number of experts: 16/256. Experts local to global index map: 0->16, 1->17, 2->18, 3->19, 4->20, 5->21, 6->22, 7->23, 8->24, 9->25, 10->26, 11->27, 12->28, 13->29, 14->30, 15->31.
2026-02-27T23:18:36.5068201Z (Worker_DP0_TP7_EP7 pid=1703) INFO 02-27 23:18:36 [fused_moe.py:293] [EP Rank 7/16] Expert parallelism is enabled. Local/global number of experts: 16/256. Experts local to global index map: 0->112, 1->113, 2->114, 3->115, 4->116, 5->117, 6->118, 7->119, 8->120, 9->121, 10->122, 11->123, 12->124, 13->125, 14->126, 15->127.
2026-02-27T23:18:36.5079625Z (Worker_DP1_TP4_EP12 pid=1388) INFO 02-27 23:18:36 [fused_moe.py:293] [EP Rank 12/16] Expert parallelism is enabled. Local/global number of experts: 16/256. Experts local to global index map: 0->192, 1->193, 2->194, 3->195, 4->196, 5->197, 6->198, 7->199, 8->200, 9->201, 10->202, 11->203, 12->204, 13->205, 14->206, 15->207.
2026-02-27T23:18:36.5096424Z (Worker_DP1_TP5_EP13 pid=1492) /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-02-27T23:18:36.5097607Z (Worker_DP1_TP5_EP13 pid=1492)   return func(*args, **kwargs)
2026-02-27T23:18:36.5098593Z (Worker_DP1_TP7_EP15 pid=1700) INFO 02-27 23:18:36 [fused_moe.py:293] [EP Rank 15/16] Expert parallelism is enabled. Local/global number of experts: 16/256. Experts local to global index map: 0->240, 1->241, 2->242, 3->243, 4->244, 5->245, 6->246, 7->247, 8->248, 9->249, 10->250, 11->251, 12->252, 13->253, 14->254, 15->255.
2026-02-27T23:18:36.5240196Z (Worker_DP0_TP2_EP2 pid=1183) INFO 02-27 23:18:36 [fused_moe.py:293] [EP Rank 2/16] Expert parallelism is enabled. Local/global number of experts: 16/256. Experts local to global index map: 0->32, 1->33, 2->34, 3->35, 4->36, 5->37, 6->38, 7->39, 8->40, 9->41, 10->42, 11->43, 12->44, 13->45, 14->46, 15->47.
2026-02-27T23:18:36.5265531Z (Worker_DP0_TP3_EP3 pid=1287) INFO 02-27 23:18:36 [fused_moe.py:293] [EP Rank 3/16] Expert parallelism is enabled. Local/global number of experts: 16/256. Experts local to global index map: 0->48, 1->49, 2->50, 3->51, 4->52, 5->53, 6->54, 7->55, 8->56, 9->57, 10->58, 11->59, 12->60, 13->61, 14->62, 15->63.
2026-02-27T23:18:36.5288554Z (Worker_DP1_TP2_EP10 pid=1180) INFO 02-27 23:18:36 [fused_moe.py:293] [EP Rank 10/16] Expert parallelism is enabled. Local/global number of experts: 16/256. Experts local to global index map: 0->160, 1->161, 2->162, 3->163, 4->164, 5->165, 6->166, 7->167, 8->168, 9->169, 10->170, 11->171, 12->172, 13->173, 14->174, 15->175.
2026-02-27T23:18:36.5322346Z (Worker_DP1_TP3_EP11 pid=1284) INFO 02-27 23:18:36 [fused_moe.py:293] [EP Rank 11/16] Expert parallelism is enabled. Local/global number of experts: 16/256. Experts local to global index map: 0->176, 1->177, 2->178, 3->179, 4->180, 5->181, 6->182, 7->183, 8->184, 9->185, 10->186, 11->187, 12->188, 13->189, 14->190, 15->191.
2026-02-27T23:18:36.5427319Z (Worker_DP0_TP0_EP0 pid=1040) INFO 02-27 23:18:36 [fused_moe.py:293] [EP Rank 0/16] Expert parallelism is enabled. Local/global number of experts: 16/256. Experts local to global index map: 0->0, 1->1, 2->2, 3->3, 4->4, 5->5, 6->6, 7->7, 8->8, 9->9, 10->10, 11->11, 12->12, 13->13, 14->14, 15->15.
2026-02-27T23:18:36.5644967Z (Worker_DP0_TP6_EP6 pid=1599) INFO 02-27 23:18:36 [fused_moe.py:293] [EP Rank 6/16] Expert parallelism is enabled. Local/global number of experts: 16/256. Experts local to global index map: 0->96, 1->97, 2->98, 3->99, 4->100, 5->101, 6->102, 7->103, 8->104, 9->105, 10->106, 11->107, 12->108, 13->109, 14->110, 15->111.
2026-02-27T23:18:36.5747709Z (Worker_DP1_TP6_EP14 pid=1596) INFO 02-27 23:18:36 [fused_moe.py:293] [EP Rank 14/16] Expert parallelism is enabled. Local/global number of experts: 16/256. Experts local to global index map: 0->224, 1->225, 2->226, 3->227, 4->228, 5->229, 6->230, 7->231, 8->232, 9->233, 10->234, 11->235, 12->236, 13->237, 14->238, 15->239.
2026-02-27T23:18:36.5794286Z (Worker_DP1_TP5_EP13 pid=1492) INFO 02-27 23:18:36 [fused_moe.py:293] [EP Rank 13/16] Expert parallelism is enabled. Local/global number of experts: 16/256. Experts local to global index map: 0->208, 1->209, 2->210, 3->211, 4->212, 5->213, 6->214, 7->215, 8->216, 9->217, 10->218, 11->219, 12->220, 13->221, 14->222, 15->223.
2026-02-27T23:18:36.6024026Z (Worker_DP0_TP5_EP5 pid=1495) /usr/local/python3.11.14/lib/python3.11/site-packages/torch/utils/_device.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
2026-02-27T23:18:36.6025198Z (Worker_DP0_TP5_EP5 pid=1495)   return func(*args, **kwargs)
2026-02-27T23:18:36.6560638Z (Worker_DP0_TP5_EP5 pid=1495) INFO 02-27 23:18:36 [fused_moe.py:293] [EP Rank 5/16] Expert parallelism is enabled. Local/global number of experts: 16/256. Experts local to global index map: 0->80, 1->81, 2->82, 3->83, 4->84, 5->85, 6->86, 7->87, 8->88, 9->89, 10->90, 11->91, 12->92, 13->93, 14->94, 15->95.
2026-02-27T23:18:36.8166822Z (Worker_DP0_TP0_EP0 pid=1040) INFO 02-27 23:18:36 [fused_moe.py:532] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-02-27T23:18:36.8403088Z (Worker_DP1_TP4_EP12 pid=1388) INFO 02-27 23:18:36 [fused_moe.py:532] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-02-27T23:18:36.8404137Z (Worker_DP0_TP4_EP4 pid=1391) INFO 02-27 23:18:36 [fused_moe.py:532] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-02-27T23:18:36.8405250Z (Worker_DP0_TP7_EP7 pid=1703) INFO 02-27 23:18:36 [fused_moe.py:532] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-02-27T23:18:36.8406146Z (Worker_DP1_TP7_EP15 pid=1700) INFO 02-27 23:18:36 [fused_moe.py:532] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-02-27T23:18:36.8407032Z (Worker_DP1_TP0_EP8 pid=1041) INFO 02-27 23:18:36 [fused_moe.py:532] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-02-27T23:18:36.8407772Z (Worker_DP1_TP1_EP9 pid=1074) INFO 02-27 23:18:36 [fused_moe.py:532] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-02-27T23:18:36.8776164Z (Worker_DP1_TP3_EP11 pid=1284) INFO 02-27 23:18:36 [fused_moe.py:532] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-02-27T23:18:36.8777008Z (Worker_DP1_TP2_EP10 pid=1180) INFO 02-27 23:18:36 [fused_moe.py:532] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-02-27T23:18:36.8781083Z (Worker_DP0_TP3_EP3 pid=1287) INFO 02-27 23:18:36 [fused_moe.py:532] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-02-27T23:18:36.8781863Z (Worker_DP0_TP2_EP2 pid=1183) INFO 02-27 23:18:36 [fused_moe.py:532] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-02-27T23:18:36.8817102Z (Worker_DP0_TP1_EP1 pid=1077) INFO 02-27 23:18:36 [fused_moe.py:532] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-02-27T23:18:36.9055942Z (Worker_DP1_TP6_EP14 pid=1596) INFO 02-27 23:18:36 [fused_moe.py:532] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-02-27T23:18:36.9100815Z (Worker_DP0_TP6_EP6 pid=1599) INFO 02-27 23:18:36 [fused_moe.py:532] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-02-27T23:18:36.9144533Z (Worker_DP1_TP5_EP13 pid=1492) INFO 02-27 23:18:36 [fused_moe.py:532] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-02-27T23:18:36.9831535Z (Worker_DP0_TP5_EP5 pid=1495) INFO 02-27 23:18:36 [fused_moe.py:532] Sequence parallelism is enabled, shared experts are replicated for best performance.
2026-02-27T23:18:41.9850234Z (Worker_DP0_TP0_EP0 pid=1040) INFO 02-27 23:18:41 [compilation.py:903] Using OOT custom backend for compilation.
2026-02-27T23:18:41.9867725Z (Worker_DP0_TP7_EP7 pid=1703) INFO 02-27 23:18:41 [compilation.py:903] Using OOT custom backend for compilation.
2026-02-27T23:18:42.0251540Z (Worker_DP1_TP0_EP8 pid=1041) INFO 02-27 23:18:42 [compilation.py:903] Using OOT custom backend for compilation.
2026-02-27T23:18:42.0662878Z (Worker_DP0_TP4_EP4 pid=1391) INFO 02-27 23:18:42 [compilation.py:903] Using OOT custom backend for compilation.
2026-02-27T23:18:42.0811691Z (Worker_DP1_TP1_EP9 pid=1074) INFO 02-27 23:18:42 [compilation.py:903] Using OOT custom backend for compilation.
2026-02-27T23:18:42.1906294Z (Worker_DP0_TP1_EP1 pid=1077) INFO 02-27 23:18:42 [compilation.py:903] Using OOT custom backend for compilation.
2026-02-27T23:18:42.1913902Z (Worker_DP0_TP6_EP6 pid=1599) INFO 02-27 23:18:42 [compilation.py:903] Using OOT custom backend for compilation.
2026-02-27T23:18:42.1975429Z (Worker_DP1_TP7_EP15 pid=1700) INFO 02-27 23:18:42 [compilation.py:903] Using OOT custom backend for compilation.
2026-02-27T23:18:42.1998900Z (Worker_DP1_TP6_EP14 pid=1596) INFO 02-27 23:18:42 [compilation.py:903] Using OOT custom backend for compilation.
2026-02-27T23:18:42.2189080Z (Worker_DP0_TP3_EP3 pid=1287) INFO 02-27 23:18:42 [compilation.py:903] Using OOT custom backend for compilation.
2026-02-27T23:18:42.2756709Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:18:42.2757112Z Loading safetensors checkpoint shards:   0% Completed | 0/163 [00:00<?, ?it/s]
2026-02-27T23:18:42.3375152Z (Worker_DP0_TP5_EP5 pid=1495) INFO 02-27 23:18:42 [compilation.py:903] Using OOT custom backend for compilation.
2026-02-27T23:18:42.3706521Z (Worker_DP1_TP4_EP12 pid=1388) INFO 02-27 23:18:42 [compilation.py:903] Using OOT custom backend for compilation.
2026-02-27T23:18:42.3725657Z (Worker_DP1_TP5_EP13 pid=1492) INFO 02-27 23:18:42 [compilation.py:903] Using OOT custom backend for compilation.
2026-02-27T23:18:42.4365260Z (Worker_DP1_TP3_EP11 pid=1284) INFO 02-27 23:18:42 [compilation.py:903] Using OOT custom backend for compilation.
2026-02-27T23:18:42.4371703Z (Worker_DP0_TP2_EP2 pid=1183) INFO 02-27 23:18:42 [compilation.py:903] Using OOT custom backend for compilation.
2026-02-27T23:18:42.4372436Z (Worker_DP1_TP2_EP10 pid=1180) INFO 02-27 23:18:42 [compilation.py:903] Using OOT custom backend for compilation.
2026-02-27T23:18:48.4166146Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:18:48.4166728Z Loading safetensors checkpoint shards:   1% Completed | 1/163 [00:06<16:34,  6.14s/it]
2026-02-27T23:18:49.7675367Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:18:49.7675862Z Loading safetensors checkpoint shards:   1% Completed | 2/163 [00:07<08:55,  3.32s/it]
2026-02-27T23:18:51.5368673Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:18:51.5369136Z Loading safetensors checkpoint shards:   2% Completed | 3/163 [00:09<06:58,  2.61s/it]
2026-02-27T23:18:55.6168859Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:18:55.6169315Z Loading safetensors checkpoint shards:   2% Completed | 4/163 [00:13<08:27,  3.19s/it]
2026-02-27T23:18:57.1776575Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:18:57.1777253Z Loading safetensors checkpoint shards:   3% Completed | 5/163 [00:14<06:51,  2.60s/it]
2026-02-27T23:19:00.8027108Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:19:00.8027541Z Loading safetensors checkpoint shards:   4% Completed | 6/163 [00:18<07:43,  2.95s/it]
2026-02-27T23:19:02.4107187Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:19:02.4107776Z Loading safetensors checkpoint shards:   4% Completed | 7/163 [00:20<06:31,  2.51s/it]
2026-02-27T23:19:04.3007175Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:19:04.3007652Z Loading safetensors checkpoint shards:   5% Completed | 8/163 [00:22<05:58,  2.31s/it]
2026-02-27T23:19:08.2202875Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:19:08.2203281Z Loading safetensors checkpoint shards:   6% Completed | 9/163 [00:25<07:13,  2.82s/it]
2026-02-27T23:19:09.6930555Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:19:09.6931026Z Loading safetensors checkpoint shards:   6% Completed | 10/163 [00:27<06:07,  2.40s/it]
2026-02-27T23:19:11.5679490Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:19:11.5680010Z Loading safetensors checkpoint shards:   7% Completed | 11/163 [00:29<05:40,  2.24s/it]
2026-02-27T23:19:15.4846277Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:19:15.4846923Z Loading safetensors checkpoint shards:   7% Completed | 12/163 [00:33<06:55,  2.75s/it]
2026-02-27T23:19:17.0051218Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:19:17.0051741Z Loading safetensors checkpoint shards:   8% Completed | 13/163 [00:34<05:56,  2.38s/it]
2026-02-27T23:19:20.2830135Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:19:20.2830756Z Loading safetensors checkpoint shards:   9% Completed | 14/163 [00:38<06:34,  2.65s/it]
2026-02-27T23:19:25.5348298Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:19:25.5348797Z Loading safetensors checkpoint shards:   9% Completed | 15/163 [00:43<08:28,  3.43s/it]
2026-02-27T23:19:25.7192487Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:19:25.7192949Z Loading safetensors checkpoint shards:  10% Completed | 16/163 [00:43<06:01,  2.46s/it]
2026-02-27T23:19:35.8398287Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:19:35.8398719Z Loading safetensors checkpoint shards:  10% Completed | 17/163 [00:53<11:35,  4.76s/it]
2026-02-27T23:19:36.0382351Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:19:36.0383022Z Loading safetensors checkpoint shards:  11% Completed | 18/163 [00:53<08:11,  3.39s/it]
2026-02-27T23:19:36.8922870Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:19:36.8923613Z Loading safetensors checkpoint shards:  12% Completed | 19/163 [00:54<06:18,  2.63s/it]
2026-02-27T23:19:45.9572205Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:19:45.9572693Z Loading safetensors checkpoint shards:  12% Completed | 20/163 [01:03<10:52,  4.56s/it]
2026-02-27T23:19:46.1597982Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:19:46.1598427Z Loading safetensors checkpoint shards:  13% Completed | 21/163 [01:03<07:41,  3.25s/it]
2026-02-27T23:19:48.2721264Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:19:48.2721716Z Loading safetensors checkpoint shards:  13% Completed | 22/163 [01:05<06:50,  2.91s/it]
2026-02-27T23:19:58.1998882Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:19:58.1999410Z Loading safetensors checkpoint shards:  14% Completed | 23/163 [01:15<11:42,  5.02s/it]
2026-02-27T23:20:00.2585694Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:20:00.2586261Z Loading safetensors checkpoint shards:  15% Completed | 24/163 [01:17<09:33,  4.13s/it]
2026-02-27T23:20:10.2989267Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:20:10.2989825Z Loading safetensors checkpoint shards:  15% Completed | 25/163 [01:28<13:34,  5.90s/it]
2026-02-27T23:20:11.6086535Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:20:11.6086995Z Loading safetensors checkpoint shards:  16% Completed | 26/163 [01:29<10:19,  4.52s/it]
2026-02-27T23:20:11.7695303Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:20:11.7695685Z Loading safetensors checkpoint shards:  17% Completed | 27/163 [01:29<07:17,  3.22s/it]
2026-02-27T23:20:21.1158754Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:20:21.1159301Z Loading safetensors checkpoint shards:  17% Completed | 28/163 [01:38<11:22,  5.05s/it]
2026-02-27T23:20:22.9893125Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:20:22.9893781Z Loading safetensors checkpoint shards:  18% Completed | 29/163 [01:40<09:09,  4.10s/it]
2026-02-27T23:20:24.9703967Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:20:24.9704537Z Loading safetensors checkpoint shards:  18% Completed | 30/163 [01:42<07:40,  3.46s/it]
2026-02-27T23:20:34.1792390Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:20:34.1792882Z Loading safetensors checkpoint shards:  19% Completed | 31/163 [01:51<11:24,  5.19s/it]
2026-02-27T23:20:35.9891237Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:20:35.9891700Z Loading safetensors checkpoint shards:  20% Completed | 32/163 [01:53<09:06,  4.17s/it]
2026-02-27T23:20:42.5055363Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:20:42.5055843Z Loading safetensors checkpoint shards:  20% Completed | 33/163 [02:00<10:34,  4.88s/it]
2026-02-27T23:20:49.2031344Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:20:49.2031833Z Loading safetensors checkpoint shards:  21% Completed | 34/163 [02:06<11:39,  5.42s/it]
2026-02-27T23:20:49.3850058Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:20:49.3850609Z Loading safetensors checkpoint shards:  21% Completed | 35/163 [02:07<08:12,  3.85s/it]
2026-02-27T23:20:57.7919026Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:20:57.7919449Z Loading safetensors checkpoint shards:  22% Completed | 36/163 [02:15<11:02,  5.22s/it]
2026-02-27T23:20:57.9796541Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:20:57.9797050Z Loading safetensors checkpoint shards:  23% Completed | 37/163 [02:15<07:47,  3.71s/it]
2026-02-27T23:20:59.6165241Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:20:59.6165740Z Loading safetensors checkpoint shards:  23% Completed | 38/163 [02:17<06:25,  3.09s/it]
2026-02-27T23:21:08.9726049Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:21:08.9726662Z Loading safetensors checkpoint shards:  24% Completed | 39/163 [02:26<10:16,  4.97s/it]
2026-02-27T23:21:10.0522848Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:21:10.0523452Z Loading safetensors checkpoint shards:  25% Completed | 40/163 [02:27<07:47,  3.80s/it]
2026-02-27T23:21:12.3079444Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:21:12.3079924Z Loading safetensors checkpoint shards:  25% Completed | 41/163 [02:30<06:47,  3.34s/it]
2026-02-27T23:21:21.0388102Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:21:21.0388560Z Loading safetensors checkpoint shards:  26% Completed | 42/163 [02:38<09:59,  4.96s/it]
2026-02-27T23:21:22.9194931Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:21:22.9195829Z Loading safetensors checkpoint shards:  26% Completed | 43/163 [02:40<08:03,  4.03s/it]
2026-02-27T23:21:32.2243753Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:21:32.2244371Z Loading safetensors checkpoint shards:  27% Completed | 44/163 [02:49<11:08,  5.61s/it]
2026-02-27T23:21:32.4160162Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:21:32.4160618Z Loading safetensors checkpoint shards:  28% Completed | 45/163 [02:50<07:50,  3.99s/it]
2026-02-27T23:21:34.0497295Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:21:34.0497886Z Loading safetensors checkpoint shards:  28% Completed | 46/163 [02:51<06:23,  3.28s/it]
2026-02-27T23:21:44.0076707Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:21:44.0077146Z Loading safetensors checkpoint shards:  29% Completed | 47/163 [03:01<10:12,  5.28s/it]
2026-02-27T23:21:45.6456268Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:21:45.6456724Z Loading safetensors checkpoint shards:  29% Completed | 48/163 [03:03<08:01,  4.19s/it]
2026-02-27T23:21:48.1850372Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:21:48.1850947Z Loading safetensors checkpoint shards:  30% Completed | 49/163 [03:05<07:01,  3.70s/it]
2026-02-27T23:21:58.0197937Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:21:58.0198381Z Loading safetensors checkpoint shards:  31% Completed | 50/163 [03:15<10:25,  5.54s/it]
2026-02-27T23:21:59.9071625Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:21:59.9072428Z Loading safetensors checkpoint shards:  31% Completed | 51/163 [03:17<08:17,  4.44s/it]
2026-02-27T23:22:06.6926643Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:22:06.6927180Z Loading safetensors checkpoint shards:  32% Completed | 52/163 [03:24<09:31,  5.15s/it]
2026-02-27T23:22:09.6293037Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:22:09.6293454Z Loading safetensors checkpoint shards:  33% Completed | 53/163 [03:27<08:13,  4.48s/it]
2026-02-27T23:22:10.8712279Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:22:10.8712847Z Loading safetensors checkpoint shards:  33% Completed | 54/163 [03:28<06:22,  3.51s/it]
2026-02-27T23:22:20.4433979Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:22:20.4434552Z Loading safetensors checkpoint shards:  34% Completed | 55/163 [03:38<09:35,  5.33s/it]
2026-02-27T23:22:21.1980495Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:22:21.1981124Z Loading safetensors checkpoint shards:  34% Completed | 56/163 [03:38<07:03,  3.96s/it]
2026-02-27T23:22:23.3472193Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:22:23.3472764Z Loading safetensors checkpoint shards:  35% Completed | 57/163 [03:41<06:01,  3.41s/it]
2026-02-27T23:22:32.3229126Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:22:32.3229733Z Loading safetensors checkpoint shards:  36% Completed | 58/163 [03:50<08:53,  5.08s/it]
2026-02-27T23:22:33.9507334Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:22:33.9507833Z Loading safetensors checkpoint shards:  36% Completed | 59/163 [03:51<07:00,  4.05s/it]
2026-02-27T23:22:39.2212125Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:22:39.2212660Z Loading safetensors checkpoint shards:  37% Completed | 60/163 [03:56<07:34,  4.41s/it]
2026-02-27T23:22:48.5355908Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:22:48.5356354Z Loading safetensors checkpoint shards:  37% Completed | 61/163 [04:06<10:00,  5.88s/it]
2026-02-27T23:22:48.7179428Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:22:48.7179845Z Loading safetensors checkpoint shards:  38% Completed | 62/163 [04:06<07:01,  4.17s/it]
2026-02-27T23:22:55.8934349Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:22:55.8934920Z Loading safetensors checkpoint shards:  39% Completed | 63/163 [04:13<08:27,  5.07s/it]
2026-02-27T23:22:56.0866310Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:22:56.0866780Z Loading safetensors checkpoint shards:  39% Completed | 64/163 [04:13<05:57,  3.61s/it]
2026-02-27T23:22:57.9647912Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:22:57.9648494Z Loading safetensors checkpoint shards:  40% Completed | 65/163 [04:15<05:02,  3.09s/it]
2026-02-27T23:23:07.8530027Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:23:07.8530983Z Loading safetensors checkpoint shards:  40% Completed | 66/163 [04:25<08:17,  5.13s/it]
2026-02-27T23:23:09.8152087Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:23:09.8152522Z Loading safetensors checkpoint shards:  41% Completed | 67/163 [04:27<06:41,  4.18s/it]
2026-02-27T23:23:12.3488165Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:23:12.3488690Z Loading safetensors checkpoint shards:  42% Completed | 68/163 [04:30<05:50,  3.69s/it]
2026-02-27T23:23:20.7896575Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:23:20.7897154Z Loading safetensors checkpoint shards:  42% Completed | 69/163 [04:38<08:00,  5.11s/it]
2026-02-27T23:23:22.7142733Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:23:22.7143262Z Loading safetensors checkpoint shards:  43% Completed | 70/163 [04:40<06:26,  4.16s/it]
2026-02-27T23:23:31.5287453Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:23:31.5287887Z Loading safetensors checkpoint shards:  44% Completed | 71/163 [04:49<08:30,  5.55s/it]
2026-02-27T23:23:31.7216266Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:23:31.7216889Z Loading safetensors checkpoint shards:  44% Completed | 72/163 [04:49<05:59,  3.95s/it]
2026-02-27T23:23:33.2631449Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:23:33.2631946Z Loading safetensors checkpoint shards:  45% Completed | 73/163 [04:50<04:50,  3.22s/it]
2026-02-27T23:23:43.0285095Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:23:43.0285576Z Loading safetensors checkpoint shards:  45% Completed | 74/163 [05:00<07:41,  5.19s/it]
2026-02-27T23:23:44.2355597Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:23:44.2356045Z Loading safetensors checkpoint shards:  46% Completed | 75/163 [05:01<05:51,  3.99s/it]
2026-02-27T23:23:46.4747002Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:23:46.4747434Z Loading safetensors checkpoint shards:  47% Completed | 76/163 [05:04<05:01,  3.47s/it]
2026-02-27T23:23:56.0041269Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:23:57.6578535Z Loading safetensors checkpoint shards:  47% Completed | 77/163 [05:13<07:34,  5.29s/it]
2026-02-27T23:23:57.6579130Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:23:57.6579475Z Loading safetensors checkpoint shards:  48% Completed | 78/163 [05:15<05:56,  4.20s/it]
2026-02-27T23:24:03.6552178Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:24:03.6552793Z Loading safetensors checkpoint shards:  48% Completed | 79/163 [05:21<06:37,  4.74s/it]
2026-02-27T23:24:08.7394484Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:24:08.7395066Z Loading safetensors checkpoint shards:  49% Completed | 80/163 [05:26<06:41,  4.84s/it]
2026-02-27T23:24:08.9095570Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:24:08.9096054Z Loading safetensors checkpoint shards:  50% Completed | 81/163 [05:26<04:42,  3.44s/it]
2026-02-27T23:24:17.7442400Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:24:17.7442870Z Loading safetensors checkpoint shards:  50% Completed | 82/163 [05:35<06:49,  5.06s/it]
2026-02-27T23:24:19.3673142Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:24:19.3673603Z Loading safetensors checkpoint shards:  51% Completed | 83/163 [05:37<05:22,  4.03s/it]
2026-02-27T23:24:21.6286539Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:24:21.6287129Z Loading safetensors checkpoint shards:  52% Completed | 84/163 [05:39<04:36,  3.50s/it]
2026-02-27T23:24:31.3944921Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:24:31.3945387Z Loading safetensors checkpoint shards:  52% Completed | 85/163 [05:49<06:59,  5.38s/it]
2026-02-27T23:24:31.5931220Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:24:31.5931631Z Loading safetensors checkpoint shards:  53% Completed | 86/163 [05:49<04:54,  3.82s/it]
2026-02-27T23:24:34.1423712Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:24:34.1424132Z Loading safetensors checkpoint shards:  53% Completed | 87/163 [05:51<04:21,  3.44s/it]
2026-02-27T23:24:42.6921156Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:24:42.6921619Z Loading safetensors checkpoint shards:  54% Completed | 88/163 [06:00<06:13,  4.97s/it]
2026-02-27T23:24:44.5918062Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:24:44.5918902Z Loading safetensors checkpoint shards:  55% Completed | 89/163 [06:02<04:59,  4.05s/it]
2026-02-27T23:24:55.1673809Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:24:55.1674540Z Loading safetensors checkpoint shards:  55% Completed | 90/163 [06:12<07:18,  6.01s/it]
2026-02-27T23:24:55.3587388Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:24:55.3587903Z Loading safetensors checkpoint shards:  56% Completed | 91/163 [06:13<05:06,  4.26s/it]
2026-02-27T23:24:56.5756735Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:24:56.5757194Z Loading safetensors checkpoint shards:  56% Completed | 92/163 [06:14<03:57,  3.35s/it]
2026-02-27T23:25:06.0026930Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:25:06.0027409Z Loading safetensors checkpoint shards:  57% Completed | 93/163 [06:23<06:02,  5.17s/it]
2026-02-27T23:25:07.8214898Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:25:07.8215405Z Loading safetensors checkpoint shards:  58% Completed | 94/163 [06:25<04:47,  4.17s/it]
2026-02-27T23:25:09.7094032Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:25:09.7094578Z Loading safetensors checkpoint shards:  58% Completed | 95/163 [06:27<03:56,  3.48s/it]
2026-02-27T23:25:18.7710566Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:25:18.7711008Z Loading safetensors checkpoint shards:  59% Completed | 96/163 [06:36<05:45,  5.16s/it]
2026-02-27T23:25:20.5100446Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:25:20.5101065Z Loading safetensors checkpoint shards:  60% Completed | 97/163 [06:38<04:32,  4.13s/it]
2026-02-27T23:25:28.9650965Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:25:28.9651513Z Loading safetensors checkpoint shards:  60% Completed | 98/163 [06:46<05:52,  5.43s/it]
2026-02-27T23:25:30.5546469Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:25:30.5547497Z Loading safetensors checkpoint shards:  61% Completed | 99/163 [06:48<04:33,  4.28s/it]
2026-02-27T23:25:31.2097585Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:25:31.2098117Z Loading safetensors checkpoint shards:  61% Completed | 100/163 [06:48<03:20,  3.19s/it]
2026-02-27T23:25:41.1202530Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:25:41.1203254Z Loading safetensors checkpoint shards:  62% Completed | 101/163 [06:58<05:22,  5.21s/it]
2026-02-27T23:25:42.8458140Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:25:42.8458672Z Loading safetensors checkpoint shards:  63% Completed | 102/163 [07:00<04:13,  4.16s/it]
2026-02-27T23:25:44.8050528Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:25:44.8051143Z Loading safetensors checkpoint shards:  63% Completed | 103/163 [07:02<03:30,  3.50s/it]
2026-02-27T23:25:53.8991779Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:25:53.8992342Z Loading safetensors checkpoint shards:  64% Completed | 104/163 [07:11<05:05,  5.18s/it]
2026-02-27T23:25:56.0583611Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:25:56.0584038Z Loading safetensors checkpoint shards:  64% Completed | 105/163 [07:13<04:07,  4.27s/it]
2026-02-27T23:26:02.6325109Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:26:02.6325623Z Loading safetensors checkpoint shards:  65% Completed | 106/163 [07:20<04:42,  4.96s/it]
2026-02-27T23:26:10.0095685Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:26:10.0096153Z Loading safetensors checkpoint shards:  66% Completed | 107/163 [07:27<05:18,  5.69s/it]
2026-02-27T23:26:10.1810126Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:26:10.1810744Z Loading safetensors checkpoint shards:  66% Completed | 108/163 [07:27<03:41,  4.03s/it]
2026-02-27T23:26:17.5100062Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:26:17.5100476Z Loading safetensors checkpoint shards:  67% Completed | 109/163 [07:35<04:31,  5.02s/it]
2026-02-27T23:26:17.9856821Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:26:17.9857285Z Loading safetensors checkpoint shards:  67% Completed | 110/163 [07:35<03:13,  3.66s/it]
2026-02-27T23:26:19.9033352Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:26:19.9033970Z Loading safetensors checkpoint shards:  68% Completed | 111/163 [07:37<02:43,  3.14s/it]
2026-02-27T23:26:29.5460294Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:26:29.5461110Z Loading safetensors checkpoint shards:  69% Completed | 112/163 [07:47<04:19,  5.09s/it]
2026-02-27T23:26:31.5190903Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:26:31.5191469Z Loading safetensors checkpoint shards:  69% Completed | 113/163 [07:49<03:27,  4.15s/it]
2026-02-27T23:26:33.6791232Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:26:33.6791751Z Loading safetensors checkpoint shards:  70% Completed | 114/163 [07:51<02:54,  3.56s/it]
2026-02-27T23:26:43.2819223Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:26:43.2819797Z Loading safetensors checkpoint shards:  71% Completed | 115/163 [08:01<04:17,  5.37s/it]
2026-02-27T23:26:44.9102208Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:26:44.9102706Z Loading safetensors checkpoint shards:  71% Completed | 116/163 [08:02<03:19,  4.25s/it]
2026-02-27T23:26:53.8733721Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:26:53.8734244Z Loading safetensors checkpoint shards:  72% Completed | 117/163 [08:11<04:20,  5.66s/it]
2026-02-27T23:26:54.0663703Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:26:54.0664480Z Loading safetensors checkpoint shards:  72% Completed | 118/163 [08:11<03:00,  4.02s/it]
2026-02-27T23:26:55.9116561Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:27:05.6372207Z Loading safetensors checkpoint shards:  73% Completed | 119/163 [08:13<02:28,  3.37s/it]
2026-02-27T23:27:05.6372664Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:27:05.6373030Z Loading safetensors checkpoint shards:  74% Completed | 120/163 [08:23<03:46,  5.28s/it]
2026-02-27T23:27:06.4396935Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:27:06.4397365Z Loading safetensors checkpoint shards:  74% Completed | 121/163 [08:24<02:45,  3.93s/it]
2026-02-27T23:27:08.5532388Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:27:08.5533271Z Loading safetensors checkpoint shards:  75% Completed | 122/163 [08:26<02:18,  3.39s/it]
2026-02-27T23:27:16.0846515Z (ApiServer_1 pid=1026) Process ApiServer_1:
2026-02-27T23:27:16.0887345Z (ApiServer_0 pid=1025) Process ApiServer_0:
2026-02-27T23:27:16.1081483Z (ApiServer_1 pid=1026) Traceback (most recent call last):
2026-02-27T23:27:16.1082120Z (ApiServer_0 pid=1025) Traceback (most recent call last):
2026-02-27T23:27:16.1082649Z (ApiServer_1 pid=1026)   File "/usr/local/python3.11.14/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
2026-02-27T23:27:16.1083130Z (ApiServer_1 pid=1026)     self.run()
2026-02-27T23:27:16.1083568Z (ApiServer_1 pid=1026)   File "/usr/local/python3.11.14/lib/python3.11/multiprocessing/process.py", line 108, in run
2026-02-27T23:27:16.1084745Z (ApiServer_1 pid=1026)     self._target(*self._args, **self._kwargs)
2026-02-27T23:27:16.1085344Z (ApiServer_1 pid=1026)   File "/vllm-workspace/vllm/vllm/entrypoints/cli/serve.py", line 300, in run_api_server_worker_proc
2026-02-27T23:27:16.1085846Z (ApiServer_1 pid=1026)     uvloop.run(
2026-02-27T23:27:16.1086713Z (ApiServer_1 pid=1026)   File "/usr/local/python3.11.14/lib/python3.11/site-packages/uvloop/__init__.py", line 92, in run
2026-02-27T23:27:16.1087230Z (ApiServer_1 pid=1026)     return runner.run(wrapper())
2026-02-27T23:27:16.1087580Z (ApiServer_1 pid=1026)            ^^^^^^^^^^^^^^^^^^^^^
2026-02-27T23:27:16.1088045Z (ApiServer_1 pid=1026)   File "/usr/local/python3.11.14/lib/python3.11/asyncio/runners.py", line 118, in run
2026-02-27T23:27:16.1088479Z (ApiServer_1 pid=1026)     return self._loop.run_until_complete(task)
2026-02-27T23:27:16.1088856Z (ApiServer_1 pid=1026)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-27T23:27:16.1089344Z (ApiServer_1 pid=1026)   File "uvloop/loop.pyx", line 1518, in uvloop.loop.Loop.run_until_complete
2026-02-27T23:27:16.1089942Z (ApiServer_1 pid=1026)   File "/usr/local/python3.11.14/lib/python3.11/site-packages/uvloop/__init__.py", line 48, in wrapper
2026-02-27T23:27:16.1090439Z (ApiServer_1 pid=1026)     return await main
2026-02-27T23:27:16.1090682Z (ApiServer_1 pid=1026)            ^^^^^^^^^^
2026-02-27T23:27:16.1091159Z (ApiServer_1 pid=1026)   File "/vllm-workspace/vllm/vllm/entrypoints/openai/api_server.py", line 476, in run_server_worker
2026-02-27T23:27:16.1091969Z (ApiServer_1 pid=1026)     async with build_async_engine_client(
2026-02-27T23:27:16.1092587Z (ApiServer_1 pid=1026)   File "/usr/local/python3.11.14/lib/python3.11/contextlib.py", line 210, in __aenter__
2026-02-27T23:27:16.1093052Z (ApiServer_1 pid=1026)     return await anext(self.gen)
2026-02-27T23:27:16.1093337Z (ApiServer_1 pid=1026)            ^^^^^^^^^^^^^^^^^^^^^
2026-02-27T23:27:16.1093814Z (ApiServer_1 pid=1026)   File "/vllm-workspace/vllm/vllm/entrypoints/openai/api_server.py", line 96, in build_async_engine_client
2026-02-27T23:27:16.1094375Z (ApiServer_1 pid=1026)     async with build_async_engine_client_from_engine_args(
2026-02-27T23:27:16.1094917Z (ApiServer_1 pid=1026)   File "/usr/local/python3.11.14/lib/python3.11/contextlib.py", line 210, in __aenter__
2026-02-27T23:27:16.1095345Z (ApiServer_1 pid=1026)     return await anext(self.gen)
2026-02-27T23:27:16.1095643Z (ApiServer_1 pid=1026)            ^^^^^^^^^^^^^^^^^^^^^
2026-02-27T23:27:16.1096162Z (ApiServer_1 pid=1026)   File "/vllm-workspace/vllm/vllm/entrypoints/openai/api_server.py", line 137, in build_async_engine_client_from_engine_args
2026-02-27T23:27:16.1096708Z (ApiServer_1 pid=1026)     async_llm = AsyncLLM.from_vllm_config(
2026-02-27T23:27:16.1097051Z (ApiServer_1 pid=1026)                 ^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-27T23:27:16.1097504Z (ApiServer_1 pid=1026)   File "/vllm-workspace/vllm/vllm/v1/engine/async_llm.py", line 222, in from_vllm_config
2026-02-27T23:27:16.1097926Z (ApiServer_1 pid=1026)     return cls(
2026-02-27T23:27:16.1098213Z (ApiServer_1 pid=1026)            ^^^^
2026-02-27T23:27:16.1098598Z (ApiServer_1 pid=1026)   File "/vllm-workspace/vllm/vllm/v1/engine/async_llm.py", line 148, in __init__
2026-02-27T23:27:16.1099300Z (ApiServer_1 pid=1026)     self.engine_core = EngineCoreClient.make_async_mp_client(
2026-02-27T23:27:16.1099747Z (ApiServer_1 pid=1026)                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-27T23:27:16.1100218Z (ApiServer_1 pid=1026)   File "/vllm-workspace/vllm/vllm/v1/engine/core_client.py", line 123, in make_async_mp_client
2026-02-27T23:27:16.1100689Z (ApiServer_1 pid=1026)     return DPLBAsyncMPClient(*client_args)
2026-02-27T23:27:16.1101067Z (ApiServer_1 pid=1026)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-27T23:27:16.1101464Z (ApiServer_1 pid=1026)   File "/vllm-workspace/vllm/vllm/v1/engine/core_client.py", line 1232, in __init__
2026-02-27T23:27:16.1101870Z (ApiServer_1 pid=1026)     super().__init__(
2026-02-27T23:27:16.1102361Z (ApiServer_1 pid=1026)   File "/vllm-workspace/vllm/vllm/v1/engine/core_client.py", line 1061, in __init__
2026-02-27T23:27:16.1102763Z (ApiServer_1 pid=1026)     super().__init__(
2026-02-27T23:27:16.1103144Z (ApiServer_1 pid=1026)   File "/vllm-workspace/vllm/vllm/v1/engine/core_client.py", line 835, in __init__
2026-02-27T23:27:16.1103550Z (ApiServer_1 pid=1026)     super().__init__(
2026-02-27T23:27:16.1103937Z (ApiServer_1 pid=1026)   File "/vllm-workspace/vllm/vllm/v1/engine/core_client.py", line 541, in __init__
2026-02-27T23:27:16.1104364Z (ApiServer_1 pid=1026)     raise TimeoutError(
2026-02-27T23:27:16.1104781Z (ApiServer_1 pid=1026) TimeoutError: Timed out waiting for engines to send initial message on input socket.
2026-02-27T23:27:16.1105337Z (ApiServer_0 pid=1025)   File "/usr/local/python3.11.14/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
2026-02-27T23:27:16.1105797Z (ApiServer_0 pid=1025)     self.run()
2026-02-27T23:27:16.1106219Z (ApiServer_0 pid=1025)   File "/usr/local/python3.11.14/lib/python3.11/multiprocessing/process.py", line 108, in run
2026-02-27T23:27:16.1106658Z (ApiServer_0 pid=1025)     self._target(*self._args, **self._kwargs)
2026-02-27T23:27:16.1107160Z (ApiServer_0 pid=1025)   File "/vllm-workspace/vllm/vllm/entrypoints/cli/serve.py", line 300, in run_api_server_worker_proc
2026-02-27T23:27:16.1107588Z (ApiServer_0 pid=1025)     uvloop.run(
2026-02-27T23:27:16.1108105Z (ApiServer_0 pid=1025)   File "/usr/local/python3.11.14/lib/python3.11/site-packages/uvloop/__init__.py", line 92, in run
2026-02-27T23:27:16.1108575Z (ApiServer_0 pid=1025)     return runner.run(wrapper())
2026-02-27T23:27:16.1108852Z (ApiServer_0 pid=1025)            ^^^^^^^^^^^^^^^^^^^^^
2026-02-27T23:27:16.1109345Z (ApiServer_0 pid=1025)   File "/usr/local/python3.11.14/lib/python3.11/asyncio/runners.py", line 118, in run
2026-02-27T23:27:16.1109829Z (ApiServer_0 pid=1025)     return self._loop.run_until_complete(task)
2026-02-27T23:27:16.1110186Z (ApiServer_0 pid=1025)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-27T23:27:16.1110619Z (ApiServer_0 pid=1025)   File "uvloop/loop.pyx", line 1518, in uvloop.loop.Loop.run_until_complete
2026-02-27T23:27:16.1111154Z (ApiServer_0 pid=1025)   File "/usr/local/python3.11.14/lib/python3.11/site-packages/uvloop/__init__.py", line 48, in wrapper
2026-02-27T23:27:16.1111611Z (ApiServer_0 pid=1025)     return await main
2026-02-27T23:27:16.1111873Z (ApiServer_0 pid=1025)            ^^^^^^^^^^
2026-02-27T23:27:16.1112412Z (ApiServer_0 pid=1025)   File "/vllm-workspace/vllm/vllm/entrypoints/openai/api_server.py", line 476, in run_server_worker
2026-02-27T23:27:16.1112903Z (ApiServer_0 pid=1025)     async with build_async_engine_client(
2026-02-27T23:27:16.1113331Z (ApiServer_0 pid=1025)   File "/usr/local/python3.11.14/lib/python3.11/contextlib.py", line 210, in __aenter__
2026-02-27T23:27:16.1113761Z (ApiServer_0 pid=1025)     return await anext(self.gen)
2026-02-27T23:27:16.1114027Z (ApiServer_0 pid=1025)            ^^^^^^^^^^^^^^^^^^^^^
2026-02-27T23:27:16.1114526Z (ApiServer_0 pid=1025)   File "/vllm-workspace/vllm/vllm/entrypoints/openai/api_server.py", line 96, in build_async_engine_client
2026-02-27T23:27:16.1115148Z (ApiServer_0 pid=1025)     async with build_async_engine_client_from_engine_args(
2026-02-27T23:27:16.1115610Z (ApiServer_0 pid=1025)   File "/usr/local/python3.11.14/lib/python3.11/contextlib.py", line 210, in __aenter__
2026-02-27T23:27:16.1116063Z (ApiServer_0 pid=1025)     return await anext(self.gen)
2026-02-27T23:27:16.1116340Z (ApiServer_0 pid=1025)            ^^^^^^^^^^^^^^^^^^^^^
2026-02-27T23:27:16.1116838Z (ApiServer_0 pid=1025)   File "/vllm-workspace/vllm/vllm/entrypoints/openai/api_server.py", line 137, in build_async_engine_client_from_engine_args
2026-02-27T23:27:16.1117373Z (ApiServer_0 pid=1025)     async_llm = AsyncLLM.from_vllm_config(
2026-02-27T23:27:16.1117719Z (ApiServer_0 pid=1025)                 ^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-27T23:27:16.1118155Z (ApiServer_0 pid=1025)   File "/vllm-workspace/vllm/vllm/v1/engine/async_llm.py", line 222, in from_vllm_config
2026-02-27T23:27:16.1118555Z (ApiServer_0 pid=1025)     return cls(
2026-02-27T23:27:16.1118807Z (ApiServer_0 pid=1025)            ^^^^
2026-02-27T23:27:16.1119231Z (ApiServer_0 pid=1025)   File "/vllm-workspace/vllm/vllm/v1/engine/async_llm.py", line 148, in __init__
2026-02-27T23:27:16.1119727Z (ApiServer_0 pid=1025)     self.engine_core = EngineCoreClient.make_async_mp_client(
2026-02-27T23:27:16.1120174Z (ApiServer_0 pid=1025)                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-27T23:27:16.1120633Z (ApiServer_0 pid=1025)   File "/vllm-workspace/vllm/vllm/v1/engine/core_client.py", line 123, in make_async_mp_client
2026-02-27T23:27:16.1121107Z (ApiServer_0 pid=1025)     return DPLBAsyncMPClient(*client_args)
2026-02-27T23:27:16.1121430Z (ApiServer_0 pid=1025)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-27T23:27:16.1121865Z (ApiServer_0 pid=1025)   File "/vllm-workspace/vllm/vllm/v1/engine/core_client.py", line 1232, in __init__
2026-02-27T23:27:16.1122379Z (ApiServer_0 pid=1025)     super().__init__(
2026-02-27T23:27:16.1122749Z (ApiServer_0 pid=1025)   File "/vllm-workspace/vllm/vllm/v1/engine/core_client.py", line 1061, in __init__
2026-02-27T23:27:16.1123158Z (ApiServer_0 pid=1025)     super().__init__(
2026-02-27T23:27:16.1123511Z (ApiServer_0 pid=1025)   File "/vllm-workspace/vllm/vllm/v1/engine/core_client.py", line 835, in __init__
2026-02-27T23:27:16.1123919Z (ApiServer_0 pid=1025)     super().__init__(
2026-02-27T23:27:16.1124365Z (ApiServer_0 pid=1025)   File "/vllm-workspace/vllm/vllm/v1/engine/core_client.py", line 541, in __init__
2026-02-27T23:27:16.1124792Z (ApiServer_0 pid=1025)     raise TimeoutError(
2026-02-27T23:27:16.1125269Z (ApiServer_0 pid=1025) TimeoutError: Timed out waiting for engines to send initial message on input socket.
2026-02-27T23:27:16.5197024Z (ApiServer_1 pid=1026) sys:1: DeprecationWarning: builtin type swigvarlink has no __module__ attribute
2026-02-27T23:27:16.6811777Z (ApiServer_0 pid=1025) sys:1: DeprecationWarning: builtin type swigvarlink has no __module__ attribute
2026-02-27T23:27:18.0683018Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:27:18.0683691Z Loading safetensors checkpoint shards:  75% Completed | 123/163 [08:35<03:29,  5.23s/it]
2026-02-27T23:27:20.0357079Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:27:20.0357710Z Loading safetensors checkpoint shards:  76% Completed | 124/163 [08:37<02:45,  4.25s/it]
2026-02-27T23:27:25.9807829Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:27:25.9808356Z Loading safetensors checkpoint shards:  77% Completed | 125/163 [08:43<03:00,  4.76s/it]
2026-02-27T23:27:30.1478549Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:27:30.1479015Z Loading safetensors checkpoint shards:  77% Completed | 126/163 [08:47<02:49,  4.58s/it]
2026-02-27T23:27:30.3208353Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:27:30.3208721Z Loading safetensors checkpoint shards:  78% Completed | 127/163 [08:48<01:57,  3.26s/it]
2026-02-27T23:27:39.6006931Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:27:39.6007410Z Loading safetensors checkpoint shards:  79% Completed | 128/163 [08:57<02:57,  5.06s/it]
2026-02-27T23:27:41.0517643Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:27:41.0518400Z Loading safetensors checkpoint shards:  79% Completed | 129/163 [08:58<02:15,  3.98s/it]
2026-02-27T23:27:42.9505413Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:27:42.9505933Z Loading safetensors checkpoint shards:  80% Completed | 130/163 [09:00<01:50,  3.36s/it]
2026-02-27T23:27:53.0197493Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:27:53.0197947Z Loading safetensors checkpoint shards:  80% Completed | 131/163 [09:10<02:51,  5.37s/it]
2026-02-27T23:27:54.2753765Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:27:54.2754223Z Loading safetensors checkpoint shards:  81% Completed | 132/163 [09:11<02:08,  4.14s/it]
2026-02-27T23:27:58.1025373Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:27:58.1025831Z Loading safetensors checkpoint shards:  82% Completed | 133/163 [09:15<02:01,  4.04s/it]
2026-02-27T23:28:03.2107833Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:28:03.2108285Z Loading safetensors checkpoint shards:  82% Completed | 134/163 [09:20<02:06,  4.36s/it]
2026-02-27T23:28:03.8667505Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:28:03.8667996Z Loading safetensors checkpoint shards:  83% Completed | 135/163 [09:21<01:30,  3.25s/it]
2026-02-27T23:28:08.2793230Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:28:08.2793908Z Loading safetensors checkpoint shards:  83% Completed | 136/163 [09:26<01:37,  3.60s/it]
2026-02-27T23:28:09.4935096Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:28:09.4935620Z Loading safetensors checkpoint shards:  84% Completed | 137/163 [09:27<01:14,  2.88s/it]
2026-02-27T23:28:11.2799711Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:28:11.2800171Z Loading safetensors checkpoint shards:  85% Completed | 138/163 [09:29<01:03,  2.55s/it]
2026-02-27T23:28:15.7165545Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:28:15.7166031Z Loading safetensors checkpoint shards:  85% Completed | 139/163 [09:33<01:14,  3.12s/it]
2026-02-27T23:28:17.0487333Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:28:17.0487799Z Loading safetensors checkpoint shards:  86% Completed | 140/163 [09:34<00:59,  2.58s/it]
2026-02-27T23:28:19.0003414Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:28:19.0003913Z Loading safetensors checkpoint shards:  87% Completed | 141/163 [09:36<00:52,  2.39s/it]
2026-02-27T23:28:23.5767331Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:28:23.5768195Z Loading safetensors checkpoint shards:  87% Completed | 142/163 [09:41<01:04,  3.05s/it]
2026-02-27T23:28:25.1290695Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:28:25.1291309Z Loading safetensors checkpoint shards:  88% Completed | 143/163 [09:42<00:51,  2.60s/it]
2026-02-27T23:28:29.1730566Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:28:29.1731016Z Loading safetensors checkpoint shards:  88% Completed | 144/163 [09:46<00:57,  3.03s/it]
2026-02-27T23:28:30.5180149Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:28:30.5180754Z Loading safetensors checkpoint shards:  89% Completed | 145/163 [09:48<00:45,  2.53s/it]
2026-02-27T23:28:32.3077649Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:28:32.3078102Z Loading safetensors checkpoint shards:  90% Completed | 146/163 [09:50<00:39,  2.31s/it]
2026-02-27T23:28:36.8900461Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:28:36.8900931Z Loading safetensors checkpoint shards:  90% Completed | 147/163 [09:54<00:47,  2.99s/it]
2026-02-27T23:28:38.1451484Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:28:38.1452280Z Loading safetensors checkpoint shards:  91% Completed | 148/163 [09:55<00:37,  2.47s/it]
2026-02-27T23:28:39.9071914Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:28:39.9072600Z Loading safetensors checkpoint shards:  91% Completed | 149/163 [09:57<00:31,  2.26s/it]
2026-02-27T23:28:48.2899932Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:28:48.2900410Z Loading safetensors checkpoint shards:  92% Completed | 150/163 [10:06<00:53,  4.09s/it]
2026-02-27T23:28:49.6848720Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:28:49.6849258Z Loading safetensors checkpoint shards:  93% Completed | 151/163 [10:07<00:39,  3.28s/it]
2026-02-27T23:28:56.7468036Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:28:56.7469014Z Loading safetensors checkpoint shards:  93% Completed | 152/163 [10:14<00:48,  4.42s/it]
2026-02-27T23:29:02.4852169Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:29:02.4852667Z Loading safetensors checkpoint shards:  94% Completed | 153/163 [10:20<00:48,  4.81s/it]
2026-02-27T23:29:02.6587948Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:29:02.6588618Z Loading safetensors checkpoint shards:  94% Completed | 154/163 [10:20<00:30,  3.42s/it]
2026-02-27T23:29:08.0204003Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:29:08.0204510Z Loading safetensors checkpoint shards:  95% Completed | 155/163 [10:25<00:32,  4.00s/it]
2026-02-27T23:29:09.0824997Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:29:09.0825641Z Loading safetensors checkpoint shards:  96% Completed | 156/163 [10:26<00:21,  3.12s/it]
2026-02-27T23:29:10.8115995Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:29:10.8116598Z Loading safetensors checkpoint shards:  96% Completed | 157/163 [10:28<00:16,  2.70s/it]
2026-02-27T23:29:13.0000824Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:29:13.0001382Z Loading safetensors checkpoint shards:  97% Completed | 158/163 [10:30<00:12,  2.55s/it]
2026-02-27T23:29:14.5033656Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:29:14.5034093Z Loading safetensors checkpoint shards:  98% Completed | 159/163 [10:32<00:08,  2.24s/it]
2026-02-27T23:29:16.0249837Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:29:16.0250339Z Loading safetensors checkpoint shards:  98% Completed | 160/163 [10:33<00:06,  2.02s/it]
2026-02-27T23:29:18.4496638Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:29:18.4497123Z Loading safetensors checkpoint shards:  99% Completed | 162/163 [10:36<00:01,  1.65s/it]
2026-02-27T23:29:22.3722658Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:29:22.3723279Z Loading safetensors checkpoint shards: 100% Completed | 163/163 [10:40<00:00,  2.21s/it]
2026-02-27T23:29:22.3723666Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:29:22.3724124Z Loading safetensors checkpoint shards: 100% Completed | 163/163 [10:40<00:00,  3.93s/it]
2026-02-27T23:29:22.3724561Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:29:22.3874307Z (Worker_DP1_TP0_EP8 pid=1041) INFO 02-27 23:29:22 [default_loader.py:293] Loading weights took 640.11 seconds
2026-02-27T23:29:22.4130976Z (Worker_DP0_TP0_EP0 pid=1040) INFO 02-27 23:29:22 [default_loader.py:293] Loading weights took 640.14 seconds
2026-02-27T23:29:36.2178637Z INFO 02-27 23:29:36 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T23:29:36.2179232Z INFO 02-27 23:29:36 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T23:29:36.2179790Z INFO 02-27 23:29:36 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T23:29:36.2180288Z INFO 02-27 23:29:36 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T23:29:36.2180696Z INFO 02-27 23:29:36 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T23:29:36.2181117Z INFO 02-27 23:29:36 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T23:29:36.2181647Z INFO 02-27 23:29:36 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T23:29:36.2182228Z INFO 02-27 23:29:36 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T23:29:36.2182713Z INFO 02-27 23:29:36 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T23:29:36.2183239Z INFO 02-27 23:29:36 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T23:29:36.2183635Z INFO 02-27 23:29:36 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T23:29:36.2184100Z INFO 02-27 23:29:36 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T23:29:36.2184702Z INFO 02-27 23:29:36 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T23:29:36.2185107Z INFO 02-27 23:29:36 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T23:29:36.2185838Z INFO 02-27 23:29:36 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T23:29:36.2186203Z INFO 02-27 23:29:36 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T23:29:36.2186661Z INFO 02-27 23:29:36 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T23:29:36.2187267Z INFO 02-27 23:29:36 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T23:29:36.2187862Z INFO 02-27 23:29:36 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T23:29:36.2188249Z INFO 02-27 23:29:36 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T23:29:36.2188648Z INFO 02-27 23:29:36 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T23:29:36.2188963Z INFO 02-27 23:29:36 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T23:29:36.2189430Z INFO 02-27 23:29:36 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T23:29:36.2190111Z INFO 02-27 23:29:36 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T23:29:36.2190586Z INFO 02-27 23:29:36 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T23:29:36.2190971Z INFO 02-27 23:29:36 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T23:29:36.2191320Z INFO 02-27 23:29:36 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T23:29:36.2191734Z INFO 02-27 23:29:36 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T23:29:36.2192325Z INFO 02-27 23:29:36 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T23:29:36.2192784Z INFO 02-27 23:29:36 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T23:29:36.2193147Z INFO 02-27 23:29:36 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T23:29:36.2193586Z INFO 02-27 23:29:36 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T23:29:36.2194345Z INFO 02-27 23:29:36 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T23:29:36.2194860Z INFO 02-27 23:29:36 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T23:29:36.2195216Z INFO 02-27 23:29:36 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T23:29:36.2195783Z INFO 02-27 23:29:36 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T23:29:36.2346993Z INFO 02-27 23:29:36 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T23:29:36.2347344Z INFO 02-27 23:29:36 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T23:29:36.2347801Z INFO 02-27 23:29:36 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T23:29:36.2348131Z INFO 02-27 23:29:36 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T23:29:36.2348481Z INFO 02-27 23:29:36 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T23:29:36.2348878Z INFO 02-27 23:29:36 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T23:29:36.2349211Z INFO 02-27 23:29:36 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T23:29:36.2349558Z INFO 02-27 23:29:36 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T23:29:36.2349912Z INFO 02-27 23:29:36 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T23:29:36.2350269Z INFO 02-27 23:29:36 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T23:29:36.2350591Z INFO 02-27 23:29:36 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T23:29:36.2351060Z INFO 02-27 23:29:36 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T23:29:36.2815797Z INFO 02-27 23:29:36 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T23:29:36.2816189Z INFO 02-27 23:29:36 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T23:29:36.2816620Z INFO 02-27 23:29:36 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T23:29:36.2817153Z INFO 02-27 23:29:36 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T23:29:36.2817676Z INFO 02-27 23:29:36 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T23:29:36.2818181Z INFO 02-27 23:29:36 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T23:29:36.2891752Z INFO 02-27 23:29:36 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T23:29:36.2892228Z INFO 02-27 23:29:36 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T23:29:36.3436124Z INFO 02-27 23:29:36 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T23:29:36.3436567Z INFO 02-27 23:29:36 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T23:29:36.3436942Z INFO 02-27 23:29:36 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-27T23:29:36.3437543Z INFO 02-27 23:29:36 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T23:29:36.3438079Z INFO 02-27 23:29:36 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-27T23:29:36.3438546Z INFO 02-27 23:29:36 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-27T23:29:36.3510475Z INFO 02-27 23:29:36 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T23:29:36.3510847Z INFO 02-27 23:29:36 [__init__.py:212] Platform plugin ascend is activated
2026-02-27T23:30:03.6792144Z (Worker_DP1_TP3_EP11 pid=1284) WARNING 02-27 23:30:03 [sfa_v1.py:497] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-02-27T23:30:03.6793005Z (Worker_DP0_TP3_EP3 pid=1287) WARNING 02-27 23:30:03 [sfa_v1.py:497] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-02-27T23:30:03.7271225Z (Worker_DP1_TP3_EP11 pid=1284) INFO 02-27 23:30:03 [model_runner_v1.py:2359] Loading drafter model...
2026-02-27T23:30:03.7286186Z (Worker_DP0_TP3_EP3 pid=1287) INFO 02-27 23:30:03 [model_runner_v1.py:2359] Loading drafter model...
2026-02-27T23:30:03.9447284Z (Worker_DP1_TP6_EP14 pid=1596) WARNING 02-27 23:30:03 [sfa_v1.py:497] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-02-27T23:30:03.9533716Z (Worker_DP0_TP6_EP6 pid=1599) WARNING 02-27 23:30:03 [sfa_v1.py:497] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-02-27T23:30:03.9986119Z (Worker_DP1_TP6_EP14 pid=1596) INFO 02-27 23:30:03 [model_runner_v1.py:2359] Loading drafter model...
2026-02-27T23:30:04.0075054Z (Worker_DP0_TP6_EP6 pid=1599) INFO 02-27 23:30:04 [model_runner_v1.py:2359] Loading drafter model...
2026-02-27T23:30:04.0095072Z (Worker_DP0_TP0_EP0 pid=1040) WARNING 02-27 23:30:04 [sfa_v1.py:497] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-02-27T23:30:04.0293765Z (Worker_DP0_TP2_EP2 pid=1183) WARNING 02-27 23:30:04 [sfa_v1.py:497] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-02-27T23:30:04.0576465Z (Worker_DP0_TP0_EP0 pid=1040) INFO 02-27 23:30:04 [model_runner_v1.py:2359] Loading drafter model...
2026-02-27T23:30:04.0768869Z (Worker_DP0_TP2_EP2 pid=1183) INFO 02-27 23:30:04 [model_runner_v1.py:2359] Loading drafter model...
2026-02-27T23:30:04.1364121Z (Worker_DP1_TP0_EP8 pid=1041) WARNING 02-27 23:30:04 [sfa_v1.py:497] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-02-27T23:30:04.1395185Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:30:04.1395639Z Loading safetensors checkpoint shards:   0% Completed | 0/163 [00:00<?, ?it/s]
2026-02-27T23:30:04.1838595Z (Worker_DP1_TP0_EP8 pid=1041) INFO 02-27 23:30:04 [model_runner_v1.py:2359] Loading drafter model...
2026-02-27T23:30:04.2554922Z (Worker_DP1_TP2_EP10 pid=1180) WARNING 02-27 23:30:04 [sfa_v1.py:497] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-02-27T23:30:04.2810694Z (Worker_DP1_TP4_EP12 pid=1388) WARNING 02-27 23:30:04 [sfa_v1.py:497] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-02-27T23:30:04.2946542Z (Worker_DP0_TP4_EP4 pid=1391) WARNING 02-27 23:30:04 [sfa_v1.py:497] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-02-27T23:30:04.3025127Z (Worker_DP1_TP2_EP10 pid=1180) INFO 02-27 23:30:04 [model_runner_v1.py:2359] Loading drafter model...
2026-02-27T23:30:04.3184873Z (Worker_DP0_TP1_EP1 pid=1077) WARNING 02-27 23:30:04 [sfa_v1.py:497] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-02-27T23:30:04.3337439Z (Worker_DP1_TP4_EP12 pid=1388) INFO 02-27 23:30:04 [model_runner_v1.py:2359] Loading drafter model...
2026-02-27T23:30:04.3493184Z (Worker_DP0_TP4_EP4 pid=1391) INFO 02-27 23:30:04 [model_runner_v1.py:2359] Loading drafter model...
2026-02-27T23:30:04.3522663Z (Worker_DP1_TP1_EP9 pid=1074) WARNING 02-27 23:30:04 [sfa_v1.py:497] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-02-27T23:30:04.3660672Z (Worker_DP0_TP1_EP1 pid=1077) INFO 02-27 23:30:04 [model_runner_v1.py:2359] Loading drafter model...
2026-02-27T23:30:04.4002657Z (Worker_DP1_TP1_EP9 pid=1074) INFO 02-27 23:30:04 [model_runner_v1.py:2359] Loading drafter model...
2026-02-27T23:30:04.4242463Z (Worker_DP1_TP7_EP15 pid=1700) WARNING 02-27 23:30:04 [sfa_v1.py:497] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-02-27T23:30:04.4495915Z (Worker_DP1_TP5_EP13 pid=1492) WARNING 02-27 23:30:04 [sfa_v1.py:497] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-02-27T23:30:04.4710602Z (Worker_DP1_TP7_EP15 pid=1700) INFO 02-27 23:30:04 [model_runner_v1.py:2359] Loading drafter model...
2026-02-27T23:30:04.4726422Z (Worker_DP0_TP5_EP5 pid=1495) WARNING 02-27 23:30:04 [sfa_v1.py:497] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-02-27T23:30:04.4972287Z (Worker_DP1_TP5_EP13 pid=1492) INFO 02-27 23:30:04 [model_runner_v1.py:2359] Loading drafter model...
2026-02-27T23:30:04.5234765Z (Worker_DP0_TP5_EP5 pid=1495) INFO 02-27 23:30:04 [model_runner_v1.py:2359] Loading drafter model...
2026-02-27T23:30:04.5411840Z (Worker_DP0_TP7_EP7 pid=1703) WARNING 02-27 23:30:04 [sfa_v1.py:497] Currently mlapo does not support SFA with CP,thus mlapo is disabled for these layers.
2026-02-27T23:30:04.5895686Z (Worker_DP0_TP7_EP7 pid=1703) INFO 02-27 23:30:04 [model_runner_v1.py:2359] Loading drafter model...
2026-02-27T23:30:04.6741765Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:30:04.6742494Z Loading safetensors checkpoint shards:   1% Completed | 1/163 [00:00<01:26,  1.87it/s]
2026-02-27T23:30:05.9993177Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:30:05.9993757Z Loading safetensors checkpoint shards:   1% Completed | 2/163 [00:01<02:40,  1.00it/s]
2026-02-27T23:30:07.4958367Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:30:07.4958994Z Loading safetensors checkpoint shards:   2% Completed | 3/163 [00:03<03:16,  1.23s/it]
2026-02-27T23:30:08.8452830Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:30:08.8453412Z Loading safetensors checkpoint shards:   2% Completed | 4/163 [00:04<03:22,  1.27s/it]
2026-02-27T23:30:10.4712543Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:30:10.4713091Z Loading safetensors checkpoint shards:   3% Completed | 5/163 [00:06<03:41,  1.40s/it]
2026-02-27T23:30:11.8838790Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:30:11.8839219Z Loading safetensors checkpoint shards:   4% Completed | 6/163 [00:07<03:40,  1.41s/it]
2026-02-27T23:30:13.3361978Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:30:13.3362630Z Loading safetensors checkpoint shards:   4% Completed | 7/163 [00:09<03:41,  1.42s/it]
2026-02-27T23:30:14.8055691Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:30:14.8056213Z Loading safetensors checkpoint shards:   5% Completed | 8/163 [00:10<03:42,  1.44s/it]
2026-02-27T23:30:16.2574838Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:30:16.2575297Z Loading safetensors checkpoint shards:   6% Completed | 9/163 [00:12<03:41,  1.44s/it]
2026-02-27T23:30:17.7714223Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:30:17.7714914Z Loading safetensors checkpoint shards:   6% Completed | 10/163 [00:13<03:43,  1.46s/it]
2026-02-27T23:30:19.2037176Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:30:19.2038001Z Loading safetensors checkpoint shards:   7% Completed | 11/163 [00:15<03:41,  1.45s/it]
2026-02-27T23:30:20.5356689Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:30:20.5357306Z Loading safetensors checkpoint shards:   7% Completed | 12/163 [00:16<03:33,  1.42s/it]
2026-02-27T23:30:21.9731557Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:30:21.9732069Z Loading safetensors checkpoint shards:   8% Completed | 13/163 [00:17<03:33,  1.42s/it]
2026-02-27T23:30:23.4450080Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:30:23.4450628Z Loading safetensors checkpoint shards:   9% Completed | 14/163 [00:19<03:34,  1.44s/it]
2026-02-27T23:30:24.7949661Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:30:24.7950136Z Loading safetensors checkpoint shards:   9% Completed | 15/163 [00:20<03:28,  1.41s/it]
2026-02-27T23:30:26.1462364Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:30:26.1462914Z Loading safetensors checkpoint shards:  10% Completed | 16/163 [00:22<03:24,  1.39s/it]
2026-02-27T23:30:27.5321749Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:30:27.5322313Z Loading safetensors checkpoint shards:  10% Completed | 17/163 [00:23<03:23,  1.39s/it]
2026-02-27T23:30:29.1747213Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:30:29.1747715Z Loading safetensors checkpoint shards:  11% Completed | 18/163 [00:25<03:32,  1.47s/it]
2026-02-27T23:30:30.5947844Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:30:30.5948302Z Loading safetensors checkpoint shards:  12% Completed | 19/163 [00:26<03:29,  1.45s/it]
2026-02-27T23:30:31.9618282Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:30:31.9619262Z Loading safetensors checkpoint shards:  12% Completed | 20/163 [00:27<03:24,  1.43s/it]
2026-02-27T23:30:33.4470420Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:30:33.4470892Z Loading safetensors checkpoint shards:  13% Completed | 21/163 [00:29<03:25,  1.44s/it]
2026-02-27T23:30:35.0661805Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:30:35.0662415Z Loading safetensors checkpoint shards:  13% Completed | 22/163 [00:30<03:31,  1.50s/it]
2026-02-27T23:30:36.4063797Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:30:36.4064335Z Loading safetensors checkpoint shards:  14% Completed | 23/163 [00:32<03:22,  1.45s/it]
2026-02-27T23:30:37.7727971Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:30:37.7728536Z Loading safetensors checkpoint shards:  15% Completed | 24/163 [00:33<03:18,  1.42s/it]
2026-02-27T23:30:39.1231508Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:30:39.1232100Z Loading safetensors checkpoint shards:  15% Completed | 25/163 [00:34<03:13,  1.40s/it]
2026-02-27T23:30:40.4778257Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:30:40.4778727Z Loading safetensors checkpoint shards:  16% Completed | 26/163 [00:36<03:10,  1.39s/it]
2026-02-27T23:30:41.9154189Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:30:41.9154710Z Loading safetensors checkpoint shards:  17% Completed | 27/163 [00:37<03:10,  1.40s/it]
2026-02-27T23:30:43.2135089Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:30:43.2135651Z Loading safetensors checkpoint shards:  17% Completed | 28/163 [00:39<03:05,  1.37s/it]
2026-02-27T23:30:44.8194183Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:30:44.8194807Z Loading safetensors checkpoint shards:  18% Completed | 29/163 [00:40<03:13,  1.44s/it]
2026-02-27T23:30:46.1737966Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:30:46.1738770Z Loading safetensors checkpoint shards:  18% Completed | 30/163 [00:42<03:08,  1.42s/it]
2026-02-27T23:30:47.5418264Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:30:47.5418861Z Loading safetensors checkpoint shards:  19% Completed | 31/163 [00:43<03:04,  1.40s/it]
2026-02-27T23:30:48.9585863Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:30:48.9586381Z Loading safetensors checkpoint shards:  20% Completed | 32/163 [00:44<03:04,  1.41s/it]
2026-02-27T23:30:50.3143337Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:30:50.3143776Z Loading safetensors checkpoint shards:  20% Completed | 33/163 [00:46<03:00,  1.39s/it]
2026-02-27T23:30:51.7095469Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:30:51.7096151Z Loading safetensors checkpoint shards:  21% Completed | 34/163 [00:47<02:59,  1.39s/it]
2026-02-27T23:30:53.1518092Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:30:53.1518679Z Loading safetensors checkpoint shards:  21% Completed | 35/163 [00:49<03:00,  1.41s/it]
2026-02-27T23:30:54.5394753Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:30:54.5395343Z Loading safetensors checkpoint shards:  22% Completed | 36/163 [00:50<02:57,  1.40s/it]
2026-02-27T23:30:55.8880952Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:30:55.8881436Z Loading safetensors checkpoint shards:  23% Completed | 37/163 [00:51<02:54,  1.39s/it]
2026-02-27T23:30:57.3088170Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:30:57.3088696Z Loading safetensors checkpoint shards:  23% Completed | 38/163 [00:53<02:54,  1.40s/it]
2026-02-27T23:30:58.6634762Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:30:58.6635174Z Loading safetensors checkpoint shards:  24% Completed | 39/163 [00:54<02:51,  1.38s/it]
2026-02-27T23:31:00.0512949Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:31:00.0513445Z Loading safetensors checkpoint shards:  25% Completed | 40/163 [00:55<02:50,  1.38s/it]
2026-02-27T23:31:01.5742221Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:31:01.5742704Z Loading safetensors checkpoint shards:  25% Completed | 41/163 [00:57<02:54,  1.43s/it]
2026-02-27T23:31:02.9662176Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:31:02.9662772Z Loading safetensors checkpoint shards:  26% Completed | 42/163 [00:58<02:51,  1.42s/it]
2026-02-27T23:31:04.2768817Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:31:04.2769879Z Loading safetensors checkpoint shards:  26% Completed | 43/163 [01:00<02:46,  1.38s/it]
2026-02-27T23:31:05.6690829Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:31:05.6691447Z Loading safetensors checkpoint shards:  27% Completed | 44/163 [01:01<02:45,  1.39s/it]
2026-02-27T23:31:07.0909551Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:31:07.0910045Z Loading safetensors checkpoint shards:  28% Completed | 45/163 [01:02<02:44,  1.40s/it]
2026-02-27T23:31:08.6055404Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:31:08.6055873Z Loading safetensors checkpoint shards:  28% Completed | 46/163 [01:04<02:47,  1.43s/it]
2026-02-27T23:31:09.9326640Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:31:09.9327088Z Loading safetensors checkpoint shards:  29% Completed | 47/163 [01:05<02:42,  1.40s/it]
2026-02-27T23:31:11.3505759Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:31:11.3506266Z Loading safetensors checkpoint shards:  29% Completed | 48/163 [01:07<02:41,  1.41s/it]
2026-02-27T23:31:12.8358784Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:31:14.2154725Z Loading safetensors checkpoint shards:  30% Completed | 49/163 [01:08<02:42,  1.43s/it]
2026-02-27T23:31:14.2155269Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:31:14.2155622Z Loading safetensors checkpoint shards:  31% Completed | 50/163 [01:10<02:39,  1.41s/it]
2026-02-27T23:31:15.7179190Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:31:15.7179625Z Loading safetensors checkpoint shards:  31% Completed | 51/163 [01:11<02:41,  1.44s/it]
2026-02-27T23:31:17.0942332Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:31:17.0942931Z Loading safetensors checkpoint shards:  32% Completed | 52/163 [01:12<02:37,  1.42s/it]
2026-02-27T23:31:18.5022289Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:31:18.5023313Z Loading safetensors checkpoint shards:  33% Completed | 53/163 [01:14<02:35,  1.42s/it]
2026-02-27T23:31:20.0523347Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:31:20.0523963Z Loading safetensors checkpoint shards:  33% Completed | 54/163 [01:15<02:38,  1.46s/it]
2026-02-27T23:31:21.4018365Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:31:21.4018937Z Loading safetensors checkpoint shards:  34% Completed | 55/163 [01:17<02:33,  1.42s/it]
2026-02-27T23:31:22.8387653Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:31:22.8388079Z Loading safetensors checkpoint shards:  34% Completed | 56/163 [01:18<02:32,  1.43s/it]
2026-02-27T23:31:24.2265499Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:31:24.2265972Z Loading safetensors checkpoint shards:  35% Completed | 57/163 [01:20<02:30,  1.42s/it]
2026-02-27T23:31:25.6658880Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:31:25.6659340Z Loading safetensors checkpoint shards:  36% Completed | 58/163 [01:21<02:29,  1.42s/it]
2026-02-27T23:31:27.0780509Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:31:27.0781021Z Loading safetensors checkpoint shards:  36% Completed | 59/163 [01:22<02:27,  1.42s/it]
2026-02-27T23:31:28.4838708Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:31:28.4839434Z Loading safetensors checkpoint shards:  37% Completed | 60/163 [01:24<02:25,  1.42s/it]
2026-02-27T23:31:29.9539799Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:31:29.9540361Z Loading safetensors checkpoint shards:  37% Completed | 61/163 [01:25<02:26,  1.43s/it]
2026-02-27T23:31:31.4389061Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:31:31.4389623Z Loading safetensors checkpoint shards:  38% Completed | 62/163 [01:27<02:26,  1.45s/it]
2026-02-27T23:31:32.7717617Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:31:32.7718119Z Loading safetensors checkpoint shards:  39% Completed | 63/163 [01:28<02:21,  1.41s/it]
2026-02-27T23:31:34.1936055Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:31:34.1936565Z Loading safetensors checkpoint shards:  39% Completed | 64/163 [01:30<02:20,  1.42s/it]
2026-02-27T23:31:35.6826704Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:31:35.6827135Z Loading safetensors checkpoint shards:  40% Completed | 65/163 [01:31<02:20,  1.44s/it]
2026-02-27T23:31:37.0351158Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:31:37.0352216Z Loading safetensors checkpoint shards:  40% Completed | 66/163 [01:32<02:17,  1.41s/it]
2026-02-27T23:31:38.3772467Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:31:38.3773012Z Loading safetensors checkpoint shards:  41% Completed | 67/163 [01:34<02:13,  1.39s/it]
2026-02-27T23:31:39.8863173Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:31:39.8863655Z Loading safetensors checkpoint shards:  42% Completed | 68/163 [01:35<02:15,  1.43s/it]
2026-02-27T23:31:41.3420421Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:31:41.3421106Z Loading safetensors checkpoint shards:  42% Completed | 69/163 [01:37<02:14,  1.44s/it]
2026-02-27T23:31:42.8875849Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:31:42.8876310Z Loading safetensors checkpoint shards:  43% Completed | 70/163 [01:38<02:16,  1.47s/it]
2026-02-27T23:31:44.3869249Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:31:44.3869733Z Loading safetensors checkpoint shards:  44% Completed | 71/163 [01:40<02:15,  1.48s/it]
2026-02-27T23:31:46.0476380Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:31:46.0476864Z Loading safetensors checkpoint shards:  44% Completed | 72/163 [01:41<02:19,  1.53s/it]
2026-02-27T23:31:47.5481634Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:31:47.5482190Z Loading safetensors checkpoint shards:  45% Completed | 73/163 [01:43<02:17,  1.52s/it]
2026-02-27T23:31:48.9188595Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:31:48.9189117Z Loading safetensors checkpoint shards:  45% Completed | 74/163 [01:44<02:11,  1.48s/it]
2026-02-27T23:31:50.3498147Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:31:50.3498597Z Loading safetensors checkpoint shards:  46% Completed | 75/163 [01:46<02:08,  1.46s/it]
2026-02-27T23:31:51.8477438Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:31:51.8477996Z Loading safetensors checkpoint shards:  47% Completed | 76/163 [01:47<02:08,  1.47s/it]
2026-02-27T23:31:53.3234104Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:31:53.3234556Z Loading safetensors checkpoint shards:  47% Completed | 77/163 [01:49<02:06,  1.47s/it]
2026-02-27T23:31:54.7238247Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:31:54.7238851Z Loading safetensors checkpoint shards:  48% Completed | 78/163 [01:50<02:03,  1.45s/it]
2026-02-27T23:31:56.0590766Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:31:56.0591216Z Loading safetensors checkpoint shards:  48% Completed | 79/163 [01:51<01:59,  1.42s/it]
2026-02-27T23:31:57.5324512Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:31:57.5324948Z Loading safetensors checkpoint shards:  49% Completed | 80/163 [01:53<01:59,  1.43s/it]
2026-02-27T23:31:58.9140666Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:31:58.9141155Z Loading safetensors checkpoint shards:  50% Completed | 81/163 [01:54<01:56,  1.42s/it]
2026-02-27T23:32:00.2490852Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:32:00.2491356Z Loading safetensors checkpoint shards:  50% Completed | 82/163 [01:56<01:52,  1.39s/it]
2026-02-27T23:32:01.6881235Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:32:01.6881824Z Loading safetensors checkpoint shards:  51% Completed | 83/163 [01:57<01:52,  1.41s/it]
2026-02-27T23:32:03.1819452Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:32:03.1820052Z Loading safetensors checkpoint shards:  52% Completed | 84/163 [01:59<01:53,  1.43s/it]
2026-02-27T23:32:04.6167843Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:32:04.6168447Z Loading safetensors checkpoint shards:  52% Completed | 85/163 [02:00<01:51,  1.43s/it]
2026-02-27T23:32:06.1377774Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:32:06.1378221Z Loading safetensors checkpoint shards:  53% Completed | 86/163 [02:01<01:52,  1.46s/it]
2026-02-27T23:32:07.6366683Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:32:07.6367255Z Loading safetensors checkpoint shards:  53% Completed | 87/163 [02:03<01:51,  1.47s/it]
2026-02-27T23:32:09.0608625Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:32:09.0609071Z Loading safetensors checkpoint shards:  54% Completed | 88/163 [02:04<01:49,  1.46s/it]
2026-02-27T23:32:10.5371382Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:32:10.5371847Z Loading safetensors checkpoint shards:  55% Completed | 89/163 [02:06<01:48,  1.46s/it]
2026-02-27T23:32:11.9231650Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:32:11.9232262Z Loading safetensors checkpoint shards:  55% Completed | 90/163 [02:07<01:45,  1.44s/it]
2026-02-27T23:32:13.3899106Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:32:13.3899755Z Loading safetensors checkpoint shards:  56% Completed | 91/163 [02:09<01:44,  1.45s/it]
2026-02-27T23:32:14.9100287Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:32:14.9100914Z Loading safetensors checkpoint shards:  56% Completed | 92/163 [02:10<01:44,  1.47s/it]
2026-02-27T23:32:16.2739052Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:32:16.2739613Z Loading safetensors checkpoint shards:  57% Completed | 93/163 [02:12<01:40,  1.44s/it]
2026-02-27T23:32:17.7521018Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:32:17.7521629Z Loading safetensors checkpoint shards:  58% Completed | 94/163 [02:13<01:40,  1.45s/it]
2026-02-27T23:32:19.2567176Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:32:19.2567896Z Loading safetensors checkpoint shards:  58% Completed | 95/163 [02:15<01:39,  1.47s/it]
2026-02-27T23:32:20.7179570Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:32:20.7179981Z Loading safetensors checkpoint shards:  59% Completed | 96/163 [02:16<01:38,  1.46s/it]
2026-02-27T23:32:22.1655993Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:32:22.1656440Z Loading safetensors checkpoint shards:  60% Completed | 97/163 [02:18<01:36,  1.46s/it]
2026-02-27T23:32:23.6352489Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:32:23.6352915Z Loading safetensors checkpoint shards:  60% Completed | 98/163 [02:19<01:35,  1.46s/it]
2026-02-27T23:32:25.0801268Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:32:25.0801742Z Loading safetensors checkpoint shards:  61% Completed | 99/163 [02:20<01:33,  1.46s/it]
2026-02-27T23:32:26.4342410Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:32:26.4343053Z Loading safetensors checkpoint shards:  61% Completed | 100/163 [02:22<01:29,  1.43s/it]
2026-02-27T23:32:27.7013111Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:32:27.7013694Z Loading safetensors checkpoint shards:  62% Completed | 101/163 [02:23<01:25,  1.38s/it]
2026-02-27T23:32:29.0726943Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:32:29.0727510Z Loading safetensors checkpoint shards:  63% Completed | 102/163 [02:24<01:23,  1.38s/it]
2026-02-27T23:32:30.4751474Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:32:30.4752097Z Loading safetensors checkpoint shards:  63% Completed | 103/163 [02:26<01:23,  1.38s/it]
2026-02-27T23:32:31.7182155Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:32:31.7182595Z Loading safetensors checkpoint shards:  64% Completed | 104/163 [02:27<01:19,  1.34s/it]
2026-02-27T23:32:33.2447855Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:32:33.2448318Z Loading safetensors checkpoint shards:  64% Completed | 105/163 [02:29<01:21,  1.40s/it]
2026-02-27T23:32:34.7398274Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:32:34.7398788Z Loading safetensors checkpoint shards:  65% Completed | 106/163 [02:30<01:21,  1.43s/it]
2026-02-27T23:32:36.0874766Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:32:36.0875306Z Loading safetensors checkpoint shards:  66% Completed | 107/163 [02:31<01:18,  1.40s/it]
2026-02-27T23:32:37.3655426Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:32:37.3655929Z Loading safetensors checkpoint shards:  66% Completed | 108/163 [02:33<01:15,  1.37s/it]
2026-02-27T23:32:38.5966429Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:32:38.5967036Z Loading safetensors checkpoint shards:  67% Completed | 109/163 [02:34<01:11,  1.33s/it]
2026-02-27T23:32:40.3387955Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:32:40.3388827Z Loading safetensors checkpoint shards:  67% Completed | 110/163 [02:36<01:16,  1.45s/it]
2026-02-27T23:32:41.6776981Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:32:42.9078858Z Loading safetensors checkpoint shards:  68% Completed | 111/163 [02:37<01:13,  1.42s/it]
2026-02-27T23:32:42.9079395Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:32:42.9079748Z Loading safetensors checkpoint shards:  69% Completed | 112/163 [02:38<01:09,  1.36s/it]
2026-02-27T23:32:44.2452933Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:32:44.2453424Z Loading safetensors checkpoint shards:  69% Completed | 113/163 [02:40<01:07,  1.35s/it]
2026-02-27T23:32:45.5530252Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:32:45.5530711Z Loading safetensors checkpoint shards:  70% Completed | 114/163 [02:41<01:05,  1.34s/it]
2026-02-27T23:32:46.8268874Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:32:46.8269304Z Loading safetensors checkpoint shards:  71% Completed | 115/163 [02:42<01:03,  1.32s/it]
2026-02-27T23:32:48.0963911Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:32:48.0964353Z Loading safetensors checkpoint shards:  71% Completed | 116/163 [02:43<01:01,  1.30s/it]
2026-02-27T23:32:49.4516108Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:32:49.4516607Z Loading safetensors checkpoint shards:  72% Completed | 117/163 [02:45<01:00,  1.32s/it]
2026-02-27T23:32:50.7594136Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:32:50.7594808Z Loading safetensors checkpoint shards:  72% Completed | 118/163 [02:46<00:59,  1.32s/it]
2026-02-27T23:32:52.1080976Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:32:52.1081444Z Loading safetensors checkpoint shards:  73% Completed | 119/163 [02:47<00:58,  1.33s/it]
2026-02-27T23:32:53.3745898Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:32:53.3746405Z Loading safetensors checkpoint shards:  74% Completed | 120/163 [02:49<00:56,  1.31s/it]
2026-02-27T23:32:54.6793441Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:32:54.6793902Z Loading safetensors checkpoint shards:  74% Completed | 121/163 [02:50<00:54,  1.31s/it]
2026-02-27T23:32:55.9556875Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:32:55.9557371Z Loading safetensors checkpoint shards:  75% Completed | 122/163 [02:51<00:53,  1.30s/it]
2026-02-27T23:32:57.2268613Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:32:57.2269079Z Loading safetensors checkpoint shards:  75% Completed | 123/163 [02:53<00:51,  1.29s/it]
2026-02-27T23:32:58.5914001Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:32:58.5914557Z Loading safetensors checkpoint shards:  76% Completed | 124/163 [02:54<00:51,  1.31s/it]
2026-02-27T23:32:59.8977023Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:32:59.8977548Z Loading safetensors checkpoint shards:  77% Completed | 125/163 [02:55<00:49,  1.31s/it]
2026-02-27T23:33:01.1716884Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:33:01.1717368Z Loading safetensors checkpoint shards:  77% Completed | 126/163 [02:57<00:48,  1.30s/it]
2026-02-27T23:33:02.5967415Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:33:02.5967968Z Loading safetensors checkpoint shards:  78% Completed | 127/163 [02:58<00:48,  1.34s/it]
2026-02-27T23:33:03.9578430Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:33:03.9578895Z Loading safetensors checkpoint shards:  79% Completed | 128/163 [02:59<00:47,  1.34s/it]
2026-02-27T23:33:05.2891574Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:33:05.2892145Z Loading safetensors checkpoint shards:  79% Completed | 129/163 [03:01<00:45,  1.34s/it]
2026-02-27T23:33:06.7207656Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:33:06.7208213Z Loading safetensors checkpoint shards:  80% Completed | 130/163 [03:02<00:45,  1.37s/it]
2026-02-27T23:33:08.0710083Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:33:08.0710540Z Loading safetensors checkpoint shards:  80% Completed | 131/163 [03:03<00:43,  1.36s/it]
2026-02-27T23:33:09.4126797Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:33:09.4127280Z Loading safetensors checkpoint shards:  81% Completed | 132/163 [03:05<00:42,  1.36s/it]
2026-02-27T23:33:10.7947101Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:33:10.7947664Z Loading safetensors checkpoint shards:  82% Completed | 133/163 [03:06<00:40,  1.36s/it]
2026-02-27T23:33:12.0422528Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:33:12.0423187Z Loading safetensors checkpoint shards:  82% Completed | 134/163 [03:07<00:38,  1.33s/it]
2026-02-27T23:33:13.4223984Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:33:13.4224436Z Loading safetensors checkpoint shards:  83% Completed | 135/163 [03:09<00:37,  1.34s/it]
2026-02-27T23:33:14.9251125Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:33:14.9251610Z Loading safetensors checkpoint shards:  83% Completed | 136/163 [03:10<00:37,  1.39s/it]
2026-02-27T23:33:16.3992103Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:33:16.3992612Z Loading safetensors checkpoint shards:  84% Completed | 137/163 [03:12<00:36,  1.42s/it]
2026-02-27T23:33:17.7976982Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:33:17.7977417Z Loading safetensors checkpoint shards:  85% Completed | 138/163 [03:13<00:35,  1.41s/it]
2026-02-27T23:33:19.1336079Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:33:19.1336544Z Loading safetensors checkpoint shards:  85% Completed | 139/163 [03:14<00:33,  1.39s/it]
2026-02-27T23:33:20.5756301Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:33:20.5756770Z Loading safetensors checkpoint shards:  86% Completed | 140/163 [03:16<00:32,  1.40s/it]
2026-02-27T23:33:22.1877274Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:33:22.1877808Z Loading safetensors checkpoint shards:  87% Completed | 141/163 [03:18<00:32,  1.47s/it]
2026-02-27T23:33:23.4920987Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:33:23.4921429Z Loading safetensors checkpoint shards:  87% Completed | 142/163 [03:19<00:29,  1.42s/it]
2026-02-27T23:33:24.8327139Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:33:24.8327607Z Loading safetensors checkpoint shards:  88% Completed | 143/163 [03:20<00:27,  1.39s/it]
2026-02-27T23:33:26.1189364Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:33:26.1189839Z Loading safetensors checkpoint shards:  88% Completed | 144/163 [03:21<00:25,  1.36s/it]
2026-02-27T23:33:27.4588390Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:33:27.4588934Z Loading safetensors checkpoint shards:  89% Completed | 145/163 [03:23<00:24,  1.36s/it]
2026-02-27T23:33:28.7699768Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:33:28.7700213Z Loading safetensors checkpoint shards:  90% Completed | 146/163 [03:24<00:22,  1.34s/it]
2026-02-27T23:33:30.0899187Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:33:30.0899788Z Loading safetensors checkpoint shards:  90% Completed | 147/163 [03:25<00:21,  1.34s/it]
2026-02-27T23:33:31.5001085Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:33:31.5001633Z Loading safetensors checkpoint shards:  91% Completed | 148/163 [03:27<00:20,  1.36s/it]
2026-02-27T23:33:32.8206469Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:33:32.8207059Z Loading safetensors checkpoint shards:  91% Completed | 149/163 [03:28<00:18,  1.35s/it]
2026-02-27T23:33:34.0703430Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:33:34.0704064Z Loading safetensors checkpoint shards:  92% Completed | 150/163 [03:29<00:17,  1.32s/it]
2026-02-27T23:33:35.4416700Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:33:35.4417341Z Loading safetensors checkpoint shards:  93% Completed | 151/163 [03:31<00:16,  1.33s/it]
2026-02-27T23:33:36.7036319Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:33:36.7036798Z Loading safetensors checkpoint shards:  93% Completed | 152/163 [03:32<00:14,  1.31s/it]
2026-02-27T23:33:38.2837338Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:33:38.2837839Z Loading safetensors checkpoint shards:  94% Completed | 153/163 [03:34<00:13,  1.39s/it]
2026-02-27T23:33:39.6747204Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:33:39.6747683Z Loading safetensors checkpoint shards:  94% Completed | 154/163 [03:35<00:12,  1.39s/it]
2026-02-27T23:33:40.9278752Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:33:40.9279219Z Loading safetensors checkpoint shards:  95% Completed | 155/163 [03:36<00:10,  1.35s/it]
2026-02-27T23:33:42.2307589Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:33:42.2308157Z Loading safetensors checkpoint shards:  96% Completed | 156/163 [03:38<00:09,  1.34s/it]
2026-02-27T23:33:43.6328199Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:33:43.6328855Z Loading safetensors checkpoint shards:  96% Completed | 157/163 [03:39<00:08,  1.36s/it]
2026-02-27T23:33:46.5597434Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:33:46.5597849Z Loading safetensors checkpoint shards:  97% Completed | 158/163 [03:42<00:09,  1.83s/it]
2026-02-27T23:33:47.8337471Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:33:47.8337908Z Loading safetensors checkpoint shards:  98% Completed | 159/163 [03:43<00:06,  1.66s/it]
2026-02-27T23:33:49.5002717Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:33:49.5003161Z Loading safetensors checkpoint shards:  98% Completed | 160/163 [03:45<00:04,  1.66s/it]
2026-02-27T23:33:54.3303870Z (Worker_DP0_TP4_EP4 pid=1391) INFO 02-27 23:33:54 [eagle_proposer.py:237] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-02-27T23:33:54.3764235Z (Worker_DP1_TP4_EP12 pid=1388) INFO 02-27 23:33:54 [eagle_proposer.py:237] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-02-27T23:33:54.4453791Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:33:54.4454369Z Loading safetensors checkpoint shards:  99% Completed | 161/163 [03:50<00:05,  2.65s/it]
2026-02-27T23:33:54.4484434Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:33:54.4484824Z Loading safetensors checkpoint shards: 100% Completed | 163/163 [03:50<00:00,  1.41s/it]
2026-02-27T23:33:54.4485245Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:33:54.4697487Z (Worker_DP0_TP5_EP5 pid=1495) INFO 02-27 23:33:54 [eagle_proposer.py:237] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-02-27T23:33:54.4748236Z (Worker_DP1_TP0_EP8 pid=1041) INFO 02-27 23:33:54 [default_loader.py:293] Loading weights took 230.21 seconds
2026-02-27T23:33:54.4966292Z (Worker_DP0_TP7_EP7 pid=1703) INFO 02-27 23:33:54 [eagle_proposer.py:237] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-02-27T23:33:54.5273185Z (Worker_DP1_TP3_EP11 pid=1284) INFO 02-27 23:33:54 [eagle_proposer.py:237] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-02-27T23:33:54.5284284Z (Worker_DP1_TP5_EP13 pid=1492) INFO 02-27 23:33:54 [eagle_proposer.py:237] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-02-27T23:33:54.5339725Z (Worker_DP0_TP0_EP0 pid=1040) INFO 02-27 23:33:54 [default_loader.py:293] Loading weights took 230.40 seconds
2026-02-27T23:33:54.5360460Z (Worker_DP1_TP0_EP8 pid=1041) INFO 02-27 23:33:54 [eagle_proposer.py:237] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-02-27T23:33:54.5489497Z (Worker_DP1_TP2_EP10 pid=1180) INFO 02-27 23:33:54 [eagle_proposer.py:237] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-02-27T23:33:54.5542410Z (Worker_DP1_TP7_EP15 pid=1700) INFO 02-27 23:33:54 [eagle_proposer.py:237] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-02-27T23:33:54.5722603Z (Worker_DP1_TP1_EP9 pid=1074) INFO 02-27 23:33:54 [eagle_proposer.py:237] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-02-27T23:33:54.5869176Z (Worker_DP1_TP6_EP14 pid=1596) INFO 02-27 23:33:54 [eagle_proposer.py:237] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-02-27T23:33:54.5939136Z (Worker_DP0_TP0_EP0 pid=1040) INFO 02-27 23:33:54 [eagle_proposer.py:237] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-02-27T23:33:54.6094081Z (Worker_DP0_TP2_EP2 pid=1183) INFO 02-27 23:33:54 [eagle_proposer.py:237] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-02-27T23:33:54.6352987Z (Worker_DP0_TP3_EP3 pid=1287) INFO 02-27 23:33:54 [eagle_proposer.py:237] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-02-27T23:33:54.6554420Z (Worker_DP0_TP1_EP1 pid=1077) INFO 02-27 23:33:54 [eagle_proposer.py:237] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-02-27T23:33:54.6768194Z (Worker_DP0_TP6_EP6 pid=1599) INFO 02-27 23:33:54 [eagle_proposer.py:237] Detected MTP model. Sharing target model embedding weights with the draft model.
2026-02-27T23:33:55.3699527Z (Worker_DP1_TP3_EP11 pid=1284) INFO 02-27 23:33:55 [model_runner_v1.py:2368] Loading model weights took 50.2985 GB
2026-02-27T23:33:55.4477870Z (Worker_DP0_TP3_EP3 pid=1287) INFO 02-27 23:33:55 [model_runner_v1.py:2368] Loading model weights took 50.2985 GB
2026-02-27T23:33:56.8145512Z (Worker_DP1_TP6_EP14 pid=1596) INFO 02-27 23:33:56 [model_runner_v1.py:2368] Loading model weights took 50.2985 GB
2026-02-27T23:33:57.1361687Z (Worker_DP0_TP0_EP0 pid=1040) INFO 02-27 23:33:57 [model_runner_v1.py:2368] Loading model weights took 50.2985 GB
2026-02-27T23:33:57.5063491Z (Worker_DP0_TP4_EP4 pid=1391) INFO 02-27 23:33:57 [model_runner_v1.py:2368] Loading model weights took 50.2985 GB
2026-02-27T23:33:57.5659747Z (Worker_DP1_TP4_EP12 pid=1388) INFO 02-27 23:33:57 [model_runner_v1.py:2368] Loading model weights took 50.2985 GB
2026-02-27T23:33:57.6680337Z (Worker_DP1_TP1_EP9 pid=1074) INFO 02-27 23:33:57 [model_runner_v1.py:2368] Loading model weights took 50.2985 GB
2026-02-27T23:33:57.7802587Z (Worker_DP0_TP1_EP1 pid=1077) INFO 02-27 23:33:57 [model_runner_v1.py:2368] Loading model weights took 50.2985 GB
2026-02-27T23:33:57.7948916Z (Worker_DP1_TP0_EP8 pid=1041) INFO 02-27 23:33:57 [model_runner_v1.py:2368] Loading model weights took 50.2985 GB
2026-02-27T23:33:57.8555505Z (Worker_DP1_TP7_EP15 pid=1700) INFO 02-27 23:33:57 [model_runner_v1.py:2368] Loading model weights took 50.2985 GB
2026-02-27T23:33:57.9158610Z (Worker_DP0_TP6_EP6 pid=1599) INFO 02-27 23:33:57 [model_runner_v1.py:2368] Loading model weights took 50.2985 GB
2026-02-27T23:33:57.9700526Z (Worker_DP0_TP5_EP5 pid=1495) INFO 02-27 23:33:57 [model_runner_v1.py:2368] Loading model weights took 50.2985 GB
2026-02-27T23:33:58.1556401Z (Worker_DP1_TP2_EP10 pid=1180) INFO 02-27 23:33:58 [model_runner_v1.py:2368] Loading model weights took 50.2985 GB
2026-02-27T23:33:58.2253699Z (Worker_DP0_TP2_EP2 pid=1183) INFO 02-27 23:33:58 [model_runner_v1.py:2368] Loading model weights took 50.2985 GB
2026-02-27T23:33:58.2302959Z (Worker_DP1_TP5_EP13 pid=1492) INFO 02-27 23:33:58 [model_runner_v1.py:2368] Loading model weights took 50.2985 GB
2026-02-27T23:33:58.2505481Z (Worker_DP0_TP7_EP7 pid=1703) INFO 02-27 23:33:58 [model_runner_v1.py:2368] Loading model weights took 50.2985 GB
2026-02-27T23:34:03.8322157Z (Worker_DP1_TP0_EP8 pid=1041) INFO 02-27 23:34:03 [backends.py:916] Using cache directory: /root/.cache/vllm/torch_compile_cache/270dc2acfb/rank_0_1/backbone for vLLM's torch.compile
2026-02-27T23:34:03.8437291Z (Worker_DP1_TP0_EP8 pid=1041) INFO 02-27 23:34:03 [backends.py:976] Dynamo bytecode transform time: 5.10 s
2026-02-27T23:34:03.8779629Z (Worker_DP0_TP0_EP0 pid=1040) INFO 02-27 23:34:03 [backends.py:916] Using cache directory: /root/.cache/vllm/torch_compile_cache/270dc2acfb/rank_0_0/backbone for vLLM's torch.compile
2026-02-27T23:34:03.8897546Z (Worker_DP0_TP0_EP0 pid=1040) INFO 02-27 23:34:03 [backends.py:976] Dynamo bytecode transform time: 5.15 s
2026-02-27T23:34:10.4090661Z (Worker_DP1_TP3_EP11 pid=1284) /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in reduce-overhead mode: config.experimental_config.enable_view_optimize:True, set_dim_gears, dynamo_export, scope, npu_print
2026-02-27T23:34:10.4091838Z (Worker_DP1_TP3_EP11 pid=1284)   warnings.warn(
2026-02-27T23:34:10.4281206Z (Worker_DP1_TP0_EP8 pid=1041) /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in reduce-overhead mode: config.experimental_config.enable_view_optimize:True, set_dim_gears, dynamo_export, scope, npu_print
2026-02-27T23:34:10.4282502Z (Worker_DP1_TP0_EP8 pid=1041)   warnings.warn(
2026-02-27T23:34:10.4640464Z (Worker_DP0_TP3_EP3 pid=1287) /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in reduce-overhead mode: config.experimental_config.enable_view_optimize:True, set_dim_gears, dynamo_export, scope, npu_print
2026-02-27T23:34:10.4658746Z (Worker_DP0_TP3_EP3 pid=1287)   warnings.warn(
2026-02-27T23:34:10.4715335Z (Worker_DP1_TP6_EP14 pid=1596) /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in reduce-overhead mode: config.experimental_config.enable_view_optimize:True, set_dim_gears, dynamo_export, scope, npu_print
2026-02-27T23:34:10.4716502Z (Worker_DP1_TP6_EP14 pid=1596)   warnings.warn(
2026-02-27T23:34:10.4717513Z (Worker_DP1_TP1_EP9 pid=1074) /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in reduce-overhead mode: config.experimental_config.enable_view_optimize:True, set_dim_gears, dynamo_export, scope, npu_print
2026-02-27T23:34:10.4718706Z (Worker_DP1_TP1_EP9 pid=1074)   warnings.warn(
2026-02-27T23:34:10.4758604Z (Worker_DP1_TP7_EP15 pid=1700) /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in reduce-overhead mode: config.experimental_config.enable_view_optimize:True, set_dim_gears, dynamo_export, scope, npu_print
2026-02-27T23:34:10.4759631Z (Worker_DP1_TP7_EP15 pid=1700)   warnings.warn(
2026-02-27T23:34:10.4910788Z (Worker_DP0_TP2_EP2 pid=1183) /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in reduce-overhead mode: config.experimental_config.enable_view_optimize:True, set_dim_gears, dynamo_export, scope, npu_print
2026-02-27T23:34:10.4912189Z (Worker_DP0_TP2_EP2 pid=1183)   warnings.warn(
2026-02-27T23:34:10.4931349Z (Worker_DP0_TP1_EP1 pid=1077) /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in reduce-overhead mode: config.experimental_config.enable_view_optimize:True, set_dim_gears, dynamo_export, scope, npu_print
2026-02-27T23:34:10.4932498Z (Worker_DP0_TP1_EP1 pid=1077)   warnings.warn(
2026-02-27T23:34:10.4996491Z (Worker_DP1_TP4_EP12 pid=1388) /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in reduce-overhead mode: config.experimental_config.enable_view_optimize:True, set_dim_gears, dynamo_export, scope, npu_print
2026-02-27T23:34:10.4997619Z (Worker_DP1_TP4_EP12 pid=1388)   warnings.warn(
2026-02-27T23:34:10.5020432Z (Worker_DP0_TP5_EP5 pid=1495) /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in reduce-overhead mode: config.experimental_config.enable_view_optimize:True, set_dim_gears, dynamo_export, scope, npu_print
2026-02-27T23:34:10.5021500Z (Worker_DP0_TP5_EP5 pid=1495)   warnings.warn(
2026-02-27T23:34:10.5030163Z (Worker_DP0_TP4_EP4 pid=1391) /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in reduce-overhead mode: config.experimental_config.enable_view_optimize:True, set_dim_gears, dynamo_export, scope, npu_print
2026-02-27T23:34:10.5031186Z (Worker_DP0_TP4_EP4 pid=1391)   warnings.warn(
2026-02-27T23:34:10.5049202Z (Worker_DP0_TP6_EP6 pid=1599) /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in reduce-overhead mode: config.experimental_config.enable_view_optimize:True, set_dim_gears, dynamo_export, scope, npu_print
2026-02-27T23:34:10.5050209Z (Worker_DP0_TP6_EP6 pid=1599)   warnings.warn(
2026-02-27T23:34:10.5065138Z (Worker_DP1_TP5_EP13 pid=1492) /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in reduce-overhead mode: config.experimental_config.enable_view_optimize:True, set_dim_gears, dynamo_export, scope, npu_print
2026-02-27T23:34:10.5066156Z (Worker_DP1_TP5_EP13 pid=1492)   warnings.warn(
2026-02-27T23:34:10.5144724Z (Worker_DP0_TP7_EP7 pid=1703) /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in reduce-overhead mode: config.experimental_config.enable_view_optimize:True, set_dim_gears, dynamo_export, scope, npu_print
2026-02-27T23:34:10.5145802Z (Worker_DP0_TP7_EP7 pid=1703)   warnings.warn(
2026-02-27T23:34:10.5268716Z (Worker_DP1_TP2_EP10 pid=1180) /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in reduce-overhead mode: config.experimental_config.enable_view_optimize:True, set_dim_gears, dynamo_export, scope, npu_print
2026-02-27T23:34:10.5269693Z (Worker_DP1_TP2_EP10 pid=1180)   warnings.warn(
2026-02-27T23:34:10.5690083Z (Worker_DP0_TP0_EP0 pid=1040) /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in reduce-overhead mode: config.experimental_config.enable_view_optimize:True, set_dim_gears, dynamo_export, scope, npu_print
2026-02-27T23:34:10.5691151Z (Worker_DP0_TP0_EP0 pid=1040)   warnings.warn(
2026-02-27T23:34:23.1914570Z (Worker_DP1_TP0_EP8 pid=1041) INFO 02-27 23:34:23 [backends.py:368] Compiling a graph for compile range (1, 8196) takes 12.84 s
2026-02-27T23:34:23.1915238Z (Worker_DP1_TP0_EP8 pid=1041) INFO 02-27 23:34:23 [monitor.py:34] torch.compile takes 17.94 s in total
2026-02-27T23:34:23.6560147Z (Worker_DP0_TP0_EP0 pid=1040) INFO 02-27 23:34:23 [backends.py:368] Compiling a graph for compile range (1, 8196) takes 13.16 s
2026-02-27T23:34:23.6560759Z (Worker_DP0_TP0_EP0 pid=1040) INFO 02-27 23:34:23 [monitor.py:34] torch.compile takes 18.31 s in total
2026-02-27T23:34:27.3952884Z (Worker_DP0_TP0_EP0 pid=1040) INFO 02-27 23:34:27 [worker.py:359] Available KV cache memory: 5.17 GiB
2026-02-27T23:34:27.4267475Z (Worker_DP1_TP0_EP8 pid=1041) INFO 02-27 23:34:27 [worker.py:359] Available KV cache memory: 5.18 GiB
2026-02-27T23:34:27.4819675Z (EngineCore_DP0 pid=995) INFO 02-27 23:34:27 [kv_cache_utils.py:1307] GPU KV cache size: 63,616 tokens
2026-02-27T23:34:27.4820331Z (EngineCore_DP0 pid=995) INFO 02-27 23:34:27 [kv_cache_utils.py:1312] Maximum concurrency for 8,192 tokens per request: 7.77x
2026-02-27T23:34:27.5036799Z (EngineCore_DP1 pid=1014) INFO 02-27 23:34:27 [kv_cache_utils.py:1307] GPU KV cache size: 63,744 tokens
2026-02-27T23:34:27.5037676Z (EngineCore_DP1 pid=1014) INFO 02-27 23:34:27 [kv_cache_utils.py:1312] Maximum concurrency for 8,192 tokens per request: 7.78x
2026-02-27T23:34:28.0061299Z (Worker_DP0_TP0_EP0 pid=1040) 
2026-02-27T23:34:42.3583814Z Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s][rank10]:[W227 23:34:42.799556722 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-02-27T23:34:42.3584828Z [rank11]:[W227 23:34:42.799558113 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-02-27T23:34:42.3585926Z [rank3]:[W227 23:34:42.799558052 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-02-27T23:34:42.3586642Z [rank12]:[W227 23:34:42.799558052 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-02-27T23:34:42.3587348Z [rank15]:[W227 23:34:42.799564493 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-02-27T23:34:42.3588061Z [rank2]:[W227 23:34:42.799567743 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-02-27T23:34:42.3588759Z [rank14]:[W227 23:34:42.799574873 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-02-27T23:34:42.3589459Z [rank1]:[W227 23:34:42.799574803 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-02-27T23:34:42.3590153Z [rank9]:[W227 23:34:42.799574743 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-02-27T23:34:42.3590831Z [rank6]:[W227 23:34:42.799583893 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-02-27T23:34:42.3591589Z [rank13]:[W227 23:34:42.799587383 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-02-27T23:34:42.3592540Z [rank8]:[W227 23:34:42.799639653 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-02-27T23:34:42.3593209Z [rank0]:[W227 23:34:42.799813695 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-02-27T23:34:42.3593888Z [rank7]:[W227 23:34:42.805695631 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-02-27T23:34:42.3594581Z [rank4]:[W227 23:34:42.809297519 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-02-27T23:34:42.3595310Z [rank5]:[W227 23:34:42.812607705 compiler_depend.ts:207] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())
2026-02-27T23:34:45.2284454Z [rank13]:[W227 23:34:45.681650137 compiler_depend.ts:3667] Warning: Tensor not is not allocated by NPUCachingAllocator, skip eraseStream. (function operator())
2026-02-27T23:34:45.2285258Z [rank9]:[W227 23:34:45.682052680 compiler_depend.ts:3667] Warning: Tensor not is not allocated by NPUCachingAllocator, skip eraseStream. (function operator())
2026-02-27T23:34:45.2303492Z [rank10]:[W227 23:34:45.684073616 compiler_depend.ts:3667] Warning: Tensor not is not allocated by NPUCachingAllocator, skip eraseStream. (function operator())
2026-02-27T23:34:45.2313675Z [rank15]:[W227 23:34:45.685082014 compiler_depend.ts:3667] Warning: Tensor not is not allocated by NPUCachingAllocator, skip eraseStream. (function operator())
2026-02-27T23:34:45.2314758Z [rank14]:[W227 23:34:45.685209435 compiler_depend.ts:3667] Warning: Tensor not is not allocated by NPUCachingAllocator, skip eraseStream. (function operator())
2026-02-27T23:34:45.2318889Z [rank12]:[W227 23:34:45.685634888 compiler_depend.ts:3667] Warning: Tensor not is not allocated by NPUCachingAllocator, skip eraseStream. (function operator())
2026-02-27T23:34:45.2319689Z [rank11]:[W227 23:34:45.685675928 compiler_depend.ts:3667] Warning: Tensor not is not allocated by NPUCachingAllocator, skip eraseStream. (function operator())
2026-02-27T23:34:45.2323510Z [rank8]:[W227 23:34:45.686020221 compiler_depend.ts:3667] Warning: Tensor not is not allocated by NPUCachingAllocator, skip eraseStream. (function operator())
2026-02-27T23:34:45.2330297Z [rank1]:[W227 23:34:45.686784027 compiler_depend.ts:3667] Warning: Tensor not is not allocated by NPUCachingAllocator, skip eraseStream. (function operator())
2026-02-27T23:34:45.2349340Z [rank4]:[W227 23:34:45.688661662 compiler_depend.ts:3667] Warning: Tensor not is not allocated by NPUCachingAllocator, skip eraseStream. (function operator())
2026-02-27T23:34:45.2351494Z [rank3]:[W227 23:34:45.688830573 compiler_depend.ts:3667] Warning: Tensor not is not allocated by NPUCachingAllocator, skip eraseStream. (function operator())
2026-02-27T23:34:45.2354650Z [rank2]:[W227 23:34:45.689224606 compiler_depend.ts:3667] Warning: Tensor not is not allocated by NPUCachingAllocator, skip eraseStream. (function operator())
2026-02-27T23:34:45.2356545Z [rank7]:[W227 23:34:45.689417168 compiler_depend.ts:3667] Warning: Tensor not is not allocated by NPUCachingAllocator, skip eraseStream. (function operator())
2026-02-27T23:34:45.2361518Z [rank6]:[W227 23:34:45.689901112 compiler_depend.ts:3667] Warning: Tensor not is not allocated by NPUCachingAllocator, skip eraseStream. (function operator())
2026-02-27T23:34:45.2376319Z [rank0]:[W227 23:34:45.691378093 compiler_depend.ts:3667] Warning: Tensor not is not allocated by NPUCachingAllocator, skip eraseStream. (function operator())
2026-02-27T23:34:45.2380317Z [rank5]:[W227 23:34:45.691796076 compiler_depend.ts:3667] Warning: Tensor not is not allocated by NPUCachingAllocator, skip eraseStream. (function operator())
2026-02-27T23:34:45.2496753Z 
2026-02-27T23:34:51.2100956Z Capturing CUDA graphs (decode, FULL):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:17<00:17, 17.24s/it]
2026-02-27T23:34:51.2101874Z Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:23<00:00, 10.61s/it]
2026-02-27T23:34:51.2102377Z Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:23<00:00, 11.60s/it]
2026-02-27T23:34:51.6626863Z (Worker_DP1_TP0_EP8 pid=1041) INFO 02-27 23:34:51 [gpu_model_runner.py:5246] Graph capturing finished in 24 secs, took 0.26 GiB
2026-02-27T23:34:51.6688357Z (Worker_DP0_TP0_EP0 pid=1040) INFO 02-27 23:34:51 [gpu_model_runner.py:5246] Graph capturing finished in 24 secs, took 0.25 GiB
2026-02-27T23:34:51.6986845Z (EngineCore_DP0 pid=995) INFO 02-27 23:34:51 [core.py:278] init engine (profile, create kv cache, warmup model) took 53.44 seconds
2026-02-27T23:34:51.7077803Z (EngineCore_DP1 pid=1014) INFO 02-27 23:34:51 [core.py:278] init engine (profile, create kv cache, warmup model) took 53.47 seconds
2026-02-27T23:34:52.6224111Z INFO 02-27 23:34:52 [coordinator.py:200] All engine subscriptions received by DP coordinator
2026-02-27T23:34:52.6224778Z (EngineCore_DP0 pid=995) INFO 02-27 23:34:52 [vllm.py:689] Asynchronous scheduling is enabled.
2026-02-27T23:34:52.6225251Z (EngineCore_DP1 pid=1014) INFO 02-27 23:34:52 [vllm.py:689] Asynchronous scheduling is enabled.
2026-02-27T23:34:52.6228305Z INFO 02-27 23:34:52 [utils.py:248] Waiting for API servers to complete ...
2026-02-27T23:34:52.6235017Z (EngineCore_DP1 pid=1014) INFO 02-27 23:34:52 [ascend_config.py:454] Dynamic EPLB is False
2026-02-27T23:34:52.6235527Z (EngineCore_DP0 pid=995) INFO 02-27 23:34:52 [ascend_config.py:454] Dynamic EPLB is False
2026-02-27T23:34:52.6235991Z (EngineCore_DP0 pid=995) INFO 02-27 23:34:52 [ascend_config.py:455] The number of redundant experts is 0
2026-02-27T23:34:52.6236523Z (EngineCore_DP1 pid=1014) INFO 02-27 23:34:52 [ascend_config.py:455] The number of redundant experts is 0
2026-02-27T23:34:52.6237478Z (EngineCore_DP0 pid=995) INFO 02-27 23:34:52 [ascend_config.py:55] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-27T23:34:52.6239372Z (EngineCore_DP1 pid=1014) INFO 02-27 23:34:52 [ascend_config.py:55] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-27T23:34:52.6240389Z (EngineCore_DP0 pid=995) INFO 02-27 23:34:52 [platform.py:301] FULL_DECODE_ONLY compilation enabled on NPU. use_inductor not supported - using only ACL Graph mode
2026-02-27T23:34:52.6241276Z (EngineCore_DP1 pid=1014) INFO 02-27 23:34:52 [platform.py:301] FULL_DECODE_ONLY compilation enabled on NPU. use_inductor not supported - using only ACL Graph mode
2026-02-27T23:34:52.6242108Z (EngineCore_DP0 pid=995) WARNING 02-27 23:34:52 [platform.py:318] [91m
2026-02-27T23:34:52.6242547Z (EngineCore_DP0 pid=995) WARNING 02-27 23:34:52 [platform.py:318]             **********************************************************************************
2026-02-27T23:34:52.6243091Z (EngineCore_DP0 pid=995) WARNING 02-27 23:34:52 [platform.py:318]             * WARNING: You have enabled the *full graph* feature.
2026-02-27T23:34:52.6243677Z (EngineCore_DP0 pid=995) WARNING 02-27 23:34:52 [platform.py:318]             * This is an early experimental stage and may involve various unknown issues.
2026-02-27T23:34:52.6244306Z (EngineCore_DP0 pid=995) WARNING 02-27 23:34:52 [platform.py:318]             * A known problem is that capturing too many batch sizes can lead to OOM
2026-02-27T23:34:52.6244995Z (EngineCore_DP0 pid=995) WARNING 02-27 23:34:52 [platform.py:318]             * (Out of Memory) errors or inference hangs. If you encounter such issues,
2026-02-27T23:34:52.6245628Z (EngineCore_DP0 pid=995) WARNING 02-27 23:34:52 [platform.py:318]             * consider reducing `gpu_memory_utilization` or manually specifying a smaller
2026-02-27T23:34:52.6246174Z (EngineCore_DP0 pid=995) WARNING 02-27 23:34:52 [platform.py:318]             * batch size for graph capture.
2026-02-27T23:34:52.6246879Z (EngineCore_DP0 pid=995) WARNING 02-27 23:34:52 [platform.py:318]             * For more details, please refer to:
2026-02-27T23:34:52.6247487Z (EngineCore_DP0 pid=995) WARNING 02-27 23:34:52 [platform.py:318]             * https://docs.vllm.ai/en/stable/configuration/conserving_memory.html#reduce-cuda-graphs
2026-02-27T23:34:52.6248207Z (EngineCore_DP0 pid=995) WARNING 02-27 23:34:52 [platform.py:318]             **********************************************************************************[0m
2026-02-27T23:34:52.6248653Z (EngineCore_DP0 pid=995) WARNING 02-27 23:34:52 [platform.py:318]             
2026-02-27T23:34:52.6249025Z (EngineCore_DP1 pid=1014) WARNING 02-27 23:34:52 [platform.py:318] [91m
2026-02-27T23:34:52.6249448Z (EngineCore_DP1 pid=1014) WARNING 02-27 23:34:52 [platform.py:318]             **********************************************************************************
2026-02-27T23:34:52.6249976Z (EngineCore_DP1 pid=1014) WARNING 02-27 23:34:52 [platform.py:318]             * WARNING: You have enabled the *full graph* feature.
2026-02-27T23:34:52.6250550Z (EngineCore_DP1 pid=1014) WARNING 02-27 23:34:52 [platform.py:318]             * This is an early experimental stage and may involve various unknown issues.
2026-02-27T23:34:52.6251160Z (EngineCore_DP1 pid=1014) WARNING 02-27 23:34:52 [platform.py:318]             * A known problem is that capturing too many batch sizes can lead to OOM
2026-02-27T23:34:52.6251772Z (EngineCore_DP1 pid=1014) WARNING 02-27 23:34:52 [platform.py:318]             * (Out of Memory) errors or inference hangs. If you encounter such issues,
2026-02-27T23:34:52.6252685Z (EngineCore_DP1 pid=1014) WARNING 02-27 23:34:52 [platform.py:318]             * consider reducing `gpu_memory_utilization` or manually specifying a smaller
2026-02-27T23:34:52.6253349Z (EngineCore_DP1 pid=1014) WARNING 02-27 23:34:52 [platform.py:318]             * batch size for graph capture.
2026-02-27T23:34:52.6253901Z (EngineCore_DP1 pid=1014) WARNING 02-27 23:34:52 [platform.py:318]             * For more details, please refer to:
2026-02-27T23:34:52.6254560Z (EngineCore_DP1 pid=1014) WARNING 02-27 23:34:52 [platform.py:318]             * https://docs.vllm.ai/en/stable/configuration/conserving_memory.html#reduce-cuda-graphs
2026-02-27T23:34:52.6255479Z (EngineCore_DP1 pid=1014) WARNING 02-27 23:34:52 [platform.py:318]             **********************************************************************************[0m
2026-02-27T23:34:52.6255917Z (EngineCore_DP1 pid=1014) WARNING 02-27 23:34:52 [platform.py:318]             
2026-02-27T23:34:52.6256416Z ERROR 02-27 23:34:52 [utils.py:289] Exception occurred while running API servers: Process ApiServer_0 (PID: 1025) died with exit code 1
2026-02-27T23:34:52.6256860Z ERROR 02-27 23:34:52 [utils.py:289] Traceback (most recent call last):
2026-02-27T23:34:52.6257295Z ERROR 02-27 23:34:52 [utils.py:289]   File "/vllm-workspace/vllm/vllm/v1/utils.py", line 276, in wait_for_completion_or_failure
2026-02-27T23:34:52.6257709Z ERROR 02-27 23:34:52 [utils.py:289]     raise RuntimeError(
2026-02-27T23:34:52.6258057Z ERROR 02-27 23:34:52 [utils.py:289] RuntimeError: Process ApiServer_0 (PID: 1025) died with exit code 1
2026-02-27T23:34:52.6258435Z INFO 02-27 23:34:52 [utils.py:292] Terminating remaining processes ...
2026-02-27T23:34:52.6258829Z (EngineCore_DP0 pid=995) INFO 02-27 23:34:52 [platform.py:430] Set PYTORCH_NPU_ALLOC_CONF=expandable_segments:True
2026-02-27T23:34:52.6259326Z (EngineCore_DP1 pid=1014) INFO 02-27 23:34:52 [platform.py:430] Set PYTORCH_NPU_ALLOC_CONF=expandable_segments:True
2026-02-27T23:34:52.9044498Z (Worker_DP0_TP3_EP3 pid=1287) INFO 02-27 23:34:52 [multiproc_executor.py:732] Parent process exited, terminating worker
2026-02-27T23:34:52.9045230Z (Worker_DP1_TP3_EP11 pid=1284) INFO 02-27 23:34:52 [multiproc_executor.py:732] Parent process exited, terminating worker
2026-02-27T23:34:52.9045765Z (Worker_DP0_TP0_EP0 pid=1040) INFO 02-27 23:34:52 [multiproc_executor.py:732] Parent process exited, terminating worker
2026-02-27T23:34:52.9046663Z (Worker_DP0_TP2_EP2 pid=1183) INFO 02-27 23:34:52 [multiproc_executor.py:732] Parent process exited, terminating worker
2026-02-27T23:34:52.9047176Z (Worker_DP1_TP2_EP10 pid=1180) INFO 02-27 23:34:52 [multiproc_executor.py:732] Parent process exited, terminating worker
2026-02-27T23:34:52.9047692Z (Worker_DP0_TP4_EP4 pid=1391) INFO 02-27 23:34:52 [multiproc_executor.py:732] Parent process exited, terminating worker
2026-02-27T23:34:52.9048185Z (Worker_DP0_TP7_EP7 pid=1703) INFO 02-27 23:34:52 [multiproc_executor.py:732] Parent process exited, terminating worker
2026-02-27T23:34:52.9048673Z (Worker_DP0_TP1_EP1 pid=1077) INFO 02-27 23:34:52 [multiproc_executor.py:732] Parent process exited, terminating worker
2026-02-27T23:34:52.9049173Z (Worker_DP1_TP4_EP12 pid=1388) INFO 02-27 23:34:52 [multiproc_executor.py:732] Parent process exited, terminating worker
2026-02-27T23:34:52.9049663Z (Worker_DP1_TP6_EP14 pid=1596) INFO 02-27 23:34:52 [multiproc_executor.py:732] Parent process exited, terminating worker
2026-02-27T23:34:52.9050158Z (Worker_DP0_TP5_EP5 pid=1495) INFO 02-27 23:34:52 [multiproc_executor.py:732] Parent process exited, terminating worker
2026-02-27T23:34:52.9050654Z (Worker_DP1_TP5_EP13 pid=1492) INFO 02-27 23:34:52 [multiproc_executor.py:732] Parent process exited, terminating worker
2026-02-27T23:34:52.9051119Z (Worker_DP0_TP3_EP3 pid=1287) INFO 02-27 23:34:52 [multiproc_executor.py:785] WorkerProc shutting down.
2026-02-27T23:34:52.9051545Z (Worker_DP1_TP3_EP11 pid=1284) INFO 02-27 23:34:52 [multiproc_executor.py:785] WorkerProc shutting down.
2026-02-27T23:34:52.9052099Z (Worker_DP0_TP6_EP6 pid=1599) INFO 02-27 23:34:52 [multiproc_executor.py:732] Parent process exited, terminating worker
2026-02-27T23:34:52.9052571Z (Worker_DP0_TP0_EP0 pid=1040) INFO 02-27 23:34:52 [multiproc_executor.py:785] WorkerProc shutting down.
2026-02-27T23:34:52.9053026Z (Worker_DP1_TP0_EP8 pid=1041) INFO 02-27 23:34:52 [multiproc_executor.py:732] Parent process exited, terminating worker
2026-02-27T23:34:52.9053485Z (Worker_DP0_TP2_EP2 pid=1183) INFO 02-27 23:34:52 [multiproc_executor.py:785] WorkerProc shutting down.
2026-02-27T23:34:52.9053918Z (Worker_DP1_TP2_EP10 pid=1180) INFO 02-27 23:34:52 [multiproc_executor.py:785] WorkerProc shutting down.
2026-02-27T23:34:52.9054448Z (Worker_DP0_TP4_EP4 pid=1391) INFO 02-27 23:34:52 [multiproc_executor.py:785] WorkerProc shutting down.
2026-02-27T23:34:52.9054930Z (Worker_DP0_TP1_EP1 pid=1077) INFO 02-27 23:34:52 [multiproc_executor.py:785] WorkerProc shutting down.
2026-02-27T23:34:52.9055389Z (Worker_DP0_TP7_EP7 pid=1703) INFO 02-27 23:34:52 [multiproc_executor.py:785] WorkerProc shutting down.
2026-02-27T23:34:52.9055852Z (Worker_DP1_TP7_EP15 pid=1700) INFO 02-27 23:34:52 [multiproc_executor.py:732] Parent process exited, terminating worker
2026-02-27T23:34:52.9056324Z (Worker_DP1_TP4_EP12 pid=1388) INFO 02-27 23:34:52 [multiproc_executor.py:785] WorkerProc shutting down.
2026-02-27T23:34:52.9056745Z (Worker_DP1_TP6_EP14 pid=1596) INFO 02-27 23:34:52 [multiproc_executor.py:785] WorkerProc shutting down.
2026-02-27T23:34:52.9057218Z (Worker_DP1_TP1_EP9 pid=1074) INFO 02-27 23:34:52 [multiproc_executor.py:732] Parent process exited, terminating worker
2026-02-27T23:34:52.9057671Z (Worker_DP0_TP5_EP5 pid=1495) INFO 02-27 23:34:52 [multiproc_executor.py:785] WorkerProc shutting down.
2026-02-27T23:34:52.9058088Z (Worker_DP1_TP5_EP13 pid=1492) INFO 02-27 23:34:52 [multiproc_executor.py:785] WorkerProc shutting down.
2026-02-27T23:34:52.9058516Z (Worker_DP1_TP0_EP8 pid=1041) INFO 02-27 23:34:52 [multiproc_executor.py:785] WorkerProc shutting down.
2026-02-27T23:34:52.9058924Z (Worker_DP0_TP6_EP6 pid=1599) INFO 02-27 23:34:52 [multiproc_executor.py:785] WorkerProc shutting down.
2026-02-27T23:34:52.9059354Z (Worker_DP1_TP7_EP15 pid=1700) INFO 02-27 23:34:52 [multiproc_executor.py:785] WorkerProc shutting down.
2026-02-27T23:34:52.9059779Z (Worker_DP1_TP1_EP9 pid=1074) INFO 02-27 23:34:52 [multiproc_executor.py:785] WorkerProc shutting down.
2026-02-27T23:34:57.9345435Z Traceback (most recent call last):
2026-02-27T23:34:57.9345747Z   File "/usr/local/python3.11.14/bin/vllm", line 7, in <module>
2026-02-27T23:34:57.9378713Z     sys.exit(main())
2026-02-27T23:34:57.9380193Z              ^^^^^^
2026-02-27T23:34:57.9380483Z   File "/vllm-workspace/vllm/vllm/entrypoints/cli/main.py", line 73, in main
2026-02-27T23:34:57.9390987Z     args.dispatch_function(args)
2026-02-27T23:34:57.9391256Z   File "/vllm-workspace/vllm/vllm/entrypoints/cli/serve.py", line 108, in cmd
2026-02-27T23:34:57.9397597Z     run_multi_api_server(args)
2026-02-27T23:34:57.9398702Z   File "/vllm-workspace/vllm/vllm/entrypoints/cli/serve.py", line 282, in run_multi_api_server
2026-02-27T23:34:57.9399056Z     wait_for_completion_or_failure(
2026-02-27T23:34:57.9399365Z   File "/vllm-workspace/vllm/vllm/v1/utils.py", line 276, in wait_for_completion_or_failure
2026-02-27T23:34:57.9399675Z     raise RuntimeError(
2026-02-27T23:34:57.9399924Z RuntimeError: Process ApiServer_0 (PID: 1025) died with exit code 1
2026-02-27T23:34:58.0319528Z [ERROR] 2026-02-27-23:34:57 (PID:979, Device:-1, RankID:-1) ERR99999 UNKNOWN applicaiton exception
2026-02-27T23:34:58.3099157Z sys:1: DeprecationWarning: builtin type swigvarlink has no __module__ attribute
2026-02-27T23:34:59.8778978Z /usr/local/python3.11.14/lib/python3.11/multiprocessing/resource_tracker.py:254: UserWarning: resource_tracker: There appear to be 2 leaked shared_memory objects to clean up at shutdown
2026-02-27T23:34:59.8779639Z   warnings.warn('resource_tracker: There appear to be %d '
2026-02-27T23:35:04.8972485Z FAILED
2026-02-27T23:35:04.8972705Z 
2026-02-27T23:35:04.8972857Z =================================== FAILURES ===================================
2026-02-27T23:35:04.8973198Z _______________ test_models[2-8-vllm-ascend/DeepSeek-V3.2-W8A8] ________________
2026-02-27T23:35:04.8973415Z 
2026-02-27T23:35:04.8973543Z model = 'vllm-ascend/DeepSeek-V3.2-W8A8', tp_size = 8, dp_size = 2
2026-02-27T23:35:04.8973768Z 
2026-02-27T23:35:04.8973845Z     @pytest.mark.asyncio
2026-02-27T23:35:04.8974032Z     @pytest.mark.parametrize("model", MODELS)
2026-02-27T23:35:04.8974286Z     @pytest.mark.parametrize("tp_size", TENSOR_PARALLELS)
2026-02-27T23:35:04.8974553Z     @pytest.mark.parametrize("dp_size", DATA_PARALLELS)
2026-02-27T23:35:04.8975327Z     async def test_models(model: str, tp_size: int, dp_size: int) -> None:
2026-02-27T23:35:04.8975608Z         port = get_open_port()
2026-02-27T23:35:04.8975782Z         env_dict = {
2026-02-27T23:35:04.8975945Z             "HCCL_OP_EXPANSION_MODE": "AIV",
2026-02-27T23:35:04.8976145Z             "OMP_PROC_BIND": "false",
2026-02-27T23:35:04.8976333Z             "OMP_NUM_THREADS": "1",
2026-02-27T23:35:04.8976510Z             "HCCL_BUFFSIZE": "1024",
2026-02-27T23:35:04.8976703Z             "VLLM_ASCEND_ENABLE_MLAPO": "1",
2026-02-27T23:35:04.8976937Z             "PYTORCH_NPU_ALLOC_CONF": "expandable_segments:True",
2026-02-27T23:35:04.8977181Z             "VLLM_ASCEND_ENABLE_FLASHCOMM1": "1",
2026-02-27T23:35:04.8977373Z         }
2026-02-27T23:35:04.8977494Z     
2026-02-27T23:35:04.8977614Z         server_args = [
2026-02-27T23:35:04.8977830Z             "--enable-expert-parallel", "--tensor-parallel-size",
2026-02-27T23:35:04.8978161Z             str(tp_size), "--data-parallel-size",
2026-02-27T23:35:04.8978369Z             str(dp_size), "--port",
2026-02-27T23:35:04.8978614Z             str(port), "--max-model-len", "8192", "--max-num-batched-tokens",
2026-02-27T23:35:04.8978938Z             "8192", "--max-num-seqs", "4", "--trust-remote-code", "--quantization",
2026-02-27T23:35:04.8979281Z             "ascend", "--gpu-memory-utilization", "0.98", "--compilation-config",
2026-02-27T23:35:04.8979652Z             '{"cudagraph_capture_sizes":[8, 16, 24, 32, 40, 48], "cudagraph_mode":"FULL_DECODE_ONLY"}',
2026-02-27T23:35:04.8979946Z             "--speculative-config",
2026-02-27T23:35:04.8980177Z             '{"num_speculative_tokens": 3, "method":"deepseek_mtp"}',
2026-02-27T23:35:04.8980542Z             "--additional-config",
2026-02-27T23:35:04.8980754Z             '{"layer_sharding": ["q_b_proj", "o_proj"]}',
2026-02-27T23:35:04.8981040Z             "--reasoning-parser", "deepseek_v3", "--tokenizer_mode", "deepseek_v32"
2026-02-27T23:35:04.8981300Z         ]
2026-02-27T23:35:04.8981448Z         request_keyword_args: dict[str, Any] = {
2026-02-27T23:35:04.8981650Z             **api_keyword_args,
2026-02-27T23:35:04.8981800Z         }
2026-02-27T23:35:04.8981942Z >       with RemoteOpenAIServer(model,
2026-02-27T23:35:04.8982245Z                                 server_args,
2026-02-27T23:35:04.8982434Z                                 server_port=port,
2026-02-27T23:35:04.8982633Z                                 env_dict=env_dict,
2026-02-27T23:35:04.8982838Z                                 auto_port=False) as server:
2026-02-27T23:35:04.8982986Z 
2026-02-27T23:35:04.8983118Z tests/e2e/nightly/single_node/models/test_deepseek_v3_2_w8a8.py:107: 
2026-02-27T23:35:04.8983404Z _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
2026-02-27T23:35:04.8983646Z tests/e2e/conftest.py:306: in __init__
2026-02-27T23:35:04.8983840Z     self._wait_for_multiple_servers(
2026-02-27T23:35:04.8984053Z _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
2026-02-27T23:35:04.8984220Z 
2026-02-27T23:35:04.8984371Z self = <tests.e2e.conftest.RemoteOpenAIServer object at 0xffff16378c10>
2026-02-27T23:35:04.8984707Z targets = [('0.0.0.0', 'http://0.0.0.0:58945/health')], timeout = 2800
2026-02-27T23:35:04.8984937Z log_interval = 30.0
2026-02-27T23:35:04.8985025Z 
2026-02-27T23:35:04.8985093Z     def _wait_for_multiple_servers(self,
2026-02-27T23:35:04.8985279Z                                    targets,
2026-02-27T23:35:04.8985469Z                                    timeout: float,
2026-02-27T23:35:04.8985677Z                                    log_interval: float = 30.0):
2026-02-27T23:35:04.8985874Z         """
2026-02-27T23:35:04.8986014Z         targets: List[(node_ip, url)]
2026-02-27T23:35:04.8986189Z         log_interval
2026-02-27T23:35:04.8986324Z         """
2026-02-27T23:35:04.8986453Z         start = time.time()
2026-02-27T23:35:04.8986610Z         client = requests
2026-02-27T23:35:04.8986758Z     
2026-02-27T23:35:04.8987000Z         ready = {node_ip: False for node_ip, _ in targets}
2026-02-27T23:35:04.8987203Z     
2026-02-27T23:35:04.8987322Z         last_log_time = 0.0
2026-02-27T23:35:04.8987474Z     
2026-02-27T23:35:04.8987596Z         while True:
2026-02-27T23:35:04.8987737Z             now = time.time()
2026-02-27T23:35:04.8987903Z             all_ready = True
2026-02-27T23:35:04.8988166Z             should_log = (now - last_log_time) >= log_interval
2026-02-27T23:35:04.8988375Z     
2026-02-27T23:35:04.8988501Z             for node_ip, url in targets:
2026-02-27T23:35:04.8988687Z                 if ready[node_ip]:
2026-02-27T23:35:04.8988858Z                     continue
2026-02-27T23:35:04.8989010Z     
2026-02-27T23:35:04.8989124Z                 try:
2026-02-27T23:35:04.8989280Z                     resp = client.get(url)
2026-02-27T23:35:04.8989477Z                     if resp.status_code == 200:
2026-02-27T23:35:04.8989671Z                         ready[node_ip] = True
2026-02-27T23:35:04.8989921Z                         logger.info(f"[READY] Node {node_ip} is ready.")
2026-02-27T23:35:04.8990145Z                 except RequestException:
2026-02-27T23:35:04.8990340Z                     all_ready = False
2026-02-27T23:35:04.8990507Z                     if should_log:
2026-02-27T23:35:04.8990724Z                         logger.debug(f"[WAIT] {url}: connection failed")
2026-02-27T23:35:04.8990939Z     
2026-02-27T23:35:04.8991065Z                     # check unexpected exit
2026-02-27T23:35:04.8991257Z                     result = self._poll()
2026-02-27T23:35:04.8991458Z                     if result is not None and result != 0:
2026-02-27T23:35:04.8991665Z >                       raise RuntimeError(
2026-02-27T23:35:04.8991952Z                             f"Server at {node_ip} exited unexpectedly."
2026-02-27T23:35:04.8992286Z                         ) from None
2026-02-27T23:35:04.8992507Z E                       RuntimeError: Server at 0.0.0.0 exited unexpectedly.
2026-02-27T23:35:04.8992695Z 
2026-02-27T23:35:04.8992772Z tests/e2e/conftest.py:399: RuntimeError
2026-02-27T23:35:04.8993028Z ------------------------------ Captured log call -------------------------------
2026-02-27T23:35:04.8994770Z INFO     tests.e2e.conftest:conftest.py:241 Starting server with command: vllm serve vllm-ascend/DeepSeek-V3.2-W8A8 --enable-expert-parallel --tensor-parallel-size 8 --data-parallel-size 2 --port 58945 --max-model-len 8192 --max-num-batched-tokens 8192 --max-num-seqs 4 --trust-remote-code --quantization ascend --gpu-memory-utilization 0.98 --compilation-config {"cudagraph_capture_sizes":[8, 16, 24, 32, 40, 48], "cudagraph_mode":"FULL_DECODE_ONLY"} --speculative-config {"num_speculative_tokens": 3, "method":"deepseek_mtp"} --additional-config {"layer_sharding": ["q_b_proj", "o_proj"]} --reasoning-parser deepseek_v3 --tokenizer_mode deepseek_v32
2026-02-27T23:35:04.8996470Z =============================== warnings summary ===============================
2026-02-27T23:35:04.8996805Z <frozen importlib._bootstrap>:241
2026-02-27T23:35:04.8997170Z   <frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyPacked has no __module__ attribute
2026-02-27T23:35:04.8997463Z 
2026-02-27T23:35:04.8997530Z <frozen importlib._bootstrap>:241
2026-02-27T23:35:04.8997875Z   <frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyObject has no __module__ attribute
2026-02-27T23:35:04.8998219Z 
2026-02-27T23:35:04.8998456Z ../../usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647
2026-02-27T23:35:04.8999426Z   /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-27T23:35:04.9000243Z     warnings.warn(
2026-02-27T23:35:04.9000331Z 
2026-02-27T23:35:04.9000520Z ../../usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/__init__.py:8
2026-02-27T23:35:04.9001335Z   /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/__init__.py:8: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html
2026-02-27T23:35:04.9001937Z     import pkg_resources
2026-02-27T23:35:04.9002129Z 
2026-02-27T23:35:04.9002280Z -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
2026-02-27T23:35:04.9002596Z =========================== short test summary info ============================
2026-02-27T23:35:04.9003199Z FAILED tests/e2e/nightly/single_node/models/test_deepseek_v3_2_w8a8.py::test_models[2-8-vllm-ascend/DeepSeek-V3.2-W8A8] - RuntimeError: Server at 0.0.0.0 exited unexpectedly.
2026-02-27T23:35:04.9003756Z ================== 1 failed, 4 warnings in 1111.54s (0:18:31) ==================
2026-02-27T23:35:06.8994014Z ##[error]Error: failed to run script step: Error: command terminated with non-zero exit code: command terminated with exit code 1
2026-02-27T23:35:06.9031779Z ##[error]Process completed with exit code 1.
2026-02-27T23:35:06.9122892Z ##[error]Executing the custom container implementation failed. Please contact your self hosted runner administrator.
2026-02-27T23:35:06.9165729Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-27T23:35:06.9166400Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-27T23:35:06.9166637Z ##[endgroup]
2026-02-27T23:35:07.3771861Z Cleaning up orphan processes
