# Run ID: 22070488769
# Commit: f0caeeadcb37261beebd4a6e32934fa9f460db98
# Job: multi-node (multi-node-dpsk3.2-2node, DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml, 2) / DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
# Date: 2026-02-16
============================================================

ï»¿2026-02-16T17:10:37.6478235Z Current runner version: '2.330.0'
2026-02-16T17:10:37.6482837Z Runner name: 'linux-aarch64-a3-0-n4cwm-runner-gktkh'
2026-02-16T17:10:37.6483534Z Runner group name: 'Default'
2026-02-16T17:10:37.6484275Z Machine name: 'linux-aarch64-a3-0-n4cwm-runner-gktkh'
2026-02-16T17:10:37.6487563Z ##[group]GITHUB_TOKEN Permissions
2026-02-16T17:10:37.6489364Z Actions: write
2026-02-16T17:10:37.6489764Z ArtifactMetadata: write
2026-02-16T17:10:37.6490287Z Attestations: write
2026-02-16T17:10:37.6490679Z Checks: write
2026-02-16T17:10:37.6491026Z Contents: write
2026-02-16T17:10:37.6491434Z Deployments: write
2026-02-16T17:10:37.6491939Z Discussions: write
2026-02-16T17:10:37.6492473Z Issues: write
2026-02-16T17:10:37.6492871Z Metadata: read
2026-02-16T17:10:37.6493212Z Models: read
2026-02-16T17:10:37.6493584Z Packages: write
2026-02-16T17:10:37.6493970Z Pages: write
2026-02-16T17:10:37.6494315Z PullRequests: write
2026-02-16T17:10:37.6494773Z RepositoryProjects: write
2026-02-16T17:10:37.6495398Z SecurityEvents: write
2026-02-16T17:10:37.6495842Z Statuses: write
2026-02-16T17:10:37.6496236Z ##[endgroup]
2026-02-16T17:10:37.6497939Z Secret source: Actions
2026-02-16T17:10:37.6498415Z Prepare workflow directory
2026-02-16T17:10:37.7035548Z Prepare all required actions
2026-02-16T17:10:37.7066796Z Getting action download info
2026-02-16T17:10:39.1764769Z Download action repository 'actions/checkout@v6' (SHA:de0fac2e4500dabe0009e67214ff5f5447ce83dd)
2026-02-16T17:10:43.4500008Z Download action repository 'actions/upload-artifact@v6' (SHA:b7c566a772e6b6bfb58ed0dc250532a479d7789f)
2026-02-16T17:10:50.5380485Z Uses: vllm-project/vllm-ascend/.github/workflows/_e2e_nightly_multi_node.yaml@refs/heads/main (f0caeeadcb37261beebd4a6e32934fa9f460db98)
2026-02-16T17:10:50.5383812Z ##[group] Inputs
2026-02-16T17:10:50.5384133Z   soc_version: a3
2026-02-16T17:10:50.5384407Z   runner: linux-aarch64-a3-0
2026-02-16T17:10:50.5384839Z   image: swr.cn-southwest-2.myhuaweicloud.com/base_image/ascend-ci/vllm-ascend:nightly-a3
2026-02-16T17:10:50.5385390Z   config_file_path: DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-02-16T17:10:50.5385722Z   replicas: 1
2026-02-16T17:10:50.5385939Z   size: 2
2026-02-16T17:10:50.5386129Z   vllm_version: v0.15.0
2026-02-16T17:10:50.5386518Z   vllm_ascend_remote_url: https://github.com/vllm-project/vllm-ascend.git
2026-02-16T17:10:50.5386874Z   vllm_ascend_ref: main
2026-02-16T17:10:50.5387164Z ##[endgroup]
2026-02-16T17:10:50.5387670Z Complete job name: multi-node (multi-node-dpsk3.2-2node, DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml, 2) / DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-02-16T17:10:50.5877904Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-16T17:10:50.5880156Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-16T17:10:50.5880642Z ##[endgroup]
2026-02-16T17:11:06.1024822Z (node:69) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-16T17:11:06.1025692Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-16T17:11:07.9943811Z ##[group]Run # Decode and save kubeconfig
2026-02-16T17:11:07.9944234Z [36;1m# Decode and save kubeconfig[0m
2026-02-16T17:11:07.9976591Z [36;1mecho "***" | base64 -d > "$KUBECONFIG"[0m
2026-02-16T17:11:07.9977249Z shell: bash -el {0}
2026-02-16T17:11:07.9977483Z ##[endgroup]
2026-02-16T17:11:08.0100227Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-16T17:11:08.0101165Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-16T17:11:08.0101508Z ##[endgroup]
2026-02-16T17:11:08.3579949Z (node:400) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-16T17:11:08.3580771Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-16T17:11:09.2209672Z ##[group]Run actions/checkout@v6
2026-02-16T17:11:09.2210146Z with:
2026-02-16T17:11:09.2210461Z   repository: vllm-project/vllm-ascend
2026-02-16T17:11:09.2211176Z   token: ***
2026-02-16T17:11:09.2211395Z   ssh-strict: true
2026-02-16T17:11:09.2211634Z   ssh-user: git
2026-02-16T17:11:09.2211870Z   persist-credentials: true
2026-02-16T17:11:09.2212258Z   clean: true
2026-02-16T17:11:09.2212521Z   sparse-checkout-cone-mode: true
2026-02-16T17:11:09.2212819Z   fetch-depth: 1
2026-02-16T17:11:09.2213078Z   fetch-tags: false
2026-02-16T17:11:09.2213316Z   show-progress: true
2026-02-16T17:11:09.2213502Z   lfs: false
2026-02-16T17:11:09.2213738Z   submodules: false
2026-02-16T17:11:09.2213970Z   set-safe-directory: true
2026-02-16T17:11:09.2214178Z ##[endgroup]
2026-02-16T17:11:09.2255958Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-16T17:11:09.2256972Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-16T17:11:09.2257312Z ##[endgroup]
2026-02-16T17:11:09.5760646Z (node:431) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-16T17:11:09.5761575Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-16T17:11:10.1606839Z Syncing repository: vllm-project/vllm-ascend
2026-02-16T17:11:10.1607893Z ##[group]Getting Git version info
2026-02-16T17:11:10.1608249Z Working directory is '/__w/vllm-ascend/vllm-ascend'
2026-02-16T17:11:10.1608750Z [command]/usr/bin/git version
2026-02-16T17:11:10.1709507Z git version 2.34.1
2026-02-16T17:11:10.1726193Z ##[endgroup]
2026-02-16T17:11:10.1733987Z Copying '/root/.gitconfig' to '/__w/_temp/acc348cb-bf3f-42d8-8e7c-f3b9f407eae6/.gitconfig'
2026-02-16T17:11:10.1744515Z Temporarily overriding HOME='/__w/_temp/acc348cb-bf3f-42d8-8e7c-f3b9f407eae6' before making global git config changes
2026-02-16T17:11:10.1745201Z Adding repository directory to the temporary git global config as a safe directory
2026-02-16T17:11:10.1748471Z [command]/usr/bin/git config --global --add safe.directory /__w/vllm-ascend/vllm-ascend
2026-02-16T17:11:10.1784711Z Deleting the contents of '/__w/vllm-ascend/vllm-ascend'
2026-02-16T17:11:10.1787093Z ##[group]Initializing the repository
2026-02-16T17:11:10.1790644Z [command]/usr/bin/git init /__w/vllm-ascend/vllm-ascend
2026-02-16T17:11:10.1898378Z hint: Using 'master' as the name for the initial branch. This default branch name
2026-02-16T17:11:10.1898877Z hint: is subject to change. To configure the initial branch name to use in all
2026-02-16T17:11:10.1899318Z hint: of your new repositories, which will suppress this warning, call:
2026-02-16T17:11:10.1899616Z hint: 
2026-02-16T17:11:10.1899938Z hint: 	git config --global init.defaultBranch <name>
2026-02-16T17:11:10.1900252Z hint: 
2026-02-16T17:11:10.1900594Z hint: Names commonly chosen instead of 'master' are 'main', 'trunk' and
2026-02-16T17:11:10.1901085Z hint: 'development'. The just-created branch can be renamed via this command:
2026-02-16T17:11:10.1901440Z hint: 
2026-02-16T17:11:10.1901632Z hint: 	git branch -m <name>
2026-02-16T17:11:10.1909911Z Initialized empty Git repository in /__w/vllm-ascend/vllm-ascend/.git/
2026-02-16T17:11:10.1919035Z [command]/usr/bin/git remote add origin https://github.com/vllm-project/vllm-ascend
2026-02-16T17:11:10.1962455Z ##[endgroup]
2026-02-16T17:11:10.1962871Z ##[group]Disabling automatic garbage collection
2026-02-16T17:11:10.1965672Z [command]/usr/bin/git config --local gc.auto 0
2026-02-16T17:11:10.1989768Z ##[endgroup]
2026-02-16T17:11:10.1990118Z ##[group]Setting up auth
2026-02-16T17:11:10.1991492Z Removing SSH command configuration
2026-02-16T17:11:10.1996464Z [command]/usr/bin/git config --local --name-only --get-regexp core\.sshCommand
2026-02-16T17:11:10.2022357Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'core\.sshCommand' && git config --local --unset-all 'core.sshCommand' || :"
2026-02-16T17:11:10.2475383Z Removing HTTP extra header
2026-02-16T17:11:10.2479180Z [command]/usr/bin/git config --local --name-only --get-regexp http\.https\:\/\/github\.com\/\.extraheader
2026-02-16T17:11:10.2503400Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'http\.https\:\/\/github\.com\/\.extraheader' && git config --local --unset-all 'http.https://github.com/.extraheader' || :"
2026-02-16T17:11:10.2676382Z Removing includeIf entries pointing to credentials config files
2026-02-16T17:11:10.2680724Z [command]/usr/bin/git config --local --name-only --get-regexp ^includeIf\.gitdir:
2026-02-16T17:11:10.2705901Z [command]/usr/bin/git submodule foreach --recursive git config --local --show-origin --name-only --get-regexp remote.origin.url
2026-02-16T17:11:10.2884394Z [command]/usr/bin/git config --file /__w/_temp/git-credentials-df1c6ae4-a4a0-474f-96b3-a8685b4ab275.config http.https://github.com/.extraheader AUTHORIZATION: basic ***
2026-02-16T17:11:10.2916040Z [command]/usr/bin/git config --local includeIf.gitdir:/__w/vllm-ascend/vllm-ascend/.git.path /__w/_temp/git-credentials-df1c6ae4-a4a0-474f-96b3-a8685b4ab275.config
2026-02-16T17:11:10.2976568Z [command]/usr/bin/git config --local includeIf.gitdir:/__w/vllm-ascend/vllm-ascend/.git/worktrees/*.path /__w/_temp/git-credentials-df1c6ae4-a4a0-474f-96b3-a8685b4ab275.config
2026-02-16T17:11:10.3000762Z [command]/usr/bin/git config --local includeIf.gitdir:/github/workspace/.git.path /github/runner_temp/git-credentials-df1c6ae4-a4a0-474f-96b3-a8685b4ab275.config
2026-02-16T17:11:10.3024693Z [command]/usr/bin/git config --local includeIf.gitdir:/github/workspace/.git/worktrees/*.path /github/runner_temp/git-credentials-df1c6ae4-a4a0-474f-96b3-a8685b4ab275.config
2026-02-16T17:11:10.3045416Z ##[endgroup]
2026-02-16T17:11:10.3045794Z ##[group]Fetching the repository
2026-02-16T17:11:10.3053237Z [command]/usr/bin/git -c protocol.version=2 fetch --no-tags --prune --no-recurse-submodules --depth=1 origin +f0caeeadcb37261beebd4a6e32934fa9f460db98:refs/remotes/origin/main
2026-02-16T17:11:11.9343066Z From https://gh-proxy.test.osinfra.cn/https://github.com/vllm-project/vllm-ascend
2026-02-16T17:11:11.9343730Z  * [new ref]         f0caeeadcb37261beebd4a6e32934fa9f460db98 -> origin/main
2026-02-16T17:11:11.9364229Z [command]/usr/bin/git branch --list --remote origin/main
2026-02-16T17:11:11.9386788Z   origin/main
2026-02-16T17:11:11.9393110Z [command]/usr/bin/git rev-parse refs/remotes/origin/main
2026-02-16T17:11:11.9410403Z f0caeeadcb37261beebd4a6e32934fa9f460db98
2026-02-16T17:11:11.9413880Z ##[endgroup]
2026-02-16T17:11:11.9414282Z ##[group]Determining the checkout info
2026-02-16T17:11:11.9415909Z ##[endgroup]
2026-02-16T17:11:11.9419421Z [command]/usr/bin/git sparse-checkout disable
2026-02-16T17:11:11.9455461Z [command]/usr/bin/git config --local --unset-all extensions.worktreeConfig
2026-02-16T17:11:11.9479303Z ##[group]Checking out the ref
2026-02-16T17:11:11.9483415Z [command]/usr/bin/git checkout --progress --force -B main refs/remotes/origin/main
2026-02-16T17:11:12.0346698Z Switched to a new branch 'main'
2026-02-16T17:11:12.0347123Z Branch 'main' set up to track remote branch 'main' from 'origin'.
2026-02-16T17:11:12.0355492Z ##[endgroup]
2026-02-16T17:11:12.0387025Z [command]/usr/bin/git log -1 --format=%H
2026-02-16T17:11:12.0408213Z f0caeeadcb37261beebd4a6e32934fa9f460db98
2026-02-16T17:11:13.6198268Z ##[group]Run # prepare for lws entrypoint scripts
2026-02-16T17:11:13.6198661Z [36;1m# prepare for lws entrypoint scripts[0m
2026-02-16T17:11:13.6199059Z [36;1minstall -D tests/e2e/nightly/multi_node/scripts/run.sh /root/.cache/tests/run.sh[0m
2026-02-16T17:11:13.6199599Z shell: bash -el {0}
2026-02-16T17:11:13.6199919Z ##[endgroup]
2026-02-16T17:11:13.6288286Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-16T17:11:13.6289076Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-16T17:11:13.6289384Z ##[endgroup]
2026-02-16T17:11:13.9840627Z (node:486) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-16T17:11:13.9841511Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-16T17:11:14.8925758Z ##[group]Run set -euo pipefail
2026-02-16T17:11:14.8926013Z [36;1mset -euo pipefail[0m
2026-02-16T17:11:14.8926184Z [36;1m[0m
2026-02-16T17:11:14.8926335Z [36;1mCRD_NAME="${CRD_NAME:-vllm}"[0m
2026-02-16T17:11:14.8926530Z [36;1mTIMEOUT=${TIMEOUT:-120}[0m
2026-02-16T17:11:14.8926716Z [36;1mSLEEP_INTERVAL=2[0m
2026-02-16T17:11:14.8926877Z [36;1m[0m
2026-02-16T17:11:14.8927111Z [36;1mecho "Deleting leaderworkerset [$CRD_NAME] in namespace [$NAMESPACE]..."[0m
2026-02-16T17:11:14.8927524Z [36;1mkubectl delete leaderworkerset "$CRD_NAME" -n "$NAMESPACE" --ignore-not-found[0m
2026-02-16T17:11:14.8927824Z [36;1m[0m
2026-02-16T17:11:14.8928033Z [36;1mecho "Waiting for all pods starting with 'vllm' to be deleted..."[0m
2026-02-16T17:11:14.8928310Z [36;1mSTART_TIME=$(date +%s)[0m
2026-02-16T17:11:14.8928480Z [36;1m[0m
2026-02-16T17:11:14.8928621Z [36;1mwhile true; do[0m
2026-02-16T17:11:14.8928791Z [36;1m  NOW=$(date +%s)[0m
2026-02-16T17:11:14.8929006Z [36;1m  ELAPSED=$((NOW - START_TIME))[0m
2026-02-16T17:11:14.8929190Z [36;1m[0m
2026-02-16T17:11:14.8929349Z [36;1m  if [[ $ELAPSED -ge $TIMEOUT ]]; then[0m
2026-02-16T17:11:14.8929634Z [36;1m    echo "Timeout reached ($TIMEOUT seconds), some pods still exist:"[0m
2026-02-16T17:11:14.8929956Z [36;1m    kubectl get pods -n "$NAMESPACE" | grep '^vllm' || true[0m
2026-02-16T17:11:14.8930195Z [36;1m    exit 1[0m
2026-02-16T17:11:14.8930337Z [36;1m  fi[0m
2026-02-16T17:11:14.8930471Z [36;1m[0m
2026-02-16T17:11:14.8930847Z [36;1m  PODS_EXIST=$(kubectl get pods -n "$NAMESPACE" -o jsonpath='{.items[*].metadata.name}' 2>/dev/null | tr ' ' '\n' | grep '^vllm' || true)[0m
2026-02-16T17:11:14.8931246Z [36;1m[0m
2026-02-16T17:11:14.8931396Z [36;1m  if [[ -z "$PODS_EXIST" ]]; then[0m
2026-02-16T17:11:14.8931685Z [36;1m    echo "All vllm pods deleted."[0m
2026-02-16T17:11:14.8931879Z [36;1m    break[0m
2026-02-16T17:11:14.8932187Z [36;1m  else[0m
2026-02-16T17:11:14.8932399Z [36;1m    echo "Waiting for pods to be deleted: $PODS_EXIST"[0m
2026-02-16T17:11:14.8932640Z [36;1m    sleep $SLEEP_INTERVAL[0m
2026-02-16T17:11:14.8932826Z [36;1m  fi[0m
2026-02-16T17:11:14.8932961Z [36;1mdone[0m
2026-02-16T17:11:14.8933236Z shell: bash -el {0}
2026-02-16T17:11:14.8933393Z ##[endgroup]
2026-02-16T17:11:14.9016521Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-16T17:11:14.9017145Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-16T17:11:14.9017368Z ##[endgroup]
2026-02-16T17:11:15.2637830Z (node:541) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-16T17:11:15.2638494Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-16T17:11:15.7960344Z Deleting leaderworkerset [vllm] in namespace [vllm-project]...
2026-02-16T17:11:16.1041078Z Waiting for all pods starting with 'vllm' to be deleted...
2026-02-16T17:11:16.1727338Z All vllm pods deleted.
2026-02-16T17:11:16.6074264Z ##[group]Run set -e
2026-02-16T17:11:16.6074485Z [36;1mset -e[0m
2026-02-16T17:11:16.6074634Z [36;1m[0m
2026-02-16T17:11:16.6074767Z [36;1msize="2"[0m
2026-02-16T17:11:16.6074918Z [36;1mreplicas="1"[0m
2026-02-16T17:11:16.6075248Z [36;1mimage="swr.cn-southwest-2.myhuaweicloud.com/base_image/ascend-ci/vllm-ascend:nightly-a3"[0m
2026-02-16T17:11:16.6075669Z [36;1mconfig_file_path="DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml"[0m
2026-02-16T17:11:16.6075989Z [36;1mfail_tag=FAIL_TAG_"DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml"[0m
2026-02-16T17:11:16.6076272Z [36;1mecho "FAIL_TAG=${fail_tag}" >> "$GITHUB_ENV"[0m
2026-02-16T17:11:16.6076478Z [36;1m[0m
2026-02-16T17:11:16.6076691Z [36;1mrequired_params=("size" "replicas" "image" "config_file_path")[0m
2026-02-16T17:11:16.6076987Z [36;1mfor param in "${required_params[@]}"; do[0m
2026-02-16T17:11:16.6077208Z [36;1m  if [ -z "${!param}" ]; then[0m
2026-02-16T17:11:16.6077651Z [36;1m    echo "Error: Parameter '$param' is required but empty"[0m
2026-02-16T17:11:16.6077889Z [36;1m    exit 1[0m
2026-02-16T17:11:16.6078041Z [36;1m  fi[0m
2026-02-16T17:11:16.6078188Z [36;1mdone[0m
2026-02-16T17:11:16.6078321Z [36;1m[0m
2026-02-16T17:11:16.6078463Z [36;1mif [ "a3" = "a3" ]; then[0m
2026-02-16T17:11:16.6078643Z [36;1m  npu_per_node=16[0m
2026-02-16T17:11:16.6078909Z [36;1m  TEMPLATE_FILE="tests/e2e/nightly/multi_node/scripts/lws.yaml.jinja2"[0m
2026-02-16T17:11:16.6079185Z [36;1melse[0m
2026-02-16T17:11:16.6079326Z [36;1m  npu_per_node=8[0m
2026-02-16T17:11:16.6079591Z [36;1m  TEMPLATE_FILE="tests/e2e/nightly/multi_node/scripts/lws-a2.yaml.jinja2"[0m
2026-02-16T17:11:16.6079869Z [36;1mfi[0m
2026-02-16T17:11:16.6079997Z [36;1m[0m
2026-02-16T17:11:16.6080144Z [36;1mjinja2 $TEMPLATE_FILE \[0m
2026-02-16T17:11:16.6080335Z [36;1m  -D size="$size" \[0m
2026-02-16T17:11:16.6080512Z [36;1m  -D replicas="$replicas" \[0m
2026-02-16T17:11:16.6080708Z [36;1m  -D image="$image" \[0m
2026-02-16T17:11:16.6080915Z [36;1m  -D config_file_path="$config_file_path" \[0m
2026-02-16T17:11:16.6081153Z [36;1m  -D npu_per_node="$npu_per_node" \[0m
2026-02-16T17:11:16.6081362Z [36;1m  -D fail_tag="$fail_tag" \[0m
2026-02-16T17:11:16.6081546Z [36;1m  --outfile lws.yaml[0m
2026-02-16T17:11:16.6081712Z [36;1m[0m
2026-02-16T17:11:16.6081855Z [36;1mkubectl apply -f ./lws.yaml[0m
2026-02-16T17:11:16.6082350Z shell: bash -el {0}
2026-02-16T17:11:16.6082511Z ##[endgroup]
2026-02-16T17:11:16.6186770Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-16T17:11:16.6187455Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-16T17:11:16.6187666Z ##[endgroup]
2026-02-16T17:11:16.9906561Z (node:607) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-16T17:11:16.9907250Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-16T17:11:17.9294804Z leaderworkerset.leaderworkerset.x-k8s.io/vllm created
2026-02-16T17:11:17.9470349Z service/vllm-leader created
2026-02-16T17:11:18.3664639Z ##[group]Run POD_PREFIX="${POD_PREFIX:-vllm-0}"
2026-02-16T17:11:18.3665062Z [36;1mPOD_PREFIX="${POD_PREFIX:-vllm-0}"[0m
2026-02-16T17:11:18.3665315Z [36;1mSIZE="2"[0m
2026-02-16T17:11:18.3665562Z [36;1mTIMEOUT=1200  # default timeout 20 minutes[0m
2026-02-16T17:11:18.3665872Z [36;1m[0m
2026-02-16T17:11:18.3666222Z [36;1mecho "Waiting for Pods in namespace [$NAMESPACE] to become Running and Ready (timeout ${TIMEOUT}s)..."[0m
2026-02-16T17:11:18.3666641Z [36;1m[0m
2026-02-16T17:11:18.3666959Z [36;1mSTART_TIME=$(date +%s)[0m
2026-02-16T17:11:18.3667179Z [36;1m[0m
2026-02-16T17:11:18.3667375Z [36;1mwhile true; do[0m
2026-02-16T17:11:18.3667642Z [36;1m  NOW=$(date +%s)[0m
2026-02-16T17:11:18.3667875Z [36;1m  ELAPSED=$((NOW - START_TIME))[0m
2026-02-16T17:11:18.3668157Z [36;1m  if [[ $ELAPSED -ge $TIMEOUT ]]; then[0m
2026-02-16T17:11:18.3668505Z [36;1m    echo "Timeout reached after ${ELAPSED}s"[0m
2026-02-16T17:11:18.3668869Z [36;1m    echo "Dumping pod status for debugging:"[0m
2026-02-16T17:11:18.3669184Z [36;1m    kubectl get pods -n "$NAMESPACE"[0m
2026-02-16T17:11:18.3669483Z [36;1m    kubectl describe pod "$LEADER_POD" -n "$NAMESPACE"[0m
2026-02-16T17:11:18.3669810Z [36;1m    exit 1[0m
2026-02-16T17:11:18.3670084Z [36;1m  fi[0m
2026-02-16T17:11:18.3670255Z [36;1m[0m
2026-02-16T17:11:18.3670466Z [36;1m  # 1) check follower pods[0m
2026-02-16T17:11:18.3670729Z [36;1m  ALL_FOLLOWERS_READY=true[0m
2026-02-16T17:11:18.3670961Z [36;1m  for ((i=1; i<SIZE; i++)); do[0m
2026-02-16T17:11:18.3671250Z [36;1m    POD="${POD_PREFIX}-${i}"[0m
2026-02-16T17:11:18.3671713Z [36;1m    PHASE=$(kubectl get pod "$POD" -n "$NAMESPACE" -o jsonpath='{.status.phase}' 2>/dev/null || echo "NotFound")[0m
2026-02-16T17:11:18.3672427Z [36;1m    READY=$(kubectl get pod "$POD" -n "$NAMESPACE" -o jsonpath='{.status.containerStatuses[*].ready}' 2>/dev/null)[0m
2026-02-16T17:11:18.3673068Z [36;1m[0m
2026-02-16T17:11:18.3673351Z [36;1m    echo "Follower [$POD] phase=$PHASE ready=$READY"[0m
2026-02-16T17:11:18.3673643Z [36;1m[0m
2026-02-16T17:11:18.3673902Z [36;1m    if [[ "$PHASE" != "Running" || "$READY" != "true" ]]; then[0m
2026-02-16T17:11:18.3674322Z [36;1m      echo "Follower [$POD] not Ready yet..."[0m
2026-02-16T17:11:18.3674596Z [36;1m      ALL_FOLLOWERS_READY=false[0m
2026-02-16T17:11:18.3674858Z [36;1m      break[0m
2026-02-16T17:11:18.3675022Z [36;1m    fi[0m
2026-02-16T17:11:18.3675163Z [36;1m  done[0m
2026-02-16T17:11:18.3675293Z [36;1m[0m
2026-02-16T17:11:18.3675436Z [36;1m  # 2) check leader pod[0m
2026-02-16T17:11:18.3675827Z [36;1m  LEADER_PHASE=$(kubectl get pod "$LEADER_POD" -n "$NAMESPACE" -o jsonpath='{.status.phase}' 2>/dev/null || echo "NotFound")[0m
2026-02-16T17:11:18.3676422Z [36;1m  LEADER_READY=$(kubectl get pod "$LEADER_POD" -n "$NAMESPACE" -o jsonpath='{.status.containerStatuses[*].ready}' 2>/dev/null)[0m
2026-02-16T17:11:18.3676821Z [36;1m[0m
2026-02-16T17:11:18.3677044Z [36;1m  echo "Leader [$LEADER_POD] phase=$LEADER_PHASE ready=$LEADER_READY"[0m
2026-02-16T17:11:18.3677305Z [36;1m[0m
2026-02-16T17:11:18.3677515Z [36;1m  if [[ "$LEADER_PHASE" != "Running" || "$LEADER_READY" != "true" ]]; then[0m
2026-02-16T17:11:18.3677800Z [36;1m    echo "Leader not Ready yet..."[0m
2026-02-16T17:11:18.3678057Z [36;1m    ALL_FOLLOWERS_READY=false[0m
2026-02-16T17:11:18.3678245Z [36;1m  fi[0m
2026-02-16T17:11:18.3678376Z [36;1m[0m
2026-02-16T17:11:18.3678546Z [36;1m  if [[ "$ALL_FOLLOWERS_READY" == "true" ]]; then[0m
2026-02-16T17:11:18.3678881Z [36;1m    echo "All follower pods and leader pod are Running and Ready â€” continuing."[0m
2026-02-16T17:11:18.3679166Z [36;1m    break[0m
2026-02-16T17:11:18.3679314Z [36;1m  fi[0m
2026-02-16T17:11:18.3679447Z [36;1m[0m
2026-02-16T17:11:18.3679573Z [36;1m  sleep 2[0m
2026-02-16T17:11:18.3679719Z [36;1mdone[0m
2026-02-16T17:11:18.3679984Z shell: bash -el {0}
2026-02-16T17:11:18.3680138Z env:
2026-02-16T17:11:18.3680462Z   FAIL_TAG: FAIL_TAG_DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-02-16T17:11:18.3680694Z ##[endgroup]
2026-02-16T17:11:18.3751835Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-16T17:11:18.3752732Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-16T17:11:18.3752943Z ##[endgroup]
2026-02-16T17:11:18.7241473Z (node:685) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-16T17:11:18.7242224Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-16T17:11:19.2548212Z Waiting for Pods in namespace [vllm-project] to become Running and Ready (timeout 1200s)...
2026-02-16T17:11:19.3780157Z Follower [vllm-0-1] phase=Pending ready=
2026-02-16T17:11:19.3780398Z Follower [vllm-0-1] not Ready yet...
2026-02-16T17:11:19.4974179Z Leader [vllm-0] phase=Pending ready=
2026-02-16T17:11:19.4974440Z Leader not Ready yet...
2026-02-16T17:11:21.6109707Z Follower [vllm-0-1] phase=Pending ready=
2026-02-16T17:11:21.6109980Z Follower [vllm-0-1] not Ready yet...
2026-02-16T17:11:21.7218196Z Leader [vllm-0] phase=Pending ready=
2026-02-16T17:11:21.7218451Z Leader not Ready yet...
2026-02-16T17:11:23.8378130Z Follower [vllm-0-1] phase=Pending ready=
2026-02-16T17:11:23.8378403Z Follower [vllm-0-1] not Ready yet...
2026-02-16T17:11:23.9480774Z Leader [vllm-0] phase=Pending ready=
2026-02-16T17:11:23.9481002Z Leader not Ready yet...
2026-02-16T17:11:26.0631141Z Follower [vllm-0-1] phase=Pending ready=
2026-02-16T17:11:26.0631402Z Follower [vllm-0-1] not Ready yet...
2026-02-16T17:11:26.1777634Z Leader [vllm-0] phase=Pending ready=
2026-02-16T17:11:26.1777875Z Leader not Ready yet...
2026-02-16T17:11:28.2895746Z Follower [vllm-0-1] phase=Pending ready=
2026-02-16T17:11:28.2896000Z Follower [vllm-0-1] not Ready yet...
2026-02-16T17:11:28.3995143Z Leader [vllm-0] phase=Pending ready=
2026-02-16T17:11:28.3995598Z Leader not Ready yet...
2026-02-16T17:11:30.5159183Z Follower [vllm-0-1] phase=Pending ready=
2026-02-16T17:11:30.5159496Z Follower [vllm-0-1] not Ready yet...
2026-02-16T17:11:30.6330773Z Leader [vllm-0] phase=Pending ready=false
2026-02-16T17:11:30.6331040Z Leader not Ready yet...
2026-02-16T17:11:32.7477756Z Follower [vllm-0-1] phase=Pending ready=false
2026-02-16T17:11:32.7478036Z Follower [vllm-0-1] not Ready yet...
2026-02-16T17:11:32.8739360Z Leader [vllm-0] phase=Running ready=true
2026-02-16T17:11:34.9985326Z Follower [vllm-0-1] phase=Running ready=true
2026-02-16T17:11:35.1218989Z Leader [vllm-0] phase=Running ready=true
2026-02-16T17:11:35.1219525Z All follower pods and leader pod are Running and Ready â€” continuing.
2026-02-16T17:11:36.0708692Z ##[group]Run set -euo pipefail
2026-02-16T17:11:36.0708951Z [36;1mset -euo pipefail[0m
2026-02-16T17:11:36.0709119Z [36;1m[0m
2026-02-16T17:11:36.0709259Z [36;1msize="2"[0m
2026-02-16T17:11:36.0709404Z [36;1mpids=()[0m
2026-02-16T17:11:36.0709558Z [36;1m[0m
2026-02-16T17:11:36.0709694Z [36;1mcleanup() {[0m
2026-02-16T17:11:36.0709889Z [36;1m  echo "Cleaning up background log streams..."[0m
2026-02-16T17:11:36.0710134Z [36;1m  for pid in "${pids[@]}"; do[0m
2026-02-16T17:11:36.0710341Z [36;1m    kill "$pid" 2>/dev/null || true[0m
2026-02-16T17:11:36.0710531Z [36;1m  done[0m
2026-02-16T17:11:36.0710674Z [36;1m}[0m
2026-02-16T17:11:36.0710819Z [36;1mtrap cleanup EXIT[0m
2026-02-16T17:11:36.0710998Z [36;1m[0m
2026-02-16T17:11:36.0711148Z [36;1mfor i in $(seq 1 $((size - 1))); do[0m
2026-02-16T17:11:36.0711342Z [36;1m  POD="vllm-0-${i}"[0m
2026-02-16T17:11:36.0711507Z [36;1m[0m
2026-02-16T17:11:36.0711716Z [36;1m  echo "==== Collecting logs from worker pod: $POD ===="[0m
2026-02-16T17:11:36.0712152Z [36;1m  kubectl logs -f "$POD" -n "$NAMESPACE" \[0m
2026-02-16T17:11:36.0712405Z [36;1m    > "/tmp/${POD}_logs.txt" 2>&1 &[0m
2026-02-16T17:11:36.0712591Z [36;1m[0m
2026-02-16T17:11:36.0712728Z [36;1m  pids+=($!)[0m
2026-02-16T17:11:36.0712895Z [36;1mdone[0m
2026-02-16T17:11:36.0713027Z [36;1m[0m
2026-02-16T17:11:36.0713224Z [36;1mecho "==== Streaming logs from leader pod: $LEADER_POD ===="[0m
2026-02-16T17:11:36.0713511Z [36;1mecho "Looking for logs containing: $FAIL_TAG"[0m
2026-02-16T17:11:36.0713720Z [36;1m[0m
2026-02-16T17:11:36.0713954Z [36;1mkubectl logs -f "$LEADER_POD" -n "$NAMESPACE" | while IFS= read -r line; do[0m
2026-02-16T17:11:36.0714242Z [36;1m  echo "$line"[0m
2026-02-16T17:11:36.0714435Z [36;1m  if echo "$line" | grep -q "$FAIL_TAG"; then[0m
2026-02-16T17:11:36.0714726Z [36;1m    exit 1[0m
2026-02-16T17:11:36.0714877Z [36;1m  fi[0m
2026-02-16T17:11:36.0715015Z [36;1mdone[0m
2026-02-16T17:11:36.0715334Z shell: bash -el {0}
2026-02-16T17:11:36.0715476Z env:
2026-02-16T17:11:36.0715672Z   FAIL_TAG: FAIL_TAG_DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-02-16T17:11:36.0715905Z ##[endgroup]
2026-02-16T17:11:36.0818942Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-16T17:11:36.0819700Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-16T17:11:36.0819961Z ##[endgroup]
2026-02-16T17:11:36.4349479Z (node:780) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-16T17:11:36.4350176Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-16T17:11:36.9754126Z ==== Collecting logs from worker pod: vllm-0-1 ====
2026-02-16T17:11:36.9754473Z ==== Streaming logs from leader pod: vllm-0 ====
2026-02-16T17:11:36.9754773Z Looking for logs containing: FAIL_TAG_DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-02-16T17:11:37.0519124Z /usr/local/Ascend/ascend-toolkit/set_env.sh: line 31: CMAKE_PREFIX_PATH: unbound variable
2026-02-16T17:11:37.0530988Z ====> Check NPU info
2026-02-16T17:11:37.0540848Z +------------------------------------------------------------------------------------------------+
2026-02-16T17:11:37.0551316Z | npu-smi 25.5.0                   Version: 25.5.0                                               |
2026-02-16T17:11:37.0561563Z +---------------------------+---------------+----------------------------------------------------+
2026-02-16T17:11:37.0570800Z | NPU   Name                | Health        | Power(W)    Temp(C)           Hugepages-Usage(page)|
2026-02-16T17:11:37.0580439Z | Chip  Phy-ID              | Bus-Id        | AICore(%)   Memory-Usage(MB)  HBM-Usage(MB)        |
2026-02-16T17:11:37.0592853Z +===========================+===============+====================================================+
2026-02-16T17:11:37.0605718Z | 0     Ascend910           | OK            | 161.9       37                0    / 0             |
2026-02-16T17:11:37.0615890Z | 0     0                   | 0000:9D:00.0  | 0           0    / 0          3144 / 65536         |
2026-02-16T17:11:37.0625717Z +------------------------------------------------------------------------------------------------+
2026-02-16T17:11:37.0635948Z | 0     Ascend910           | OK            | -           37                0    / 0             |
2026-02-16T17:11:37.0646241Z | 1     1                   | 0000:9F:00.0  | 0           0    / 0          2889 / 65536         |
2026-02-16T17:11:37.0655486Z +===========================+===============+====================================================+
2026-02-16T17:11:37.0665641Z | 1     Ascend910           | OK            | 163.6       36                0    / 0             |
2026-02-16T17:11:37.0675367Z | 0     2                   | 0000:99:00.0  | 0           0    / 0          3158 / 65536         |
2026-02-16T17:11:37.0688485Z +------------------------------------------------------------------------------------------------+
2026-02-16T17:11:37.0698063Z | 1     Ascend910           | OK            | -           37                0    / 0             |
2026-02-16T17:11:37.0708029Z | 1     3                   | 0000:9B:00.0  | 0           0    / 0          2877 / 65536         |
2026-02-16T17:11:37.0717748Z +===========================+===============+====================================================+
2026-02-16T17:11:37.0727088Z | 2     Ascend910           | OK            | 163.3       37                0    / 0             |
2026-02-16T17:11:37.0736540Z | 0     4                   | 0000:95:00.0  | 0           0    / 0          3160 / 65536         |
2026-02-16T17:11:37.0746472Z +------------------------------------------------------------------------------------------------+
2026-02-16T17:11:37.0755689Z | 2     Ascend910           | OK            | -           37                0    / 0             |
2026-02-16T17:11:37.0766004Z | 1     5                   | 0000:97:00.0  | 0           0    / 0          2880 / 65536         |
2026-02-16T17:11:37.0776318Z +===========================+===============+====================================================+
2026-02-16T17:11:37.0786694Z | 3     Ascend910           | OK            | 167.7       37                0    / 0             |
2026-02-16T17:11:37.0796822Z | 0     6                   | 0000:91:00.0  | 0           0    / 0          3160 / 65536         |
2026-02-16T17:11:37.0807784Z +------------------------------------------------------------------------------------------------+
2026-02-16T17:11:37.0816995Z | 3     Ascend910           | OK            | -           37                0    / 0             |
2026-02-16T17:11:37.0826657Z | 1     7                   | 0000:93:00.0  | 0           0    / 0          2878 / 65536         |
2026-02-16T17:11:37.0836760Z +===========================+===============+====================================================+
2026-02-16T17:11:37.0847054Z | 4     Ascend910           | OK            | 161.6       38                0    / 0             |
2026-02-16T17:11:37.0856507Z | 0     8                   | 0000:8D:00.0  | 0           0    / 0          3159 / 65536         |
2026-02-16T17:11:37.0866501Z +------------------------------------------------------------------------------------------------+
2026-02-16T17:11:37.0878889Z | 4     Ascend910           | OK            | -           36                0    / 0             |
2026-02-16T17:11:37.0888281Z | 1     9                   | 0000:8F:00.0  | 0           0    / 0          2878 / 65536         |
2026-02-16T17:11:37.0898322Z +===========================+===============+====================================================+
2026-02-16T17:11:37.0908272Z | 5     Ascend910           | OK            | 162.7       37                0    / 0             |
2026-02-16T17:11:37.0917631Z | 0     10                  | 0000:89:00.0  | 0           0    / 0          3146 / 65536         |
2026-02-16T17:11:37.0930657Z +------------------------------------------------------------------------------------------------+
2026-02-16T17:11:37.0941048Z | 5     Ascend910           | OK            | -           38                0    / 0             |
2026-02-16T17:11:37.0950058Z | 1     11                  | 0000:8B:00.0  | 0           0    / 0          2890 / 65536         |
2026-02-16T17:11:37.0960361Z +===========================+===============+====================================================+
2026-02-16T17:11:37.0969992Z | 6     Ascend910           | OK            | 159.0       37                0    / 0             |
2026-02-16T17:11:37.0979643Z | 0     12                  | 0000:85:00.0  | 0           0    / 0          3145 / 65536         |
2026-02-16T17:11:37.0989600Z +------------------------------------------------------------------------------------------------+
2026-02-16T17:11:37.1002253Z | 6     Ascend910           | OK            | -           37                0    / 0             |
2026-02-16T17:11:37.1013184Z | 1     13                  | 0000:87:00.0  | 0           0    / 0          2889 / 65536         |
2026-02-16T17:11:37.1023156Z +===========================+===============+====================================================+
2026-02-16T17:11:37.1035524Z | 7     Ascend910           | OK            | 164.2       37                0    / 0             |
2026-02-16T17:11:37.1047479Z | 0     14                  | 0000:81:00.0  | 0           0    / 0          3151 / 65536         |
2026-02-16T17:11:37.1056900Z +------------------------------------------------------------------------------------------------+
2026-02-16T17:11:37.1067074Z | 7     Ascend910           | OK            | -           37                0    / 0             |
2026-02-16T17:11:37.1076801Z | 1     15                  | 0000:83:00.0  | 0           0    / 0          2874 / 65536         |
2026-02-16T17:11:37.1087826Z +===========================+===============+====================================================+
2026-02-16T17:11:37.1097166Z +---------------------------+---------------+----------------------------------------------------+
2026-02-16T17:11:37.1106799Z | NPU     Chip              | Process id    | Process name             | Process memory(MB)      |
2026-02-16T17:11:37.1116271Z +===========================+===============+====================================================+
2026-02-16T17:11:37.1127201Z | No running processes found in NPU 0                                                            |
2026-02-16T17:11:37.1136141Z +===========================+===============+====================================================+
2026-02-16T17:11:37.1145661Z | No running processes found in NPU 1                                                            |
2026-02-16T17:11:37.1154409Z +===========================+===============+====================================================+
2026-02-16T17:11:37.1164478Z | No running processes found in NPU 2                                                            |
2026-02-16T17:11:37.1173899Z +===========================+===============+====================================================+
2026-02-16T17:11:37.1183311Z | No running processes found in NPU 3                                                            |
2026-02-16T17:11:37.1192767Z +===========================+===============+====================================================+
2026-02-16T17:11:37.1202376Z | No running processes found in NPU 4                                                            |
2026-02-16T17:11:37.1211814Z +===========================+===============+====================================================+
2026-02-16T17:11:37.1221358Z | No running processes found in NPU 5                                                            |
2026-02-16T17:11:37.1230439Z +===========================+===============+====================================================+
2026-02-16T17:11:37.1239593Z | No running processes found in NPU 6                                                            |
2026-02-16T17:11:37.1248476Z +===========================+===============+====================================================+
2026-02-16T17:11:37.1258447Z | No running processes found in NPU 7                                                            |
2026-02-16T17:11:37.1269170Z +===========================+===============+====================================================+
2026-02-16T17:11:37.1277827Z package_name=Ascend-cann-toolkit
2026-02-16T17:11:37.1287610Z version=8.5.0
2026-02-16T17:11:37.1296482Z innerversion=V100R001C25SPC001B232
2026-02-16T17:11:37.1305761Z compatible_version=[V100R001C15],[V100R001C18],[V100R001C19],[V100R001C20],[V100R001C21],[V100R001C23]
2026-02-16T17:11:37.1315037Z arch=aarch64
2026-02-16T17:11:37.1324407Z os=linux
2026-02-16T17:11:37.1333728Z path=/usr/local/Ascend/cann-8.5.0
2026-02-16T17:11:37.1343074Z ====> Configure mirrors and git proxy
2026-02-16T17:11:37.1352229Z Writing to /root/.config/pip/pip.conf
2026-02-16T17:11:37.1361428Z Installed vLLM-related Python packages:
2026-02-16T17:11:37.1370653Z ais_bench_benchmark               3.0.20250930                /vllm-workspace/vllm-ascend/benchmark
2026-02-16T17:11:37.1379798Z vllm                              0.15.0+empty                /vllm-workspace/vllm
2026-02-16T17:11:37.1389785Z vllm_ascend                       0.14.0rc2.dev171+gf0caeeadc /vllm-workspace/vllm-ascend
2026-02-16T17:11:37.1401348Z 
2026-02-16T17:11:37.1410625Z ============================
2026-02-16T17:11:37.1419399Z vLLM Git information
2026-02-16T17:11:37.1428146Z ============================
2026-02-16T17:11:37.1436475Z Branch:      HEAD
2026-02-16T17:11:37.1446591Z Commit hash: f176443446f659dbab5315e056e605d8984fd976
2026-02-16T17:11:37.1455734Z Author:      TJian <tunjian.tan@embeddedllm.com>
2026-02-16T17:11:37.1464395Z Date:        2026-01-29 14:45:42 +0800
2026-02-16T17:11:37.1473002Z Message:     [Release] [CI] Optim release pipeline (#33156)
2026-02-16T17:11:37.1482241Z Tags:        v0.15.0
2026-02-16T17:11:37.1494101Z Remote:      origin	https://ghfast.top/https://github.com/vllm-project/vllm.git (fetch)
2026-02-16T17:11:37.1503451Z 
2026-02-16T17:11:37.1513518Z 
2026-02-16T17:11:37.1523047Z ============================
2026-02-16T17:11:37.1532485Z vLLM-Ascend Git information
2026-02-16T17:11:37.1543133Z ============================
2026-02-16T17:11:37.1551684Z Branch:      main
2026-02-16T17:11:37.1561077Z Commit hash: f0caeeadcb37261beebd4a6e32934fa9f460db98
2026-02-16T17:11:37.1570664Z Author:      Nengjun Ma <nengjunma@outlook.com>
2026-02-16T17:11:37.1580035Z Date:        2026-02-14 18:54:04 +0800
2026-02-16T17:11:37.1588978Z Message:     [CI] unlock when load model (#6771)
2026-02-16T17:11:37.1599452Z Tags:        
2026-02-16T17:11:37.1608950Z Remote:      origin	https://ghfast.top/https://github.com/vllm-project/vllm-ascend (fetch)
2026-02-16T17:11:37.1617619Z 
2026-02-16T17:11:37.1626064Z ====> Check triton ascend info
2026-02-16T17:11:37.1635074Z Ubuntu clang version 15.0.7
2026-02-16T17:11:37.1644725Z Target: aarch64-unknown-linux-gnu
2026-02-16T17:11:37.1654218Z Thread model: posix
2026-02-16T17:11:37.1663433Z InstalledDir: /usr/bin
2026-02-16T17:11:37.1672572Z Found candidate GCC installation: /usr/bin/../lib/gcc/aarch64-linux-gnu/11
2026-02-16T17:11:37.1682445Z Selected GCC installation: /usr/bin/../lib/gcc/aarch64-linux-gnu/11
2026-02-16T17:11:37.1691096Z Candidate multilib: .;@m64
2026-02-16T17:11:37.1700648Z Selected multilib: .;@m64
2026-02-16T17:11:37.1709979Z /usr/local/Ascend/cann-8.5.0/tools/bishengir/bin/bishengir-compile
2026-02-16T17:11:37.1719174Z Name: triton-ascend
2026-02-16T17:11:37.1728895Z Version: 3.2.0
2026-02-16T17:11:37.1738283Z Summary: A language and compiler for custom Deep Learning operations on Ascend hardwares
2026-02-16T17:11:37.1747492Z Home-page: https://gitcode.com/Ascend/triton-ascend/
2026-02-16T17:11:37.1756405Z Author: 
2026-02-16T17:11:37.1766944Z Author-email: 
2026-02-16T17:11:37.1776634Z License: 
2026-02-16T17:11:37.1786656Z Location: /usr/local/python3.11.14/lib/python3.11/site-packages
2026-02-16T17:11:37.1796067Z Requires: 
2026-02-16T17:11:37.1805814Z Required-by: vllm_ascend
2026-02-16T17:11:54.5883801Z INFO 02-16 17:11:54 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-16T17:11:54.5894135Z INFO 02-16 17:11:54 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-16T17:11:54.5902948Z INFO 02-16 17:11:54 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-16T17:11:54.6357977Z INFO 02-16 17:11:54 [__init__.py:217] Platform plugin ascend is activated
2026-02-16T17:12:00.8352732Z ============================= test session starts ==============================
2026-02-16T17:12:00.8362741Z platform linux -- Python 3.11.14, pytest-8.4.2, pluggy-1.6.0 -- /usr/local/python3.11.14/bin/python3
2026-02-16T17:12:00.8373098Z cachedir: .pytest_cache
2026-02-16T17:12:00.8382888Z rootdir: /vllm-workspace/vllm-ascend
2026-02-16T17:12:00.8391415Z configfile: pyproject.toml
2026-02-16T17:12:00.8402185Z plugins: cov-7.0.0, mock-3.15.1, asyncio-1.3.0, anyio-4.12.1
2026-02-16T17:12:00.8414431Z asyncio: mode=Mode.STRICT, debug=False, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function
2026-02-16T17:12:01.5918557Z collecting ... collected 1 item
2026-02-16T17:12:01.5929766Z 
2026-02-16T17:12:01.5940589Z [2026-02-16 17:12:01] INFO multi_node_config.py:294: Loading config yaml: tests/e2e/nightly/multi_node/config/DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-02-16T17:12:01.5991829Z [2026-02-16 17:12:01] INFO multi_node_config.py:351: Resolving cluster IPs via DNS...
2026-02-16T17:12:01.6031817Z [2026-02-16 17:12:01] INFO multi_node_config.py:212: Node 0 envs: {'HCCL_OP_EXPANSION_MODE': 'AIV', 'VLLM_USE_MODELSCOPE': 'True', 'HCCL_BUFFSIZE': '1024', 'SERVER_PORT': '8080', 'OMP_PROC_BIND': 'False', 'OMP_NUM_THREADS': '1', 'PYTORCH_NPU_ALLOC_CONF': 'expandable_segments:True', 'VLLM_ASCEND_ENABLE_FLASHCOMM1': '1', 'ASCEND_A3_EBA_ENABLE': '1', 'HCCL_IF_IP': '10.0.0.167', 'HCCL_SOCKET_IFNAME': 'eth0', 'GLOO_SOCKET_IFNAME': 'eth0', 'TP_SOCKET_IFNAME': 'eth0', 'LOCAL_IP': '10.0.0.167', 'NIC_NAME': 'eth0', 'MASTER_IP': '10.0.0.167'}
2026-02-16T17:12:01.6050894Z [2026-02-16 17:12:01] INFO multi_node_config.py:137: Not launching proxy on non-master node
2026-02-16T17:12:01.6065639Z [2026-02-16 17:12:01] INFO conftest.py:241: Starting server with command: vllm serve vllm-ascend/DeepSeek-V3.2-W8A8 --host 0.0.0.0 --port 8080 --data-parallel-size 4 --data-parallel-size-local 2 --data-parallel-address 10.0.0.167 --data-parallel-rpc-port 13399 --tensor-parallel-size 8 --quantization ascend --seed 1024 --enable-expert-parallel --max-num-seqs 16 --max-model-len 8192 --max-num-batched-tokens 4096 --no-enable-prefix-caching --gpu-memory-utilization 0.85 --trust-remote-code --speculative-config {"num_speculative_tokens": 2, "method":"deepseek_mtp"} --compilation-config {"cudagraph_capture_sizes": [3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45, 48], "cudagraph_mode": "FULL_DECODE_ONLY"} --additional-config {"layer_sharding": ["q_b_proj", "o_proj"]} --tokenizer-mode deepseek_v32 --reasoning-parser deepseek_v3
2026-02-16T17:12:06.0842314Z tests/e2e/nightly/multi_node/scripts/test_multi_node.py::test_multi_node INFO 02-16 17:12:06 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-16T17:12:06.0848517Z INFO 02-16 17:12:06 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-16T17:12:06.0858615Z INFO 02-16 17:12:06 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-16T17:12:06.0906260Z INFO 02-16 17:12:06 [__init__.py:217] Platform plugin ascend is activated
2026-02-16T17:12:12.4363964Z 2026-02-16 17:12:12,433 - 138 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-16T17:12:12.4670264Z INFO 02-16 17:12:12 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-16T17:12:12.6132948Z INFO 02-16 17:12:12 [serve.py:100] Defaulting api_server_count to data_parallel_size (4).
2026-02-16T17:12:12.6159298Z INFO 02-16 17:12:12 [utils.py:325] 
2026-02-16T17:12:12.6169616Z INFO 02-16 17:12:12 [utils.py:325]        â–ˆ     â–ˆ     â–ˆâ–„   â–„â–ˆ
2026-02-16T17:12:12.6179748Z INFO 02-16 17:12:12 [utils.py:325]  â–„â–„ â–„â–ˆ â–ˆ     â–ˆ     â–ˆ â–€â–„â–€ â–ˆ  version 0.15.0
2026-02-16T17:12:12.6188829Z INFO 02-16 17:12:12 [utils.py:325]   â–ˆâ–„â–ˆâ–€ â–ˆ     â–ˆ     â–ˆ     â–ˆ  model   vllm-ascend/DeepSeek-V3.2-W8A8
2026-02-16T17:12:12.6199032Z INFO 02-16 17:12:12 [utils.py:325]    â–€â–€  â–€â–€â–€â–€â–€ â–€â–€â–€â–€â–€ â–€     â–€
2026-02-16T17:12:12.6212087Z INFO 02-16 17:12:12 [utils.py:325] 
2026-02-16T17:12:12.6231179Z INFO 02-16 17:12:12 [utils.py:261] non-default args: {'model_tag': 'vllm-ascend/DeepSeek-V3.2-W8A8', 'api_server_count': 4, 'host': '0.0.0.0', 'port': 8080, 'model': 'vllm-ascend/DeepSeek-V3.2-W8A8', 'tokenizer_mode': 'deepseek_v32', 'trust_remote_code': True, 'seed': 1024, 'max_model_len': 8192, 'quantization': 'ascend', 'reasoning_parser': 'deepseek_v3', 'tensor_parallel_size': 8, 'data_parallel_size': 4, 'data_parallel_size_local': 2, 'data_parallel_address': '10.0.0.167', 'data_parallel_rpc_port': 13399, 'enable_expert_parallel': True, 'gpu_memory_utilization': 0.85, 'enable_prefix_caching': False, 'max_num_batched_tokens': 4096, 'max_num_seqs': 16, 'speculative_config': {'num_speculative_tokens': 2, 'method': 'deepseek_mtp'}, 'compilation_config': {'level': None, 'mode': None, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'vllm_ascend.compilation.compiler_interface.AscendCompiler', 'custom_ops': [], 'splitting_ops': None, 'compile_mm_encoder': False, 'compile_sizes': None, 'compile_ranges_split_points': None, 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_DECODE_ONLY: (2, 0)>, 'cudagraph_num_of_warmups': 0, 'cudagraph_capture_sizes': [3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45, 48], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': None, 'pass_config': {}, 'max_cudagraph_capture_size': None, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>, 'evaluate_guards': False, 'assume_32_bit_indexing': True}, 'local_cache_dir': None}, 'additional_config': {'layer_sharding': ['q_b_proj', 'o_proj']}}
2026-02-16T17:12:12.6550342Z 2026-02-16 17:12:12,653 - modelscope - WARNING - We can not confirm the cached file is for revision: master
2026-02-16T17:12:12.6619580Z INFO 02-16 17:12:12 [arg_utils.py:602] HF_HUB_OFFLINE is True, replace model_id [vllm-ascend/DeepSeek-V3.2-W8A8] to model_path [/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8]
2026-02-16T17:12:12.6638405Z The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-16T17:12:12.6666113Z The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-16T17:12:12.6690038Z The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-16T17:12:12.6700328Z You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-16T17:12:12.6882602Z INFO 02-16 17:12:12 [model.py:541] Resolved architecture: DeepseekV32ForCausalLM
2026-02-16T17:12:12.6891535Z INFO 02-16 17:12:12 [model.py:1561] Using max model len 8192
2026-02-16T17:12:12.9589250Z WARNING 02-16 17:12:12 [speculative.py:270] method `deepseek_mtp` is deprecated and replaced with mtp.
2026-02-16T17:12:12.9624018Z The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-16T17:12:12.9634248Z The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-16T17:12:12.9644529Z You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-16T17:12:12.9703959Z INFO 02-16 17:12:12 [model.py:541] Resolved architecture: DeepSeekMTPModel
2026-02-16T17:12:12.9713187Z INFO 02-16 17:12:12 [model.py:1561] Using max model len 163840
2026-02-16T17:12:12.9723790Z WARNING 02-16 17:12:12 [speculative.py:388] Enabling num_speculative_tokens > 1 will runmultiple times of forward on same MTP layer,which may result in lower acceptance rate
2026-02-16T17:12:12.9732506Z INFO 02-16 17:12:12 [scheduler.py:226] Chunked prefill is enabled with max_num_batched_tokens=4096.
2026-02-16T17:12:13.5769019Z INFO 02-16 17:12:13 [vllm.py:624] Asynchronous scheduling is enabled.
2026-02-16T17:12:13.5777985Z INFO 02-16 17:12:13 [vllm.py:634] Disabling NCCL for DP synchronization when using async scheduling.
2026-02-16T17:12:13.5788752Z WARNING 02-16 17:12:13 [platform.py:730] Speculative quantization is set but Ascend automatically uses the main model's quantization method. Resetting to None.
2026-02-16T17:12:13.5799704Z WARNING 02-16 17:12:13 [platform.py:771] Ignored parameter 'use_trtllm_ragged_deepseek_prefill'. This is a GPU-specific feature not supported on Ascend. Resetting to False.
2026-02-16T17:12:13.5808476Z INFO 02-16 17:12:13 [ascend_config.py:412] Dynamic EPLB is False
2026-02-16T17:12:13.5818168Z INFO 02-16 17:12:13 [ascend_config.py:413] The number of redundant experts is 0
2026-02-16T17:12:13.5828597Z INFO 02-16 17:12:13 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-16T17:12:13.5838441Z WARNING 02-16 17:12:13 [vllm.py:1062] Batch sizes [3, 6, 9, 12, 15, 18, 21, 27, 30, 33, 36, 39, 42, 45] are removed because they are not multiple of tp_size 8 when sequence parallelism is enabled
2026-02-16T17:12:13.5848484Z INFO 02-16 17:12:13 [platform.py:318] FULL_DECODE_ONLY compilation enabled on NPU. use_inductor not supported - using only ACL Graph mode
2026-02-16T17:12:13.5858505Z WARNING 02-16 17:12:13 [platform.py:335] [91m
2026-02-16T17:12:13.5867691Z WARNING 02-16 17:12:13 [platform.py:335]             **********************************************************************************
2026-02-16T17:12:13.5877246Z WARNING 02-16 17:12:13 [platform.py:335]             * WARNING: You have enabled the *full graph* feature.
2026-02-16T17:12:13.5888001Z WARNING 02-16 17:12:13 [platform.py:335]             * This is an early experimental stage and may involve various unknown issues.
2026-02-16T17:12:13.5897783Z WARNING 02-16 17:12:13 [platform.py:335]             * A known problem is that capturing too many batch sizes can lead to OOM
2026-02-16T17:12:13.5907464Z WARNING 02-16 17:12:13 [platform.py:335]             * (Out of Memory) errors or inference hangs. If you encounter such issues,
2026-02-16T17:12:13.5916730Z WARNING 02-16 17:12:13 [platform.py:335]             * consider reducing `gpu_memory_utilization` or manually specifying a smaller
2026-02-16T17:12:13.5927489Z WARNING 02-16 17:12:13 [platform.py:335]             * batch size for graph capture.
2026-02-16T17:12:13.5937221Z WARNING 02-16 17:12:13 [platform.py:335]             * For more details, please refer to:
2026-02-16T17:12:13.5947978Z WARNING 02-16 17:12:13 [platform.py:335]             * https://docs.vllm.ai/en/stable/configuration/conserving_memory.html#reduce-cuda-graphs
2026-02-16T17:12:13.5958052Z WARNING 02-16 17:12:13 [platform.py:335]             **********************************************************************************[0m
2026-02-16T17:12:13.5968805Z WARNING 02-16 17:12:13 [platform.py:335]             
2026-02-16T17:12:13.5979806Z INFO 02-16 17:12:13 [platform.py:443] Set PYTORCH_NPU_ALLOC_CONF=expandable_segments:True
2026-02-16T17:12:13.5989432Z INFO 02-16 17:12:13 [utils.py:851] Started DP Coordinator process (PID: 151)
2026-02-16T17:12:18.0321203Z INFO 02-16 17:12:18 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-16T17:12:18.0329922Z INFO 02-16 17:12:18 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-16T17:12:18.0339519Z INFO 02-16 17:12:18 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-16T17:12:18.0390911Z INFO 02-16 17:12:18 [__init__.py:217] Platform plugin ascend is activated
2026-02-16T17:12:18.2128751Z INFO 02-16 17:12:18 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-16T17:12:18.2135510Z INFO 02-16 17:12:18 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-16T17:12:18.2145620Z INFO 02-16 17:12:18 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-16T17:12:18.2198836Z INFO 02-16 17:12:18 [__init__.py:217] Platform plugin ascend is activated
2026-02-16T17:12:27.6968417Z INFO 02-16 17:12:27 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-16T17:12:27.6978447Z INFO 02-16 17:12:27 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-16T17:12:27.6988723Z INFO 02-16 17:12:27 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-16T17:12:27.7038027Z INFO 02-16 17:12:27 [__init__.py:217] Platform plugin ascend is activated
2026-02-16T17:12:32.9409174Z INFO 02-16 17:12:32 [utils.py:218] Started 4 API server processes
2026-02-16T17:12:33.1309896Z [0;36m(EngineCore_DP0 pid=154)[0;0m 2026-02-16 17:12:33,128 - 154 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-16T17:12:33.1330375Z [0;36m(EngineCore_DP1 pid=173)[0;0m 2026-02-16 17:12:33,129 - 173 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-16T17:12:33.1352847Z [0;36m(EngineCore_DP0 pid=154)[0;0m INFO 02-16 17:12:33 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-16T17:12:33.1378100Z [0;36m(EngineCore_DP0 pid=154)[0;0m INFO 02-16 17:12:33 [core.py:96] Initializing a V1 LLM engine (v0.15.0) with config: model='/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8', speculative_config=SpeculativeConfig(method='mtp', model='/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8', num_spec_tokens=2), tokenizer='/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8', skip_tokenizer_init=False, tokenizer_mode=deepseek_v32, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=8, pipeline_parallel_size=1, data_parallel_size=4, disable_custom_all_reduce=True, quantization=ascend, enforce_eager=False, enable_return_routed_experts=False, kv_cache_dtype=bfloat16, device_config=npu, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='deepseek_v3', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01, cudagraph_metrics=False, enable_layerwise_nvtx_tracing=False, enable_mfu_metrics=False, enable_mm_processor_stats=False, enable_logging_iteration_details=False), seed=1024, served_model_name=/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'vllm_ascend.compilation.compiler_interface.AscendCompiler', 'custom_ops': ['all'], 'splitting_ops': [], 'compile_mm_encoder': False, 'compile_sizes': [], 'compile_ranges_split_points': [4096], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_DECODE_ONLY: (2, 0)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [24, 48], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': True, 'fuse_act_quant': True, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 48, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>, 'evaluate_guards': False, 'assume_32_bit_indexing': True}, 'local_cache_dir': None}
2026-02-16T17:12:33.1386104Z [0;36m(EngineCore_DP1 pid=173)[0;0m INFO 02-16 17:12:33 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-16T17:12:37.4147991Z INFO 02-16 17:12:37 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-16T17:12:37.4158784Z INFO 02-16 17:12:37 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-16T17:12:37.4169493Z INFO 02-16 17:12:37 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-16T17:12:37.4217645Z INFO 02-16 17:12:37 [__init__.py:217] Platform plugin ascend is activated
2026-02-16T17:12:38.1323845Z INFO 02-16 17:12:38 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-16T17:12:38.1324367Z INFO 02-16 17:12:38 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-16T17:12:38.1324807Z INFO 02-16 17:12:38 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-16T17:12:38.1394381Z INFO 02-16 17:12:38 [__init__.py:217] Platform plugin ascend is activated
2026-02-16T17:12:38.1568704Z INFO 02-16 17:12:38 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-16T17:12:38.1577423Z INFO 02-16 17:12:38 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-16T17:12:38.1587345Z INFO 02-16 17:12:38 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-16T17:12:38.1678000Z INFO 02-16 17:12:38 [__init__.py:217] Platform plugin ascend is activated
2026-02-16T17:12:38.3090987Z INFO 02-16 17:12:38 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-16T17:12:38.3109256Z INFO 02-16 17:12:38 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-16T17:12:38.3118985Z INFO 02-16 17:12:38 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-16T17:12:38.3184124Z INFO 02-16 17:12:38 [__init__.py:217] Platform plugin ascend is activated
2026-02-16T17:12:38.4361194Z INFO 02-16 17:12:38 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-16T17:12:38.4371161Z INFO 02-16 17:12:38 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-16T17:12:38.4379421Z INFO 02-16 17:12:38 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-16T17:12:38.4456990Z INFO 02-16 17:12:38 [__init__.py:217] Platform plugin ascend is activated
2026-02-16T17:12:38.5303129Z INFO 02-16 17:12:38 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-16T17:12:38.5311644Z INFO 02-16 17:12:38 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-16T17:12:38.5320791Z INFO 02-16 17:12:38 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-16T17:12:38.5432085Z INFO 02-16 17:12:38 [__init__.py:217] Platform plugin ascend is activated
2026-02-16T17:12:43.2233703Z [0;36m(ApiServer_0 pid=184)[0;0m 2026-02-16 17:12:43,220 - 184 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-16T17:12:43.2367736Z [0;36m(ApiServer_0 pid=184)[0;0m INFO 02-16 17:12:43 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-16T17:12:43.2642482Z [0;36m(ApiServer_0 pid=184)[0;0m 2026-02-16 17:12:43,262 - modelscope - WARNING - We can not confirm the cached file is for revision: master
2026-02-16T17:12:43.2706627Z [0;36m(ApiServer_0 pid=184)[0;0m INFO 02-16 17:12:43 [arg_utils.py:602] HF_HUB_OFFLINE is True, replace model_id [vllm-ascend/DeepSeek-V3.2-W8A8] to model_path [/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8]
2026-02-16T17:12:43.3666579Z [0;36m(ApiServer_0 pid=184)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-16T17:12:43.3699884Z [0;36m(ApiServer_0 pid=184)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-16T17:12:43.3715882Z [0;36m(ApiServer_0 pid=184)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-16T17:12:43.3727619Z [0;36m(ApiServer_0 pid=184)[0;0m You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-16T17:12:43.3792219Z [0;36m(ApiServer_0 pid=184)[0;0m INFO 02-16 17:12:43 [model.py:541] Resolved architecture: DeepseekV32ForCausalLM
2026-02-16T17:12:43.3814991Z [0;36m(ApiServer_0 pid=184)[0;0m INFO 02-16 17:12:43 [model.py:1561] Using max model len 8192
2026-02-16T17:12:43.4861420Z [0;36m(ApiServer_0 pid=184)[0;0m WARNING 02-16 17:12:43 [speculative.py:270] method `deepseek_mtp` is deprecated and replaced with mtp.
2026-02-16T17:12:43.4882043Z [0;36m(ApiServer_0 pid=184)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-16T17:12:43.4892164Z [0;36m(ApiServer_0 pid=184)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-16T17:12:43.4902712Z [0;36m(ApiServer_0 pid=184)[0;0m You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-16T17:12:43.4946597Z [0;36m(ApiServer_0 pid=184)[0;0m INFO 02-16 17:12:43 [model.py:541] Resolved architecture: DeepSeekMTPModel
2026-02-16T17:12:43.4975050Z [0;36m(ApiServer_0 pid=184)[0;0m INFO 02-16 17:12:43 [model.py:1561] Using max model len 163840
2026-02-16T17:12:43.4985657Z [0;36m(ApiServer_0 pid=184)[0;0m WARNING 02-16 17:12:43 [speculative.py:388] Enabling num_speculative_tokens > 1 will runmultiple times of forward on same MTP layer,which may result in lower acceptance rate
2026-02-16T17:12:43.4994468Z [0;36m(ApiServer_0 pid=184)[0;0m INFO 02-16 17:12:43 [scheduler.py:226] Chunked prefill is enabled with max_num_batched_tokens=4096.
2026-02-16T17:12:43.5868359Z 2026-02-16 17:12:43,584 - 201 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-16T17:12:43.5932376Z INFO 02-16 17:12:43 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-16T17:12:43.8817460Z [0;36m(ApiServer_0 pid=184)[0;0m INFO 02-16 17:12:43 [vllm.py:624] Asynchronous scheduling is enabled.
2026-02-16T17:12:43.8825260Z [0;36m(ApiServer_0 pid=184)[0;0m INFO 02-16 17:12:43 [vllm.py:634] Disabling NCCL for DP synchronization when using async scheduling.
2026-02-16T17:12:43.8836206Z [0;36m(ApiServer_0 pid=184)[0;0m WARNING 02-16 17:12:43 [platform.py:730] Speculative quantization is set but Ascend automatically uses the main model's quantization method. Resetting to None.
2026-02-16T17:12:43.8846900Z [0;36m(ApiServer_0 pid=184)[0;0m WARNING 02-16 17:12:43 [platform.py:771] Ignored parameter 'use_trtllm_ragged_deepseek_prefill'. This is a GPU-specific feature not supported on Ascend. Resetting to False.
2026-02-16T17:12:43.8855886Z [0;36m(ApiServer_0 pid=184)[0;0m INFO 02-16 17:12:43 [ascend_config.py:412] Dynamic EPLB is False
2026-02-16T17:12:43.8865861Z [0;36m(ApiServer_0 pid=184)[0;0m INFO 02-16 17:12:43 [ascend_config.py:413] The number of redundant experts is 0
2026-02-16T17:12:43.8876444Z [0;36m(ApiServer_0 pid=184)[0;0m INFO 02-16 17:12:43 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-16T17:12:43.8886200Z [0;36m(ApiServer_0 pid=184)[0;0m WARNING 02-16 17:12:43 [vllm.py:1062] Batch sizes [3, 6, 9, 12, 15, 18, 21, 27, 30, 33, 36, 39, 42, 45] are removed because they are not multiple of tp_size 8 when sequence parallelism is enabled
2026-02-16T17:12:43.8941720Z [0;36m(ApiServer_0 pid=184)[0;0m INFO 02-16 17:12:43 [platform.py:318] FULL_DECODE_ONLY compilation enabled on NPU. use_inductor not supported - using only ACL Graph mode
2026-02-16T17:12:43.8942452Z [0;36m(ApiServer_0 pid=184)[0;0m WARNING 02-16 17:12:43 [platform.py:335] [91m
2026-02-16T17:12:43.8942978Z [0;36m(ApiServer_0 pid=184)[0;0m WARNING 02-16 17:12:43 [platform.py:335]             **********************************************************************************
2026-02-16T17:12:43.8943602Z [0;36m(ApiServer_0 pid=184)[0;0m WARNING 02-16 17:12:43 [platform.py:335]             * WARNING: You have enabled the *full graph* feature.
2026-02-16T17:12:43.8944284Z [0;36m(ApiServer_0 pid=184)[0;0m WARNING 02-16 17:12:43 [platform.py:335]             * This is an early experimental stage and may involve various unknown issues.
2026-02-16T17:12:43.8945433Z [0;36m(ApiServer_0 pid=184)[0;0m WARNING 02-16 17:12:43 [platform.py:335]             * A known problem is that capturing too many batch sizes can lead to OOM
2026-02-16T17:12:43.8954500Z [0;36m(ApiServer_0 pid=184)[0;0m WARNING 02-16 17:12:43 [platform.py:335]             * (Out of Memory) errors or inference hangs. If you encounter such issues,
2026-02-16T17:12:43.8964754Z [0;36m(ApiServer_0 pid=184)[0;0m WARNING 02-16 17:12:43 [platform.py:335]             * consider reducing `gpu_memory_utilization` or manually specifying a smaller
2026-02-16T17:12:43.8974364Z [0;36m(ApiServer_0 pid=184)[0;0m WARNING 02-16 17:12:43 [platform.py:335]             * batch size for graph capture.
2026-02-16T17:12:43.8983917Z [0;36m(ApiServer_0 pid=184)[0;0m WARNING 02-16 17:12:43 [platform.py:335]             * For more details, please refer to:
2026-02-16T17:12:43.8993765Z [0;36m(ApiServer_0 pid=184)[0;0m WARNING 02-16 17:12:43 [platform.py:335]             * https://docs.vllm.ai/en/stable/configuration/conserving_memory.html#reduce-cuda-graphs
2026-02-16T17:12:43.9003767Z [0;36m(ApiServer_0 pid=184)[0;0m WARNING 02-16 17:12:43 [platform.py:335]             **********************************************************************************[0m
2026-02-16T17:12:43.9013585Z [0;36m(ApiServer_0 pid=184)[0;0m WARNING 02-16 17:12:43 [platform.py:335]             
2026-02-16T17:12:43.9023019Z [0;36m(ApiServer_0 pid=184)[0;0m INFO 02-16 17:12:43 [platform.py:443] Set PYTORCH_NPU_ALLOC_CONF=expandable_segments:True
2026-02-16T17:12:44.1240275Z 2026-02-16 17:12:44,121 - 202 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-16T17:12:44.1302264Z INFO 02-16 17:12:44 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-16T17:12:44.1496307Z [0;36m(ApiServer_1 pid=185)[0;0m 2026-02-16 17:12:44,147 - 185 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-16T17:12:44.1647240Z [0;36m(ApiServer_1 pid=185)[0;0m INFO 02-16 17:12:44 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-16T17:12:44.1822238Z [0;36m(ApiServer_1 pid=185)[0;0m 2026-02-16 17:12:44,179 - modelscope - WARNING - We can not confirm the cached file is for revision: master
2026-02-16T17:12:44.1880812Z [0;36m(ApiServer_1 pid=185)[0;0m INFO 02-16 17:12:44 [arg_utils.py:602] HF_HUB_OFFLINE is True, replace model_id [vllm-ascend/DeepSeek-V3.2-W8A8] to model_path [/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8]
2026-02-16T17:12:44.2040836Z [0;36m(ApiServer_3 pid=187)[0;0m 2026-02-16 17:12:44,202 - 187 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-16T17:12:44.2190022Z [0;36m(ApiServer_3 pid=187)[0;0m INFO 02-16 17:12:44 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-16T17:12:44.2362523Z [0;36m(ApiServer_3 pid=187)[0;0m 2026-02-16 17:12:44,234 - modelscope - WARNING - We can not confirm the cached file is for revision: master
2026-02-16T17:12:44.2418017Z [0;36m(ApiServer_3 pid=187)[0;0m INFO 02-16 17:12:44 [arg_utils.py:602] HF_HUB_OFFLINE is True, replace model_id [vllm-ascend/DeepSeek-V3.2-W8A8] to model_path [/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8]
2026-02-16T17:12:44.2883751Z [0;36m(ApiServer_1 pid=185)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-16T17:12:44.2908669Z [0;36m(ApiServer_1 pid=185)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-16T17:12:44.2919028Z [0;36m(ApiServer_1 pid=185)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-16T17:12:44.2931210Z [0;36m(ApiServer_1 pid=185)[0;0m You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-16T17:12:44.2979496Z [0;36m(ApiServer_1 pid=185)[0;0m INFO 02-16 17:12:44 [model.py:541] Resolved architecture: DeepseekV32ForCausalLM
2026-02-16T17:12:44.3003670Z [0;36m(ApiServer_1 pid=185)[0;0m INFO 02-16 17:12:44 [model.py:1561] Using max model len 8192
2026-02-16T17:12:44.3422481Z [0;36m(ApiServer_3 pid=187)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-16T17:12:44.3450021Z [0;36m(ApiServer_3 pid=187)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-16T17:12:44.3460028Z [0;36m(ApiServer_3 pid=187)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-16T17:12:44.3476147Z [0;36m(ApiServer_3 pid=187)[0;0m You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-16T17:12:44.3526296Z [0;36m(ApiServer_3 pid=187)[0;0m INFO 02-16 17:12:44 [model.py:541] Resolved architecture: DeepseekV32ForCausalLM
2026-02-16T17:12:44.3536038Z [0;36m(ApiServer_3 pid=187)[0;0m INFO 02-16 17:12:44 [model.py:1561] Using max model len 8192
2026-02-16T17:12:44.4076921Z [0;36m(ApiServer_1 pid=185)[0;0m WARNING 02-16 17:12:44 [speculative.py:270] method `deepseek_mtp` is deprecated and replaced with mtp.
2026-02-16T17:12:44.4098850Z [0;36m(ApiServer_1 pid=185)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-16T17:12:44.4107870Z [0;36m(ApiServer_1 pid=185)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-16T17:12:44.4117735Z [0;36m(ApiServer_1 pid=185)[0;0m You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-16T17:12:44.4161694Z [0;36m(ApiServer_1 pid=185)[0;0m INFO 02-16 17:12:44 [model.py:541] Resolved architecture: DeepSeekMTPModel
2026-02-16T17:12:44.4184083Z [0;36m(ApiServer_1 pid=185)[0;0m INFO 02-16 17:12:44 [model.py:1561] Using max model len 163840
2026-02-16T17:12:44.4193911Z [0;36m(ApiServer_1 pid=185)[0;0m WARNING 02-16 17:12:44 [speculative.py:388] Enabling num_speculative_tokens > 1 will runmultiple times of forward on same MTP layer,which may result in lower acceptance rate
2026-02-16T17:12:44.4203233Z [0;36m(ApiServer_1 pid=185)[0;0m INFO 02-16 17:12:44 [scheduler.py:226] Chunked prefill is enabled with max_num_batched_tokens=4096.
2026-02-16T17:12:44.4594287Z [0;36m(ApiServer_3 pid=187)[0;0m WARNING 02-16 17:12:44 [speculative.py:270] method `deepseek_mtp` is deprecated and replaced with mtp.
2026-02-16T17:12:44.4618685Z [0;36m(ApiServer_3 pid=187)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-16T17:12:44.4627707Z [0;36m(ApiServer_3 pid=187)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-16T17:12:44.4637394Z [0;36m(ApiServer_3 pid=187)[0;0m You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-16T17:12:44.4677342Z [0;36m(ApiServer_3 pid=187)[0;0m INFO 02-16 17:12:44 [model.py:541] Resolved architecture: DeepSeekMTPModel
2026-02-16T17:12:44.4700736Z [0;36m(ApiServer_3 pid=187)[0;0m INFO 02-16 17:12:44 [model.py:1561] Using max model len 163840
2026-02-16T17:12:44.4710731Z [0;36m(ApiServer_3 pid=187)[0;0m WARNING 02-16 17:12:44 [speculative.py:388] Enabling num_speculative_tokens > 1 will runmultiple times of forward on same MTP layer,which may result in lower acceptance rate
2026-02-16T17:12:44.4720292Z [0;36m(ApiServer_3 pid=187)[0;0m INFO 02-16 17:12:44 [scheduler.py:226] Chunked prefill is enabled with max_num_batched_tokens=4096.
2026-02-16T17:12:44.8472104Z [0;36m(ApiServer_1 pid=185)[0;0m INFO 02-16 17:12:44 [vllm.py:624] Asynchronous scheduling is enabled.
2026-02-16T17:12:44.8472768Z [0;36m(ApiServer_1 pid=185)[0;0m INFO 02-16 17:12:44 [vllm.py:634] Disabling NCCL for DP synchronization when using async scheduling.
2026-02-16T17:12:44.8490203Z [0;36m(ApiServer_1 pid=185)[0;0m WARNING 02-16 17:12:44 [platform.py:730] Speculative quantization is set but Ascend automatically uses the main model's quantization method. Resetting to None.
2026-02-16T17:12:44.8500414Z [0;36m(ApiServer_1 pid=185)[0;0m WARNING 02-16 17:12:44 [platform.py:771] Ignored parameter 'use_trtllm_ragged_deepseek_prefill'. This is a GPU-specific feature not supported on Ascend. Resetting to False.
2026-02-16T17:12:44.8509335Z [0;36m(ApiServer_1 pid=185)[0;0m INFO 02-16 17:12:44 [ascend_config.py:412] Dynamic EPLB is False
2026-02-16T17:12:44.8520402Z [0;36m(ApiServer_1 pid=185)[0;0m INFO 02-16 17:12:44 [ascend_config.py:413] The number of redundant experts is 0
2026-02-16T17:12:44.8530604Z [0;36m(ApiServer_1 pid=185)[0;0m INFO 02-16 17:12:44 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-16T17:12:44.8540119Z [0;36m(ApiServer_1 pid=185)[0;0m WARNING 02-16 17:12:44 [vllm.py:1062] Batch sizes [3, 6, 9, 12, 15, 18, 21, 27, 30, 33, 36, 39, 42, 45] are removed because they are not multiple of tp_size 8 when sequence parallelism is enabled
2026-02-16T17:12:44.8549455Z [0;36m(ApiServer_1 pid=185)[0;0m INFO 02-16 17:12:44 [platform.py:318] FULL_DECODE_ONLY compilation enabled on NPU. use_inductor not supported - using only ACL Graph mode
2026-02-16T17:12:44.8559751Z [0;36m(ApiServer_1 pid=185)[0;0m WARNING 02-16 17:12:44 [platform.py:335] [91m
2026-02-16T17:12:44.8569706Z [0;36m(ApiServer_1 pid=185)[0;0m WARNING 02-16 17:12:44 [platform.py:335]             **********************************************************************************
2026-02-16T17:12:44.8579286Z [0;36m(ApiServer_1 pid=185)[0;0m WARNING 02-16 17:12:44 [platform.py:335]             * WARNING: You have enabled the *full graph* feature.
2026-02-16T17:12:44.8589001Z [0;36m(ApiServer_1 pid=185)[0;0m WARNING 02-16 17:12:44 [platform.py:335]             * This is an early experimental stage and may involve various unknown issues.
2026-02-16T17:12:44.8602329Z [0;36m(ApiServer_1 pid=185)[0;0m WARNING 02-16 17:12:44 [platform.py:335]             * A known problem is that capturing too many batch sizes can lead to OOM
2026-02-16T17:12:44.8609187Z [0;36m(ApiServer_1 pid=185)[0;0m WARNING 02-16 17:12:44 [platform.py:335]             * (Out of Memory) errors or inference hangs. If you encounter such issues,
2026-02-16T17:12:44.8623450Z [0;36m(ApiServer_1 pid=185)[0;0m WARNING 02-16 17:12:44 [platform.py:335]             * consider reducing `gpu_memory_utilization` or manually specifying a smaller
2026-02-16T17:12:44.8627806Z [0;36m(ApiServer_1 pid=185)[0;0m WARNING 02-16 17:12:44 [platform.py:335]             * batch size for graph capture.
2026-02-16T17:12:44.8638482Z [0;36m(ApiServer_1 pid=185)[0;0m WARNING 02-16 17:12:44 [platform.py:335]             * For more details, please refer to:
2026-02-16T17:12:44.8648833Z [0;36m(ApiServer_1 pid=185)[0;0m WARNING 02-16 17:12:44 [platform.py:335]             * https://docs.vllm.ai/en/stable/configuration/conserving_memory.html#reduce-cuda-graphs
2026-02-16T17:12:44.8657726Z [0;36m(ApiServer_1 pid=185)[0;0m WARNING 02-16 17:12:44 [platform.py:335]             **********************************************************************************[0m
2026-02-16T17:12:44.8667268Z [0;36m(ApiServer_1 pid=185)[0;0m WARNING 02-16 17:12:44 [platform.py:335]             
2026-02-16T17:12:44.8676919Z [0;36m(ApiServer_1 pid=185)[0;0m INFO 02-16 17:12:44 [platform.py:443] Set PYTORCH_NPU_ALLOC_CONF=expandable_segments:True
2026-02-16T17:12:44.8818067Z [0;36m(ApiServer_2 pid=186)[0;0m 2026-02-16 17:12:44,879 - 186 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-16T17:12:44.8967650Z [0;36m(ApiServer_3 pid=187)[0;0m INFO 02-16 17:12:44 [vllm.py:624] Asynchronous scheduling is enabled.
2026-02-16T17:12:44.8979914Z [0;36m(ApiServer_3 pid=187)[0;0m INFO 02-16 17:12:44 [vllm.py:634] Disabling NCCL for DP synchronization when using async scheduling.
2026-02-16T17:12:44.8994216Z [0;36m(ApiServer_3 pid=187)[0;0m WARNING 02-16 17:12:44 [platform.py:730] Speculative quantization is set but Ascend automatically uses the main model's quantization method. Resetting to None.
2026-02-16T17:12:44.9005077Z [0;36m(ApiServer_3 pid=187)[0;0m WARNING 02-16 17:12:44 [platform.py:771] Ignored parameter 'use_trtllm_ragged_deepseek_prefill'. This is a GPU-specific feature not supported on Ascend. Resetting to False.
2026-02-16T17:12:44.9014885Z [0;36m(ApiServer_3 pid=187)[0;0m INFO 02-16 17:12:44 [ascend_config.py:412] Dynamic EPLB is False
2026-02-16T17:12:44.9024676Z [0;36m(ApiServer_3 pid=187)[0;0m INFO 02-16 17:12:44 [ascend_config.py:413] The number of redundant experts is 0
2026-02-16T17:12:44.9035901Z [0;36m(ApiServer_3 pid=187)[0;0m INFO 02-16 17:12:44 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-16T17:12:44.9046719Z [0;36m(ApiServer_3 pid=187)[0;0m WARNING 02-16 17:12:44 [vllm.py:1062] Batch sizes [3, 6, 9, 12, 15, 18, 21, 27, 30, 33, 36, 39, 42, 45] are removed because they are not multiple of tp_size 8 when sequence parallelism is enabled
2026-02-16T17:12:44.9056520Z [0;36m(ApiServer_2 pid=186)[0;0m INFO 02-16 17:12:44 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-16T17:12:44.9066106Z [0;36m(ApiServer_3 pid=187)[0;0m INFO 02-16 17:12:44 [platform.py:318] FULL_DECODE_ONLY compilation enabled on NPU. use_inductor not supported - using only ACL Graph mode
2026-02-16T17:12:44.9075440Z [0;36m(ApiServer_3 pid=187)[0;0m WARNING 02-16 17:12:44 [platform.py:335] [91m
2026-02-16T17:12:44.9085076Z [0;36m(ApiServer_3 pid=187)[0;0m WARNING 02-16 17:12:44 [platform.py:335]             **********************************************************************************
2026-02-16T17:12:44.9094757Z [0;36m(ApiServer_3 pid=187)[0;0m WARNING 02-16 17:12:44 [platform.py:335]             * WARNING: You have enabled the *full graph* feature.
2026-02-16T17:12:44.9104545Z [0;36m(ApiServer_3 pid=187)[0;0m WARNING 02-16 17:12:44 [platform.py:335]             * This is an early experimental stage and may involve various unknown issues.
2026-02-16T17:12:44.9114072Z [0;36m(ApiServer_3 pid=187)[0;0m WARNING 02-16 17:12:44 [platform.py:335]             * A known problem is that capturing too many batch sizes can lead to OOM
2026-02-16T17:12:44.9124185Z [0;36m(ApiServer_3 pid=187)[0;0m WARNING 02-16 17:12:44 [platform.py:335]             * (Out of Memory) errors or inference hangs. If you encounter such issues,
2026-02-16T17:12:44.9134204Z [0;36m(ApiServer_3 pid=187)[0;0m WARNING 02-16 17:12:44 [platform.py:335]             * consider reducing `gpu_memory_utilization` or manually specifying a smaller
2026-02-16T17:12:44.9143432Z [0;36m(ApiServer_3 pid=187)[0;0m WARNING 02-16 17:12:44 [platform.py:335]             * batch size for graph capture.
2026-02-16T17:12:44.9153387Z [0;36m(ApiServer_3 pid=187)[0;0m WARNING 02-16 17:12:44 [platform.py:335]             * For more details, please refer to:
2026-02-16T17:12:44.9163586Z [0;36m(ApiServer_3 pid=187)[0;0m WARNING 02-16 17:12:44 [platform.py:335]             * https://docs.vllm.ai/en/stable/configuration/conserving_memory.html#reduce-cuda-graphs
2026-02-16T17:12:44.9173482Z [0;36m(ApiServer_3 pid=187)[0;0m WARNING 02-16 17:12:44 [platform.py:335]             **********************************************************************************[0m
2026-02-16T17:12:44.9182679Z [0;36m(ApiServer_3 pid=187)[0;0m WARNING 02-16 17:12:44 [platform.py:335]             
2026-02-16T17:12:44.9191782Z [0;36m(ApiServer_3 pid=187)[0;0m INFO 02-16 17:12:44 [platform.py:443] Set PYTORCH_NPU_ALLOC_CONF=expandable_segments:True
2026-02-16T17:12:44.9202281Z [0;36m(ApiServer_2 pid=186)[0;0m 2026-02-16 17:12:44,915 - modelscope - WARNING - We can not confirm the cached file is for revision: master
2026-02-16T17:12:44.9244043Z [0;36m(ApiServer_2 pid=186)[0;0m INFO 02-16 17:12:44 [arg_utils.py:602] HF_HUB_OFFLINE is True, replace model_id [vllm-ascend/DeepSeek-V3.2-W8A8] to model_path [/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8]
2026-02-16T17:12:45.0269396Z [0;36m(ApiServer_2 pid=186)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-16T17:12:45.0296316Z [0;36m(ApiServer_2 pid=186)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-16T17:12:45.0304821Z [0;36m(ApiServer_2 pid=186)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-16T17:12:45.0321169Z [0;36m(ApiServer_2 pid=186)[0;0m You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-16T17:12:45.0372340Z [0;36m(ApiServer_2 pid=186)[0;0m INFO 02-16 17:12:45 [model.py:541] Resolved architecture: DeepseekV32ForCausalLM
2026-02-16T17:12:45.0382123Z [0;36m(ApiServer_2 pid=186)[0;0m INFO 02-16 17:12:45 [model.py:1561] Using max model len 8192
2026-02-16T17:12:45.1477241Z [0;36m(ApiServer_2 pid=186)[0;0m WARNING 02-16 17:12:45 [speculative.py:270] method `deepseek_mtp` is deprecated and replaced with mtp.
2026-02-16T17:12:45.1498648Z [0;36m(ApiServer_2 pid=186)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-16T17:12:45.1507942Z [0;36m(ApiServer_2 pid=186)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-16T17:12:45.1517250Z [0;36m(ApiServer_2 pid=186)[0;0m You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-16T17:12:45.1559152Z [0;36m(ApiServer_2 pid=186)[0;0m INFO 02-16 17:12:45 [model.py:541] Resolved architecture: DeepSeekMTPModel
2026-02-16T17:12:45.1614216Z [0;36m(ApiServer_2 pid=186)[0;0m INFO 02-16 17:12:45 [model.py:1561] Using max model len 163840
2026-02-16T17:12:45.1624783Z [0;36m(ApiServer_2 pid=186)[0;0m WARNING 02-16 17:12:45 [speculative.py:388] Enabling num_speculative_tokens > 1 will runmultiple times of forward on same MTP layer,which may result in lower acceptance rate
2026-02-16T17:12:45.1633853Z [0;36m(ApiServer_2 pid=186)[0;0m INFO 02-16 17:12:45 [scheduler.py:226] Chunked prefill is enabled with max_num_batched_tokens=4096.
2026-02-16T17:12:45.5738502Z [0;36m(ApiServer_2 pid=186)[0;0m INFO 02-16 17:12:45 [vllm.py:624] Asynchronous scheduling is enabled.
2026-02-16T17:12:45.5747380Z [0;36m(ApiServer_2 pid=186)[0;0m INFO 02-16 17:12:45 [vllm.py:634] Disabling NCCL for DP synchronization when using async scheduling.
2026-02-16T17:12:45.5756555Z [0;36m(ApiServer_2 pid=186)[0;0m WARNING 02-16 17:12:45 [platform.py:730] Speculative quantization is set but Ascend automatically uses the main model's quantization method. Resetting to None.
2026-02-16T17:12:45.5767397Z [0;36m(ApiServer_2 pid=186)[0;0m WARNING 02-16 17:12:45 [platform.py:771] Ignored parameter 'use_trtllm_ragged_deepseek_prefill'. This is a GPU-specific feature not supported on Ascend. Resetting to False.
2026-02-16T17:12:45.5776365Z [0;36m(ApiServer_2 pid=186)[0;0m INFO 02-16 17:12:45 [ascend_config.py:412] Dynamic EPLB is False
2026-02-16T17:12:45.5787744Z [0;36m(ApiServer_2 pid=186)[0;0m INFO 02-16 17:12:45 [ascend_config.py:413] The number of redundant experts is 0
2026-02-16T17:12:45.5797995Z [0;36m(ApiServer_2 pid=186)[0;0m INFO 02-16 17:12:45 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-16T17:12:45.5809178Z [0;36m(ApiServer_2 pid=186)[0;0m WARNING 02-16 17:12:45 [vllm.py:1062] Batch sizes [3, 6, 9, 12, 15, 18, 21, 27, 30, 33, 36, 39, 42, 45] are removed because they are not multiple of tp_size 8 when sequence parallelism is enabled
2026-02-16T17:12:45.5818579Z [0;36m(ApiServer_2 pid=186)[0;0m INFO 02-16 17:12:45 [platform.py:318] FULL_DECODE_ONLY compilation enabled on NPU. use_inductor not supported - using only ACL Graph mode
2026-02-16T17:12:45.5827864Z [0;36m(ApiServer_2 pid=186)[0;0m WARNING 02-16 17:12:45 [platform.py:335] [91m
2026-02-16T17:12:45.5837843Z [0;36m(ApiServer_2 pid=186)[0;0m WARNING 02-16 17:12:45 [platform.py:335]             **********************************************************************************
2026-02-16T17:12:45.5848619Z [0;36m(ApiServer_2 pid=186)[0;0m WARNING 02-16 17:12:45 [platform.py:335]             * WARNING: You have enabled the *full graph* feature.
2026-02-16T17:12:45.5858955Z [0;36m(ApiServer_2 pid=186)[0;0m WARNING 02-16 17:12:45 [platform.py:335]             * This is an early experimental stage and may involve various unknown issues.
2026-02-16T17:12:45.5868884Z [0;36m(ApiServer_2 pid=186)[0;0m WARNING 02-16 17:12:45 [platform.py:335]             * A known problem is that capturing too many batch sizes can lead to OOM
2026-02-16T17:12:45.5879294Z [0;36m(ApiServer_2 pid=186)[0;0m WARNING 02-16 17:12:45 [platform.py:335]             * (Out of Memory) errors or inference hangs. If you encounter such issues,
2026-02-16T17:12:45.5896672Z [0;36m(ApiServer_2 pid=186)[0;0m WARNING 02-16 17:12:45 [platform.py:335]             * consider reducing `gpu_memory_utilization` or manually specifying a smaller
2026-02-16T17:12:45.5898940Z [0;36m(ApiServer_2 pid=186)[0;0m WARNING 02-16 17:12:45 [platform.py:335]             * batch size for graph capture.
2026-02-16T17:12:45.5909059Z [0;36m(ApiServer_2 pid=186)[0;0m WARNING 02-16 17:12:45 [platform.py:335]             * For more details, please refer to:
2026-02-16T17:12:45.5920076Z [0;36m(ApiServer_2 pid=186)[0;0m WARNING 02-16 17:12:45 [platform.py:335]             * https://docs.vllm.ai/en/stable/configuration/conserving_memory.html#reduce-cuda-graphs
2026-02-16T17:12:45.5930070Z [0;36m(ApiServer_2 pid=186)[0;0m WARNING 02-16 17:12:45 [platform.py:335]             **********************************************************************************[0m
2026-02-16T17:12:45.5939568Z [0;36m(ApiServer_2 pid=186)[0;0m WARNING 02-16 17:12:45 [platform.py:335]             
2026-02-16T17:12:45.5949358Z [0;36m(ApiServer_2 pid=186)[0;0m INFO 02-16 17:12:45 [platform.py:443] Set PYTORCH_NPU_ALLOC_CONF=expandable_segments:True
2026-02-16T17:12:45.6834643Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-16T17:12:45.6842920Z   warnings.warn(
2026-02-16T17:12:45.6856515Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-16T17:12:45.6864568Z   warnings.warn(
2026-02-16T17:12:47.7724941Z INFO 02-16 17:12:47 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-16T17:12:47.7725350Z INFO 02-16 17:12:47 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-16T17:12:47.7725800Z INFO 02-16 17:12:47 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-16T17:12:47.7767745Z INFO 02-16 17:12:47 [__init__.py:217] Platform plugin ascend is activated
2026-02-16T17:12:48.6145233Z INFO 02-16 17:12:48 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-16T17:12:48.6155651Z INFO 02-16 17:12:48 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-16T17:12:48.6166703Z INFO 02-16 17:12:48 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-16T17:12:48.6219390Z INFO 02-16 17:12:48 [__init__.py:217] Platform plugin ascend is activated
2026-02-16T17:12:49.0827384Z INFO 02-16 17:12:49 [ascend_config.py:412] Dynamic EPLB is False
2026-02-16T17:12:49.0837636Z INFO 02-16 17:12:49 [ascend_config.py:412] Dynamic EPLB is False
2026-02-16T17:12:49.0848071Z INFO 02-16 17:12:49 [ascend_config.py:413] The number of redundant experts is 0
2026-02-16T17:12:49.0857222Z INFO 02-16 17:12:49 [ascend_config.py:413] The number of redundant experts is 0
2026-02-16T17:12:49.0868159Z INFO 02-16 17:12:49 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-16T17:12:49.0878836Z INFO 02-16 17:12:49 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-16T17:12:49.1612410Z INFO 02-16 17:12:49 [parallel_state.py:1212] world_size=32 rank=8 local_rank=0 distributed_init_method=tcp://10.0.0.167:45299 backend=hccl
2026-02-16T17:12:49.1652092Z INFO 02-16 17:12:49 [parallel_state.py:1212] world_size=32 rank=0 local_rank=0 distributed_init_method=tcp://10.0.0.167:45299 backend=hccl
2026-02-16T17:12:52.7060325Z 2026-02-16 17:12:52,703 - 251 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-16T17:12:52.7094443Z INFO 02-16 17:12:52 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-16T17:12:53.6438680Z 2026-02-16 17:12:53,641 - 257 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-16T17:12:53.6498518Z INFO 02-16 17:12:53 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-16T17:12:54.0170632Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-16T17:12:54.0176987Z   warnings.warn(
2026-02-16T17:12:54.9702850Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-16T17:12:54.9740706Z   warnings.warn(
2026-02-16T17:12:56.1350392Z INFO 02-16 17:12:56 [ascend_config.py:412] Dynamic EPLB is False
2026-02-16T17:12:56.1361060Z INFO 02-16 17:12:56 [ascend_config.py:413] The number of redundant experts is 0
2026-02-16T17:12:56.1373451Z INFO 02-16 17:12:56 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-16T17:12:56.5821104Z INFO 02-16 17:12:56 [parallel_state.py:1212] world_size=32 rank=9 local_rank=1 distributed_init_method=tcp://10.0.0.167:45299 backend=hccl
2026-02-16T17:12:57.0932083Z INFO 02-16 17:12:57 [ascend_config.py:412] Dynamic EPLB is False
2026-02-16T17:12:57.0942080Z INFO 02-16 17:12:57 [ascend_config.py:413] The number of redundant experts is 0
2026-02-16T17:12:57.0953467Z INFO 02-16 17:12:57 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-16T17:12:57.1088633Z INFO 02-16 17:12:57 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-16T17:12:57.1097673Z INFO 02-16 17:12:57 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-16T17:12:57.1106922Z INFO 02-16 17:12:57 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-16T17:12:57.1175259Z INFO 02-16 17:12:57 [__init__.py:217] Platform plugin ascend is activated
2026-02-16T17:12:57.5140760Z INFO 02-16 17:12:57 [parallel_state.py:1212] world_size=32 rank=1 local_rank=1 distributed_init_method=tcp://10.0.0.167:45299 backend=hccl
2026-02-16T17:12:58.1417234Z INFO 02-16 17:12:58 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-16T17:12:58.1426172Z INFO 02-16 17:12:58 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-16T17:12:58.1436653Z INFO 02-16 17:12:58 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-16T17:12:58.1493848Z INFO 02-16 17:12:58 [__init__.py:217] Platform plugin ascend is activated
2026-02-16T17:13:02.1893261Z 2026-02-16 17:13:02,186 - 369 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-16T17:13:02.1975953Z INFO 02-16 17:13:02 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-16T17:13:03.3364524Z 2026-02-16 17:13:03,333 - 372 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-16T17:13:03.3423309Z INFO 02-16 17:13:03 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-16T17:13:03.4759685Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-16T17:13:03.4768609Z   warnings.warn(
2026-02-16T17:13:04.6616610Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-16T17:13:04.6624694Z   warnings.warn(
2026-02-16T17:13:05.5632563Z INFO 02-16 17:13:05 [ascend_config.py:412] Dynamic EPLB is False
2026-02-16T17:13:05.5641359Z INFO 02-16 17:13:05 [ascend_config.py:413] The number of redundant experts is 0
2026-02-16T17:13:05.5652190Z INFO 02-16 17:13:05 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-16T17:13:06.0140437Z INFO 02-16 17:13:06 [parallel_state.py:1212] world_size=32 rank=10 local_rank=2 distributed_init_method=tcp://10.0.0.167:45299 backend=hccl
2026-02-16T17:13:06.6403218Z INFO 02-16 17:13:06 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-16T17:13:06.6411096Z INFO 02-16 17:13:06 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-16T17:13:06.6421323Z INFO 02-16 17:13:06 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-16T17:13:06.6481339Z INFO 02-16 17:13:06 [__init__.py:217] Platform plugin ascend is activated
2026-02-16T17:13:06.7552389Z INFO 02-16 17:13:06 [ascend_config.py:412] Dynamic EPLB is False
2026-02-16T17:13:06.7561942Z INFO 02-16 17:13:06 [ascend_config.py:413] The number of redundant experts is 0
2026-02-16T17:13:06.7573405Z INFO 02-16 17:13:06 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-16T17:13:07.1926115Z INFO 02-16 17:13:07 [parallel_state.py:1212] world_size=32 rank=2 local_rank=2 distributed_init_method=tcp://10.0.0.167:45299 backend=hccl
2026-02-16T17:13:07.7914144Z INFO 02-16 17:13:07 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-16T17:13:07.7927055Z INFO 02-16 17:13:07 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-16T17:13:07.7937638Z INFO 02-16 17:13:07 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-16T17:13:07.7987797Z INFO 02-16 17:13:07 [__init__.py:217] Platform plugin ascend is activated
2026-02-16T17:13:11.5883894Z 2026-02-16 17:13:11,585 - 473 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-16T17:13:11.5938953Z INFO 02-16 17:13:11 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-16T17:13:12.7886036Z 2026-02-16 17:13:12,786 - 477 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-16T17:13:12.7926836Z INFO 02-16 17:13:12 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-16T17:13:12.8862785Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-16T17:13:12.8870522Z   warnings.warn(
2026-02-16T17:13:14.1342409Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-16T17:13:14.1348686Z   warnings.warn(
2026-02-16T17:13:15.0044895Z INFO 02-16 17:13:14 [ascend_config.py:412] Dynamic EPLB is False
2026-02-16T17:13:15.0052368Z INFO 02-16 17:13:14 [ascend_config.py:413] The number of redundant experts is 0
2026-02-16T17:13:15.0063435Z INFO 02-16 17:13:14 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-16T17:13:15.4407897Z INFO 02-16 17:13:15 [parallel_state.py:1212] world_size=32 rank=11 local_rank=3 distributed_init_method=tcp://10.0.0.167:45299 backend=hccl
2026-02-16T17:13:16.0518332Z INFO 02-16 17:13:16 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-16T17:13:16.0520289Z INFO 02-16 17:13:16 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-16T17:13:16.0520785Z INFO 02-16 17:13:16 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-16T17:13:16.0584613Z INFO 02-16 17:13:16 [__init__.py:217] Platform plugin ascend is activated
2026-02-16T17:13:16.2783150Z INFO 02-16 17:13:16 [ascend_config.py:412] Dynamic EPLB is False
2026-02-16T17:13:16.2791751Z INFO 02-16 17:13:16 [ascend_config.py:413] The number of redundant experts is 0
2026-02-16T17:13:16.2803584Z INFO 02-16 17:13:16 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-16T17:13:16.7342465Z INFO 02-16 17:13:16 [parallel_state.py:1212] world_size=32 rank=3 local_rank=3 distributed_init_method=tcp://10.0.0.167:45299 backend=hccl
2026-02-16T17:13:17.3481555Z INFO 02-16 17:13:17 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-16T17:13:17.3489055Z INFO 02-16 17:13:17 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-16T17:13:17.3501092Z INFO 02-16 17:13:17 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-16T17:13:17.3566255Z INFO 02-16 17:13:17 [__init__.py:217] Platform plugin ascend is activated
2026-02-16T17:13:21.0459078Z 2026-02-16 17:13:21,043 - 577 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-16T17:13:21.0520680Z INFO 02-16 17:13:21 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-16T17:13:22.2970289Z 2026-02-16 17:13:22,294 - 581 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-16T17:13:22.3026482Z INFO 02-16 17:13:22 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-16T17:13:22.3764298Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-16T17:13:22.3771693Z   warnings.warn(
2026-02-16T17:13:23.6297424Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-16T17:13:23.6302533Z   warnings.warn(
2026-02-16T17:13:24.4694129Z INFO 02-16 17:13:24 [ascend_config.py:412] Dynamic EPLB is False
2026-02-16T17:13:24.4700891Z INFO 02-16 17:13:24 [ascend_config.py:413] The number of redundant experts is 0
2026-02-16T17:13:24.4712184Z INFO 02-16 17:13:24 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-16T17:13:24.8910202Z INFO 02-16 17:13:24 [parallel_state.py:1212] world_size=32 rank=12 local_rank=4 distributed_init_method=tcp://10.0.0.167:45299 backend=hccl
2026-02-16T17:13:25.6437159Z INFO 02-16 17:13:25 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-16T17:13:25.6446044Z INFO 02-16 17:13:25 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-16T17:13:25.6455472Z INFO 02-16 17:13:25 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-16T17:13:25.6525336Z INFO 02-16 17:13:25 [__init__.py:217] Platform plugin ascend is activated
2026-02-16T17:13:25.7442138Z INFO 02-16 17:13:25 [ascend_config.py:412] Dynamic EPLB is False
2026-02-16T17:13:25.7452978Z INFO 02-16 17:13:25 [ascend_config.py:413] The number of redundant experts is 0
2026-02-16T17:13:25.7463405Z INFO 02-16 17:13:25 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-16T17:13:26.1873352Z INFO 02-16 17:13:26 [parallel_state.py:1212] world_size=32 rank=4 local_rank=4 distributed_init_method=tcp://10.0.0.167:45299 backend=hccl
2026-02-16T17:13:26.7583326Z INFO 02-16 17:13:26 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-16T17:13:26.7592299Z INFO 02-16 17:13:26 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-16T17:13:26.7602678Z INFO 02-16 17:13:26 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-16T17:13:26.7658785Z INFO 02-16 17:13:26 [__init__.py:217] Platform plugin ascend is activated
2026-02-16T17:13:30.7273309Z 2026-02-16 17:13:30,724 - 681 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-16T17:13:30.7328389Z INFO 02-16 17:13:30 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-16T17:13:31.7404478Z 2026-02-16 17:13:31,736 - 685 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-16T17:13:31.7427904Z INFO 02-16 17:13:31 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-16T17:13:32.0372336Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-16T17:13:32.0380306Z   warnings.warn(
2026-02-16T17:13:33.0264828Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-16T17:13:33.0275603Z   warnings.warn(
2026-02-16T17:13:34.1618274Z INFO 02-16 17:13:34 [ascend_config.py:412] Dynamic EPLB is False
2026-02-16T17:13:34.1627126Z INFO 02-16 17:13:34 [ascend_config.py:413] The number of redundant experts is 0
2026-02-16T17:13:34.1638496Z INFO 02-16 17:13:34 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-16T17:13:34.5892835Z INFO 02-16 17:13:34 [parallel_state.py:1212] world_size=32 rank=13 local_rank=5 distributed_init_method=tcp://10.0.0.167:45299 backend=hccl
2026-02-16T17:13:35.1724014Z INFO 02-16 17:13:35 [ascend_config.py:412] Dynamic EPLB is False
2026-02-16T17:13:35.1733379Z INFO 02-16 17:13:35 [ascend_config.py:413] The number of redundant experts is 0
2026-02-16T17:13:35.1742277Z INFO 02-16 17:13:35 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-16T17:13:35.1756207Z INFO 02-16 17:13:35 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-16T17:13:35.1783038Z INFO 02-16 17:13:35 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-16T17:13:35.1794140Z INFO 02-16 17:13:35 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-16T17:13:35.1850993Z INFO 02-16 17:13:35 [__init__.py:217] Platform plugin ascend is activated
2026-02-16T17:13:35.5940207Z INFO 02-16 17:13:35 [parallel_state.py:1212] world_size=32 rank=5 local_rank=5 distributed_init_method=tcp://10.0.0.167:45299 backend=hccl
2026-02-16T17:13:36.1784121Z INFO 02-16 17:13:36 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-16T17:13:36.1793491Z INFO 02-16 17:13:36 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-16T17:13:36.1805238Z INFO 02-16 17:13:36 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-16T17:13:36.1856820Z INFO 02-16 17:13:36 [__init__.py:217] Platform plugin ascend is activated
2026-02-16T17:13:40.3523626Z 2026-02-16 17:13:40,349 - 785 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-16T17:13:40.3643104Z INFO 02-16 17:13:40 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-16T17:13:41.2185024Z 2026-02-16 17:13:41,216 - 788 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-16T17:13:41.2244738Z INFO 02-16 17:13:41 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-16T17:13:41.6488693Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-16T17:13:41.6495572Z   warnings.warn(
2026-02-16T17:13:42.5421658Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-16T17:13:42.5427970Z   warnings.warn(
2026-02-16T17:13:43.7168170Z INFO 02-16 17:13:43 [ascend_config.py:412] Dynamic EPLB is False
2026-02-16T17:13:43.7177767Z INFO 02-16 17:13:43 [ascend_config.py:413] The number of redundant experts is 0
2026-02-16T17:13:43.7187957Z INFO 02-16 17:13:43 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-16T17:13:44.1469896Z INFO 02-16 17:13:44 [parallel_state.py:1212] world_size=32 rank=14 local_rank=6 distributed_init_method=tcp://10.0.0.167:45299 backend=hccl
2026-02-16T17:13:44.5978636Z INFO 02-16 17:13:44 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-16T17:13:44.5985189Z INFO 02-16 17:13:44 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-16T17:13:44.5994800Z INFO 02-16 17:13:44 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-16T17:13:44.6051744Z INFO 02-16 17:13:44 [__init__.py:217] Platform plugin ascend is activated
2026-02-16T17:13:44.6475801Z INFO 02-16 17:13:44 [ascend_config.py:412] Dynamic EPLB is False
2026-02-16T17:13:44.6485121Z INFO 02-16 17:13:44 [ascend_config.py:413] The number of redundant experts is 0
2026-02-16T17:13:44.6495720Z INFO 02-16 17:13:44 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-16T17:13:45.1096981Z INFO 02-16 17:13:45 [parallel_state.py:1212] world_size=32 rank=6 local_rank=6 distributed_init_method=tcp://10.0.0.167:45299 backend=hccl
2026-02-16T17:13:45.6465387Z INFO 02-16 17:13:45 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-16T17:13:45.6473187Z INFO 02-16 17:13:45 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-16T17:13:45.6482475Z INFO 02-16 17:13:45 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-16T17:13:45.6538791Z INFO 02-16 17:13:45 [__init__.py:217] Platform plugin ascend is activated
2026-02-16T17:13:49.4145388Z 2026-02-16 17:13:49,412 - 889 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-16T17:13:49.4206939Z INFO 02-16 17:13:49 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-16T17:13:50.5966424Z 2026-02-16 17:13:50,594 - 892 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-16T17:13:50.6021718Z INFO 02-16 17:13:50 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-16T17:13:50.6974811Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-16T17:13:50.6983577Z   warnings.warn(
2026-02-16T17:13:51.8645075Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-16T17:13:51.8653182Z   warnings.warn(
2026-02-16T17:13:52.7424640Z INFO 02-16 17:13:52 [ascend_config.py:412] Dynamic EPLB is False
2026-02-16T17:13:52.7433791Z INFO 02-16 17:13:52 [ascend_config.py:413] The number of redundant experts is 0
2026-02-16T17:13:52.7443667Z INFO 02-16 17:13:52 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-16T17:13:53.1715588Z INFO 02-16 17:13:53 [parallel_state.py:1212] world_size=32 rank=15 local_rank=7 distributed_init_method=tcp://10.0.0.167:45299 backend=hccl
2026-02-16T17:13:53.8857186Z INFO 02-16 17:13:53 [ascend_config.py:412] Dynamic EPLB is False
2026-02-16T17:13:53.8869163Z INFO 02-16 17:13:53 [ascend_config.py:413] The number of redundant experts is 0
2026-02-16T17:13:53.8882483Z INFO 02-16 17:13:53 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-16T17:13:54.3181964Z INFO 02-16 17:13:54 [parallel_state.py:1212] world_size=32 rank=7 local_rank=7 distributed_init_method=tcp://10.0.0.167:45299 backend=hccl
2026-02-16T17:13:55.9463466Z [Gloo] Rank 2 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-16T17:13:55.9471228Z [Gloo] Rank 4 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-16T17:13:55.9482147Z [Gloo] Rank 7 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-16T17:13:55.9492604Z [Gloo] Rank 3 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-16T17:13:55.9501761Z [Gloo] Rank 0 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-16T17:13:55.9998504Z [Gloo] Rank 12 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-16T17:13:56.0025067Z [Gloo] Rank 8 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-16T17:13:56.0047809Z [Gloo] Rank 9 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-16T17:13:56.0058165Z [Gloo] Rank 1 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-16T17:13:56.0070441Z [Gloo] Rank 5 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-16T17:13:56.0078497Z [Gloo] Rank 6 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-16T17:13:56.0090125Z [Gloo] Rank 10 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-16T17:13:56.0099881Z [Gloo] Rank 13 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-16T17:13:56.0835276Z [Gloo] Rank 15 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-16T17:13:56.0846068Z [Gloo] Rank 11 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-16T17:13:56.0856617Z [Gloo] Rank 14 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-16T17:13:56.1710068Z [Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-16T17:13:56.1719467Z [Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-16T17:13:56.1728552Z [Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-16T17:13:56.1738060Z [Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-16T17:13:56.1746999Z [Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-16T17:13:56.1756075Z [Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-16T17:13:56.1766698Z [Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-16T17:13:56.1778728Z [Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-16T17:13:56.1790286Z [Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-16T17:13:56.1801676Z [Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-16T17:13:56.1812829Z [Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-16T17:13:56.1823627Z [Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-16T17:13:56.1833876Z [Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-16T17:13:56.1843290Z [Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-16T17:13:56.1853054Z [Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-16T17:13:56.1862602Z [Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-16T17:13:56.1872324Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-16T17:13:56.1881686Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-16T17:13:56.1891704Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-16T17:13:56.1900995Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-16T17:13:56.1910150Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-16T17:13:56.1920070Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-16T17:13:56.1929790Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-16T17:13:56.1939163Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-16T17:13:56.1948728Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-16T17:13:56.1957922Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-16T17:13:56.1969698Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-16T17:13:56.1984500Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-16T17:13:56.1996059Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-16T17:13:56.2006304Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-16T17:13:56.2016518Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-16T17:13:56.2026244Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-16T17:13:56.2036258Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-16T17:13:56.2047099Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-16T17:13:56.2056949Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-16T17:13:56.2066058Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-16T17:13:56.2075492Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-16T17:13:56.2087840Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-16T17:13:56.2098828Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-16T17:13:56.2108509Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-16T17:13:56.2694285Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-16T17:13:56.2703601Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-16T17:13:56.2712505Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-16T17:13:56.2722437Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-16T17:13:56.2731664Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-16T17:13:56.2740923Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-16T17:13:56.2749610Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-16T17:13:56.2760560Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-16T17:13:56.2771699Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-16T17:13:56.2781791Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-16T17:13:56.2793250Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-16T17:13:56.2803193Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-16T17:13:56.2813507Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-16T17:13:56.2822860Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-16T17:13:56.2831593Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-16T17:13:56.2841723Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-16T17:13:56.2850690Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-16T17:13:56.2859255Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-16T17:13:56.2869231Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-16T17:13:56.2878182Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-16T17:13:56.2888106Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-16T17:13:56.2897285Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-16T17:13:56.2906259Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-16T17:13:56.2915565Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-16T17:13:56.2925507Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-16T17:13:56.2934589Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-16T17:13:56.2943721Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-16T17:13:56.2953034Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-16T17:13:56.2962796Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-16T17:13:56.2972169Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-16T17:13:56.2981460Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-16T17:13:56.2990299Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-16T17:13:56.2999748Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-16T17:13:56.3009226Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-16T17:13:56.3018636Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-16T17:13:56.3028065Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-16T17:13:56.3037177Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-16T17:13:56.3046859Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-16T17:13:56.3056316Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-16T17:13:56.3065508Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-16T17:13:56.3171915Z [Gloo] Rank 0 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-16T17:13:56.3190839Z INFO 02-16 17:13:56 [parallel_state.py:1423] rank 0 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
2026-02-16T17:13:56.3800566Z [Gloo] Rank 1 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-16T17:13:56.3809409Z [Gloo] Rank 8 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-16T17:13:56.3820655Z INFO 02-16 17:13:56 [parallel_state.py:1423] rank 1 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 1, EP rank 1
2026-02-16T17:13:56.3833989Z [Gloo] Rank 10 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-16T17:13:56.3844018Z [Gloo] Rank 12 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-16T17:13:56.3854403Z INFO 02-16 17:13:56 [parallel_state.py:1423] rank 8 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 0, EP rank 8
2026-02-16T17:13:56.3863944Z INFO 02-16 17:13:56 [parallel_state.py:1423] rank 12 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 4, EP rank 12
2026-02-16T17:13:56.3873718Z INFO 02-16 17:13:56 [parallel_state.py:1423] rank 10 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 2, EP rank 10
2026-02-16T17:13:56.4521639Z [Gloo] Rank 2 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-16T17:13:56.4540363Z INFO 02-16 17:13:56 [parallel_state.py:1423] rank 2 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 2, EP rank 2
2026-02-16T17:13:56.4559447Z [Gloo] Rank 6 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-16T17:13:56.4568798Z [Gloo] Rank 5 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-16T17:13:56.4577686Z [Gloo] Rank 4 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-16T17:13:56.4586385Z [Gloo] Rank 3 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-16T17:13:56.4596177Z INFO 02-16 17:13:56 [parallel_state.py:1423] rank 6 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 6, EP rank 6
2026-02-16T17:13:56.4610961Z [Gloo] Rank 9 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-16T17:13:56.4614470Z [Gloo] Rank 7 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-16T17:13:56.4623389Z INFO 02-16 17:13:56 [parallel_state.py:1423] rank 5 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 5, EP rank 5
2026-02-16T17:13:56.4632273Z INFO 02-16 17:13:56 [parallel_state.py:1423] rank 4 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 4, EP rank 4
2026-02-16T17:13:56.4640909Z [Gloo] Rank 13 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-16T17:13:56.4650413Z [Gloo] Rank 15 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-16T17:13:56.4659481Z [Gloo] Rank 11 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-16T17:13:56.4668420Z INFO 02-16 17:13:56 [parallel_state.py:1423] rank 3 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 3, EP rank 3
2026-02-16T17:13:56.4677995Z INFO 02-16 17:13:56 [parallel_state.py:1423] rank 7 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 7, EP rank 7
2026-02-16T17:13:56.4687666Z INFO 02-16 17:13:56 [parallel_state.py:1423] rank 9 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 1, EP rank 9
2026-02-16T17:13:56.4696423Z [Gloo] Rank 14 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-16T17:13:56.4705677Z INFO 02-16 17:13:56 [parallel_state.py:1423] rank 15 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 7, EP rank 15
2026-02-16T17:13:56.4715196Z INFO 02-16 17:13:56 [parallel_state.py:1423] rank 13 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 5, EP rank 13
2026-02-16T17:13:56.4724933Z INFO 02-16 17:13:56 [parallel_state.py:1423] rank 11 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 3, EP rank 11
2026-02-16T17:13:56.4734084Z INFO 02-16 17:13:56 [parallel_state.py:1423] rank 14 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 6, EP rank 14
2026-02-16T17:13:56.4920997Z [Gloo] Rank 0 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-16T17:13:56.4939843Z [Gloo] Rank 4 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-16T17:13:56.4951173Z [Gloo] Rank 3 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-16T17:13:56.4960236Z [Gloo] Rank 2 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-16T17:13:56.4970785Z [Gloo] Rank 6 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-16T17:13:56.4980002Z [Gloo] Rank 1 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-16T17:13:56.4988715Z [Gloo] Rank 9 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-16T17:13:56.4998580Z [Gloo] Rank 5 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-16T17:13:56.5007940Z [Gloo] Rank 13 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-16T17:13:56.5017173Z [Gloo] Rank 7 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-16T17:13:56.5025918Z [Gloo] Rank 11 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-16T17:13:56.5035260Z [Gloo] Rank 8 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-16T17:13:56.5044192Z [Gloo] Rank 15 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-16T17:13:56.5053514Z [Gloo] Rank 10 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-16T17:13:56.5064589Z [Gloo] Rank 14 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-16T17:13:56.5076569Z [Gloo] Rank 12 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-16T17:13:56.5090036Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-16T17:13:56.5102123Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-16T17:13:56.5113456Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-16T17:13:56.5123601Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-16T17:13:56.5133176Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-16T17:13:56.5143639Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-16T17:13:56.5152879Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-16T17:13:56.5164316Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-16T17:13:56.5173349Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-16T17:13:56.5182340Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-16T17:13:56.5191440Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-16T17:13:56.5201896Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-16T17:13:56.5210784Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-16T17:13:56.5220129Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-16T17:13:56.5230082Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-16T17:13:56.5239523Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-16T17:13:56.5787608Z WARNING 02-16 17:13:56 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-16T17:13:56.5797974Z WARNING 02-16 17:13:56 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-16T17:13:56.5807723Z WARNING 02-16 17:13:56 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-16T17:13:56.5816682Z WARNING 02-16 17:13:56 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-16T17:13:56.5826229Z WARNING 02-16 17:13:56 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-16T17:13:56.5835197Z WARNING 02-16 17:13:56 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-16T17:13:56.5844868Z WARNING 02-16 17:13:56 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-16T17:13:56.5854590Z WARNING 02-16 17:13:56 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-16T17:13:56.5864588Z WARNING 02-16 17:13:56 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-16T17:13:56.5874991Z WARNING 02-16 17:13:56 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-16T17:13:56.5884878Z WARNING 02-16 17:13:56 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-16T17:13:56.5894346Z WARNING 02-16 17:13:56 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-16T17:13:56.5903644Z WARNING 02-16 17:13:56 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-16T17:13:56.5913262Z WARNING 02-16 17:13:56 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-16T17:13:56.5922723Z WARNING 02-16 17:13:56 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-16T17:13:56.5932214Z WARNING 02-16 17:13:56 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-16T17:13:56.6308792Z WARNING 02-16 17:13:56 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-16T17:13:56.6319303Z WARNING 02-16 17:13:56 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-16T17:13:56.6328727Z WARNING 02-16 17:13:56 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-16T17:13:56.6337725Z WARNING 02-16 17:13:56 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-16T17:13:56.6347263Z WARNING 02-16 17:13:56 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-16T17:13:56.6356102Z WARNING 02-16 17:13:56 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-16T17:13:56.6365780Z WARNING 02-16 17:13:56 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-16T17:13:56.6375918Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m INFO 02-16 17:13:56 [model_runner_v1.py:2308] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-16T17:13:56.6385266Z WARNING 02-16 17:13:56 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-16T17:13:56.6394404Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m INFO 02-16 17:13:56 [model_runner_v1.py:2308] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-16T17:13:56.6404113Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m INFO 02-16 17:13:56 [model_runner_v1.py:2308] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-16T17:13:56.6413294Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m INFO 02-16 17:13:56 [model_runner_v1.py:2308] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-16T17:13:56.6422679Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m INFO 02-16 17:13:56 [model_runner_v1.py:2308] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-16T17:13:56.6431621Z WARNING 02-16 17:13:56 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-16T17:13:56.6441111Z WARNING 02-16 17:13:56 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-16T17:13:56.6450911Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m INFO 02-16 17:13:56 [model_runner_v1.py:2308] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-16T17:13:56.6460411Z WARNING 02-16 17:13:56 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-16T17:13:56.6473227Z WARNING 02-16 17:13:56 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-16T17:13:56.6483332Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m INFO 02-16 17:13:56 [model_runner_v1.py:2308] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-16T17:13:56.6492525Z WARNING 02-16 17:13:56 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-16T17:13:56.6501725Z WARNING 02-16 17:13:56 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-16T17:13:56.6510997Z WARNING 02-16 17:13:56 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-16T17:13:56.6520492Z WARNING 02-16 17:13:56 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-16T17:13:56.6530398Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m INFO 02-16 17:13:56 [model_runner_v1.py:2308] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-16T17:13:56.6539765Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m INFO 02-16 17:13:56 [model_runner_v1.py:2308] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-16T17:13:56.6549676Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m INFO 02-16 17:13:56 [model_runner_v1.py:2308] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-16T17:13:56.6558590Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m INFO 02-16 17:13:56 [model_runner_v1.py:2308] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-16T17:13:56.6569400Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m INFO 02-16 17:13:56 [model_runner_v1.py:2308] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-16T17:13:56.6578347Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m INFO 02-16 17:13:56 [model_runner_v1.py:2308] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-16T17:13:56.6588082Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m INFO 02-16 17:13:56 [model_runner_v1.py:2308] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-16T17:13:56.6597240Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m INFO 02-16 17:13:56 [model_runner_v1.py:2308] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-16T17:13:56.7297498Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m INFO 02-16 17:13:56 [model_runner_v1.py:2308] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-16T17:13:57.0040379Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m [2026-02-16 17:13:57] INFO modelslim_config.py:286: Using the vLLM Ascend modelslim Quantization now!
2026-02-16T17:13:57.0153880Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m [2026-02-16 17:13:57] INFO modelslim_config.py:286: Using the vLLM Ascend modelslim Quantization now!
2026-02-16T17:13:57.0676129Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m [2026-02-16 17:13:57] INFO modelslim_config.py:286: Using the vLLM Ascend modelslim Quantization now!
2026-02-16T17:13:57.0796040Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m [2026-02-16 17:13:57] INFO modelslim_config.py:286: Using the vLLM Ascend modelslim Quantization now!
2026-02-16T17:13:57.0862595Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m [2026-02-16 17:13:57] INFO modelslim_config.py:286: Using the vLLM Ascend modelslim Quantization now!
2026-02-16T17:13:57.1292578Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m [2026-02-16 17:13:57] INFO modelslim_config.py:286: Using the vLLM Ascend modelslim Quantization now!
2026-02-16T17:13:57.1913283Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m INFO 02-16 17:13:57 [layer.py:475] [EP Rank 14/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->112, 1->113, 2->114, 3->115, 4->116, 5->117, 6->118, 7->119.
2026-02-16T17:13:57.1936402Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m INFO 02-16 17:13:57 [layer.py:475] [EP Rank 7/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->56, 1->57, 2->58, 3->59, 4->60, 5->61, 6->62, 7->63.
2026-02-16T17:13:57.1946723Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m INFO 02-16 17:13:57 [layer.py:475] [EP Rank 2/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->16, 1->17, 2->18, 3->19, 4->20, 5->21, 6->22, 7->23.
2026-02-16T17:13:57.1976895Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m INFO 02-16 17:13:57 [layer.py:475] [EP Rank 1/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->8, 1->9, 2->10, 3->11, 4->12, 5->13, 6->14, 7->15.
2026-02-16T17:13:57.2040975Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m INFO 02-16 17:13:57 [layer.py:475] [EP Rank 10/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->80, 1->81, 2->82, 3->83, 4->84, 5->85, 6->86, 7->87.
2026-02-16T17:13:57.2459312Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m INFO 02-16 17:13:57 [layer.py:475] [EP Rank 3/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->24, 1->25, 2->26, 3->27, 4->28, 5->29, 6->30, 7->31.
2026-02-16T17:13:57.3451554Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m [2026-02-16 17:13:57] INFO modelslim_config.py:286: Using the vLLM Ascend modelslim Quantization now!
2026-02-16T17:13:57.4399079Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m [2026-02-16 17:13:57] INFO modelslim_config.py:286: Using the vLLM Ascend modelslim Quantization now!
2026-02-16T17:13:57.4467173Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m [2026-02-16 17:13:57] INFO modelslim_config.py:286: Using the vLLM Ascend modelslim Quantization now!
2026-02-16T17:13:57.4578844Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m INFO 02-16 17:13:57 [layer.py:475] [EP Rank 9/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->72, 1->73, 2->74, 3->75, 4->76, 5->77, 6->78, 7->79.
2026-02-16T17:13:57.4825327Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m [2026-02-16 17:13:57] INFO modelslim_config.py:286: Using the vLLM Ascend modelslim Quantization now!
2026-02-16T17:13:57.4898091Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m [2026-02-16 17:13:57] INFO modelslim_config.py:286: Using the vLLM Ascend modelslim Quantization now!
2026-02-16T17:13:57.5552515Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m INFO 02-16 17:13:57 [layer.py:475] [EP Rank 4/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->32, 1->33, 2->34, 3->35, 4->36, 5->37, 6->38, 7->39.
2026-02-16T17:13:57.5591486Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m INFO 02-16 17:13:57 [layer.py:475] [EP Rank 6/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->48, 1->49, 2->50, 3->51, 4->52, 5->53, 6->54, 7->55.
2026-02-16T17:13:57.5993530Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m INFO 02-16 17:13:57 [layer.py:475] [EP Rank 13/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->104, 1->105, 2->106, 3->107, 4->108, 5->109, 6->110, 7->111.
2026-02-16T17:13:57.6613974Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m INFO 02-16 17:13:57 [layer.py:475] [EP Rank 0/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->0, 1->1, 2->2, 3->3, 4->4, 5->5, 6->6, 7->7.
2026-02-16T17:13:57.6639046Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m [2026-02-16 17:13:57] INFO modelslim_config.py:286: Using the vLLM Ascend modelslim Quantization now!
2026-02-16T17:13:57.7253786Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m [2026-02-16 17:13:57] INFO modelslim_config.py:286: Using the vLLM Ascend modelslim Quantization now!
2026-02-16T17:13:57.7427711Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m [2026-02-16 17:13:57] INFO modelslim_config.py:286: Using the vLLM Ascend modelslim Quantization now!
2026-02-16T17:13:57.8296877Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m INFO 02-16 17:13:57 [layer.py:475] [EP Rank 8/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->64, 1->65, 2->66, 3->67, 4->68, 5->69, 6->70, 7->71.
2026-02-16T17:13:57.8393668Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m INFO 02-16 17:13:57 [layer.py:475] [EP Rank 5/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->40, 1->41, 2->42, 3->43, 4->44, 5->45, 6->46, 7->47.
2026-02-16T17:13:57.8613952Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m INFO 02-16 17:13:57 [layer.py:475] [EP Rank 11/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->88, 1->89, 2->90, 3->91, 4->92, 5->93, 6->94, 7->95.
2026-02-16T17:13:57.8654872Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m [2026-02-16 17:13:57] INFO modelslim_config.py:286: Using the vLLM Ascend modelslim Quantization now!
2026-02-16T17:13:57.9751601Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m INFO 02-16 17:13:57 [layer.py:475] [EP Rank 12/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->96, 1->97, 2->98, 3->99, 4->100, 5->101, 6->102, 7->103.
2026-02-16T17:13:58.0743535Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m [2026-02-16 17:13:58] INFO modelslim_config.py:286: Using the vLLM Ascend modelslim Quantization now!
2026-02-16T17:13:58.2019547Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m INFO 02-16 17:13:58 [layer.py:475] [EP Rank 15/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->120, 1->121, 2->122, 3->123, 4->124, 5->125, 6->126, 7->127.
2026-02-16T17:13:59.6335490Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-16T17:13:59.6346229Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-16T17:13:59.6357814Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-16T17:13:59.6368111Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-16T17:13:59.6377893Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.6388440Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-16T17:13:59.6398341Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-16T17:13:59.6407301Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 404, in load_model
2026-02-16T17:13:59.6416402Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-16T17:13:59.6426758Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2311, in load_model
2026-02-16T17:13:59.6436864Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-16T17:13:59.6447323Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.6457480Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-16T17:13:59.6467451Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     return loader.load_model(
2026-02-16T17:13:59.6477326Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.6487986Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-16T17:13:59.6497157Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     model = initialize_model(
2026-02-16T17:13:59.6506050Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.6515776Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-16T17:13:59.6526180Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-16T17:13:59.6536350Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.6546493Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-16T17:13:59.6556313Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-16T17:13:59.6566768Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-16T17:13:59.6576248Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-16T17:13:59.6585970Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-16T17:13:59.6596171Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-16T17:13:59.6606411Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-16T17:13:59.6616967Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-16T17:13:59.6626811Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-16T17:13:59.6636755Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     + [
2026-02-16T17:13:59.6646001Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]       ^
2026-02-16T17:13:59.6655964Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-16T17:13:59.6664941Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-16T17:13:59.6674737Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.6684601Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-16T17:13:59.6693968Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-16T17:13:59.6703656Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.6713631Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-16T17:13:59.6724575Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-16T17:13:59.6732606Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-16T17:13:59.6744432Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-16T17:13:59.6751826Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-16T17:13:59.6761785Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-16T17:13:59.6772988Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 401, in __init__
2026-02-16T17:13:59.6792370Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-16T17:13:59.6794587Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 162, in __init__
2026-02-16T17:13:59.6804557Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-16T17:13:59.6814494Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-16T17:13:59.6824320Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-16T17:13:59.6834105Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.6844507Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-16T17:13:59.6853756Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-16T17:13:59.6863051Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.6873633Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 419, in get_quant_method
2026-02-16T17:13:59.6883498Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-16T17:13:59.6893495Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.6903199Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 295, in create_scheme_for_layer
2026-02-16T17:13:59.6912062Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     return scheme_cls()
2026-02-16T17:13:59.6921634Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-16T17:13:59.6931570Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-16T17:13:59.6940642Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-16T17:13:59.6949948Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.6961141Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-16T17:13:59.6970645Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772] [ERROR] 2026-02-16-17:13:58 (PID:202, Device:0, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-16T17:13:59.6979470Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772] 
2026-02-16T17:13:59.6988884Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m INFO 02-16 17:13:59 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-16T17:13:59.7161540Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m INFO 02-16 17:13:59 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-16T17:13:59.7232430Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-16T17:13:59.7242449Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-16T17:13:59.7253254Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-16T17:13:59.7262400Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-16T17:13:59.7272520Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.7282447Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-16T17:13:59.7292136Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-16T17:13:59.7301326Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 404, in load_model
2026-02-16T17:13:59.7310444Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-16T17:13:59.7320847Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2311, in load_model
2026-02-16T17:13:59.7330879Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-16T17:13:59.7341108Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.7350682Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-16T17:13:59.7360119Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     return loader.load_model(
2026-02-16T17:13:59.7370039Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.7379305Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-16T17:13:59.7388488Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     model = initialize_model(
2026-02-16T17:13:59.7397902Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.7407961Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-16T17:13:59.7417946Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-16T17:13:59.7427402Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.7437146Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-16T17:13:59.7446676Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-16T17:13:59.7456725Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-16T17:13:59.7465726Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-16T17:13:59.7475166Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-16T17:13:59.7485320Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-16T17:13:59.7494603Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-16T17:13:59.7504665Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-16T17:13:59.7514049Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-16T17:13:59.7524109Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     + [
2026-02-16T17:13:59.7533704Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]       ^
2026-02-16T17:13:59.7543313Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-16T17:13:59.7552925Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-16T17:13:59.7562398Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.7572456Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-16T17:13:59.7581034Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-16T17:13:59.7595750Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.7600276Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-16T17:13:59.7655177Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-16T17:13:59.7655854Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-16T17:13:59.7656837Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-16T17:13:59.7657838Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-16T17:13:59.7658461Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-16T17:13:59.7659304Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 401, in __init__
2026-02-16T17:13:59.7667503Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-16T17:13:59.7677691Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 162, in __init__
2026-02-16T17:13:59.7687570Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-16T17:13:59.7697277Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-16T17:13:59.7713930Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-16T17:13:59.7715963Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.7726479Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-16T17:13:59.7736057Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-16T17:13:59.7745078Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.7754678Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 419, in get_quant_method
2026-02-16T17:13:59.7765509Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-16T17:13:59.7775662Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.7786409Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 295, in create_scheme_for_layer
2026-02-16T17:13:59.7796501Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     return scheme_cls()
2026-02-16T17:13:59.7806847Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-16T17:13:59.7816012Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-16T17:13:59.7824862Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-16T17:13:59.7834662Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.7845569Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-16T17:13:59.7854038Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772] [ERROR] 2026-02-16-17:13:58 (PID:477, Device:3, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-16T17:13:59.7863219Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772] 
2026-02-16T17:13:59.7873201Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m INFO 02-16 17:13:59 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-16T17:13:59.7882632Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-16T17:13:59.7891481Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-16T17:13:59.7901000Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-16T17:13:59.7910132Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-16T17:13:59.7919988Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.7930521Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-16T17:13:59.7939172Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-16T17:13:59.7948686Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 404, in load_model
2026-02-16T17:13:59.7958150Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-16T17:13:59.7968467Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2311, in load_model
2026-02-16T17:13:59.7978232Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-16T17:13:59.7987681Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.7997403Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-16T17:13:59.8007034Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     return loader.load_model(
2026-02-16T17:13:59.8016682Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.8026301Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-16T17:13:59.8035456Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     model = initialize_model(
2026-02-16T17:13:59.8046572Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.8058306Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-16T17:13:59.8068076Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-16T17:13:59.8077529Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.8087895Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-16T17:13:59.8096977Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-16T17:13:59.8107058Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-16T17:13:59.8115794Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-16T17:13:59.8125477Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-16T17:13:59.8135270Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-16T17:13:59.8145057Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-16T17:13:59.8154207Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-16T17:13:59.8164101Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-16T17:13:59.8173574Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     + [
2026-02-16T17:13:59.8182681Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]       ^
2026-02-16T17:13:59.8192532Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-16T17:13:59.8202301Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-16T17:13:59.8211926Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.8221275Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-16T17:13:59.8230306Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-16T17:13:59.8239693Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.8249350Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-16T17:13:59.8258386Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-16T17:13:59.8268044Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-16T17:13:59.8276857Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-16T17:13:59.8286983Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-16T17:13:59.8295534Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-16T17:13:59.8305505Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 401, in __init__
2026-02-16T17:13:59.8314624Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-16T17:13:59.8325641Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 162, in __init__
2026-02-16T17:13:59.8334276Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-16T17:13:59.8343674Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-16T17:13:59.8352620Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-16T17:13:59.8362458Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.8372674Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-16T17:13:59.8382143Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-16T17:13:59.8392195Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.8402524Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 419, in get_quant_method
2026-02-16T17:13:59.8412284Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-16T17:13:59.8421766Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.8431099Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 295, in create_scheme_for_layer
2026-02-16T17:13:59.8440398Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     return scheme_cls()
2026-02-16T17:13:59.8449879Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-16T17:13:59.8460027Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-16T17:13:59.8469431Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-16T17:13:59.8479692Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.8490897Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-16T17:13:59.8500036Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772] [ERROR] 2026-02-16-17:13:59 (PID:372, Device:2, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-16T17:13:59.8508867Z [0;36m(Worker_DP0_TP2_EP2 pid=372)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772] 
2026-02-16T17:13:59.8518100Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-16T17:13:59.8527816Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-16T17:13:59.8538368Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-16T17:13:59.8548038Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-16T17:13:59.8557275Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.8567260Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-16T17:13:59.8577501Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-16T17:13:59.8586649Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 404, in load_model
2026-02-16T17:13:59.8595796Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-16T17:13:59.8605863Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2311, in load_model
2026-02-16T17:13:59.8618933Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-16T17:13:59.8628936Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.8672321Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-16T17:13:59.8673114Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     return loader.load_model(
2026-02-16T17:13:59.8692359Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.8693339Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-16T17:13:59.8694135Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     model = initialize_model(
2026-02-16T17:13:59.8694708Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.8700412Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-16T17:13:59.8709015Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-16T17:13:59.8717901Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.8732930Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-16T17:13:59.8737346Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-16T17:13:59.8747467Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-16T17:13:59.8757100Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-16T17:13:59.8767747Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-16T17:13:59.8778587Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-16T17:13:59.8789112Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-16T17:13:59.8800153Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-16T17:13:59.8809863Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-16T17:13:59.8822195Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     + [
2026-02-16T17:13:59.8828083Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]       ^
2026-02-16T17:13:59.8837845Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-16T17:13:59.8848100Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-16T17:13:59.8857234Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.8870442Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-16T17:13:59.8876221Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-16T17:13:59.8892236Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.8963101Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-16T17:13:59.8963900Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-16T17:13:59.8964616Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-16T17:13:59.8965446Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-16T17:13:59.8966301Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-16T17:13:59.8966953Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-16T17:13:59.8967758Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 401, in __init__
2026-02-16T17:13:59.8968559Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-16T17:13:59.8971808Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 162, in __init__
2026-02-16T17:13:59.8980995Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-16T17:13:59.8990499Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-16T17:13:59.8999834Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-16T17:13:59.9009749Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.9019762Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-16T17:13:59.9028984Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-16T17:13:59.9038743Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.9049195Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 419, in get_quant_method
2026-02-16T17:13:59.9058637Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-16T17:13:59.9068740Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.9079109Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 295, in create_scheme_for_layer
2026-02-16T17:13:59.9087999Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     return scheme_cls()
2026-02-16T17:13:59.9097091Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-16T17:13:59.9107515Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-16T17:13:59.9116580Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-16T17:13:59.9126643Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.9136645Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-16T17:13:59.9149593Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772] [ERROR] 2026-02-16-17:13:59 (PID:201, Device:0, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-16T17:13:59.9155779Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772] 
2026-02-16T17:13:59.9167157Z [0;36m(Worker_DP1_TP0_EP8 pid=201)[0;0m INFO 02-16 17:13:59 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-16T17:13:59.9176747Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m INFO 02-16 17:13:59 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-16T17:13:59.9183472Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-16T17:13:59.9192706Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-16T17:13:59.9202658Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-16T17:13:59.9212506Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-16T17:13:59.9221320Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.9230974Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-16T17:13:59.9240130Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-16T17:13:59.9250413Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 404, in load_model
2026-02-16T17:13:59.9259056Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-16T17:13:59.9268859Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2311, in load_model
2026-02-16T17:13:59.9278960Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-16T17:13:59.9288587Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.9300053Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-16T17:13:59.9307081Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     return loader.load_model(
2026-02-16T17:13:59.9316482Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.9326893Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-16T17:13:59.9336035Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     model = initialize_model(
2026-02-16T17:13:59.9345522Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.9354967Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-16T17:13:59.9364638Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-16T17:13:59.9374557Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.9384338Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-16T17:13:59.9393844Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-16T17:13:59.9403371Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-16T17:13:59.9413999Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-16T17:13:59.9423089Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-16T17:13:59.9433451Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-16T17:13:59.9443729Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-16T17:13:59.9453257Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-16T17:13:59.9463130Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-16T17:13:59.9471724Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     + [
2026-02-16T17:13:59.9481516Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]       ^
2026-02-16T17:13:59.9491255Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-16T17:13:59.9500453Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-16T17:13:59.9509969Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.9520035Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-16T17:13:59.9529565Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-16T17:13:59.9538687Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.9548224Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-16T17:13:59.9557378Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-16T17:13:59.9567262Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-16T17:13:59.9576820Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-16T17:13:59.9586221Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-16T17:13:59.9595473Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-16T17:13:59.9605187Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 401, in __init__
2026-02-16T17:13:59.9614607Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-16T17:13:59.9624035Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 162, in __init__
2026-02-16T17:13:59.9633325Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-16T17:13:59.9645330Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-16T17:13:59.9653361Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-16T17:13:59.9708662Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.9709601Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-16T17:13:59.9710550Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-16T17:13:59.9711287Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.9712307Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 419, in get_quant_method
2026-02-16T17:13:59.9713378Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-16T17:13:59.9720571Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.9730571Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 295, in create_scheme_for_layer
2026-02-16T17:13:59.9739817Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     return scheme_cls()
2026-02-16T17:13:59.9749071Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-16T17:13:59.9759309Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-16T17:13:59.9770992Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-16T17:13:59.9781733Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.9805841Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-16T17:13:59.9807216Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772] [ERROR] 2026-02-16-17:13:59 (PID:785, Device:6, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-16T17:13:59.9811185Z [0;36m(Worker_DP1_TP6_EP14 pid=785)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772] 
2026-02-16T17:13:59.9820499Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m INFO 02-16 17:13:59 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-16T17:13:59.9829722Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m INFO 02-16 17:13:59 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-16T17:13:59.9839456Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m INFO 02-16 17:13:59 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-16T17:13:59.9849265Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-16T17:13:59.9858693Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-16T17:13:59.9868548Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-16T17:13:59.9877880Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-16T17:13:59.9887979Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.9897347Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-16T17:13:59.9906356Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-16T17:13:59.9915912Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 404, in load_model
2026-02-16T17:13:59.9925833Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-16T17:13:59.9935816Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2311, in load_model
2026-02-16T17:13:59.9945434Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-16T17:13:59.9954702Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.9965179Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-16T17:13:59.9974435Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     return loader.load_model(
2026-02-16T17:13:59.9984046Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-16T17:13:59.9993832Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-16T17:14:00.0002762Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     model = initialize_model(
2026-02-16T17:14:00.0011798Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.0021952Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-16T17:14:00.0030773Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-16T17:14:00.0040427Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.0050771Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-16T17:14:00.0059780Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-16T17:14:00.0068845Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-16T17:14:00.0078624Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-16T17:14:00.0087857Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-16T17:14:00.0097291Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-16T17:14:00.0107067Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-16T17:14:00.0116806Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-16T17:14:00.0127201Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-16T17:14:00.0136126Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     + [
2026-02-16T17:14:00.0145218Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]       ^
2026-02-16T17:14:00.0155297Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-16T17:14:00.0164481Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-16T17:14:00.0173538Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.0183943Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-16T17:14:00.0204315Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-16T17:14:00.0205034Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.0212386Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-16T17:14:00.0221542Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-16T17:14:00.0230759Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-16T17:14:00.0240660Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-16T17:14:00.0249851Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-16T17:14:00.0259545Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-16T17:14:00.0269032Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 401, in __init__
2026-02-16T17:14:00.0278563Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-16T17:14:00.0288671Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 162, in __init__
2026-02-16T17:14:00.0297982Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-16T17:14:00.0307551Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-16T17:14:00.0316806Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-16T17:14:00.0326498Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.0336079Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-16T17:14:00.0345501Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-16T17:14:00.0355077Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.0365179Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 419, in get_quant_method
2026-02-16T17:14:00.0374828Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-16T17:14:00.0384573Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.0394372Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 295, in create_scheme_for_layer
2026-02-16T17:14:00.0403700Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     return scheme_cls()
2026-02-16T17:14:00.0412565Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-16T17:14:00.0422633Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-16T17:14:00.0432209Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-16T17:14:00.0441683Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.0452571Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-16T17:14:00.0461944Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772] [ERROR] 2026-02-16-17:13:59 (PID:257, Device:1, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-16T17:14:00.0470285Z [0;36m(Worker_DP0_TP1_EP1 pid=257)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772] 
2026-02-16T17:14:00.0480055Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m INFO 02-16 17:13:59 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-16T17:14:00.0489462Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-16T17:14:00.0498774Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-16T17:14:00.0508651Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-16T17:14:00.0518092Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-16T17:14:00.0527756Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.0537567Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-16T17:14:00.0547216Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-16T17:14:00.0556493Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 404, in load_model
2026-02-16T17:14:00.0566239Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-16T17:14:00.0575724Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2311, in load_model
2026-02-16T17:14:00.0585035Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-16T17:14:00.0594418Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.0605336Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-16T17:14:00.0614103Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     return loader.load_model(
2026-02-16T17:14:00.0623267Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.0632775Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-16T17:14:00.0642220Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     model = initialize_model(
2026-02-16T17:14:00.0651711Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.0661601Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-16T17:14:00.0670829Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-16T17:14:00.0680838Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.0735837Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-16T17:14:00.0736710Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-16T17:14:00.0737314Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-16T17:14:00.0738231Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-16T17:14:00.0739080Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-16T17:14:00.0739846Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-16T17:14:00.0746504Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-16T17:14:00.0755496Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-16T17:14:00.0766569Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-16T17:14:00.0776183Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     + [
2026-02-16T17:14:00.0786399Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]       ^
2026-02-16T17:14:00.0797393Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-16T17:14:00.0807244Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-16T17:14:00.0816413Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.0826474Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-16T17:14:00.0835174Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-16T17:14:00.0846326Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.0854714Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-16T17:14:00.0863545Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-16T17:14:00.0873147Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-16T17:14:00.0883169Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-16T17:14:00.0892752Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-16T17:14:00.0902322Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-16T17:14:00.0911753Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 401, in __init__
2026-02-16T17:14:00.0922188Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-16T17:14:00.0931713Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 162, in __init__
2026-02-16T17:14:00.0940408Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-16T17:14:00.0950225Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-16T17:14:00.0960494Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-16T17:14:00.0969780Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.0978930Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-16T17:14:00.0988232Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-16T17:14:00.0997057Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.1007733Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 419, in get_quant_method
2026-02-16T17:14:00.1016411Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-16T17:14:00.1025850Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.1035862Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 295, in create_scheme_for_layer
2026-02-16T17:14:00.1044916Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     return scheme_cls()
2026-02-16T17:14:00.1054304Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-16T17:14:00.1064133Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-16T17:14:00.1073120Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-16T17:14:00.1083050Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.1093338Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-16T17:14:00.1102398Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772] [ERROR] 2026-02-16-17:13:59 (PID:892, Device:7, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-16T17:14:00.1110936Z [0;36m(Worker_DP0_TP7_EP7 pid=892)[0;0m ERROR 02-16 17:13:59 [multiproc_executor.py:772] 
2026-02-16T17:14:00.1120832Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m INFO 02-16 17:13:59 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-16T17:14:00.1130474Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m INFO 02-16 17:14:00 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-16T17:14:00.1139464Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-16T17:14:00.1149258Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-16T17:14:00.1158414Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-16T17:14:00.1167854Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-16T17:14:00.1177179Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.1186708Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-16T17:14:00.1195821Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-16T17:14:00.1205792Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 404, in load_model
2026-02-16T17:14:00.1215115Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-16T17:14:00.1224931Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2311, in load_model
2026-02-16T17:14:00.1234506Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-16T17:14:00.1244309Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.1255269Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-16T17:14:00.1263688Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     return loader.load_model(
2026-02-16T17:14:00.1272636Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.1282749Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-16T17:14:00.1292230Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     model = initialize_model(
2026-02-16T17:14:00.1301221Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.1310958Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-16T17:14:00.1320293Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-16T17:14:00.1330539Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.1340443Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-16T17:14:00.1352723Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-16T17:14:00.1360226Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-16T17:14:00.1370749Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-16T17:14:00.1379861Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-16T17:14:00.1389167Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-16T17:14:00.1398987Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-16T17:14:00.1408752Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-16T17:14:00.1417999Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-16T17:14:00.1427211Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     + [
2026-02-16T17:14:00.1436153Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]       ^
2026-02-16T17:14:00.1446476Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-16T17:14:00.1455838Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-16T17:14:00.1465128Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.1475252Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-16T17:14:00.1484676Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-16T17:14:00.1494199Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.1503225Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-16T17:14:00.1512454Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-16T17:14:00.1521929Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-16T17:14:00.1531950Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-16T17:14:00.1541115Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-16T17:14:00.1550982Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-16T17:14:00.1560488Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 401, in __init__
2026-02-16T17:14:00.1569661Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-16T17:14:00.1579732Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 162, in __init__
2026-02-16T17:14:00.1588797Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-16T17:14:00.1598775Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-16T17:14:00.1609669Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-16T17:14:00.1618988Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.1628017Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-16T17:14:00.1637592Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-16T17:14:00.1647392Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.1656993Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 419, in get_quant_method
2026-02-16T17:14:00.1693318Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-16T17:14:00.1694234Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.1695249Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 295, in create_scheme_for_layer
2026-02-16T17:14:00.1696895Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     return scheme_cls()
2026-02-16T17:14:00.1708514Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-16T17:14:00.1718765Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-16T17:14:00.1728757Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-16T17:14:00.1737546Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.1748289Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-16T17:14:00.1757289Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772] [ERROR] 2026-02-16-17:13:59 (PID:369, Device:2, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-16T17:14:00.1768391Z [0;36m(Worker_DP1_TP2_EP10 pid=369)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772] 
2026-02-16T17:14:00.1779217Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m INFO 02-16 17:14:00 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-16T17:14:00.1789799Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m INFO 02-16 17:14:00 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-16T17:14:00.1800142Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m INFO 02-16 17:14:00 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-16T17:14:00.1809727Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-16T17:14:00.1819473Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-16T17:14:00.1829216Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-16T17:14:00.1838847Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-16T17:14:00.1848762Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.1858341Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-16T17:14:00.1867586Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-16T17:14:00.1877378Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 404, in load_model
2026-02-16T17:14:00.1887296Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-16T17:14:00.1896692Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2311, in load_model
2026-02-16T17:14:00.1909737Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-16T17:14:00.1915572Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.1925754Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-16T17:14:00.1934882Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     return loader.load_model(
2026-02-16T17:14:00.1944176Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.1953647Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-16T17:14:00.1962799Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     model = initialize_model(
2026-02-16T17:14:00.1972440Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.1982291Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-16T17:14:00.1992076Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-16T17:14:00.2001427Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.2012465Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-16T17:14:00.2021188Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-16T17:14:00.2030479Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-16T17:14:00.2041143Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-16T17:14:00.2050138Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-16T17:14:00.2059794Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-16T17:14:00.2069125Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-16T17:14:00.2079012Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-16T17:14:00.2090760Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-16T17:14:00.2099451Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     + [
2026-02-16T17:14:00.2108876Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]       ^
2026-02-16T17:14:00.2119872Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-16T17:14:00.2128663Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-16T17:14:00.2137811Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.2147163Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-16T17:14:00.2156437Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-16T17:14:00.2166293Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.2176054Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-16T17:14:00.2184913Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-16T17:14:00.2194299Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-16T17:14:00.2204300Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-16T17:14:00.2213754Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-16T17:14:00.2223506Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-16T17:14:00.2232722Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 401, in __init__
2026-02-16T17:14:00.2242221Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-16T17:14:00.2252173Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 162, in __init__
2026-02-16T17:14:00.2261273Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-16T17:14:00.2271469Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-16T17:14:00.2281234Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-16T17:14:00.2291493Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.2301197Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-16T17:14:00.2310837Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-16T17:14:00.2320444Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.2331710Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 419, in get_quant_method
2026-02-16T17:14:00.2341254Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-16T17:14:00.2354133Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.2365005Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 295, in create_scheme_for_layer
2026-02-16T17:14:00.2374784Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     return scheme_cls()
2026-02-16T17:14:00.2384661Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-16T17:14:00.2394900Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-16T17:14:00.2405020Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-16T17:14:00.2414963Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.2425302Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-16T17:14:00.2434371Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772] [ERROR] 2026-02-16-17:13:59 (PID:473, Device:3, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-16T17:14:00.2443747Z [0;36m(Worker_DP1_TP3_EP11 pid=473)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772] 
2026-02-16T17:14:00.2453318Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-16T17:14:00.2463225Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-16T17:14:00.2472540Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-16T17:14:00.2481309Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-16T17:14:00.2491312Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.2500666Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-16T17:14:00.2509420Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-16T17:14:00.2519761Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 404, in load_model
2026-02-16T17:14:00.2529031Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-16T17:14:00.2538693Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2311, in load_model
2026-02-16T17:14:00.2547399Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-16T17:14:00.2557672Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.2567444Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-16T17:14:00.2577336Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     return loader.load_model(
2026-02-16T17:14:00.2586560Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.2595152Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-16T17:14:00.2604247Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     model = initialize_model(
2026-02-16T17:14:00.2614021Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.2623445Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-16T17:14:00.2632720Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-16T17:14:00.2642337Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.2652409Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-16T17:14:00.2661621Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-16T17:14:00.2670776Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-16T17:14:00.2681064Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-16T17:14:00.2690249Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-16T17:14:00.2700099Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-16T17:14:00.2708998Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-16T17:14:00.2718443Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-16T17:14:00.2727842Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-16T17:14:00.2736909Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     + [
2026-02-16T17:14:00.2746490Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]       ^
2026-02-16T17:14:00.2755991Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-16T17:14:00.2767317Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-16T17:14:00.2777658Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.2788458Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-16T17:14:00.2798830Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-16T17:14:00.2808141Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.2818018Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-16T17:14:00.2827199Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-16T17:14:00.2836626Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-16T17:14:00.2847193Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-16T17:14:00.2855933Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-16T17:14:00.2865228Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-16T17:14:00.2874921Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 401, in __init__
2026-02-16T17:14:00.2884119Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-16T17:14:00.2894434Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 162, in __init__
2026-02-16T17:14:00.2903537Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-16T17:14:00.2913559Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-16T17:14:00.2923221Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-16T17:14:00.2932551Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.2942204Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-16T17:14:00.2951458Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-16T17:14:00.2960872Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.2971379Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 419, in get_quant_method
2026-02-16T17:14:00.2980390Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-16T17:14:00.2989840Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.2999998Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 295, in create_scheme_for_layer
2026-02-16T17:14:00.3009074Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     return scheme_cls()
2026-02-16T17:14:00.3018358Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-16T17:14:00.3028119Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-16T17:14:00.3037294Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-16T17:14:00.3047539Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.3057819Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-16T17:14:00.3067214Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772] [ERROR] 2026-02-16-17:13:59 (PID:889, Device:7, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-16T17:14:00.3076410Z [0;36m(Worker_DP1_TP7_EP15 pid=889)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772] 
2026-02-16T17:14:00.3086724Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m INFO 02-16 17:14:00 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-16T17:14:00.3096400Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-16T17:14:00.3105832Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-16T17:14:00.3115855Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-16T17:14:00.3125566Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-16T17:14:00.3134962Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.3144833Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-16T17:14:00.3153816Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-16T17:14:00.3163631Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 404, in load_model
2026-02-16T17:14:00.3173143Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-16T17:14:00.3182717Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2311, in load_model
2026-02-16T17:14:00.3192197Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-16T17:14:00.3201953Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.3211908Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-16T17:14:00.3220752Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     return loader.load_model(
2026-02-16T17:14:00.3229874Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.3240346Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-16T17:14:00.3249719Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     model = initialize_model(
2026-02-16T17:14:00.3258974Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.3269256Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-16T17:14:00.3278355Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-16T17:14:00.3288480Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.3297848Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-16T17:14:00.3306934Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-16T17:14:00.3316753Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-16T17:14:00.3326899Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-16T17:14:00.3335953Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-16T17:14:00.3345645Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-16T17:14:00.3355578Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-16T17:14:00.3365264Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-16T17:14:00.3375984Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-16T17:14:00.3383986Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     + [
2026-02-16T17:14:00.3393214Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]       ^
2026-02-16T17:14:00.3403001Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-16T17:14:00.3412803Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-16T17:14:00.3424257Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.3433256Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-16T17:14:00.3440579Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-16T17:14:00.3450023Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.3492412Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-16T17:14:00.3493453Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-16T17:14:00.3494243Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-16T17:14:00.3495153Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-16T17:14:00.3498819Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-16T17:14:00.3508120Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-16T17:14:00.3518386Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 401, in __init__
2026-02-16T17:14:00.3527491Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-16T17:14:00.3536704Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 162, in __init__
2026-02-16T17:14:00.3545871Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-16T17:14:00.3555395Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-16T17:14:00.3565686Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-16T17:14:00.3575172Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.3585396Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-16T17:14:00.3594571Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-16T17:14:00.3604030Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.3614229Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 419, in get_quant_method
2026-02-16T17:14:00.3623858Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-16T17:14:00.3633350Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.3643269Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 295, in create_scheme_for_layer
2026-02-16T17:14:00.3651456Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     return scheme_cls()
2026-02-16T17:14:00.3672714Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-16T17:14:00.3673573Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-16T17:14:00.3680238Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-16T17:14:00.3689832Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.3700225Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-16T17:14:00.3727319Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772] [ERROR] 2026-02-16-17:13:59 (PID:788, Device:6, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-16T17:14:00.3728109Z [0;36m(Worker_DP0_TP6_EP6 pid=788)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772] 
2026-02-16T17:14:00.4230179Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-16T17:14:00.4238598Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-16T17:14:00.4251037Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-16T17:14:00.4310133Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-16T17:14:00.4319872Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.4323631Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-16T17:14:00.4333295Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-16T17:14:00.4342465Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 404, in load_model
2026-02-16T17:14:00.4351979Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-16T17:14:00.4361866Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2311, in load_model
2026-02-16T17:14:00.4370494Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-16T17:14:00.4380102Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.4389546Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-16T17:14:00.4399069Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     return loader.load_model(
2026-02-16T17:14:00.4408499Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.4418258Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-16T17:14:00.4427041Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     model = initialize_model(
2026-02-16T17:14:00.4436553Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.4447382Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-16T17:14:00.4455849Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-16T17:14:00.4465390Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.4475464Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-16T17:14:00.4484291Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-16T17:14:00.4493918Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-16T17:14:00.4503778Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-16T17:14:00.4513181Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-16T17:14:00.4523789Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-16T17:14:00.4532704Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-16T17:14:00.4541533Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-16T17:14:00.4551259Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-16T17:14:00.4560398Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     + [
2026-02-16T17:14:00.4569683Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]       ^
2026-02-16T17:14:00.4579130Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-16T17:14:00.4588680Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-16T17:14:00.4598123Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.4607842Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-16T17:14:00.4617592Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-16T17:14:00.4626416Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.4636004Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-16T17:14:00.4645430Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-16T17:14:00.4654939Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-16T17:14:00.4664828Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-16T17:14:00.4674263Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-16T17:14:00.4684330Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-16T17:14:00.4693653Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 401, in __init__
2026-02-16T17:14:00.4703315Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-16T17:14:00.4713502Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 162, in __init__
2026-02-16T17:14:00.4732320Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-16T17:14:00.4733304Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-16T17:14:00.4742234Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-16T17:14:00.4751158Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.4762185Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-16T17:14:00.4772439Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-16T17:14:00.4783056Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.4793626Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 419, in get_quant_method
2026-02-16T17:14:00.4803986Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-16T17:14:00.4813487Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.4823512Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 295, in create_scheme_for_layer
2026-02-16T17:14:00.4833253Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     return scheme_cls()
2026-02-16T17:14:00.4841955Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-16T17:14:00.4852300Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-16T17:14:00.4861713Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-16T17:14:00.4873132Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.4881355Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-16T17:14:00.4890522Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772] [ERROR] 2026-02-16-17:13:58 (PID:251, Device:1, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-16T17:14:00.4899815Z [0;36m(Worker_DP1_TP1_EP9 pid=251)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772] 
2026-02-16T17:14:00.4909226Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m INFO 02-16 17:14:00 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-16T17:14:00.6094973Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-16T17:14:00.6103476Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-16T17:14:00.6113470Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-16T17:14:00.6125750Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-16T17:14:00.6133070Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.6143023Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-16T17:14:00.6152567Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-16T17:14:00.6163173Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 404, in load_model
2026-02-16T17:14:00.6173283Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-16T17:14:00.6182181Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2311, in load_model
2026-02-16T17:14:00.6191246Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-16T17:14:00.6201331Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.6280815Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-16T17:14:00.6281636Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     return loader.load_model(
2026-02-16T17:14:00.6282342Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.6283114Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-16T17:14:00.6283970Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     model = initialize_model(
2026-02-16T17:14:00.6284558Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.6285322Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-16T17:14:00.6286260Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-16T17:14:00.6288094Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.6297523Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-16T17:14:00.6306543Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-16T17:14:00.6315902Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-16T17:14:00.6326053Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-16T17:14:00.6335798Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-16T17:14:00.6345255Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-16T17:14:00.6354747Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-16T17:14:00.6364909Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-16T17:14:00.6374719Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-16T17:14:00.6383584Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     + [
2026-02-16T17:14:00.6393101Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]       ^
2026-02-16T17:14:00.6403393Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-16T17:14:00.6413084Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-16T17:14:00.6422488Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.6432343Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-16T17:14:00.6441899Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-16T17:14:00.6451796Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.6462658Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-16T17:14:00.6470873Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-16T17:14:00.6480281Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-16T17:14:00.6490151Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-16T17:14:00.6499205Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-16T17:14:00.6508810Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-16T17:14:00.6518683Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 401, in __init__
2026-02-16T17:14:00.6528524Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-16T17:14:00.6537905Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 162, in __init__
2026-02-16T17:14:00.6548017Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-16T17:14:00.6557045Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-16T17:14:00.6566947Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-16T17:14:00.6576450Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.6586797Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-16T17:14:00.6595680Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-16T17:14:00.6605909Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.6615595Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 419, in get_quant_method
2026-02-16T17:14:00.6625118Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-16T17:14:00.6634387Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.6644777Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 295, in create_scheme_for_layer
2026-02-16T17:14:00.6653567Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     return scheme_cls()
2026-02-16T17:14:00.6663010Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-16T17:14:00.6672553Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-16T17:14:00.6682317Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-16T17:14:00.6691742Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.6702827Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-16T17:14:00.6711038Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772] [ERROR] 2026-02-16-17:13:58 (PID:581, Device:4, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-16T17:14:00.6720224Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772] 
2026-02-16T17:14:00.6743396Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-16T17:14:00.6744058Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-16T17:14:00.6749038Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-16T17:14:00.6792793Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-16T17:14:00.6793603Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.6794462Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-16T17:14:00.6795243Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-16T17:14:00.6802603Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 404, in load_model
2026-02-16T17:14:00.6812323Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-16T17:14:00.6822369Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2311, in load_model
2026-02-16T17:14:00.6831637Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-16T17:14:00.6841703Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.6852311Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-16T17:14:00.6862236Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     return loader.load_model(
2026-02-16T17:14:00.6871335Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.6881918Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-16T17:14:00.6891204Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     model = initialize_model(
2026-02-16T17:14:00.6900848Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.6911123Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-16T17:14:00.6921337Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-16T17:14:00.6931836Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.6942072Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-16T17:14:00.6951357Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-16T17:14:00.6961685Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-16T17:14:00.6971912Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-16T17:14:00.6981555Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-16T17:14:00.6998375Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-16T17:14:00.7001719Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-16T17:14:00.7011717Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-16T17:14:00.7021926Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-16T17:14:00.7030955Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     + [
2026-02-16T17:14:00.7041098Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]       ^
2026-02-16T17:14:00.7051010Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-16T17:14:00.7060174Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-16T17:14:00.7069883Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.7079507Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-16T17:14:00.7088796Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-16T17:14:00.7097930Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.7107802Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-16T17:14:00.7116960Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-16T17:14:00.7126576Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-16T17:14:00.7135930Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-16T17:14:00.7145488Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-16T17:14:00.7154259Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-16T17:14:00.7164170Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 401, in __init__
2026-02-16T17:14:00.7174056Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-16T17:14:00.7183869Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 162, in __init__
2026-02-16T17:14:00.7192554Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-16T17:14:00.7202309Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-16T17:14:00.7210894Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-16T17:14:00.7220626Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.7230317Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-16T17:14:00.7240197Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-16T17:14:00.7249560Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.7259656Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 419, in get_quant_method
2026-02-16T17:14:00.7268864Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-16T17:14:00.7278124Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.7288288Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 295, in create_scheme_for_layer
2026-02-16T17:14:00.7297497Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     return scheme_cls()
2026-02-16T17:14:00.7306595Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-16T17:14:00.7316281Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-16T17:14:00.7326351Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-16T17:14:00.7335758Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.7345974Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-16T17:14:00.7355631Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772] [ERROR] 2026-02-16-17:13:59 (PID:577, Device:4, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-16T17:14:00.7364295Z [0;36m(Worker_DP1_TP4_EP12 pid=577)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772] 
2026-02-16T17:14:00.7688256Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-16T17:14:00.7697819Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-16T17:14:00.7707370Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-16T17:14:00.7716684Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-16T17:14:00.7726555Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.7735819Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-16T17:14:00.7744965Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-16T17:14:00.7754378Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 404, in load_model
2026-02-16T17:14:00.7764854Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-16T17:14:00.7775353Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2311, in load_model
2026-02-16T17:14:00.7785501Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-16T17:14:00.7796092Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.7806535Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-16T17:14:00.7816043Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     return loader.load_model(
2026-02-16T17:14:00.7825202Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.7834855Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-16T17:14:00.7844533Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     model = initialize_model(
2026-02-16T17:14:00.7853542Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.7863118Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-16T17:14:00.7872471Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-16T17:14:00.7882371Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.7892297Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-16T17:14:00.7901803Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-16T17:14:00.7910425Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-16T17:14:00.7920420Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-16T17:14:00.7929534Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-16T17:14:00.7939213Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-16T17:14:00.7948533Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-16T17:14:00.7958203Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-16T17:14:00.7968493Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-16T17:14:00.7977519Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     + [
2026-02-16T17:14:00.7986822Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]       ^
2026-02-16T17:14:00.7996758Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-16T17:14:00.8006781Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-16T17:14:00.8015791Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.8025772Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-16T17:14:00.8034476Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-16T17:14:00.8044266Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.8054388Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-16T17:14:00.8063474Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-16T17:14:00.8072933Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-16T17:14:00.8082672Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-16T17:14:00.8092189Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-16T17:14:00.8101723Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-16T17:14:00.8111200Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 401, in __init__
2026-02-16T17:14:00.8120372Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-16T17:14:00.8130449Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 162, in __init__
2026-02-16T17:14:00.8139446Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-16T17:14:00.8148870Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-16T17:14:00.8158757Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-16T17:14:00.8169564Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.8179230Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-16T17:14:00.8188149Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-16T17:14:00.8197608Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.8207421Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 419, in get_quant_method
2026-02-16T17:14:00.8216857Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-16T17:14:00.8225855Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.8235489Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 295, in create_scheme_for_layer
2026-02-16T17:14:00.8245304Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     return scheme_cls()
2026-02-16T17:14:00.8254623Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-16T17:14:00.8264369Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-16T17:14:00.8273486Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-16T17:14:00.8283353Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:00.8293887Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-16T17:14:00.8303023Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772] [ERROR] 2026-02-16-17:13:59 (PID:681, Device:5, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-16T17:14:00.8312109Z [0;36m(Worker_DP1_TP5_EP13 pid=681)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772] 
2026-02-16T17:14:01.0071886Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-16T17:14:01.0081729Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-16T17:14:01.0090956Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-16T17:14:01.0099494Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-16T17:14:01.0108958Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:01.0118813Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-16T17:14:01.0128795Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-16T17:14:01.0137671Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 404, in load_model
2026-02-16T17:14:01.0147382Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-16T17:14:01.0156176Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2311, in load_model
2026-02-16T17:14:01.0166004Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-16T17:14:01.0175179Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:01.0184730Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-16T17:14:01.0193810Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     return loader.load_model(
2026-02-16T17:14:01.0202916Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:01.0212727Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-16T17:14:01.0222329Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     model = initialize_model(
2026-02-16T17:14:01.0231138Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-16T17:14:01.0241159Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-16T17:14:01.0251172Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-16T17:14:01.0259970Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:01.0270089Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-16T17:14:01.0279824Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-16T17:14:01.0289364Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-16T17:14:01.0299380Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-16T17:14:01.0308230Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-16T17:14:01.0317822Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-16T17:14:01.0327594Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-16T17:14:01.0336758Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-16T17:14:01.0346773Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-16T17:14:01.0355305Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     + [
2026-02-16T17:14:01.0365508Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]       ^
2026-02-16T17:14:01.0375182Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-16T17:14:01.0384326Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-16T17:14:01.0393943Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:01.0404495Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-16T17:14:01.0415890Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-16T17:14:01.0422956Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:01.0432582Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-16T17:14:01.0442250Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-16T17:14:01.0451874Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-16T17:14:01.0462325Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-16T17:14:01.0470452Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-16T17:14:01.0482187Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-16T17:14:01.0490113Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 401, in __init__
2026-02-16T17:14:01.0499561Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-16T17:14:01.0509363Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 162, in __init__
2026-02-16T17:14:01.0518489Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-16T17:14:01.0528581Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-16T17:14:01.0538040Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-16T17:14:01.0547010Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:01.0556722Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-16T17:14:01.0566774Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-16T17:14:01.0575988Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:01.0585881Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 419, in get_quant_method
2026-02-16T17:14:01.0596049Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-16T17:14:01.0605710Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:01.0614687Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 295, in create_scheme_for_layer
2026-02-16T17:14:01.0623996Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     return scheme_cls()
2026-02-16T17:14:01.0633252Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-16T17:14:01.0643709Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-16T17:14:01.0652655Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-16T17:14:01.0663288Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:01.0673767Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-16T17:14:01.0683861Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772] [ERROR] 2026-02-16-17:13:59 (PID:685, Device:5, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-16T17:14:01.0691884Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-16 17:14:00 [multiproc_executor.py:772] 
2026-02-16T17:14:04.4436205Z [0;36m(EngineCore_DP0 pid=154)[0;0m ERROR 02-16 17:14:04 [core.py:946] EngineCore failed to start.
2026-02-16T17:14:04.4445379Z [0;36m(EngineCore_DP0 pid=154)[0;0m ERROR 02-16 17:14:04 [core.py:946] Traceback (most recent call last):
2026-02-16T17:14:04.4455277Z [0;36m(EngineCore_DP0 pid=154)[0;0m ERROR 02-16 17:14:04 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 929, in run_engine_core
2026-02-16T17:14:04.4464919Z [0;36m(EngineCore_DP0 pid=154)[0;0m ERROR 02-16 17:14:04 [core.py:946]     engine_core = DPEngineCoreProc(*args, **kwargs)
2026-02-16T17:14:04.4473871Z [0;36m(EngineCore_DP0 pid=154)[0;0m ERROR 02-16 17:14:04 [core.py:946]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:04.4483899Z [0;36m(EngineCore_DP0 pid=154)[0;0m ERROR 02-16 17:14:04 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 1279, in __init__
2026-02-16T17:14:04.4493059Z [0;36m(EngineCore_DP0 pid=154)[0;0m ERROR 02-16 17:14:04 [core.py:946]     super().__init__(
2026-02-16T17:14:04.4502691Z [0;36m(EngineCore_DP0 pid=154)[0;0m ERROR 02-16 17:14:04 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 691, in __init__
2026-02-16T17:14:04.4511695Z [0;36m(EngineCore_DP0 pid=154)[0;0m ERROR 02-16 17:14:04 [core.py:946]     super().__init__(
2026-02-16T17:14:04.4521471Z [0;36m(EngineCore_DP0 pid=154)[0;0m ERROR 02-16 17:14:04 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 105, in __init__
2026-02-16T17:14:04.4532375Z [0;36m(EngineCore_DP0 pid=154)[0;0m ERROR 02-16 17:14:04 [core.py:946]     self.model_executor = executor_class(vllm_config)
2026-02-16T17:14:04.4540562Z [0;36m(EngineCore_DP0 pid=154)[0;0m ERROR 02-16 17:14:04 [core.py:946]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:04.4550844Z [0;36m(EngineCore_DP0 pid=154)[0;0m ERROR 02-16 17:14:04 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 97, in __init__
2026-02-16T17:14:04.4559849Z [0;36m(EngineCore_DP0 pid=154)[0;0m Process EngineCore_DP0:
2026-02-16T17:14:04.4568957Z [0;36m(EngineCore_DP0 pid=154)[0;0m ERROR 02-16 17:14:04 [core.py:946]     super().__init__(vllm_config)
2026-02-16T17:14:04.4579509Z [0;36m(EngineCore_DP0 pid=154)[0;0m ERROR 02-16 17:14:04 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/executor/abstract.py", line 101, in __init__
2026-02-16T17:14:04.4587864Z [0;36m(EngineCore_DP0 pid=154)[0;0m ERROR 02-16 17:14:04 [core.py:946]     self._init_executor()
2026-02-16T17:14:04.4599600Z [0;36m(EngineCore_DP0 pid=154)[0;0m ERROR 02-16 17:14:04 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 165, in _init_executor
2026-02-16T17:14:04.4610211Z [0;36m(EngineCore_DP0 pid=154)[0;0m ERROR 02-16 17:14:04 [core.py:946]     self.workers = WorkerProc.wait_for_ready(unready_workers)
2026-02-16T17:14:04.4622548Z [0;36m(EngineCore_DP0 pid=154)[0;0m ERROR 02-16 17:14:04 [core.py:946]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:04.4634981Z [0;36m(EngineCore_DP0 pid=154)[0;0m ERROR 02-16 17:14:04 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 678, in wait_for_ready
2026-02-16T17:14:04.4645112Z [0;36m(EngineCore_DP0 pid=154)[0;0m ERROR 02-16 17:14:04 [core.py:946]     raise e from None
2026-02-16T17:14:04.4655311Z [0;36m(EngineCore_DP0 pid=154)[0;0m ERROR 02-16 17:14:04 [core.py:946] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
2026-02-16T17:14:04.4665001Z [0;36m(EngineCore_DP0 pid=154)[0;0m Traceback (most recent call last):
2026-02-16T17:14:04.4675231Z [0;36m(EngineCore_DP0 pid=154)[0;0m   File "/usr/local/python3.11.14/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
2026-02-16T17:14:04.4686069Z [0;36m(EngineCore_DP0 pid=154)[0;0m     self.run()
2026-02-16T17:14:04.4695490Z [0;36m(EngineCore_DP0 pid=154)[0;0m   File "/usr/local/python3.11.14/lib/python3.11/multiprocessing/process.py", line 108, in run
2026-02-16T17:14:04.4704594Z [0;36m(EngineCore_DP0 pid=154)[0;0m     self._target(*self._args, **self._kwargs)
2026-02-16T17:14:04.4714106Z [0;36m(EngineCore_DP0 pid=154)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 950, in run_engine_core
2026-02-16T17:14:04.4723315Z [0;36m(EngineCore_DP0 pid=154)[0;0m     raise e
2026-02-16T17:14:04.4733034Z [0;36m(EngineCore_DP0 pid=154)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 929, in run_engine_core
2026-02-16T17:14:04.4742222Z [0;36m(EngineCore_DP0 pid=154)[0;0m     engine_core = DPEngineCoreProc(*args, **kwargs)
2026-02-16T17:14:04.4751675Z [0;36m(EngineCore_DP0 pid=154)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:04.4762170Z [0;36m(EngineCore_DP0 pid=154)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 1279, in __init__
2026-02-16T17:14:04.4772249Z [0;36m(EngineCore_DP0 pid=154)[0;0m     super().__init__(
2026-02-16T17:14:04.4782540Z [0;36m(EngineCore_DP0 pid=154)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 691, in __init__
2026-02-16T17:14:04.4792990Z [0;36m(EngineCore_DP0 pid=154)[0;0m     super().__init__(
2026-02-16T17:14:04.4803310Z [0;36m(EngineCore_DP0 pid=154)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 105, in __init__
2026-02-16T17:14:04.4812908Z [0;36m(EngineCore_DP0 pid=154)[0;0m     self.model_executor = executor_class(vllm_config)
2026-02-16T17:14:04.4822481Z [0;36m(EngineCore_DP0 pid=154)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:04.4832270Z [0;36m(EngineCore_DP0 pid=154)[0;0m   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 97, in __init__
2026-02-16T17:14:04.4841705Z [0;36m(EngineCore_DP0 pid=154)[0;0m     super().__init__(vllm_config)
2026-02-16T17:14:04.4851053Z [0;36m(EngineCore_DP0 pid=154)[0;0m   File "/vllm-workspace/vllm/vllm/v1/executor/abstract.py", line 101, in __init__
2026-02-16T17:14:04.4860230Z [0;36m(EngineCore_DP0 pid=154)[0;0m     self._init_executor()
2026-02-16T17:14:04.4869770Z [0;36m(EngineCore_DP0 pid=154)[0;0m   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 165, in _init_executor
2026-02-16T17:14:04.4879369Z [0;36m(EngineCore_DP0 pid=154)[0;0m     self.workers = WorkerProc.wait_for_ready(unready_workers)
2026-02-16T17:14:04.4888237Z [0;36m(EngineCore_DP0 pid=154)[0;0m                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:04.4897987Z [0;36m(EngineCore_DP0 pid=154)[0;0m   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 678, in wait_for_ready
2026-02-16T17:14:04.4906949Z [0;36m(EngineCore_DP0 pid=154)[0;0m     raise e from None
2026-02-16T17:14:04.4917035Z [0;36m(EngineCore_DP0 pid=154)[0;0m Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
2026-02-16T17:14:04.6826184Z [0;36m(EngineCore_DP1 pid=173)[0;0m ERROR 02-16 17:14:04 [core.py:946] EngineCore failed to start.
2026-02-16T17:14:04.6833059Z [0;36m(EngineCore_DP1 pid=173)[0;0m ERROR 02-16 17:14:04 [core.py:946] Traceback (most recent call last):
2026-02-16T17:14:04.6843315Z [0;36m(EngineCore_DP1 pid=173)[0;0m ERROR 02-16 17:14:04 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 929, in run_engine_core
2026-02-16T17:14:04.6854399Z [0;36m(EngineCore_DP1 pid=173)[0;0m ERROR 02-16 17:14:04 [core.py:946]     engine_core = DPEngineCoreProc(*args, **kwargs)
2026-02-16T17:14:04.6862076Z [0;36m(EngineCore_DP1 pid=173)[0;0m ERROR 02-16 17:14:04 [core.py:946]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:04.6870251Z [0;36m(EngineCore_DP1 pid=173)[0;0m ERROR 02-16 17:14:04 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 1279, in __init__
2026-02-16T17:14:04.6879545Z [0;36m(EngineCore_DP1 pid=173)[0;0m ERROR 02-16 17:14:04 [core.py:946]     super().__init__(
2026-02-16T17:14:04.6888567Z [0;36m(EngineCore_DP1 pid=173)[0;0m ERROR 02-16 17:14:04 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 691, in __init__
2026-02-16T17:14:04.6897651Z [0;36m(EngineCore_DP1 pid=173)[0;0m ERROR 02-16 17:14:04 [core.py:946]     super().__init__(
2026-02-16T17:14:04.6907080Z [0;36m(EngineCore_DP1 pid=173)[0;0m ERROR 02-16 17:14:04 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 105, in __init__
2026-02-16T17:14:04.6916168Z [0;36m(EngineCore_DP1 pid=173)[0;0m ERROR 02-16 17:14:04 [core.py:946]     self.model_executor = executor_class(vllm_config)
2026-02-16T17:14:04.6925311Z [0;36m(EngineCore_DP1 pid=173)[0;0m ERROR 02-16 17:14:04 [core.py:946]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:04.6934303Z [0;36m(EngineCore_DP1 pid=173)[0;0m Process EngineCore_DP1:
2026-02-16T17:14:04.6943813Z [0;36m(EngineCore_DP1 pid=173)[0;0m ERROR 02-16 17:14:04 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 97, in __init__
2026-02-16T17:14:04.6952573Z [0;36m(EngineCore_DP1 pid=173)[0;0m ERROR 02-16 17:14:04 [core.py:946]     super().__init__(vllm_config)
2026-02-16T17:14:04.6962372Z [0;36m(EngineCore_DP1 pid=173)[0;0m ERROR 02-16 17:14:04 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/executor/abstract.py", line 101, in __init__
2026-02-16T17:14:04.6971168Z [0;36m(EngineCore_DP1 pid=173)[0;0m ERROR 02-16 17:14:04 [core.py:946]     self._init_executor()
2026-02-16T17:14:04.6980706Z [0;36m(EngineCore_DP1 pid=173)[0;0m ERROR 02-16 17:14:04 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 165, in _init_executor
2026-02-16T17:14:04.6990262Z [0;36m(EngineCore_DP1 pid=173)[0;0m ERROR 02-16 17:14:04 [core.py:946]     self.workers = WorkerProc.wait_for_ready(unready_workers)
2026-02-16T17:14:04.6999256Z [0;36m(EngineCore_DP1 pid=173)[0;0m ERROR 02-16 17:14:04 [core.py:946]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:04.7008978Z [0;36m(EngineCore_DP1 pid=173)[0;0m ERROR 02-16 17:14:04 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 678, in wait_for_ready
2026-02-16T17:14:04.7018165Z [0;36m(EngineCore_DP1 pid=173)[0;0m ERROR 02-16 17:14:04 [core.py:946]     raise e from None
2026-02-16T17:14:04.7029748Z [0;36m(EngineCore_DP1 pid=173)[0;0m ERROR 02-16 17:14:04 [core.py:946] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
2026-02-16T17:14:04.7038674Z [0;36m(EngineCore_DP1 pid=173)[0;0m Traceback (most recent call last):
2026-02-16T17:14:04.7049007Z [0;36m(EngineCore_DP1 pid=173)[0;0m   File "/usr/local/python3.11.14/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
2026-02-16T17:14:04.7060043Z [0;36m(EngineCore_DP1 pid=173)[0;0m     self.run()
2026-02-16T17:14:04.7070017Z [0;36m(EngineCore_DP1 pid=173)[0;0m   File "/usr/local/python3.11.14/lib/python3.11/multiprocessing/process.py", line 108, in run
2026-02-16T17:14:04.7079485Z [0;36m(EngineCore_DP1 pid=173)[0;0m     self._target(*self._args, **self._kwargs)
2026-02-16T17:14:04.7088854Z [0;36m(EngineCore_DP1 pid=173)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 950, in run_engine_core
2026-02-16T17:14:04.7098247Z [0;36m(EngineCore_DP1 pid=173)[0;0m     raise e
2026-02-16T17:14:04.7107388Z [0;36m(EngineCore_DP1 pid=173)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 929, in run_engine_core
2026-02-16T17:14:04.7116545Z [0;36m(EngineCore_DP1 pid=173)[0;0m     engine_core = DPEngineCoreProc(*args, **kwargs)
2026-02-16T17:14:04.7126387Z [0;36m(EngineCore_DP1 pid=173)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:04.7135281Z [0;36m(EngineCore_DP1 pid=173)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 1279, in __init__
2026-02-16T17:14:04.7144256Z [0;36m(EngineCore_DP1 pid=173)[0;0m     super().__init__(
2026-02-16T17:14:04.7153542Z [0;36m(EngineCore_DP1 pid=173)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 691, in __init__
2026-02-16T17:14:04.7162404Z [0;36m(EngineCore_DP1 pid=173)[0;0m     super().__init__(
2026-02-16T17:14:04.7172476Z [0;36m(EngineCore_DP1 pid=173)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 105, in __init__
2026-02-16T17:14:04.7182252Z [0;36m(EngineCore_DP1 pid=173)[0;0m     self.model_executor = executor_class(vllm_config)
2026-02-16T17:14:04.7191166Z [0;36m(EngineCore_DP1 pid=173)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:04.7200877Z [0;36m(EngineCore_DP1 pid=173)[0;0m   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 97, in __init__
2026-02-16T17:14:04.7209655Z [0;36m(EngineCore_DP1 pid=173)[0;0m     super().__init__(vllm_config)
2026-02-16T17:14:04.7219180Z [0;36m(EngineCore_DP1 pid=173)[0;0m   File "/vllm-workspace/vllm/vllm/v1/executor/abstract.py", line 101, in __init__
2026-02-16T17:14:04.7228105Z [0;36m(EngineCore_DP1 pid=173)[0;0m     self._init_executor()
2026-02-16T17:14:04.7237448Z [0;36m(EngineCore_DP1 pid=173)[0;0m   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 165, in _init_executor
2026-02-16T17:14:04.7246994Z [0;36m(EngineCore_DP1 pid=173)[0;0m     self.workers = WorkerProc.wait_for_ready(unready_workers)
2026-02-16T17:14:04.7256899Z [0;36m(EngineCore_DP1 pid=173)[0;0m                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-16T17:14:04.7266193Z [0;36m(EngineCore_DP1 pid=173)[0;0m   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 678, in wait_for_ready
2026-02-16T17:14:04.7275707Z [0;36m(EngineCore_DP1 pid=173)[0;0m     raise e from None
2026-02-16T17:14:04.7285252Z [0;36m(EngineCore_DP1 pid=173)[0;0m Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
2026-02-16T17:14:06.1040959Z Traceback (most recent call last):
2026-02-16T17:14:06.1049274Z   File "/usr/local/python3.11.14/bin/vllm", line 7, in <module>
2026-02-16T17:14:06.1060716Z     sys.exit(main())
2026-02-16T17:14:06.1069322Z              ^^^^^^
2026-02-16T17:14:06.1079505Z   File "/vllm-workspace/vllm/vllm/entrypoints/cli/main.py", line 73, in main
2026-02-16T17:14:06.1088357Z     args.dispatch_function(args)
2026-02-16T17:14:06.1097852Z   File "/vllm-workspace/vllm/vllm/entrypoints/cli/serve.py", line 108, in cmd
2026-02-16T17:14:06.1106589Z     run_multi_api_server(args)
2026-02-16T17:14:06.1115746Z   File "/vllm-workspace/vllm/vllm/entrypoints/cli/serve.py", line 248, in run_multi_api_server
2026-02-16T17:14:06.1125030Z     with launch_core_engines(
2026-02-16T17:14:06.1137449Z   File "/usr/local/python3.11.14/lib/python3.11/contextlib.py", line 144, in __exit__
2026-02-16T17:14:06.1143645Z     next(self.gen)
2026-02-16T17:14:06.1152632Z   File "/vllm-workspace/vllm/vllm/v1/engine/utils.py", line 933, in launch_core_engines
2026-02-16T17:14:06.1161767Z     wait_for_engine_startup(
2026-02-16T17:14:06.1171732Z   File "/vllm-workspace/vllm/vllm/v1/engine/utils.py", line 992, in wait_for_engine_startup
2026-02-16T17:14:06.1180668Z     raise RuntimeError(
2026-02-16T17:14:06.1189133Z RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}
2026-02-16T17:14:06.9215428Z [ERROR] 2026-02-16-17:14:06 (PID:138, Device:-1, RankID:-1) ERR99999 UNKNOWN applicaiton exception
2026-02-16T17:14:07.2346460Z sys:1: DeprecationWarning: builtin type swigvarlink has no __module__ attribute
2026-02-16T17:14:08.7774593Z /usr/local/python3.11.14/lib/python3.11/multiprocessing/resource_tracker.py:254: UserWarning: resource_tracker: There appear to be 18 leaked shared_memory objects to clean up at shutdown
2026-02-16T17:14:08.7783989Z   warnings.warn('resource_tracker: There appear to be %d '
2026-02-16T17:14:13.1500296Z FAILED
2026-02-16T17:14:13.1512255Z 
2026-02-16T17:14:13.1524715Z =================================== FAILURES ===================================
2026-02-16T17:14:13.1534805Z _______________________________ test_multi_node ________________________________
2026-02-16T17:14:13.1545121Z 
2026-02-16T17:14:13.1554591Z     @pytest.mark.asyncio
2026-02-16T17:14:13.1564446Z     async def test_multi_node() -> None:
2026-02-16T17:14:13.1574311Z         config = MultiNodeConfigLoader.from_yaml()
2026-02-16T17:14:13.1583968Z     
2026-02-16T17:14:13.1593531Z         with ProxyLauncher(
2026-02-16T17:14:13.1603107Z                 nodes=config.nodes,
2026-02-16T17:14:13.1612558Z                 disagg_cfg=config.disagg_cfg,
2026-02-16T17:14:13.1621848Z                 envs=config.envs,
2026-02-16T17:14:13.1633253Z                 proxy_port=config.proxy_port,
2026-02-16T17:14:13.1641969Z                 cur_index=config.cur_index,
2026-02-16T17:14:13.1650950Z         ) as proxy:
2026-02-16T17:14:13.1659393Z     
2026-02-16T17:14:13.1669403Z >           with RemoteOpenAIServer(
2026-02-16T17:14:13.1679160Z                     model=config.model,
2026-02-16T17:14:13.1688607Z                     vllm_serve_args=config.server_cmd,
2026-02-16T17:14:13.1698012Z                     server_port=config.server_port,
2026-02-16T17:14:13.1707336Z                     server_host=config.master_ip,
2026-02-16T17:14:13.1716562Z                     env_dict=config.envs,
2026-02-16T17:14:13.1726911Z                     auto_port=False,
2026-02-16T17:14:13.1736104Z                     proxy_port=proxy.proxy_port,
2026-02-16T17:14:13.1745680Z                     disaggregated_prefill=config.disagg_cfg,
2026-02-16T17:14:13.1754980Z                     nodes_info=config.nodes,
2026-02-16T17:14:13.1764835Z                     max_wait_seconds=2800,
2026-02-16T17:14:13.1776647Z             ) as server:
2026-02-16T17:14:13.1786514Z 
2026-02-16T17:14:13.1801286Z tests/e2e/nightly/multi_node/scripts/test_multi_node.py:21: 
2026-02-16T17:14:13.1809642Z _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
2026-02-16T17:14:13.1816772Z tests/e2e/conftest.py:306: in __init__
2026-02-16T17:14:13.1826421Z     self._wait_for_multiple_servers(
2026-02-16T17:14:13.1835366Z _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
2026-02-16T17:14:13.1845231Z 
2026-02-16T17:14:13.1854461Z self = <tests.e2e.conftest.RemoteOpenAIServer object at 0xffff21cc3c50>
2026-02-16T17:14:13.1863970Z targets = [('10.0.0.167', 'http://10.0.0.167:8080/health')], timeout = 2800
2026-02-16T17:14:13.1873770Z log_interval = 30.0
2026-02-16T17:14:13.1882534Z 
2026-02-16T17:14:13.1892338Z     def _wait_for_multiple_servers(self,
2026-02-16T17:14:13.1901658Z                                    targets,
2026-02-16T17:14:13.1910622Z                                    timeout: float,
2026-02-16T17:14:13.1920007Z                                    log_interval: float = 30.0):
2026-02-16T17:14:13.1929249Z         """
2026-02-16T17:14:13.1938289Z         targets: List[(node_ip, url)]
2026-02-16T17:14:13.1947512Z         log_interval
2026-02-16T17:14:13.1956824Z         """
2026-02-16T17:14:13.1965867Z         start = time.time()
2026-02-16T17:14:13.1975209Z         client = requests
2026-02-16T17:14:13.1983831Z     
2026-02-16T17:14:13.1993475Z         ready = {node_ip: False for node_ip, _ in targets}
2026-02-16T17:14:13.2002479Z     
2026-02-16T17:14:13.2011948Z         last_log_time = 0.0
2026-02-16T17:14:13.2021584Z     
2026-02-16T17:14:13.2030432Z         while True:
2026-02-16T17:14:13.2040016Z             now = time.time()
2026-02-16T17:14:13.2049204Z             all_ready = True
2026-02-16T17:14:13.2058516Z             should_log = (now - last_log_time) >= log_interval
2026-02-16T17:14:13.2067457Z     
2026-02-16T17:14:13.2076509Z             for node_ip, url in targets:
2026-02-16T17:14:13.2086095Z                 if ready[node_ip]:
2026-02-16T17:14:13.2096076Z                     continue
2026-02-16T17:14:13.2104645Z     
2026-02-16T17:14:13.2114419Z                 try:
2026-02-16T17:14:13.2123207Z                     resp = client.get(url)
2026-02-16T17:14:13.2132799Z                     if resp.status_code == 200:
2026-02-16T17:14:13.2142069Z                         ready[node_ip] = True
2026-02-16T17:14:13.2150898Z                         logger.info(f"[READY] Node {node_ip} is ready.")
2026-02-16T17:14:13.2160175Z                 except RequestException:
2026-02-16T17:14:13.2169362Z                     all_ready = False
2026-02-16T17:14:13.2179799Z                     if should_log:
2026-02-16T17:14:13.2188876Z                         logger.debug(f"[WAIT] {url}: connection failed")
2026-02-16T17:14:13.2197494Z     
2026-02-16T17:14:13.2207276Z                     # check unexpected exit
2026-02-16T17:14:13.2217162Z                     result = self._poll()
2026-02-16T17:14:13.2226003Z                     if result is not None and result != 0:
2026-02-16T17:14:13.2234813Z >                       raise RuntimeError(
2026-02-16T17:14:13.2243883Z                             f"Server at {node_ip} exited unexpectedly."
2026-02-16T17:14:13.2253469Z                         ) from None
2026-02-16T17:14:13.2263098Z E                       RuntimeError: Server at 10.0.0.167 exited unexpectedly.
2026-02-16T17:14:13.2271819Z 
2026-02-16T17:14:13.2281288Z tests/e2e/conftest.py:399: RuntimeError
2026-02-16T17:14:13.2290997Z =============================== warnings summary ===============================
2026-02-16T17:14:13.2299764Z <frozen importlib._bootstrap>:241
2026-02-16T17:14:13.2309256Z   <frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyPacked has no __module__ attribute
2026-02-16T17:14:13.2317864Z 
2026-02-16T17:14:13.2327978Z <frozen importlib._bootstrap>:241
2026-02-16T17:14:13.2337137Z   <frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyObject has no __module__ attribute
2026-02-16T17:14:13.2345748Z 
2026-02-16T17:14:13.2355057Z ../../usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647
2026-02-16T17:14:13.2365452Z   /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-16T17:14:13.2374242Z     warnings.warn(
2026-02-16T17:14:13.2382669Z 
2026-02-16T17:14:13.2392231Z ../../usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/__init__.py:8
2026-02-16T17:14:13.2402305Z   /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/__init__.py:8: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html
2026-02-16T17:14:13.2411034Z     import pkg_resources
2026-02-16T17:14:13.2420162Z 
2026-02-16T17:14:13.2429882Z -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
2026-02-16T17:14:13.2439033Z =========================== short test summary info ============================
2026-02-16T17:14:13.2448606Z FAILED tests/e2e/nightly/multi_node/scripts/test_multi_node.py::test_multi_node
2026-02-16T17:14:13.2457492Z ================== 1 failed, 4 warnings in 131.00s (0:02:10) ===================
2026-02-16T17:14:14.8659154Z [0;31mFAIL_TAG_DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml âœ— ERROR: Some tests failed, please check the error stack above for details. If this is insufficient to pinpoint the error, please download and review the logs of all other nodes from the job's summary.[0m
2026-02-16T17:14:15.0859609Z Cleaning up background log streams...
2026-02-16T17:14:15.1577045Z ##[error]Error: failed to run script step: Error: command terminated with non-zero exit code: command terminated with exit code 1
2026-02-16T17:14:15.1617816Z ##[error]Process completed with exit code 1.
2026-02-16T17:14:15.1711478Z ##[error]Executing the custom container implementation failed. Please contact your self hosted runner administrator.
2026-02-16T17:14:15.2099316Z ##[group]Run actions/upload-artifact@v6
2026-02-16T17:14:15.2099603Z with:
2026-02-16T17:14:15.2099870Z   name: DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml-pod-logs
2026-02-16T17:14:15.2100384Z   path: /tmp/vllm*_logs.txt
2026-02-16T17:14:15.2100639Z   retention-days: 7
2026-02-16T17:14:15.2100846Z   if-no-files-found: warn
2026-02-16T17:14:15.2101129Z   compression-level: 6
2026-02-16T17:14:15.2101368Z   overwrite: false
2026-02-16T17:14:15.2101683Z   include-hidden-files: false
2026-02-16T17:14:15.2101957Z env:
2026-02-16T17:14:15.2102326Z   FAIL_TAG: FAIL_TAG_DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-02-16T17:14:15.2102597Z ##[endgroup]
2026-02-16T17:14:15.2127800Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-16T17:14:15.2128584Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-16T17:14:15.2128871Z ##[endgroup]
2026-02-16T17:14:15.5929774Z (node:875) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-16T17:14:15.5930622Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-16T17:14:16.3220240Z With the provided path, there will be 1 file uploaded
2026-02-16T17:14:16.3223687Z Artifact name is valid!
2026-02-16T17:14:16.3224084Z Root directory input is valid!
2026-02-16T17:14:17.4926773Z Beginning upload of artifact content to blob storage
2026-02-16T17:14:18.5966786Z Uploaded bytes 16416
2026-02-16T17:14:18.8201817Z Finished uploading artifact content to blob storage!
2026-02-16T17:14:18.8202438Z SHA256 digest of uploaded artifact zip is d62670f4666b1c7636ee7c1937de977ca299560eae4f09dd9ee5a827bb8bf588
2026-02-16T17:14:18.8204017Z Finalizing artifact upload
2026-02-16T17:14:19.7115173Z Artifact DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml-pod-logs.zip successfully finalized. Artifact ID 5528873284
2026-02-16T17:14:19.7115951Z Artifact DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml-pod-logs has been successfully uploaded! Final size is 16416 bytes. Artifact ID is 5528873284
2026-02-16T17:14:19.7116678Z Artifact download URL: https://github.com/vllm-project/vllm-ascend/actions/runs/22070488769/artifacts/5528873284
2026-02-16T17:14:20.1846748Z ##[group]Run kubectl get pods -n "$NAMESPACE" --ignore-not-found=true
2026-02-16T17:14:20.1847204Z [36;1mkubectl get pods -n "$NAMESPACE" --ignore-not-found=true[0m
2026-02-16T17:14:20.1847689Z [36;1mkubectl delete -f ./lws.yaml --ignore-not-found=true || true[0m
2026-02-16T17:14:20.1848081Z shell: bash -el {0}
2026-02-16T17:14:20.1848298Z env:
2026-02-16T17:14:20.1848590Z   FAIL_TAG: FAIL_TAG_DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-02-16T17:14:20.1848901Z ##[endgroup]
2026-02-16T17:14:20.1923766Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-16T17:14:20.1924582Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-16T17:14:20.1924895Z ##[endgroup]
2026-02-16T17:14:20.5430448Z (node:988) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-16T17:14:20.5431220Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-16T17:14:21.1531939Z NAME                                             READY   STATUS    RESTARTS     AGE
2026-02-16T17:14:21.1532532Z linux-aarch64-a3-0-n4cwm-runner-gktkh            1/1     Running   0            4m7s
2026-02-16T17:14:21.1533079Z linux-aarch64-a3-0-n4cwm-runner-gktkh-workflow   1/1     Running   0            3m31s
2026-02-16T17:14:21.1533536Z vllm-0                                           1/1     Running   1 (7s ago)   3m4s
2026-02-16T17:14:21.1533906Z vllm-0-1                                         1/1     Running   0            3m3s
2026-02-16T17:14:21.2117760Z leaderworkerset.leaderworkerset.x-k8s.io "vllm" deleted from vllm-project namespace
2026-02-16T17:14:21.2297186Z service "vllm-leader" deleted from vllm-project namespace
2026-02-16T17:14:21.7077341Z Post job cleanup.
2026-02-16T17:14:21.7108581Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-16T17:14:21.7109536Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-16T17:14:21.7109875Z ##[endgroup]
2026-02-16T17:14:22.0629112Z (node:1112) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-16T17:14:22.0629932Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-16T17:14:22.7129370Z [command]/usr/bin/git version
2026-02-16T17:14:22.7163213Z git version 2.34.1
2026-02-16T17:14:22.7190418Z Copying '/root/.gitconfig' to '/__w/_temp/fa5f48fb-207f-44a0-babb-bdb1e0559602/.gitconfig'
2026-02-16T17:14:22.7199016Z Temporarily overriding HOME='/__w/_temp/fa5f48fb-207f-44a0-babb-bdb1e0559602' before making global git config changes
2026-02-16T17:14:22.7199668Z Adding repository directory to the temporary git global config as a safe directory
2026-02-16T17:14:22.7204058Z [command]/usr/bin/git config --global --add safe.directory /__w/vllm-ascend/vllm-ascend
2026-02-16T17:14:22.7229578Z Removing SSH command configuration
2026-02-16T17:14:22.7234946Z [command]/usr/bin/git config --local --name-only --get-regexp core\.sshCommand
2026-02-16T17:14:22.7265975Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'core\.sshCommand' && git config --local --unset-all 'core.sshCommand' || :"
2026-02-16T17:14:22.7449684Z Removing HTTP extra header
2026-02-16T17:14:22.7453260Z [command]/usr/bin/git config --local --name-only --get-regexp http\.https\:\/\/github\.com\/\.extraheader
2026-02-16T17:14:22.7481022Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'http\.https\:\/\/github\.com\/\.extraheader' && git config --local --unset-all 'http.https://github.com/.extraheader' || :"
2026-02-16T17:14:22.7655272Z Removing includeIf entries pointing to credentials config files
2026-02-16T17:14:22.7659193Z [command]/usr/bin/git config --local --name-only --get-regexp ^includeIf\.gitdir:
2026-02-16T17:14:22.7678064Z includeif.gitdir:/__w/vllm-ascend/vllm-ascend/.git.path
2026-02-16T17:14:22.7678492Z includeif.gitdir:/__w/vllm-ascend/vllm-ascend/.git/worktrees/*.path
2026-02-16T17:14:22.7678894Z includeif.gitdir:/github/workspace/.git.path
2026-02-16T17:14:22.7679251Z includeif.gitdir:/github/workspace/.git/worktrees/*.path
2026-02-16T17:14:22.7685522Z [command]/usr/bin/git config --local --get-all includeif.gitdir:/__w/vllm-ascend/vllm-ascend/.git.path
2026-02-16T17:14:22.7703249Z /__w/_temp/git-credentials-df1c6ae4-a4a0-474f-96b3-a8685b4ab275.config
2026-02-16T17:14:22.7711344Z [command]/usr/bin/git config --local --unset includeif.gitdir:/__w/vllm-ascend/vllm-ascend/.git.path /__w/_temp/git-credentials-df1c6ae4-a4a0-474f-96b3-a8685b4ab275.config
2026-02-16T17:14:22.7744291Z [command]/usr/bin/git config --local --get-all includeif.gitdir:/__w/vllm-ascend/vllm-ascend/.git/worktrees/*.path
2026-02-16T17:14:22.7763203Z /__w/_temp/git-credentials-df1c6ae4-a4a0-474f-96b3-a8685b4ab275.config
2026-02-16T17:14:22.7770558Z [command]/usr/bin/git config --local --unset includeif.gitdir:/__w/vllm-ascend/vllm-ascend/.git/worktrees/*.path /__w/_temp/git-credentials-df1c6ae4-a4a0-474f-96b3-a8685b4ab275.config
2026-02-16T17:14:22.7798591Z [command]/usr/bin/git config --local --get-all includeif.gitdir:/github/workspace/.git.path
2026-02-16T17:14:22.7816667Z /github/runner_temp/git-credentials-df1c6ae4-a4a0-474f-96b3-a8685b4ab275.config
2026-02-16T17:14:22.7823593Z [command]/usr/bin/git config --local --unset includeif.gitdir:/github/workspace/.git.path /github/runner_temp/git-credentials-df1c6ae4-a4a0-474f-96b3-a8685b4ab275.config
2026-02-16T17:14:22.7850130Z [command]/usr/bin/git config --local --get-all includeif.gitdir:/github/workspace/.git/worktrees/*.path
2026-02-16T17:14:22.7868145Z /github/runner_temp/git-credentials-df1c6ae4-a4a0-474f-96b3-a8685b4ab275.config
2026-02-16T17:14:22.7874967Z [command]/usr/bin/git config --local --unset includeif.gitdir:/github/workspace/.git/worktrees/*.path /github/runner_temp/git-credentials-df1c6ae4-a4a0-474f-96b3-a8685b4ab275.config
2026-02-16T17:14:22.7902649Z [command]/usr/bin/git submodule foreach --recursive git config --local --show-origin --name-only --get-regexp remote.origin.url
2026-02-16T17:14:22.8073825Z Removing credentials config '/__w/_temp/git-credentials-df1c6ae4-a4a0-474f-96b3-a8685b4ab275.config'
2026-02-16T17:14:41.2373568Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-16T17:14:41.2374483Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-16T17:14:41.2374876Z ##[endgroup]
2026-02-16T17:14:41.6424685Z Cleaning up orphan processes
