# Run ID: 22360966349
# Commit: 0331f16a50e85a1c57f8a850376babf89201dd22
# Job: multi-node (multi-node-dpsk3.2-2node, DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml, 2) / DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
# Date: 2026-02-24
============================================================

ï»¿2026-02-24T19:23:24.3104614Z Current runner version: '2.330.0'
2026-02-24T19:23:24.3109287Z Runner name: 'linux-aarch64-a3-0-n4cwm-runner-znfxh'
2026-02-24T19:23:24.3109978Z Runner group name: 'Default'
2026-02-24T19:23:24.3110687Z Machine name: 'linux-aarch64-a3-0-n4cwm-runner-znfxh'
2026-02-24T19:23:24.3114291Z ##[group]GITHUB_TOKEN Permissions
2026-02-24T19:23:24.3116354Z Actions: write
2026-02-24T19:23:24.3116818Z ArtifactMetadata: write
2026-02-24T19:23:24.3117251Z Attestations: write
2026-02-24T19:23:24.3117627Z Checks: write
2026-02-24T19:23:24.3118012Z Contents: write
2026-02-24T19:23:24.3118491Z Deployments: write
2026-02-24T19:23:24.3118848Z Discussions: write
2026-02-24T19:23:24.3119232Z Issues: write
2026-02-24T19:23:24.3119565Z Metadata: read
2026-02-24T19:23:24.3119941Z Models: read
2026-02-24T19:23:24.3120315Z Packages: write
2026-02-24T19:23:24.3120663Z Pages: write
2026-02-24T19:23:24.3121036Z PullRequests: write
2026-02-24T19:23:24.3121441Z RepositoryProjects: write
2026-02-24T19:23:24.3122106Z SecurityEvents: write
2026-02-24T19:23:24.3122736Z Statuses: write
2026-02-24T19:23:24.3123124Z ##[endgroup]
2026-02-24T19:23:24.3125069Z Secret source: Actions
2026-02-24T19:23:24.3125575Z Prepare workflow directory
2026-02-24T19:23:24.3665842Z Prepare all required actions
2026-02-24T19:23:24.3697737Z Getting action download info
2026-02-24T19:23:25.4047048Z Download action repository 'actions/checkout@v6' (SHA:de0fac2e4500dabe0009e67214ff5f5447ce83dd)
2026-02-24T19:23:29.9600594Z Download action repository 'actions/upload-artifact@v6' (SHA:b7c566a772e6b6bfb58ed0dc250532a479d7789f)
2026-02-24T19:23:37.6872098Z Uses: vllm-project/vllm-ascend/.github/workflows/_e2e_nightly_multi_node.yaml@refs/heads/main (0331f16a50e85a1c57f8a850376babf89201dd22)
2026-02-24T19:23:37.6875357Z ##[group] Inputs
2026-02-24T19:23:37.6875667Z   soc_version: a3
2026-02-24T19:23:37.6875897Z   runner: linux-aarch64-a3-0
2026-02-24T19:23:37.6876326Z   image: swr.cn-southwest-2.myhuaweicloud.com/base_image/ascend-ci/vllm-ascend:nightly-a3
2026-02-24T19:23:37.6876872Z   config_file_path: DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-02-24T19:23:37.6877155Z   replicas: 1
2026-02-24T19:23:37.6877375Z   size: 2
2026-02-24T19:23:37.6877577Z   vllm_version: v0.15.0
2026-02-24T19:23:37.6877909Z   vllm_ascend_remote_url: https://github.com/vllm-project/vllm-ascend.git
2026-02-24T19:23:37.6878414Z   vllm_ascend_ref: main
2026-02-24T19:23:37.6878672Z ##[endgroup]
2026-02-24T19:23:37.6879136Z Complete job name: multi-node (multi-node-dpsk3.2-2node, DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml, 2) / DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-02-24T19:23:37.7378390Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-24T19:23:37.7381001Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-24T19:23:37.7381461Z ##[endgroup]
2026-02-24T19:23:53.2945791Z (node:72) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-24T19:23:53.2946638Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-24T19:23:55.0729876Z ##[group]Run # Decode and save kubeconfig
2026-02-24T19:23:55.0730340Z [36;1m# Decode and save kubeconfig[0m
2026-02-24T19:23:55.0762640Z [36;1mecho "***" | base64 -d > "$KUBECONFIG"[0m
2026-02-24T19:23:55.0763255Z shell: bash -el {0}
2026-02-24T19:23:55.0763482Z ##[endgroup]
2026-02-24T19:23:55.0877394Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-24T19:23:55.0878539Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-24T19:23:55.0878867Z ##[endgroup]
2026-02-24T19:23:55.4395675Z (node:403) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-24T19:23:55.4396444Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-24T19:23:56.3072263Z ##[group]Run actions/checkout@v6
2026-02-24T19:23:56.3072640Z with:
2026-02-24T19:23:56.3072915Z   repository: vllm-project/vllm-ascend
2026-02-24T19:23:56.3073707Z   token: ***
2026-02-24T19:23:56.3073943Z   ssh-strict: true
2026-02-24T19:23:56.3074182Z   ssh-user: git
2026-02-24T19:23:56.3074405Z   persist-credentials: true
2026-02-24T19:23:56.3074656Z   clean: true
2026-02-24T19:23:56.3074980Z   sparse-checkout-cone-mode: true
2026-02-24T19:23:56.3075244Z   fetch-depth: 1
2026-02-24T19:23:56.3075456Z   fetch-tags: false
2026-02-24T19:23:56.3075694Z   show-progress: true
2026-02-24T19:23:56.3075910Z   lfs: false
2026-02-24T19:23:56.3076120Z   submodules: false
2026-02-24T19:23:56.3076348Z   set-safe-directory: true
2026-02-24T19:23:56.3076562Z ##[endgroup]
2026-02-24T19:23:56.3116343Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-24T19:23:56.3117191Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-24T19:23:56.3117528Z ##[endgroup]
2026-02-24T19:23:56.6826630Z (node:433) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-24T19:23:56.9796505Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-24T19:23:57.2448090Z Syncing repository: vllm-project/vllm-ascend
2026-02-24T19:23:57.2449315Z ##[group]Getting Git version info
2026-02-24T19:23:57.2449670Z Working directory is '/__w/vllm-ascend/vllm-ascend'
2026-02-24T19:23:57.2450161Z [command]/usr/bin/git version
2026-02-24T19:23:57.2450432Z git version 2.34.1
2026-02-24T19:23:57.2451806Z ##[endgroup]
2026-02-24T19:23:57.2455050Z Copying '/root/.gitconfig' to '/__w/_temp/038e12be-1269-409a-8973-15bd8160b993/.gitconfig'
2026-02-24T19:23:57.2462866Z Temporarily overriding HOME='/__w/_temp/038e12be-1269-409a-8973-15bd8160b993' before making global git config changes
2026-02-24T19:23:57.2463503Z Adding repository directory to the temporary git global config as a safe directory
2026-02-24T19:23:57.2466089Z [command]/usr/bin/git config --global --add safe.directory /__w/vllm-ascend/vllm-ascend
2026-02-24T19:23:57.2495986Z Deleting the contents of '/__w/vllm-ascend/vllm-ascend'
2026-02-24T19:23:57.2498490Z ##[group]Initializing the repository
2026-02-24T19:23:57.2502118Z [command]/usr/bin/git init /__w/vllm-ascend/vllm-ascend
2026-02-24T19:23:57.2614457Z hint: Using 'master' as the name for the initial branch. This default branch name
2026-02-24T19:23:57.2614919Z hint: is subject to change. To configure the initial branch name to use in all
2026-02-24T19:23:57.2615354Z hint: of your new repositories, which will suppress this warning, call:
2026-02-24T19:23:57.2615657Z hint: 
2026-02-24T19:23:57.2615957Z hint: 	git config --global init.defaultBranch <name>
2026-02-24T19:23:57.2616211Z hint: 
2026-02-24T19:23:57.2616510Z hint: Names commonly chosen instead of 'master' are 'main', 'trunk' and
2026-02-24T19:23:57.2616940Z hint: 'development'. The just-created branch can be renamed via this command:
2026-02-24T19:23:57.2617246Z hint: 
2026-02-24T19:23:57.2617483Z hint: 	git branch -m <name>
2026-02-24T19:23:57.2622443Z Initialized empty Git repository in /__w/vllm-ascend/vllm-ascend/.git/
2026-02-24T19:23:57.2630583Z [command]/usr/bin/git remote add origin https://github.com/vllm-project/vllm-ascend
2026-02-24T19:23:57.2667923Z ##[endgroup]
2026-02-24T19:23:57.2668302Z ##[group]Disabling automatic garbage collection
2026-02-24T19:23:57.2671328Z [command]/usr/bin/git config --local gc.auto 0
2026-02-24T19:23:57.2698849Z ##[endgroup]
2026-02-24T19:23:57.2699211Z ##[group]Setting up auth
2026-02-24T19:23:57.2700612Z Removing SSH command configuration
2026-02-24T19:23:57.2705789Z [command]/usr/bin/git config --local --name-only --get-regexp core\.sshCommand
2026-02-24T19:23:57.2732152Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'core\.sshCommand' && git config --local --unset-all 'core.sshCommand' || :"
2026-02-24T19:23:57.2915160Z Removing HTTP extra header
2026-02-24T19:23:57.2918264Z [command]/usr/bin/git config --local --name-only --get-regexp http\.https\:\/\/github\.com\/\.extraheader
2026-02-24T19:23:57.2942513Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'http\.https\:\/\/github\.com\/\.extraheader' && git config --local --unset-all 'http.https://github.com/.extraheader' || :"
2026-02-24T19:23:57.3129967Z Removing includeIf entries pointing to credentials config files
2026-02-24T19:23:57.3134199Z [command]/usr/bin/git config --local --name-only --get-regexp ^includeIf\.gitdir:
2026-02-24T19:23:57.3159678Z [command]/usr/bin/git submodule foreach --recursive git config --local --show-origin --name-only --get-regexp remote.origin.url
2026-02-24T19:23:57.3335603Z [command]/usr/bin/git config --file /__w/_temp/git-credentials-849bb984-ca42-40d5-9d28-03b71029e9d7.config http.https://github.com/.extraheader AUTHORIZATION: basic ***
2026-02-24T19:23:57.3372393Z [command]/usr/bin/git config --local includeIf.gitdir:/__w/vllm-ascend/vllm-ascend/.git.path /__w/_temp/git-credentials-849bb984-ca42-40d5-9d28-03b71029e9d7.config
2026-02-24T19:23:57.3400077Z [command]/usr/bin/git config --local includeIf.gitdir:/__w/vllm-ascend/vllm-ascend/.git/worktrees/*.path /__w/_temp/git-credentials-849bb984-ca42-40d5-9d28-03b71029e9d7.config
2026-02-24T19:23:57.3426081Z [command]/usr/bin/git config --local includeIf.gitdir:/github/workspace/.git.path /github/runner_temp/git-credentials-849bb984-ca42-40d5-9d28-03b71029e9d7.config
2026-02-24T19:23:57.3450525Z [command]/usr/bin/git config --local includeIf.gitdir:/github/workspace/.git/worktrees/*.path /github/runner_temp/git-credentials-849bb984-ca42-40d5-9d28-03b71029e9d7.config
2026-02-24T19:23:57.3472802Z ##[endgroup]
2026-02-24T19:23:57.3473132Z ##[group]Fetching the repository
2026-02-24T19:23:57.3481037Z [command]/usr/bin/git -c protocol.version=2 fetch --no-tags --prune --no-recurse-submodules --depth=1 origin +0331f16a50e85a1c57f8a850376babf89201dd22:refs/remotes/origin/main
2026-02-24T19:23:59.0395227Z From https://gh-proxy.test.osinfra.cn/https://github.com/vllm-project/vllm-ascend
2026-02-24T19:23:59.0395841Z  * [new ref]         0331f16a50e85a1c57f8a850376babf89201dd22 -> origin/main
2026-02-24T19:23:59.0414734Z [command]/usr/bin/git branch --list --remote origin/main
2026-02-24T19:23:59.0436785Z   origin/main
2026-02-24T19:23:59.0444681Z [command]/usr/bin/git rev-parse refs/remotes/origin/main
2026-02-24T19:23:59.0461873Z 0331f16a50e85a1c57f8a850376babf89201dd22
2026-02-24T19:23:59.0465322Z ##[endgroup]
2026-02-24T19:23:59.0465705Z ##[group]Determining the checkout info
2026-02-24T19:23:59.0466990Z ##[endgroup]
2026-02-24T19:23:59.0470560Z [command]/usr/bin/git sparse-checkout disable
2026-02-24T19:23:59.0503041Z [command]/usr/bin/git config --local --unset-all extensions.worktreeConfig
2026-02-24T19:23:59.0525893Z ##[group]Checking out the ref
2026-02-24T19:23:59.0528994Z [command]/usr/bin/git checkout --progress --force -B main refs/remotes/origin/main
2026-02-24T19:23:59.1412258Z Switched to a new branch 'main'
2026-02-24T19:23:59.1412599Z Branch 'main' set up to track remote branch 'main' from 'origin'.
2026-02-24T19:23:59.1422493Z ##[endgroup]
2026-02-24T19:23:59.1452865Z [command]/usr/bin/git log -1 --format=%H
2026-02-24T19:23:59.1471949Z 0331f16a50e85a1c57f8a850376babf89201dd22
2026-02-24T19:23:59.5601859Z ##[group]Run # prepare for lws entrypoint scripts
2026-02-24T19:23:59.5602335Z [36;1m# prepare for lws entrypoint scripts[0m
2026-02-24T19:23:59.5602776Z [36;1minstall -D tests/e2e/nightly/multi_node/scripts/run.sh /root/.cache/tests/run.sh[0m
2026-02-24T19:23:59.5603338Z shell: bash -el {0}
2026-02-24T19:23:59.5603526Z ##[endgroup]
2026-02-24T19:23:59.5726844Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-24T19:23:59.5727729Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-24T19:23:59.5728022Z ##[endgroup]
2026-02-24T19:23:59.9240160Z (node:475) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-24T19:23:59.9240956Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-24T19:24:00.9395290Z ##[group]Run set -euo pipefail
2026-02-24T19:24:00.9395641Z [36;1mset -euo pipefail[0m
2026-02-24T19:24:00.9395899Z [36;1m[0m
2026-02-24T19:24:00.9396092Z [36;1mCRD_NAME="${CRD_NAME:-vllm}"[0m
2026-02-24T19:24:00.9396680Z [36;1mTIMEOUT=${TIMEOUT:-120}[0m
2026-02-24T19:24:00.9396915Z [36;1mSLEEP_INTERVAL=2[0m
2026-02-24T19:24:00.9397161Z [36;1m[0m
2026-02-24T19:24:00.9397477Z [36;1mecho "Deleting leaderworkerset [$CRD_NAME] in namespace [$NAMESPACE]..."[0m
2026-02-24T19:24:00.9397930Z [36;1mkubectl delete leaderworkerset "$CRD_NAME" -n "$NAMESPACE" --ignore-not-found[0m
2026-02-24T19:24:00.9398311Z [36;1m[0m
2026-02-24T19:24:00.9398602Z [36;1mecho "Waiting for all pods starting with 'vllm' to be deleted..."[0m
2026-02-24T19:24:00.9398911Z [36;1mSTART_TIME=$(date +%s)[0m
2026-02-24T19:24:00.9399162Z [36;1m[0m
2026-02-24T19:24:00.9399369Z [36;1mwhile true; do[0m
2026-02-24T19:24:00.9399577Z [36;1m  NOW=$(date +%s)[0m
2026-02-24T19:24:00.9399919Z [36;1m  ELAPSED=$((NOW - START_TIME))[0m
2026-02-24T19:24:00.9400211Z [36;1m[0m
2026-02-24T19:24:00.9400454Z [36;1m  if [[ $ELAPSED -ge $TIMEOUT ]]; then[0m
2026-02-24T19:24:00.9400807Z [36;1m    echo "Timeout reached ($TIMEOUT seconds), some pods still exist:"[0m
2026-02-24T19:24:00.9401184Z [36;1m    kubectl get pods -n "$NAMESPACE" | grep '^vllm' || true[0m
2026-02-24T19:24:00.9401504Z [36;1m    exit 1[0m
2026-02-24T19:24:00.9401711Z [36;1m  fi[0m
2026-02-24T19:24:00.9401896Z [36;1m[0m
2026-02-24T19:24:00.9402454Z [36;1m  PODS_EXIST=$(kubectl get pods -n "$NAMESPACE" -o jsonpath='{.items[*].metadata.name}' 2>/dev/null | tr ' ' '\n' | grep '^vllm' || true)[0m
2026-02-24T19:24:00.9402932Z [36;1m[0m
2026-02-24T19:24:00.9403142Z [36;1m  if [[ -z "$PODS_EXIST" ]]; then[0m
2026-02-24T19:24:00.9403472Z [36;1m    echo "All vllm pods deleted."[0m
2026-02-24T19:24:00.9403722Z [36;1m    break[0m
2026-02-24T19:24:00.9403992Z [36;1m  else[0m
2026-02-24T19:24:00.9404268Z [36;1m    echo "Waiting for pods to be deleted: $PODS_EXIST"[0m
2026-02-24T19:24:00.9404639Z [36;1m    sleep $SLEEP_INTERVAL[0m
2026-02-24T19:24:00.9404880Z [36;1m  fi[0m
2026-02-24T19:24:00.9405087Z [36;1mdone[0m
2026-02-24T19:24:00.9405398Z shell: bash -el {0}
2026-02-24T19:24:00.9405640Z ##[endgroup]
2026-02-24T19:24:00.9544737Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-24T19:24:00.9545569Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-24T19:24:00.9545861Z ##[endgroup]
2026-02-24T19:24:01.3752964Z (node:529) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-24T19:24:01.3753815Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-24T19:24:01.9655660Z Deleting leaderworkerset [vllm] in namespace [vllm-project]...
2026-02-24T19:24:02.0490448Z Waiting for all pods starting with 'vllm' to be deleted...
2026-02-24T19:24:02.1222412Z All vllm pods deleted.
2026-02-24T19:24:02.5342929Z ##[group]Run set -e
2026-02-24T19:24:02.5343232Z [36;1mset -e[0m
2026-02-24T19:24:02.5343437Z [36;1m[0m
2026-02-24T19:24:02.5343688Z [36;1msize="2"[0m
2026-02-24T19:24:02.5343895Z [36;1mreplicas="1"[0m
2026-02-24T19:24:02.5344274Z [36;1mimage="swr.cn-southwest-2.myhuaweicloud.com/base_image/ascend-ci/vllm-ascend:nightly-a3"[0m
2026-02-24T19:24:02.5344791Z [36;1mconfig_file_path="DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml"[0m
2026-02-24T19:24:02.5345257Z [36;1mfail_tag=FAIL_TAG_"DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml"[0m
2026-02-24T19:24:02.5345593Z [36;1mecho "FAIL_TAG=${fail_tag}" >> "$GITHUB_ENV"[0m
2026-02-24T19:24:02.5345877Z [36;1m[0m
2026-02-24T19:24:02.5346149Z [36;1mrequired_params=("size" "replicas" "image" "config_file_path")[0m
2026-02-24T19:24:02.5346494Z [36;1mfor param in "${required_params[@]}"; do[0m
2026-02-24T19:24:02.5346783Z [36;1m  if [ -z "${!param}" ]; then[0m
2026-02-24T19:24:02.5347359Z [36;1m    echo "Error: Parameter '$param' is required but empty"[0m
2026-02-24T19:24:02.5347641Z [36;1m    exit 1[0m
2026-02-24T19:24:02.5347842Z [36;1m  fi[0m
2026-02-24T19:24:02.5348039Z [36;1mdone[0m
2026-02-24T19:24:02.5348238Z [36;1m[0m
2026-02-24T19:24:02.5348431Z [36;1mif [ "a3" = "a3" ]; then[0m
2026-02-24T19:24:02.5348678Z [36;1m  npu_per_node=16[0m
2026-02-24T19:24:02.5349009Z [36;1m  TEMPLATE_FILE="tests/e2e/nightly/multi_node/scripts/lws.yaml.jinja2"[0m
2026-02-24T19:24:02.5349331Z [36;1melse[0m
2026-02-24T19:24:02.5349539Z [36;1m  npu_per_node=8[0m
2026-02-24T19:24:02.5349864Z [36;1m  TEMPLATE_FILE="tests/e2e/nightly/multi_node/scripts/lws-a2.yaml.jinja2"[0m
2026-02-24T19:24:02.5350204Z [36;1mfi[0m
2026-02-24T19:24:02.5350391Z [36;1m[0m
2026-02-24T19:24:02.5350628Z [36;1mjinja2 $TEMPLATE_FILE \[0m
2026-02-24T19:24:02.5350863Z [36;1m  -D size="$size" \[0m
2026-02-24T19:24:02.5351114Z [36;1m  -D replicas="$replicas" \[0m
2026-02-24T19:24:02.5351377Z [36;1m  -D image="$image" \[0m
2026-02-24T19:24:02.5351643Z [36;1m  -D config_file_path="$config_file_path" \[0m
2026-02-24T19:24:02.5351954Z [36;1m  -D npu_per_node="$npu_per_node" \[0m
2026-02-24T19:24:02.5352386Z [36;1m  -D fail_tag="$fail_tag" \[0m
2026-02-24T19:24:02.5352633Z [36;1m  --outfile lws.yaml[0m
2026-02-24T19:24:02.5352879Z [36;1m[0m
2026-02-24T19:24:02.5353090Z [36;1mkubectl apply -f ./lws.yaml[0m
2026-02-24T19:24:02.5353473Z shell: bash -el {0}
2026-02-24T19:24:02.5353726Z ##[endgroup]
2026-02-24T19:24:02.5484462Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-24T19:24:02.5485972Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-24T19:24:02.5486285Z ##[endgroup]
2026-02-24T19:24:02.9128321Z (node:595) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-24T19:24:02.9129125Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-24T19:24:03.8646028Z leaderworkerset.leaderworkerset.x-k8s.io/vllm created
2026-02-24T19:24:03.8949082Z service/vllm-leader created
2026-02-24T19:24:04.3193369Z ##[group]Run POD_PREFIX="${POD_PREFIX:-vllm-0}"
2026-02-24T19:24:04.3193662Z [36;1mPOD_PREFIX="${POD_PREFIX:-vllm-0}"[0m
2026-02-24T19:24:04.3193857Z [36;1mSIZE="2"[0m
2026-02-24T19:24:04.3194031Z [36;1mTIMEOUT=1200  # default timeout 20 minutes[0m
2026-02-24T19:24:04.3194232Z [36;1m[0m
2026-02-24T19:24:04.3194536Z [36;1mecho "Waiting for Pods in namespace [$NAMESPACE] to become Running and Ready (timeout ${TIMEOUT}s)..."[0m
2026-02-24T19:24:04.3194879Z [36;1m[0m
2026-02-24T19:24:04.3195054Z [36;1mSTART_TIME=$(date +%s)[0m
2026-02-24T19:24:04.3195235Z [36;1m[0m
2026-02-24T19:24:04.3195428Z [36;1mwhile true; do[0m
2026-02-24T19:24:04.3195596Z [36;1m  NOW=$(date +%s)[0m
2026-02-24T19:24:04.3195779Z [36;1m  ELAPSED=$((NOW - START_TIME))[0m
2026-02-24T19:24:04.3195985Z [36;1m  if [[ $ELAPSED -ge $TIMEOUT ]]; then[0m
2026-02-24T19:24:04.3196228Z [36;1m    echo "Timeout reached after ${ELAPSED}s"[0m
2026-02-24T19:24:04.3196497Z [36;1m    echo "Dumping pod status for debugging:"[0m
2026-02-24T19:24:04.3196726Z [36;1m    kubectl get pods -n "$NAMESPACE"[0m
2026-02-24T19:24:04.3196973Z [36;1m    kubectl describe pod "$LEADER_POD" -n "$NAMESPACE"[0m
2026-02-24T19:24:04.3197191Z [36;1m    exit 1[0m
2026-02-24T19:24:04.3197341Z [36;1m  fi[0m
2026-02-24T19:24:04.3197471Z [36;1m[0m
2026-02-24T19:24:04.3197606Z [36;1m  # 1) check follower pods[0m
2026-02-24T19:24:04.3197793Z [36;1m  ALL_FOLLOWERS_READY=true[0m
2026-02-24T19:24:04.3197980Z [36;1m  for ((i=1; i<SIZE; i++)); do[0m
2026-02-24T19:24:04.3198165Z [36;1m    POD="${POD_PREFIX}-${i}"[0m
2026-02-24T19:24:04.3198526Z [36;1m    PHASE=$(kubectl get pod "$POD" -n "$NAMESPACE" -o jsonpath='{.status.phase}' 2>/dev/null || echo "NotFound")[0m
2026-02-24T19:24:04.3199056Z [36;1m    READY=$(kubectl get pod "$POD" -n "$NAMESPACE" -o jsonpath='{.status.containerStatuses[*].ready}' 2>/dev/null)[0m
2026-02-24T19:24:04.3199535Z [36;1m[0m
2026-02-24T19:24:04.3199725Z [36;1m    echo "Follower [$POD] phase=$PHASE ready=$READY"[0m
2026-02-24T19:24:04.3199943Z [36;1m[0m
2026-02-24T19:24:04.3200127Z [36;1m    if [[ "$PHASE" != "Running" || "$READY" != "true" ]]; then[0m
2026-02-24T19:24:04.3200399Z [36;1m      echo "Follower [$POD] not Ready yet..."[0m
2026-02-24T19:24:04.3200615Z [36;1m      ALL_FOLLOWERS_READY=false[0m
2026-02-24T19:24:04.3200805Z [36;1m      break[0m
2026-02-24T19:24:04.3200953Z [36;1m    fi[0m
2026-02-24T19:24:04.3201087Z [36;1m  done[0m
2026-02-24T19:24:04.3201214Z [36;1m[0m
2026-02-24T19:24:04.3201347Z [36;1m  # 2) check leader pod[0m
2026-02-24T19:24:04.3201713Z [36;1m  LEADER_PHASE=$(kubectl get pod "$LEADER_POD" -n "$NAMESPACE" -o jsonpath='{.status.phase}' 2>/dev/null || echo "NotFound")[0m
2026-02-24T19:24:04.3202404Z [36;1m  LEADER_READY=$(kubectl get pod "$LEADER_POD" -n "$NAMESPACE" -o jsonpath='{.status.containerStatuses[*].ready}' 2>/dev/null)[0m
2026-02-24T19:24:04.3202795Z [36;1m[0m
2026-02-24T19:24:04.3203005Z [36;1m  echo "Leader [$LEADER_POD] phase=$LEADER_PHASE ready=$LEADER_READY"[0m
2026-02-24T19:24:04.3203266Z [36;1m[0m
2026-02-24T19:24:04.3203472Z [36;1m  if [[ "$LEADER_PHASE" != "Running" || "$LEADER_READY" != "true" ]]; then[0m
2026-02-24T19:24:04.3203740Z [36;1m    echo "Leader not Ready yet..."[0m
2026-02-24T19:24:04.3203938Z [36;1m    ALL_FOLLOWERS_READY=false[0m
2026-02-24T19:24:04.3204110Z [36;1m  fi[0m
2026-02-24T19:24:04.3204233Z [36;1m[0m
2026-02-24T19:24:04.3204389Z [36;1m  if [[ "$ALL_FOLLOWERS_READY" == "true" ]]; then[0m
2026-02-24T19:24:04.3204698Z [36;1m    echo "All follower pods and leader pod are Running and Ready â€” continuing."[0m
2026-02-24T19:24:04.3204974Z [36;1m    break[0m
2026-02-24T19:24:04.3205115Z [36;1m  fi[0m
2026-02-24T19:24:04.3205236Z [36;1m[0m
2026-02-24T19:24:04.3205460Z [36;1m  sleep 2[0m
2026-02-24T19:24:04.3205603Z [36;1mdone[0m
2026-02-24T19:24:04.3205870Z shell: bash -el {0}
2026-02-24T19:24:04.3206014Z env:
2026-02-24T19:24:04.3206335Z   FAIL_TAG: FAIL_TAG_DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-02-24T19:24:04.3206560Z ##[endgroup]
2026-02-24T19:24:04.3302539Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-24T19:24:04.3303203Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-24T19:24:04.3303413Z ##[endgroup]
2026-02-24T19:24:04.6912635Z (node:673) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-24T19:24:04.6913289Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-24T19:24:05.2429982Z Waiting for Pods in namespace [vllm-project] to become Running and Ready (timeout 1200s)...
2026-02-24T19:24:05.3738241Z Follower [vllm-0-1] phase=Pending ready=
2026-02-24T19:24:05.3738502Z Follower [vllm-0-1] not Ready yet...
2026-02-24T19:24:05.5036133Z Leader [vllm-0] phase=Pending ready=
2026-02-24T19:24:05.5036377Z Leader not Ready yet...
2026-02-24T19:24:07.6185411Z Follower [vllm-0-1] phase=Pending ready=
2026-02-24T19:24:07.6185718Z Follower [vllm-0-1] not Ready yet...
2026-02-24T19:24:07.7349250Z Leader [vllm-0] phase=Pending ready=
2026-02-24T19:24:07.7349480Z Leader not Ready yet...
2026-02-24T19:24:09.8533699Z Follower [vllm-0-1] phase=Pending ready=
2026-02-24T19:24:09.8533962Z Follower [vllm-0-1] not Ready yet...
2026-02-24T19:24:09.9721303Z Leader [vllm-0] phase=Pending ready=
2026-02-24T19:24:09.9721513Z Leader not Ready yet...
2026-02-24T19:24:12.0947171Z Follower [vllm-0-1] phase=Pending ready=
2026-02-24T19:24:12.0947531Z Follower [vllm-0-1] not Ready yet...
2026-02-24T19:24:12.2118431Z Leader [vllm-0] phase=Pending ready=
2026-02-24T19:24:12.2118668Z Leader not Ready yet...
2026-02-24T19:24:14.3275919Z Follower [vllm-0-1] phase=Pending ready=
2026-02-24T19:24:14.3276183Z Follower [vllm-0-1] not Ready yet...
2026-02-24T19:24:14.4334748Z Leader [vllm-0] phase=Pending ready=
2026-02-24T19:24:14.4335295Z Leader not Ready yet...
2026-02-24T19:24:16.5413746Z Follower [vllm-0-1] phase=Pending ready=
2026-02-24T19:24:16.5414051Z Follower [vllm-0-1] not Ready yet...
2026-02-24T19:24:16.6661439Z Leader [vllm-0] phase=Pending ready=
2026-02-24T19:24:16.6661703Z Leader not Ready yet...
2026-02-24T19:24:18.7770679Z Follower [vllm-0-1] phase=Pending ready=false
2026-02-24T19:24:18.7770970Z Follower [vllm-0-1] not Ready yet...
2026-02-24T19:24:18.8911021Z Leader [vllm-0] phase=Pending ready=false
2026-02-24T19:24:18.8911293Z Leader not Ready yet...
2026-02-24T19:24:21.0137274Z Follower [vllm-0-1] phase=Pending ready=false
2026-02-24T19:24:21.0137579Z Follower [vllm-0-1] not Ready yet...
2026-02-24T19:24:21.1258736Z Leader [vllm-0] phase=Pending ready=false
2026-02-24T19:24:21.1259061Z Leader not Ready yet...
2026-02-24T19:24:23.2467371Z Follower [vllm-0-1] phase=Pending ready=false
2026-02-24T19:24:23.2467665Z Follower [vllm-0-1] not Ready yet...
2026-02-24T19:24:23.3743494Z Leader [vllm-0] phase=Pending ready=false
2026-02-24T19:24:23.3743775Z Leader not Ready yet...
2026-02-24T19:24:25.4948037Z Follower [vllm-0-1] phase=Pending ready=false
2026-02-24T19:24:25.4948321Z Follower [vllm-0-1] not Ready yet...
2026-02-24T19:24:25.6104932Z Leader [vllm-0] phase=Pending ready=false
2026-02-24T19:24:25.6105135Z Leader not Ready yet...
2026-02-24T19:24:27.7787749Z Follower [vllm-0-1] phase=Pending ready=false
2026-02-24T19:24:27.7788005Z Follower [vllm-0-1] not Ready yet...
2026-02-24T19:24:27.9324225Z Leader [vllm-0] phase=Pending ready=false
2026-02-24T19:24:27.9324483Z Leader not Ready yet...
2026-02-24T19:24:30.0074596Z Follower [vllm-0-1] phase=Pending ready=false
2026-02-24T19:24:30.0074875Z Follower [vllm-0-1] not Ready yet...
2026-02-24T19:24:30.1253858Z Leader [vllm-0] phase=Pending ready=false
2026-02-24T19:24:30.1254118Z Leader not Ready yet...
2026-02-24T19:24:32.2495458Z Follower [vllm-0-1] phase=Pending ready=false
2026-02-24T19:24:32.2495852Z Follower [vllm-0-1] not Ready yet...
2026-02-24T19:24:32.3635772Z Leader [vllm-0] phase=Pending ready=false
2026-02-24T19:24:32.3636190Z Leader not Ready yet...
2026-02-24T19:24:34.4817560Z Follower [vllm-0-1] phase=Pending ready=false
2026-02-24T19:24:34.4818048Z Follower [vllm-0-1] not Ready yet...
2026-02-24T19:24:34.5961368Z Leader [vllm-0] phase=Pending ready=false
2026-02-24T19:24:34.5961667Z Leader not Ready yet...
2026-02-24T19:24:36.7138693Z Follower [vllm-0-1] phase=Pending ready=false
2026-02-24T19:24:36.7139075Z Follower [vllm-0-1] not Ready yet...
2026-02-24T19:24:36.8458023Z Leader [vllm-0] phase=Pending ready=false
2026-02-24T19:24:36.8458375Z Leader not Ready yet...
2026-02-24T19:24:38.9691836Z Follower [vllm-0-1] phase=Pending ready=false
2026-02-24T19:24:38.9692445Z Follower [vllm-0-1] not Ready yet...
2026-02-24T19:24:39.0906423Z Leader [vllm-0] phase=Pending ready=false
2026-02-24T19:24:39.0906717Z Leader not Ready yet...
2026-02-24T19:24:41.2041844Z Follower [vllm-0-1] phase=Pending ready=false
2026-02-24T19:24:41.2042256Z Follower [vllm-0-1] not Ready yet...
2026-02-24T19:24:41.3208412Z Leader [vllm-0] phase=Pending ready=false
2026-02-24T19:24:41.3208801Z Leader not Ready yet...
2026-02-24T19:24:43.4331384Z Follower [vllm-0-1] phase=Pending ready=false
2026-02-24T19:24:43.4331751Z Follower [vllm-0-1] not Ready yet...
2026-02-24T19:24:43.5419165Z Leader [vllm-0] phase=Pending ready=false
2026-02-24T19:24:43.5419526Z Leader not Ready yet...
2026-02-24T19:24:45.6594715Z Follower [vllm-0-1] phase=Pending ready=false
2026-02-24T19:24:45.6595096Z Follower [vllm-0-1] not Ready yet...
2026-02-24T19:24:45.7737841Z Leader [vllm-0] phase=Pending ready=false
2026-02-24T19:24:45.7738218Z Leader not Ready yet...
2026-02-24T19:24:47.8949478Z Follower [vllm-0-1] phase=Pending ready=false
2026-02-24T19:24:47.8949823Z Follower [vllm-0-1] not Ready yet...
2026-02-24T19:24:48.0105839Z Leader [vllm-0] phase=Pending ready=false
2026-02-24T19:24:48.0106165Z Leader not Ready yet...
2026-02-24T19:24:50.1302657Z Follower [vllm-0-1] phase=Pending ready=false
2026-02-24T19:24:50.1303348Z Follower [vllm-0-1] not Ready yet...
2026-02-24T19:24:50.2423903Z Leader [vllm-0] phase=Pending ready=false
2026-02-24T19:24:50.2424316Z Leader not Ready yet...
2026-02-24T19:24:52.3549322Z Follower [vllm-0-1] phase=Pending ready=false
2026-02-24T19:24:52.3549738Z Follower [vllm-0-1] not Ready yet...
2026-02-24T19:24:52.4659347Z Leader [vllm-0] phase=Pending ready=false
2026-02-24T19:24:52.4659669Z Leader not Ready yet...
2026-02-24T19:24:54.5784698Z Follower [vllm-0-1] phase=Pending ready=false
2026-02-24T19:24:54.5785078Z Follower [vllm-0-1] not Ready yet...
2026-02-24T19:24:54.6855521Z Leader [vllm-0] phase=Pending ready=false
2026-02-24T19:24:54.6855850Z Leader not Ready yet...
2026-02-24T19:24:56.8040449Z Follower [vllm-0-1] phase=Pending ready=false
2026-02-24T19:24:56.8040893Z Follower [vllm-0-1] not Ready yet...
2026-02-24T19:24:56.9249417Z Leader [vllm-0] phase=Pending ready=false
2026-02-24T19:24:56.9249786Z Leader not Ready yet...
2026-02-24T19:24:59.0419370Z Follower [vllm-0-1] phase=Pending ready=false
2026-02-24T19:24:59.0419749Z Follower [vllm-0-1] not Ready yet...
2026-02-24T19:24:59.1555737Z Leader [vllm-0] phase=Pending ready=false
2026-02-24T19:24:59.1556097Z Leader not Ready yet...
2026-02-24T19:25:01.2737078Z Follower [vllm-0-1] phase=Pending ready=false
2026-02-24T19:25:01.2737426Z Follower [vllm-0-1] not Ready yet...
2026-02-24T19:25:01.3967163Z Leader [vllm-0] phase=Pending ready=false
2026-02-24T19:25:01.3967582Z Leader not Ready yet...
2026-02-24T19:25:03.7908826Z Follower [vllm-0-1] phase=Pending ready=false
2026-02-24T19:25:03.7909259Z Follower [vllm-0-1] not Ready yet...
2026-02-24T19:25:03.9116557Z Leader [vllm-0] phase=Pending ready=false
2026-02-24T19:25:03.9116874Z Leader not Ready yet...
2026-02-24T19:25:06.0423916Z Follower [vllm-0-1] phase=Pending ready=false
2026-02-24T19:25:06.0424233Z Follower [vllm-0-1] not Ready yet...
2026-02-24T19:25:06.1588597Z Leader [vllm-0] phase=Running ready=true
2026-02-24T19:25:08.2781342Z Follower [vllm-0-1] phase=Running ready=true
2026-02-24T19:25:08.3854564Z Leader [vllm-0] phase=Running ready=true
2026-02-24T19:25:08.3855470Z All follower pods and leader pod are Running and Ready â€” continuing.
2026-02-24T19:25:08.8792127Z ##[group]Run set -euo pipefail
2026-02-24T19:25:08.8792562Z [36;1mset -euo pipefail[0m
2026-02-24T19:25:08.8792727Z [36;1m[0m
2026-02-24T19:25:08.8792936Z [36;1msize="2"[0m
2026-02-24T19:25:08.8793089Z [36;1mpids=()[0m
2026-02-24T19:25:08.8793223Z [36;1m[0m
2026-02-24T19:25:08.8793360Z [36;1mcleanup() {[0m
2026-02-24T19:25:08.8793558Z [36;1m  echo "Cleaning up background log streams..."[0m
2026-02-24T19:25:08.8793837Z [36;1m  for pid in "${pids[@]}"; do[0m
2026-02-24T19:25:08.8794045Z [36;1m    kill "$pid" 2>/dev/null || true[0m
2026-02-24T19:25:08.8794229Z [36;1m  done[0m
2026-02-24T19:25:08.8794371Z [36;1m}[0m
2026-02-24T19:25:08.8794517Z [36;1mtrap cleanup EXIT[0m
2026-02-24T19:25:08.8794675Z [36;1m[0m
2026-02-24T19:25:08.8794828Z [36;1mfor i in $(seq 1 $((size - 1))); do[0m
2026-02-24T19:25:08.8795047Z [36;1m  POD="vllm-0-${i}"[0m
2026-02-24T19:25:08.8795203Z [36;1m[0m
2026-02-24T19:25:08.8795422Z [36;1m  echo "==== Collecting logs from worker pod: $POD ===="[0m
2026-02-24T19:25:08.8795690Z [36;1m  kubectl logs -f "$POD" -n "$NAMESPACE" \[0m
2026-02-24T19:25:08.8795924Z [36;1m    > "/tmp/${POD}_logs.txt" 2>&1 &[0m
2026-02-24T19:25:08.8796113Z [36;1m[0m
2026-02-24T19:25:08.8796240Z [36;1m  pids+=($!)[0m
2026-02-24T19:25:08.8796391Z [36;1mdone[0m
2026-02-24T19:25:08.8796520Z [36;1m[0m
2026-02-24T19:25:08.8796716Z [36;1mecho "==== Streaming logs from leader pod: $LEADER_POD ===="[0m
2026-02-24T19:25:08.8796999Z [36;1mecho "Looking for logs containing: $FAIL_TAG"[0m
2026-02-24T19:25:08.8797199Z [36;1m[0m
2026-02-24T19:25:08.8797430Z [36;1mkubectl logs -f "$LEADER_POD" -n "$NAMESPACE" | while IFS= read -r line; do[0m
2026-02-24T19:25:08.8797721Z [36;1m  echo "$line"[0m
2026-02-24T19:25:08.8797911Z [36;1m  if echo "$line" | grep -q "$FAIL_TAG"; then[0m
2026-02-24T19:25:08.8798280Z [36;1m    exit 1[0m
2026-02-24T19:25:08.8798428Z [36;1m  fi[0m
2026-02-24T19:25:08.8798558Z [36;1mdone[0m
2026-02-24T19:25:08.8798890Z shell: bash -el {0}
2026-02-24T19:25:08.8799032Z env:
2026-02-24T19:25:08.8799229Z   FAIL_TAG: FAIL_TAG_DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-02-24T19:25:08.8799455Z ##[endgroup]
2026-02-24T19:25:08.8896309Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-24T19:25:08.8896991Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-24T19:25:08.8897275Z ##[endgroup]
2026-02-24T19:25:09.2434101Z (node:780) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-24T19:25:09.2434752Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-24T19:25:09.8824909Z ==== Collecting logs from worker pod: vllm-0-1 ====
2026-02-24T19:25:09.8825196Z ==== Streaming logs from leader pod: vllm-0 ====
2026-02-24T19:25:09.8825525Z Looking for logs containing: FAIL_TAG_DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-02-24T19:25:09.9599192Z /usr/local/Ascend/ascend-toolkit/set_env.sh: line 31: CMAKE_PREFIX_PATH: unbound variable
2026-02-24T19:25:09.9647615Z ====> Check NPU info
2026-02-24T19:25:09.9658194Z +------------------------------------------------------------------------------------------------+
2026-02-24T19:25:09.9668293Z | npu-smi 25.5.0                   Version: 25.5.0                                               |
2026-02-24T19:25:09.9678684Z +---------------------------+---------------+----------------------------------------------------+
2026-02-24T19:25:09.9688766Z | NPU   Name                | Health        | Power(W)    Temp(C)           Hugepages-Usage(page)|
2026-02-24T19:25:09.9698306Z | Chip  Phy-ID              | Bus-Id        | AICore(%)   Memory-Usage(MB)  HBM-Usage(MB)        |
2026-02-24T19:25:09.9708889Z +===========================+===============+====================================================+
2026-02-24T19:25:09.9718320Z | 0     Ascend910           | OK            | 162.0       37                0    / 0             |
2026-02-24T19:25:09.9727889Z | 0     0                   | 0000:9D:00.0  | 0           0    / 0          3145 / 65536         |
2026-02-24T19:25:09.9737299Z +------------------------------------------------------------------------------------------------+
2026-02-24T19:25:09.9747111Z | 0     Ascend910           | OK            | -           37                0    / 0             |
2026-02-24T19:25:09.9757035Z | 1     1                   | 0000:9F:00.0  | 0           0    / 0          2891 / 65536         |
2026-02-24T19:25:09.9768595Z +===========================+===============+====================================================+
2026-02-24T19:25:09.9777669Z | 1     Ascend910           | OK            | 163.9       35                0    / 0             |
2026-02-24T19:25:09.9787630Z | 0     2                   | 0000:99:00.0  | 0           0    / 0          3160 / 65536         |
2026-02-24T19:25:09.9798199Z +------------------------------------------------------------------------------------------------+
2026-02-24T19:25:09.9808322Z | 1     Ascend910           | OK            | -           37                0    / 0             |
2026-02-24T19:25:09.9818150Z | 1     3                   | 0000:9B:00.0  | 0           0    / 0          2878 / 65536         |
2026-02-24T19:25:09.9827522Z +===========================+===============+====================================================+
2026-02-24T19:25:09.9837672Z | 2     Ascend910           | OK            | 162.7       37                0    / 0             |
2026-02-24T19:25:09.9847496Z | 0     4                   | 0000:95:00.0  | 0           0    / 0          3159 / 65536         |
2026-02-24T19:25:09.9857264Z +------------------------------------------------------------------------------------------------+
2026-02-24T19:25:09.9867192Z | 2     Ascend910           | OK            | -           36                0    / 0             |
2026-02-24T19:25:09.9876802Z | 1     5                   | 0000:97:00.0  | 0           0    / 0          2881 / 65536         |
2026-02-24T19:25:09.9887266Z +===========================+===============+====================================================+
2026-02-24T19:25:09.9896465Z | 3     Ascend910           | OK            | 167.5       37                0    / 0             |
2026-02-24T19:25:09.9905684Z | 0     6                   | 0000:91:00.0  | 0           0    / 0          3162 / 65536         |
2026-02-24T19:25:09.9915717Z +------------------------------------------------------------------------------------------------+
2026-02-24T19:25:09.9925889Z | 3     Ascend910           | OK            | -           37                0    / 0             |
2026-02-24T19:25:09.9935328Z | 1     7                   | 0000:93:00.0  | 0           0    / 0          2879 / 65536         |
2026-02-24T19:25:09.9945075Z +===========================+===============+====================================================+
2026-02-24T19:25:09.9954911Z | 4     Ascend910           | OK            | 161.8       37                0    / 0             |
2026-02-24T19:25:09.9964849Z | 0     8                   | 0000:8D:00.0  | 0           0    / 0          3159 / 65536         |
2026-02-24T19:25:09.9974585Z +------------------------------------------------------------------------------------------------+
2026-02-24T19:25:09.9984425Z | 4     Ascend910           | OK            | -           36                0    / 0             |
2026-02-24T19:25:09.9994261Z | 1     9                   | 0000:8F:00.0  | 0           0    / 0          2880 / 65536         |
2026-02-24T19:25:10.0004085Z +===========================+===============+====================================================+
2026-02-24T19:25:10.0013483Z | 5     Ascend910           | OK            | 163.1       37                0    / 0             |
2026-02-24T19:25:10.0023579Z | 0     10                  | 0000:89:00.0  | 0           0    / 0          3145 / 65536         |
2026-02-24T19:25:10.0033187Z +------------------------------------------------------------------------------------------------+
2026-02-24T19:25:10.0043608Z | 5     Ascend910           | OK            | -           37                0    / 0             |
2026-02-24T19:25:10.0053191Z | 1     11                  | 0000:8B:00.0  | 0           0    / 0          2893 / 65536         |
2026-02-24T19:25:10.0062765Z +===========================+===============+====================================================+
2026-02-24T19:25:10.0072756Z | 6     Ascend910           | OK            | 158.9       36                0    / 0             |
2026-02-24T19:25:10.0129807Z | 0     12                  | 0000:85:00.0  | 0           0    / 0          3146 / 65536         |
2026-02-24T19:25:10.0130150Z +------------------------------------------------------------------------------------------------+
2026-02-24T19:25:10.0130478Z | 6     Ascend910           | OK            | -           36                0    / 0             |
2026-02-24T19:25:10.0130783Z | 1     13                  | 0000:87:00.0  | 0           0    / 0          2891 / 65536         |
2026-02-24T19:25:10.0131061Z +===========================+===============+====================================================+
2026-02-24T19:25:10.0132275Z | 7     Ascend910           | OK            | 165.6       37                0    / 0             |
2026-02-24T19:25:10.0144462Z | 0     14                  | 0000:81:00.0  | 0           0    / 0          3153 / 65536         |
2026-02-24T19:25:10.0153971Z +------------------------------------------------------------------------------------------------+
2026-02-24T19:25:10.0164407Z | 7     Ascend910           | OK            | -           37                0    / 0             |
2026-02-24T19:25:10.0174832Z | 1     15                  | 0000:83:00.0  | 0           0    / 0          2876 / 65536         |
2026-02-24T19:25:10.0188925Z +===========================+===============+====================================================+
2026-02-24T19:25:10.0199237Z +---------------------------+---------------+----------------------------------------------------+
2026-02-24T19:25:10.0212890Z | NPU     Chip              | Process id    | Process name             | Process memory(MB)      |
2026-02-24T19:25:10.0225446Z +===========================+===============+====================================================+
2026-02-24T19:25:10.0235733Z | No running processes found in NPU 0                                                            |
2026-02-24T19:25:10.0249828Z +===========================+===============+====================================================+
2026-02-24T19:25:10.0260185Z | No running processes found in NPU 1                                                            |
2026-02-24T19:25:10.0270981Z +===========================+===============+====================================================+
2026-02-24T19:25:10.0281576Z | No running processes found in NPU 2                                                            |
2026-02-24T19:25:10.0291224Z +===========================+===============+====================================================+
2026-02-24T19:25:10.0301093Z | No running processes found in NPU 3                                                            |
2026-02-24T19:25:10.0310840Z +===========================+===============+====================================================+
2026-02-24T19:25:10.0320274Z | No running processes found in NPU 4                                                            |
2026-02-24T19:25:10.0330146Z +===========================+===============+====================================================+
2026-02-24T19:25:10.0339498Z | No running processes found in NPU 5                                                            |
2026-02-24T19:25:10.0349179Z +===========================+===============+====================================================+
2026-02-24T19:25:10.0358842Z | No running processes found in NPU 6                                                            |
2026-02-24T19:25:10.0368222Z +===========================+===============+====================================================+
2026-02-24T19:25:10.0378080Z | No running processes found in NPU 7                                                            |
2026-02-24T19:25:10.0387562Z +===========================+===============+====================================================+
2026-02-24T19:25:10.0397237Z package_name=Ascend-cann-toolkit
2026-02-24T19:25:10.0406919Z version=8.5.0
2026-02-24T19:25:10.0416053Z innerversion=V100R001C25SPC001B232
2026-02-24T19:25:10.0425275Z compatible_version=[V100R001C15],[V100R001C18],[V100R001C19],[V100R001C20],[V100R001C21],[V100R001C23]
2026-02-24T19:25:10.0434336Z arch=aarch64
2026-02-24T19:25:10.0443320Z os=linux
2026-02-24T19:25:10.0452622Z path=/usr/local/Ascend/cann-8.5.0
2026-02-24T19:25:10.0461551Z ====> Configure mirrors and git proxy
2026-02-24T19:25:10.0470836Z Writing to /root/.config/pip/pip.conf
2026-02-24T19:25:10.0480875Z Installed vLLM-related Python packages:
2026-02-24T19:25:10.0490198Z ais_bench_benchmark               3.0.20250930                /vllm-workspace/vllm-ascend/benchmark
2026-02-24T19:25:10.0499348Z vllm                              0.15.0+empty                /vllm-workspace/vllm
2026-02-24T19:25:10.0508574Z vllm_ascend                       0.14.0rc2.dev176+ga8e951e6f /vllm-workspace/vllm-ascend
2026-02-24T19:25:10.0518254Z 
2026-02-24T19:25:10.0527692Z ============================
2026-02-24T19:25:10.0537029Z vLLM Git information
2026-02-24T19:25:10.0546792Z ============================
2026-02-24T19:25:10.0555595Z Branch:      HEAD
2026-02-24T19:25:10.0565820Z Commit hash: f176443446f659dbab5315e056e605d8984fd976
2026-02-24T19:25:10.0574730Z Author:      TJian <tunjian.tan@embeddedllm.com>
2026-02-24T19:25:10.0584427Z Date:        2026-01-29 14:45:42 +0800
2026-02-24T19:25:10.0593627Z Message:     [Release] [CI] Optim release pipeline (#33156)
2026-02-24T19:25:10.0602914Z Tags:        v0.15.0
2026-02-24T19:25:10.0612347Z Remote:      origin	https://ghfast.top/https://github.com/vllm-project/vllm.git (fetch)
2026-02-24T19:25:10.0621879Z 
2026-02-24T19:25:10.0631200Z 
2026-02-24T19:25:10.0641119Z ============================
2026-02-24T19:25:10.0650174Z vLLM-Ascend Git information
2026-02-24T19:25:10.0659662Z ============================
2026-02-24T19:25:10.0668914Z Branch:      main
2026-02-24T19:25:10.0680010Z Commit hash: a8e951e6f557514bcda0d7db6e7710fb90a2474d
2026-02-24T19:25:10.0689528Z Author:      pu-zhe <zpuaa@outlook.com>
2026-02-24T19:25:10.0698717Z Date:        2026-02-24 16:48:05 +0800
2026-02-24T19:25:10.0707971Z Message:     [Feat] 310p supports PrefillCacheHit State (#6756)
2026-02-24T19:25:10.0716913Z Tags:        
2026-02-24T19:25:10.0728084Z Remote:      origin	https://ghfast.top/https://github.com/vllm-project/vllm-ascend (fetch)
2026-02-24T19:25:10.0736660Z 
2026-02-24T19:25:10.0745836Z ====> Check triton ascend info
2026-02-24T19:25:10.0755253Z Ubuntu clang version 15.0.7
2026-02-24T19:25:10.0765708Z Target: aarch64-unknown-linux-gnu
2026-02-24T19:25:10.0775338Z Thread model: posix
2026-02-24T19:25:10.0785386Z InstalledDir: /usr/bin
2026-02-24T19:25:10.0795828Z Found candidate GCC installation: /usr/bin/../lib/gcc/aarch64-linux-gnu/11
2026-02-24T19:25:10.0805803Z Selected GCC installation: /usr/bin/../lib/gcc/aarch64-linux-gnu/11
2026-02-24T19:25:10.0814964Z Candidate multilib: .;@m64
2026-02-24T19:25:10.0823741Z Selected multilib: .;@m64
2026-02-24T19:25:10.0832850Z /usr/local/Ascend/cann-8.5.0/tools/bishengir/bin/bishengir-compile
2026-02-24T19:25:10.6046449Z Name: triton-ascend
2026-02-24T19:25:10.6057480Z Version: 3.2.0
2026-02-24T19:25:10.6068715Z Summary: A language and compiler for custom Deep Learning operations on Ascend hardwares
2026-02-24T19:25:10.6080244Z Home-page: https://gitcode.com/Ascend/triton-ascend/
2026-02-24T19:25:10.6090349Z Author: 
2026-02-24T19:25:10.6099331Z Author-email: 
2026-02-24T19:25:10.6108444Z License: 
2026-02-24T19:25:10.6117505Z Location: /usr/local/python3.11.14/lib/python3.11/site-packages
2026-02-24T19:25:10.6126833Z Requires: 
2026-02-24T19:25:10.6135466Z Required-by: vllm_ascend
2026-02-24T19:25:28.1834239Z INFO 02-24 19:25:28 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-24T19:25:28.1845109Z INFO 02-24 19:25:28 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-24T19:25:28.1856953Z INFO 02-24 19:25:28 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-24T19:25:28.2294300Z INFO 02-24 19:25:28 [__init__.py:217] Platform plugin ascend is activated
2026-02-24T19:25:34.4026411Z ============================= test session starts ==============================
2026-02-24T19:25:34.4037742Z platform linux -- Python 3.11.14, pytest-8.4.2, pluggy-1.6.0 -- /usr/local/python3.11.14/bin/python3
2026-02-24T19:25:34.4048014Z cachedir: .pytest_cache
2026-02-24T19:25:34.4059209Z rootdir: /vllm-workspace/vllm-ascend
2026-02-24T19:25:34.4068047Z configfile: pyproject.toml
2026-02-24T19:25:34.4079992Z plugins: cov-7.0.0, mock-3.15.1, asyncio-1.3.0, anyio-4.12.1
2026-02-24T19:25:34.4089957Z asyncio: mode=Mode.STRICT, debug=False, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function
2026-02-24T19:25:35.0562971Z collecting ... collected 1 item
2026-02-24T19:25:35.0569670Z 
2026-02-24T19:25:35.0581561Z [2026-02-24 19:25:35] INFO multi_node_config.py:294: Loading config yaml: tests/e2e/nightly/multi_node/config/DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-02-24T19:25:35.0622360Z [2026-02-24 19:25:35] INFO multi_node_config.py:351: Resolving cluster IPs via DNS...
2026-02-24T19:25:35.0671843Z [2026-02-24 19:25:35] INFO multi_node_config.py:212: Node 0 envs: {'HCCL_OP_EXPANSION_MODE': 'AIV', 'VLLM_USE_MODELSCOPE': 'True', 'HCCL_BUFFSIZE': '1024', 'SERVER_PORT': '8080', 'OMP_PROC_BIND': 'False', 'OMP_NUM_THREADS': '1', 'PYTORCH_NPU_ALLOC_CONF': 'expandable_segments:True', 'VLLM_ASCEND_ENABLE_FLASHCOMM1': '1', 'ASCEND_A3_EBA_ENABLE': '1', 'HCCL_IF_IP': '10.0.0.169', 'HCCL_SOCKET_IFNAME': 'eth0', 'GLOO_SOCKET_IFNAME': 'eth0', 'TP_SOCKET_IFNAME': 'eth0', 'LOCAL_IP': '10.0.0.169', 'NIC_NAME': 'eth0', 'MASTER_IP': '10.0.0.169'}
2026-02-24T19:25:35.0693936Z [2026-02-24 19:25:35] INFO multi_node_config.py:137: Not launching proxy on non-master node
2026-02-24T19:25:35.0706951Z [2026-02-24 19:25:35] INFO conftest.py:241: Starting server with command: vllm serve vllm-ascend/DeepSeek-V3.2-W8A8 --host 0.0.0.0 --port 8080 --data-parallel-size 4 --data-parallel-size-local 2 --data-parallel-address 10.0.0.169 --data-parallel-rpc-port 13399 --tensor-parallel-size 8 --quantization ascend --seed 1024 --enable-expert-parallel --max-num-seqs 16 --max-model-len 8192 --max-num-batched-tokens 4096 --no-enable-prefix-caching --gpu-memory-utilization 0.85 --trust-remote-code --speculative-config {"num_speculative_tokens": 2, "method":"deepseek_mtp"} --compilation-config {"cudagraph_capture_sizes": [3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45, 48], "cudagraph_mode": "FULL_DECODE_ONLY"} --additional-config {"layer_sharding": ["q_b_proj", "o_proj"]} --tokenizer-mode deepseek_v32 --reasoning-parser deepseek_v3
2026-02-24T19:25:39.4110967Z tests/e2e/nightly/multi_node/scripts/test_multi_node.py::test_multi_node INFO 02-24 19:25:39 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-24T19:25:39.4113525Z INFO 02-24 19:25:39 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-24T19:25:39.4122690Z INFO 02-24 19:25:39 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-24T19:25:39.4190768Z INFO 02-24 19:25:39 [__init__.py:217] Platform plugin ascend is activated
2026-02-24T19:25:45.5398429Z 2026-02-24 19:25:45,537 - 139 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-24T19:25:45.5704105Z INFO 02-24 19:25:45 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-24T19:25:45.7127143Z INFO 02-24 19:25:45 [serve.py:100] Defaulting api_server_count to data_parallel_size (4).
2026-02-24T19:25:45.7152875Z INFO 02-24 19:25:45 [utils.py:325] 
2026-02-24T19:25:45.7163227Z INFO 02-24 19:25:45 [utils.py:325]        â–ˆ     â–ˆ     â–ˆâ–„   â–„â–ˆ
2026-02-24T19:25:45.7174360Z INFO 02-24 19:25:45 [utils.py:325]  â–„â–„ â–„â–ˆ â–ˆ     â–ˆ     â–ˆ â–€â–„â–€ â–ˆ  version 0.15.0
2026-02-24T19:25:45.7184622Z INFO 02-24 19:25:45 [utils.py:325]   â–ˆâ–„â–ˆâ–€ â–ˆ     â–ˆ     â–ˆ     â–ˆ  model   vllm-ascend/DeepSeek-V3.2-W8A8
2026-02-24T19:25:45.7195011Z INFO 02-24 19:25:45 [utils.py:325]    â–€â–€  â–€â–€â–€â–€â–€ â–€â–€â–€â–€â–€ â–€     â–€
2026-02-24T19:25:45.7205864Z INFO 02-24 19:25:45 [utils.py:325] 
2026-02-24T19:25:45.7226053Z INFO 02-24 19:25:45 [utils.py:261] non-default args: {'model_tag': 'vllm-ascend/DeepSeek-V3.2-W8A8', 'api_server_count': 4, 'host': '0.0.0.0', 'port': 8080, 'model': 'vllm-ascend/DeepSeek-V3.2-W8A8', 'tokenizer_mode': 'deepseek_v32', 'trust_remote_code': True, 'seed': 1024, 'max_model_len': 8192, 'quantization': 'ascend', 'reasoning_parser': 'deepseek_v3', 'tensor_parallel_size': 8, 'data_parallel_size': 4, 'data_parallel_size_local': 2, 'data_parallel_address': '10.0.0.169', 'data_parallel_rpc_port': 13399, 'enable_expert_parallel': True, 'gpu_memory_utilization': 0.85, 'enable_prefix_caching': False, 'max_num_batched_tokens': 4096, 'max_num_seqs': 16, 'speculative_config': {'num_speculative_tokens': 2, 'method': 'deepseek_mtp'}, 'compilation_config': {'level': None, 'mode': None, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'vllm_ascend.compilation.compiler_interface.AscendCompiler', 'custom_ops': [], 'splitting_ops': None, 'compile_mm_encoder': False, 'compile_sizes': None, 'compile_ranges_split_points': None, 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_DECODE_ONLY: (2, 0)>, 'cudagraph_num_of_warmups': 0, 'cudagraph_capture_sizes': [3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45, 48], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': None, 'pass_config': {}, 'max_cudagraph_capture_size': None, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>, 'evaluate_guards': False, 'assume_32_bit_indexing': True}, 'local_cache_dir': None}, 'additional_config': {'layer_sharding': ['q_b_proj', 'o_proj']}}
2026-02-24T19:25:45.7586028Z 2026-02-24 19:25:45,756 - modelscope - WARNING - We can not confirm the cached file is for revision: master
2026-02-24T19:25:45.7646017Z INFO 02-24 19:25:45 [arg_utils.py:602] HF_HUB_OFFLINE is True, replace model_id [vllm-ascend/DeepSeek-V3.2-W8A8] to model_path [/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8]
2026-02-24T19:25:45.7679244Z The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-24T19:25:45.7703118Z The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-24T19:25:45.7722978Z The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-24T19:25:45.7734279Z You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-24T19:25:45.7919666Z INFO 02-24 19:25:45 [model.py:541] Resolved architecture: DeepseekV32ForCausalLM
2026-02-24T19:25:45.7929586Z INFO 02-24 19:25:45 [model.py:1561] Using max model len 8192
2026-02-24T19:25:46.0583779Z WARNING 02-24 19:25:46 [speculative.py:270] method `deepseek_mtp` is deprecated and replaced with mtp.
2026-02-24T19:25:46.0612758Z The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-24T19:25:46.0623503Z The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-24T19:25:46.0634156Z You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-24T19:25:46.0698302Z INFO 02-24 19:25:46 [model.py:541] Resolved architecture: DeepSeekMTPModel
2026-02-24T19:25:46.0740478Z INFO 02-24 19:25:46 [model.py:1561] Using max model len 163840
2026-02-24T19:25:46.0753118Z WARNING 02-24 19:25:46 [speculative.py:388] Enabling num_speculative_tokens > 1 will runmultiple times of forward on same MTP layer,which may result in lower acceptance rate
2026-02-24T19:25:46.0763904Z INFO 02-24 19:25:46 [scheduler.py:226] Chunked prefill is enabled with max_num_batched_tokens=4096.
2026-02-24T19:25:46.6683057Z INFO 02-24 19:25:46 [vllm.py:624] Asynchronous scheduling is enabled.
2026-02-24T19:25:46.6688870Z INFO 02-24 19:25:46 [vllm.py:634] Disabling NCCL for DP synchronization when using async scheduling.
2026-02-24T19:25:46.6706511Z WARNING 02-24 19:25:46 [platform.py:730] Speculative quantization is set but Ascend automatically uses the main model's quantization method. Resetting to None.
2026-02-24T19:25:46.6716508Z WARNING 02-24 19:25:46 [platform.py:771] Ignored parameter 'use_trtllm_ragged_deepseek_prefill'. This is a GPU-specific feature not supported on Ascend. Resetting to False.
2026-02-24T19:25:46.6725164Z INFO 02-24 19:25:46 [ascend_config.py:412] Dynamic EPLB is False
2026-02-24T19:25:46.6734563Z INFO 02-24 19:25:46 [ascend_config.py:413] The number of redundant experts is 0
2026-02-24T19:25:46.6745470Z INFO 02-24 19:25:46 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-24T19:25:46.6754708Z WARNING 02-24 19:25:46 [vllm.py:1062] Batch sizes [3, 6, 9, 12, 15, 18, 21, 27, 30, 33, 36, 39, 42, 45] are removed because they are not multiple of tp_size 8 when sequence parallelism is enabled
2026-02-24T19:25:46.6765758Z INFO 02-24 19:25:46 [platform.py:318] FULL_DECODE_ONLY compilation enabled on NPU. use_inductor not supported - using only ACL Graph mode
2026-02-24T19:25:46.6777677Z WARNING 02-24 19:25:46 [platform.py:335] [91m
2026-02-24T19:25:46.6788105Z WARNING 02-24 19:25:46 [platform.py:335]             **********************************************************************************
2026-02-24T19:25:46.6799581Z WARNING 02-24 19:25:46 [platform.py:335]             * WARNING: You have enabled the *full graph* feature.
2026-02-24T19:25:46.6810036Z WARNING 02-24 19:25:46 [platform.py:335]             * This is an early experimental stage and may involve various unknown issues.
2026-02-24T19:25:46.6820154Z WARNING 02-24 19:25:46 [platform.py:335]             * A known problem is that capturing too many batch sizes can lead to OOM
2026-02-24T19:25:46.6830237Z WARNING 02-24 19:25:46 [platform.py:335]             * (Out of Memory) errors or inference hangs. If you encounter such issues,
2026-02-24T19:25:46.6840514Z WARNING 02-24 19:25:46 [platform.py:335]             * consider reducing `gpu_memory_utilization` or manually specifying a smaller
2026-02-24T19:25:46.6851292Z WARNING 02-24 19:25:46 [platform.py:335]             * batch size for graph capture.
2026-02-24T19:25:46.6859433Z WARNING 02-24 19:25:46 [platform.py:335]             * For more details, please refer to:
2026-02-24T19:25:46.6869394Z WARNING 02-24 19:25:46 [platform.py:335]             * https://docs.vllm.ai/en/stable/configuration/conserving_memory.html#reduce-cuda-graphs
2026-02-24T19:25:46.6878730Z WARNING 02-24 19:25:46 [platform.py:335]             **********************************************************************************[0m
2026-02-24T19:25:46.6888507Z WARNING 02-24 19:25:46 [platform.py:335]             
2026-02-24T19:25:46.6898003Z INFO 02-24 19:25:46 [platform.py:443] Set PYTORCH_NPU_ALLOC_CONF=expandable_segments:True
2026-02-24T19:25:46.6908046Z INFO 02-24 19:25:46 [utils.py:851] Started DP Coordinator process (PID: 152)
2026-02-24T19:25:51.1126878Z INFO 02-24 19:25:51 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-24T19:25:51.1136212Z INFO 02-24 19:25:51 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-24T19:25:51.1151191Z INFO 02-24 19:25:51 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-24T19:25:51.1214646Z INFO 02-24 19:25:51 [__init__.py:217] Platform plugin ascend is activated
2026-02-24T19:25:51.1446501Z INFO 02-24 19:25:51 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-24T19:25:51.1457813Z INFO 02-24 19:25:51 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-24T19:25:51.1467908Z INFO 02-24 19:25:51 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-24T19:25:51.1519103Z INFO 02-24 19:25:51 [__init__.py:217] Platform plugin ascend is activated
2026-02-24T19:26:00.6949662Z INFO 02-24 19:26:00 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-24T19:26:00.6960546Z INFO 02-24 19:26:00 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-24T19:26:00.6971175Z INFO 02-24 19:26:00 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-24T19:26:00.7016796Z INFO 02-24 19:26:00 [__init__.py:217] Platform plugin ascend is activated
2026-02-24T19:26:05.8314895Z INFO 02-24 19:26:05 [utils.py:218] Started 4 API server processes
2026-02-24T19:26:06.0223837Z [0;36m(EngineCore_DP0 pid=155)[0;0m 2026-02-24 19:26:06,020 - 155 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-24T19:26:06.0259894Z [0;36m(EngineCore_DP0 pid=155)[0;0m INFO 02-24 19:26:06 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-24T19:26:06.0301692Z [0;36m(EngineCore_DP0 pid=155)[0;0m INFO 02-24 19:26:06 [core.py:96] Initializing a V1 LLM engine (v0.15.0) with config: model='/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8', speculative_config=SpeculativeConfig(method='mtp', model='/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8', num_spec_tokens=2), tokenizer='/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8', skip_tokenizer_init=False, tokenizer_mode=deepseek_v32, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=8, pipeline_parallel_size=1, data_parallel_size=4, disable_custom_all_reduce=True, quantization=ascend, enforce_eager=False, enable_return_routed_experts=False, kv_cache_dtype=bfloat16, device_config=npu, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='deepseek_v3', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01, cudagraph_metrics=False, enable_layerwise_nvtx_tracing=False, enable_mfu_metrics=False, enable_mm_processor_stats=False, enable_logging_iteration_details=False), seed=1024, served_model_name=/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'vllm_ascend.compilation.compiler_interface.AscendCompiler', 'custom_ops': ['all'], 'splitting_ops': [], 'compile_mm_encoder': False, 'compile_sizes': [], 'compile_ranges_split_points': [4096], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_DECODE_ONLY: (2, 0)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [24, 48], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': True, 'fuse_act_quant': True, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 48, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>, 'evaluate_guards': False, 'assume_32_bit_indexing': True}, 'local_cache_dir': None}
2026-02-24T19:26:06.0309134Z [0;36m(EngineCore_DP1 pid=174)[0;0m 2026-02-24 19:26:06,024 - 174 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-24T19:26:06.0314996Z [0;36m(EngineCore_DP1 pid=174)[0;0m INFO 02-24 19:26:06 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-24T19:26:10.7152617Z INFO 02-24 19:26:10 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-24T19:26:10.7161307Z INFO 02-24 19:26:10 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-24T19:26:10.7172330Z INFO 02-24 19:26:10 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-24T19:26:10.7236817Z INFO 02-24 19:26:10 [__init__.py:217] Platform plugin ascend is activated
2026-02-24T19:26:10.7501520Z INFO 02-24 19:26:10 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-24T19:26:10.7506617Z INFO 02-24 19:26:10 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-24T19:26:10.7516065Z INFO 02-24 19:26:10 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-24T19:26:10.7571025Z INFO 02-24 19:26:10 [__init__.py:217] Platform plugin ascend is activated
2026-02-24T19:26:10.7771687Z INFO 02-24 19:26:10 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-24T19:26:10.7781620Z INFO 02-24 19:26:10 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-24T19:26:10.7792512Z INFO 02-24 19:26:10 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-24T19:26:10.7848635Z INFO 02-24 19:26:10 [__init__.py:217] Platform plugin ascend is activated
2026-02-24T19:26:10.9123832Z INFO 02-24 19:26:10 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-24T19:26:10.9130866Z INFO 02-24 19:26:10 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-24T19:26:10.9157162Z INFO 02-24 19:26:10 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-24T19:26:10.9216655Z INFO 02-24 19:26:10 [__init__.py:217] Platform plugin ascend is activated
2026-02-24T19:26:10.9651928Z INFO 02-24 19:26:10 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-24T19:26:10.9661366Z INFO 02-24 19:26:10 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-24T19:26:10.9669648Z INFO 02-24 19:26:10 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-24T19:26:10.9733910Z INFO 02-24 19:26:10 [__init__.py:217] Platform plugin ascend is activated
2026-02-24T19:26:11.0979192Z INFO 02-24 19:26:11 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-24T19:26:11.0983294Z INFO 02-24 19:26:11 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-24T19:26:11.0993409Z INFO 02-24 19:26:11 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-24T19:26:11.1110229Z INFO 02-24 19:26:11 [__init__.py:217] Platform plugin ascend is activated
2026-02-24T19:26:15.8025887Z 2026-02-24 19:26:15,800 - 202 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-24T19:26:15.8109156Z INFO 02-24 19:26:15 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-24T19:26:16.0076005Z 2026-02-24 19:26:16,005 - 203 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-24T19:26:16.0135120Z INFO 02-24 19:26:16 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-24T19:26:17.1663251Z [0;36m(ApiServer_3 pid=188)[0;0m 2026-02-24 19:26:17,163 - 188 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-24T19:26:17.1852843Z [0;36m(ApiServer_3 pid=188)[0;0m INFO 02-24 19:26:17 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-24T19:26:17.1932697Z [0;36m(ApiServer_0 pid=185)[0;0m 2026-02-24 19:26:17,191 - 185 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-24T19:26:17.2078249Z [0;36m(ApiServer_3 pid=188)[0;0m 2026-02-24 19:26:17,205 - modelscope - WARNING - We can not confirm the cached file is for revision: master
2026-02-24T19:26:17.2100049Z [0;36m(ApiServer_0 pid=185)[0;0m INFO 02-24 19:26:17 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-24T19:26:17.2151522Z [0;36m(ApiServer_3 pid=188)[0;0m INFO 02-24 19:26:17 [arg_utils.py:602] HF_HUB_OFFLINE is True, replace model_id [vllm-ascend/DeepSeek-V3.2-W8A8] to model_path [/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8]
2026-02-24T19:26:17.2242805Z [0;36m(ApiServer_0 pid=185)[0;0m 2026-02-24 19:26:17,222 - modelscope - WARNING - We can not confirm the cached file is for revision: master
2026-02-24T19:26:17.2305981Z [0;36m(ApiServer_0 pid=185)[0;0m INFO 02-24 19:26:17 [arg_utils.py:602] HF_HUB_OFFLINE is True, replace model_id [vllm-ascend/DeepSeek-V3.2-W8A8] to model_path [/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8]
2026-02-24T19:26:17.2331828Z [0;36m(ApiServer_2 pid=187)[0;0m 2026-02-24 19:26:17,231 - 187 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-24T19:26:17.2522623Z [0;36m(ApiServer_2 pid=187)[0;0m INFO 02-24 19:26:17 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-24T19:26:17.2658027Z [0;36m(ApiServer_2 pid=187)[0;0m 2026-02-24 19:26:17,264 - modelscope - WARNING - We can not confirm the cached file is for revision: master
2026-02-24T19:26:17.2728680Z [0;36m(ApiServer_2 pid=187)[0;0m INFO 02-24 19:26:17 [arg_utils.py:602] HF_HUB_OFFLINE is True, replace model_id [vllm-ascend/DeepSeek-V3.2-W8A8] to model_path [/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8]
2026-02-24T19:26:17.3253482Z [0;36m(ApiServer_3 pid=188)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-24T19:26:17.3276598Z [0;36m(ApiServer_3 pid=188)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-24T19:26:17.3298662Z [0;36m(ApiServer_3 pid=188)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-24T19:26:17.3308927Z [0;36m(ApiServer_3 pid=188)[0;0m You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-24T19:26:17.3381762Z [0;36m(ApiServer_3 pid=188)[0;0m INFO 02-24 19:26:17 [model.py:541] Resolved architecture: DeepseekV32ForCausalLM
2026-02-24T19:26:17.3402867Z [0;36m(ApiServer_3 pid=188)[0;0m INFO 02-24 19:26:17 [model.py:1561] Using max model len 8192
2026-02-24T19:26:17.3518889Z [0;36m(ApiServer_0 pid=185)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-24T19:26:17.3540373Z [0;36m(ApiServer_0 pid=185)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-24T19:26:17.3559221Z [0;36m(ApiServer_0 pid=185)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-24T19:26:17.3575235Z [0;36m(ApiServer_0 pid=185)[0;0m You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-24T19:26:17.3627211Z [0;36m(ApiServer_0 pid=185)[0;0m INFO 02-24 19:26:17 [model.py:541] Resolved architecture: DeepseekV32ForCausalLM
2026-02-24T19:26:17.3647832Z [0;36m(ApiServer_0 pid=185)[0;0m INFO 02-24 19:26:17 [model.py:1561] Using max model len 8192
2026-02-24T19:26:17.3775348Z [0;36m(ApiServer_2 pid=187)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-24T19:26:17.3794130Z [0;36m(ApiServer_2 pid=187)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-24T19:26:17.3806626Z [0;36m(ApiServer_2 pid=187)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-24T19:26:17.3816014Z [0;36m(ApiServer_2 pid=187)[0;0m You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-24T19:26:17.3868411Z [0;36m(ApiServer_2 pid=187)[0;0m INFO 02-24 19:26:17 [model.py:541] Resolved architecture: DeepseekV32ForCausalLM
2026-02-24T19:26:17.3887499Z [0;36m(ApiServer_2 pid=187)[0;0m INFO 02-24 19:26:17 [model.py:1561] Using max model len 8192
2026-02-24T19:26:17.4366752Z [0;36m(ApiServer_1 pid=186)[0;0m 2026-02-24 19:26:17,434 - 186 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-24T19:26:17.4527375Z [0;36m(ApiServer_1 pid=186)[0;0m INFO 02-24 19:26:17 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-24T19:26:17.4602485Z [0;36m(ApiServer_3 pid=188)[0;0m WARNING 02-24 19:26:17 [speculative.py:270] method `deepseek_mtp` is deprecated and replaced with mtp.
2026-02-24T19:26:17.4621243Z [0;36m(ApiServer_3 pid=188)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-24T19:26:17.4630658Z [0;36m(ApiServer_3 pid=188)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-24T19:26:17.4639831Z [0;36m(ApiServer_3 pid=188)[0;0m You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-24T19:26:17.4664620Z [0;36m(ApiServer_1 pid=186)[0;0m 2026-02-24 19:26:17,464 - modelscope - WARNING - We can not confirm the cached file is for revision: master
2026-02-24T19:26:17.4687126Z [0;36m(ApiServer_3 pid=188)[0;0m INFO 02-24 19:26:17 [model.py:541] Resolved architecture: DeepSeekMTPModel
2026-02-24T19:26:17.4706454Z [0;36m(ApiServer_3 pid=188)[0;0m INFO 02-24 19:26:17 [model.py:1561] Using max model len 163840
2026-02-24T19:26:17.4715963Z [0;36m(ApiServer_3 pid=188)[0;0m WARNING 02-24 19:26:17 [speculative.py:388] Enabling num_speculative_tokens > 1 will runmultiple times of forward on same MTP layer,which may result in lower acceptance rate
2026-02-24T19:26:17.4725982Z [0;36m(ApiServer_3 pid=188)[0;0m INFO 02-24 19:26:17 [scheduler.py:226] Chunked prefill is enabled with max_num_batched_tokens=4096.
2026-02-24T19:26:17.4736963Z [0;36m(ApiServer_1 pid=186)[0;0m INFO 02-24 19:26:17 [arg_utils.py:602] HF_HUB_OFFLINE is True, replace model_id [vllm-ascend/DeepSeek-V3.2-W8A8] to model_path [/root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8]
2026-02-24T19:26:17.4992921Z [0;36m(ApiServer_0 pid=185)[0;0m WARNING 02-24 19:26:17 [speculative.py:270] method `deepseek_mtp` is deprecated and replaced with mtp.
2026-02-24T19:26:17.5011487Z [0;36m(ApiServer_0 pid=185)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-24T19:26:17.5021137Z [0;36m(ApiServer_0 pid=185)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-24T19:26:17.5030649Z [0;36m(ApiServer_0 pid=185)[0;0m You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-24T19:26:17.5040063Z [0;36m(ApiServer_2 pid=187)[0;0m WARNING 02-24 19:26:17 [speculative.py:270] method `deepseek_mtp` is deprecated and replaced with mtp.
2026-02-24T19:26:17.5050066Z [0;36m(ApiServer_2 pid=187)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-24T19:26:17.5060351Z [0;36m(ApiServer_2 pid=187)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-24T19:26:17.5070190Z [0;36m(ApiServer_2 pid=187)[0;0m You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-24T19:26:17.5085443Z [0;36m(ApiServer_0 pid=185)[0;0m INFO 02-24 19:26:17 [model.py:541] Resolved architecture: DeepSeekMTPModel
2026-02-24T19:26:17.5095693Z [0;36m(ApiServer_0 pid=185)[0;0m INFO 02-24 19:26:17 [model.py:1561] Using max model len 163840
2026-02-24T19:26:17.5105704Z [0;36m(ApiServer_0 pid=185)[0;0m WARNING 02-24 19:26:17 [speculative.py:388] Enabling num_speculative_tokens > 1 will runmultiple times of forward on same MTP layer,which may result in lower acceptance rate
2026-02-24T19:26:17.5115271Z [0;36m(ApiServer_0 pid=185)[0;0m INFO 02-24 19:26:17 [scheduler.py:226] Chunked prefill is enabled with max_num_batched_tokens=4096.
2026-02-24T19:26:17.5125442Z [0;36m(ApiServer_2 pid=187)[0;0m INFO 02-24 19:26:17 [model.py:541] Resolved architecture: DeepSeekMTPModel
2026-02-24T19:26:17.5134701Z [0;36m(ApiServer_2 pid=187)[0;0m INFO 02-24 19:26:17 [model.py:1561] Using max model len 163840
2026-02-24T19:26:17.5145000Z [0;36m(ApiServer_2 pid=187)[0;0m WARNING 02-24 19:26:17 [speculative.py:388] Enabling num_speculative_tokens > 1 will runmultiple times of forward on same MTP layer,which may result in lower acceptance rate
2026-02-24T19:26:17.5154378Z [0;36m(ApiServer_2 pid=187)[0;0m INFO 02-24 19:26:17 [scheduler.py:226] Chunked prefill is enabled with max_num_batched_tokens=4096.
2026-02-24T19:26:17.5918161Z [0;36m(ApiServer_1 pid=186)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-24T19:26:17.5964706Z [0;36m(ApiServer_1 pid=186)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-24T19:26:17.5974562Z [0;36m(ApiServer_1 pid=186)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-24T19:26:17.5984602Z [0;36m(ApiServer_1 pid=186)[0;0m You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-24T19:26:17.6025665Z [0;36m(ApiServer_3 pid=188)[0;0m INFO 02-24 19:26:17 [vllm.py:624] Asynchronous scheduling is enabled.
2026-02-24T19:26:17.6035051Z [0;36m(ApiServer_3 pid=188)[0;0m INFO 02-24 19:26:17 [vllm.py:634] Disabling NCCL for DP synchronization when using async scheduling.
2026-02-24T19:26:17.6045232Z [0;36m(ApiServer_3 pid=188)[0;0m WARNING 02-24 19:26:17 [platform.py:730] Speculative quantization is set but Ascend automatically uses the main model's quantization method. Resetting to None.
2026-02-24T19:26:17.6054871Z [0;36m(ApiServer_3 pid=188)[0;0m WARNING 02-24 19:26:17 [platform.py:771] Ignored parameter 'use_trtllm_ragged_deepseek_prefill'. This is a GPU-specific feature not supported on Ascend. Resetting to False.
2026-02-24T19:26:17.6063603Z [0;36m(ApiServer_3 pid=188)[0;0m INFO 02-24 19:26:17 [ascend_config.py:412] Dynamic EPLB is False
2026-02-24T19:26:17.6073148Z [0;36m(ApiServer_3 pid=188)[0;0m INFO 02-24 19:26:17 [ascend_config.py:413] The number of redundant experts is 0
2026-02-24T19:26:17.6083480Z [0;36m(ApiServer_3 pid=188)[0;0m INFO 02-24 19:26:17 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-24T19:26:17.6093051Z [0;36m(ApiServer_3 pid=188)[0;0m WARNING 02-24 19:26:17 [vllm.py:1062] Batch sizes [3, 6, 9, 12, 15, 18, 21, 27, 30, 33, 36, 39, 42, 45] are removed because they are not multiple of tp_size 8 when sequence parallelism is enabled
2026-02-24T19:26:17.6101741Z [0;36m(ApiServer_3 pid=188)[0;0m INFO 02-24 19:26:17 [platform.py:318] FULL_DECODE_ONLY compilation enabled on NPU. use_inductor not supported - using only ACL Graph mode
2026-02-24T19:26:17.6111030Z [0;36m(ApiServer_3 pid=188)[0;0m WARNING 02-24 19:26:17 [platform.py:335] [91m
2026-02-24T19:26:17.6120576Z [0;36m(ApiServer_3 pid=188)[0;0m WARNING 02-24 19:26:17 [platform.py:335]             **********************************************************************************
2026-02-24T19:26:17.6129948Z [0;36m(ApiServer_3 pid=188)[0;0m WARNING 02-24 19:26:17 [platform.py:335]             * WARNING: You have enabled the *full graph* feature.
2026-02-24T19:26:17.6139745Z [0;36m(ApiServer_3 pid=188)[0;0m WARNING 02-24 19:26:17 [platform.py:335]             * This is an early experimental stage and may involve various unknown issues.
2026-02-24T19:26:17.6150124Z [0;36m(ApiServer_3 pid=188)[0;0m WARNING 02-24 19:26:17 [platform.py:335]             * A known problem is that capturing too many batch sizes can lead to OOM
2026-02-24T19:26:17.6158313Z [0;36m(ApiServer_3 pid=188)[0;0m WARNING 02-24 19:26:17 [platform.py:335]             * (Out of Memory) errors or inference hangs. If you encounter such issues,
2026-02-24T19:26:17.6168933Z [0;36m(ApiServer_3 pid=188)[0;0m WARNING 02-24 19:26:17 [platform.py:335]             * consider reducing `gpu_memory_utilization` or manually specifying a smaller
2026-02-24T19:26:17.6177566Z [0;36m(ApiServer_3 pid=188)[0;0m WARNING 02-24 19:26:17 [platform.py:335]             * batch size for graph capture.
2026-02-24T19:26:17.6187517Z [0;36m(ApiServer_3 pid=188)[0;0m WARNING 02-24 19:26:17 [platform.py:335]             * For more details, please refer to:
2026-02-24T19:26:17.6197199Z [0;36m(ApiServer_3 pid=188)[0;0m WARNING 02-24 19:26:17 [platform.py:335]             * https://docs.vllm.ai/en/stable/configuration/conserving_memory.html#reduce-cuda-graphs
2026-02-24T19:26:17.6207113Z [0;36m(ApiServer_3 pid=188)[0;0m WARNING 02-24 19:26:17 [platform.py:335]             **********************************************************************************[0m
2026-02-24T19:26:17.6216217Z [0;36m(ApiServer_3 pid=188)[0;0m WARNING 02-24 19:26:17 [platform.py:335]             
2026-02-24T19:26:17.6225521Z [0;36m(ApiServer_3 pid=188)[0;0m INFO 02-24 19:26:17 [platform.py:443] Set PYTORCH_NPU_ALLOC_CONF=expandable_segments:True
2026-02-24T19:26:17.6234784Z [0;36m(ApiServer_1 pid=186)[0;0m INFO 02-24 19:26:17 [model.py:541] Resolved architecture: DeepseekV32ForCausalLM
2026-02-24T19:26:17.6244894Z [0;36m(ApiServer_1 pid=186)[0;0m INFO 02-24 19:26:17 [model.py:1561] Using max model len 8192
2026-02-24T19:26:17.6352631Z [0;36m(ApiServer_2 pid=187)[0;0m INFO 02-24 19:26:17 [vllm.py:624] Asynchronous scheduling is enabled.
2026-02-24T19:26:17.6362432Z [0;36m(ApiServer_2 pid=187)[0;0m INFO 02-24 19:26:17 [vllm.py:634] Disabling NCCL for DP synchronization when using async scheduling.
2026-02-24T19:26:17.6374217Z [0;36m(ApiServer_2 pid=187)[0;0m WARNING 02-24 19:26:17 [platform.py:730] Speculative quantization is set but Ascend automatically uses the main model's quantization method. Resetting to None.
2026-02-24T19:26:17.6383843Z [0;36m(ApiServer_2 pid=187)[0;0m WARNING 02-24 19:26:17 [platform.py:771] Ignored parameter 'use_trtllm_ragged_deepseek_prefill'. This is a GPU-specific feature not supported on Ascend. Resetting to False.
2026-02-24T19:26:17.6392669Z [0;36m(ApiServer_2 pid=187)[0;0m INFO 02-24 19:26:17 [ascend_config.py:412] Dynamic EPLB is False
2026-02-24T19:26:17.6402407Z [0;36m(ApiServer_2 pid=187)[0;0m INFO 02-24 19:26:17 [ascend_config.py:413] The number of redundant experts is 0
2026-02-24T19:26:17.6413453Z [0;36m(ApiServer_2 pid=187)[0;0m INFO 02-24 19:26:17 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-24T19:26:17.6422436Z [0;36m(ApiServer_2 pid=187)[0;0m WARNING 02-24 19:26:17 [vllm.py:1062] Batch sizes [3, 6, 9, 12, 15, 18, 21, 27, 30, 33, 36, 39, 42, 45] are removed because they are not multiple of tp_size 8 when sequence parallelism is enabled
2026-02-24T19:26:17.6432541Z [0;36m(ApiServer_2 pid=187)[0;0m INFO 02-24 19:26:17 [platform.py:318] FULL_DECODE_ONLY compilation enabled on NPU. use_inductor not supported - using only ACL Graph mode
2026-02-24T19:26:17.6442170Z [0;36m(ApiServer_2 pid=187)[0;0m WARNING 02-24 19:26:17 [platform.py:335] [91m
2026-02-24T19:26:17.6451951Z [0;36m(ApiServer_2 pid=187)[0;0m WARNING 02-24 19:26:17 [platform.py:335]             **********************************************************************************
2026-02-24T19:26:17.6461970Z [0;36m(ApiServer_2 pid=187)[0;0m WARNING 02-24 19:26:17 [platform.py:335]             * WARNING: You have enabled the *full graph* feature.
2026-02-24T19:26:17.6471898Z [0;36m(ApiServer_2 pid=187)[0;0m WARNING 02-24 19:26:17 [platform.py:335]             * This is an early experimental stage and may involve various unknown issues.
2026-02-24T19:26:17.6481204Z [0;36m(ApiServer_2 pid=187)[0;0m WARNING 02-24 19:26:17 [platform.py:335]             * A known problem is that capturing too many batch sizes can lead to OOM
2026-02-24T19:26:17.6491472Z [0;36m(ApiServer_2 pid=187)[0;0m WARNING 02-24 19:26:17 [platform.py:335]             * (Out of Memory) errors or inference hangs. If you encounter such issues,
2026-02-24T19:26:17.6502296Z [0;36m(ApiServer_2 pid=187)[0;0m WARNING 02-24 19:26:17 [platform.py:335]             * consider reducing `gpu_memory_utilization` or manually specifying a smaller
2026-02-24T19:26:17.6511819Z [0;36m(ApiServer_2 pid=187)[0;0m WARNING 02-24 19:26:17 [platform.py:335]             * batch size for graph capture.
2026-02-24T19:26:17.6519428Z [0;36m(ApiServer_2 pid=187)[0;0m WARNING 02-24 19:26:17 [platform.py:335]             * For more details, please refer to:
2026-02-24T19:26:17.6528745Z [0;36m(ApiServer_2 pid=187)[0;0m WARNING 02-24 19:26:17 [platform.py:335]             * https://docs.vllm.ai/en/stable/configuration/conserving_memory.html#reduce-cuda-graphs
2026-02-24T19:26:17.6539050Z [0;36m(ApiServer_2 pid=187)[0;0m WARNING 02-24 19:26:17 [platform.py:335]             **********************************************************************************[0m
2026-02-24T19:26:17.6547872Z [0;36m(ApiServer_2 pid=187)[0;0m WARNING 02-24 19:26:17 [platform.py:335]             
2026-02-24T19:26:17.6557507Z [0;36m(ApiServer_2 pid=187)[0;0m INFO 02-24 19:26:17 [platform.py:443] Set PYTORCH_NPU_ALLOC_CONF=expandable_segments:True
2026-02-24T19:26:17.6567454Z [0;36m(ApiServer_0 pid=185)[0;0m INFO 02-24 19:26:17 [vllm.py:624] Asynchronous scheduling is enabled.
2026-02-24T19:26:17.6577265Z [0;36m(ApiServer_0 pid=185)[0;0m INFO 02-24 19:26:17 [vllm.py:634] Disabling NCCL for DP synchronization when using async scheduling.
2026-02-24T19:26:17.6588910Z [0;36m(ApiServer_0 pid=185)[0;0m WARNING 02-24 19:26:17 [platform.py:730] Speculative quantization is set but Ascend automatically uses the main model's quantization method. Resetting to None.
2026-02-24T19:26:17.6601517Z [0;36m(ApiServer_0 pid=185)[0;0m WARNING 02-24 19:26:17 [platform.py:771] Ignored parameter 'use_trtllm_ragged_deepseek_prefill'. This is a GPU-specific feature not supported on Ascend. Resetting to False.
2026-02-24T19:26:17.6610816Z [0;36m(ApiServer_0 pid=185)[0;0m INFO 02-24 19:26:17 [ascend_config.py:412] Dynamic EPLB is False
2026-02-24T19:26:17.6621487Z [0;36m(ApiServer_0 pid=185)[0;0m INFO 02-24 19:26:17 [ascend_config.py:413] The number of redundant experts is 0
2026-02-24T19:26:17.6631334Z [0;36m(ApiServer_0 pid=185)[0;0m INFO 02-24 19:26:17 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-24T19:26:17.6641327Z [0;36m(ApiServer_0 pid=185)[0;0m WARNING 02-24 19:26:17 [vllm.py:1062] Batch sizes [3, 6, 9, 12, 15, 18, 21, 27, 30, 33, 36, 39, 42, 45] are removed because they are not multiple of tp_size 8 when sequence parallelism is enabled
2026-02-24T19:26:17.6653094Z [0;36m(ApiServer_0 pid=185)[0;0m INFO 02-24 19:26:17 [platform.py:318] FULL_DECODE_ONLY compilation enabled on NPU. use_inductor not supported - using only ACL Graph mode
2026-02-24T19:26:17.6671838Z [0;36m(ApiServer_0 pid=185)[0;0m WARNING 02-24 19:26:17 [platform.py:335] [91m
2026-02-24T19:26:17.6682953Z [0;36m(ApiServer_0 pid=185)[0;0m WARNING 02-24 19:26:17 [platform.py:335]             **********************************************************************************
2026-02-24T19:26:17.6693612Z [0;36m(ApiServer_0 pid=185)[0;0m WARNING 02-24 19:26:17 [platform.py:335]             * WARNING: You have enabled the *full graph* feature.
2026-02-24T19:26:17.6704687Z [0;36m(ApiServer_0 pid=185)[0;0m WARNING 02-24 19:26:17 [platform.py:335]             * This is an early experimental stage and may involve various unknown issues.
2026-02-24T19:26:17.6714590Z [0;36m(ApiServer_0 pid=185)[0;0m WARNING 02-24 19:26:17 [platform.py:335]             * A known problem is that capturing too many batch sizes can lead to OOM
2026-02-24T19:26:17.6725054Z [0;36m(ApiServer_0 pid=185)[0;0m WARNING 02-24 19:26:17 [platform.py:335]             * (Out of Memory) errors or inference hangs. If you encounter such issues,
2026-02-24T19:26:17.6734457Z [0;36m(ApiServer_0 pid=185)[0;0m WARNING 02-24 19:26:17 [platform.py:335]             * consider reducing `gpu_memory_utilization` or manually specifying a smaller
2026-02-24T19:26:17.6743466Z [0;36m(ApiServer_0 pid=185)[0;0m WARNING 02-24 19:26:17 [platform.py:335]             * batch size for graph capture.
2026-02-24T19:26:17.6752911Z [0;36m(ApiServer_0 pid=185)[0;0m WARNING 02-24 19:26:17 [platform.py:335]             * For more details, please refer to:
2026-02-24T19:26:17.6763990Z [0;36m(ApiServer_0 pid=185)[0;0m WARNING 02-24 19:26:17 [platform.py:335]             * https://docs.vllm.ai/en/stable/configuration/conserving_memory.html#reduce-cuda-graphs
2026-02-24T19:26:17.6774982Z [0;36m(ApiServer_0 pid=185)[0;0m WARNING 02-24 19:26:17 [platform.py:335]             **********************************************************************************[0m
2026-02-24T19:26:17.6784621Z [0;36m(ApiServer_0 pid=185)[0;0m WARNING 02-24 19:26:17 [platform.py:335]             
2026-02-24T19:26:17.6794571Z [0;36m(ApiServer_0 pid=185)[0;0m INFO 02-24 19:26:17 [platform.py:443] Set PYTORCH_NPU_ALLOC_CONF=expandable_segments:True
2026-02-24T19:26:17.7376547Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-24T19:26:17.7384626Z   warnings.warn(
2026-02-24T19:26:17.7401249Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-24T19:26:17.7410142Z   warnings.warn(
2026-02-24T19:26:17.7457455Z [0;36m(ApiServer_1 pid=186)[0;0m WARNING 02-24 19:26:17 [speculative.py:270] method `deepseek_mtp` is deprecated and replaced with mtp.
2026-02-24T19:26:17.7481387Z [0;36m(ApiServer_1 pid=186)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-24T19:26:17.7490700Z [0;36m(ApiServer_1 pid=186)[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
2026-02-24T19:26:17.7500647Z [0;36m(ApiServer_1 pid=186)[0;0m You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
2026-02-24T19:26:17.7536729Z [0;36m(ApiServer_1 pid=186)[0;0m INFO 02-24 19:26:17 [model.py:541] Resolved architecture: DeepSeekMTPModel
2026-02-24T19:26:17.7559335Z [0;36m(ApiServer_1 pid=186)[0;0m INFO 02-24 19:26:17 [model.py:1561] Using max model len 163840
2026-02-24T19:26:17.7569506Z [0;36m(ApiServer_1 pid=186)[0;0m WARNING 02-24 19:26:17 [speculative.py:388] Enabling num_speculative_tokens > 1 will runmultiple times of forward on same MTP layer,which may result in lower acceptance rate
2026-02-24T19:26:17.7578470Z [0;36m(ApiServer_1 pid=186)[0;0m INFO 02-24 19:26:17 [scheduler.py:226] Chunked prefill is enabled with max_num_batched_tokens=4096.
2026-02-24T19:26:17.8759576Z [0;36m(ApiServer_1 pid=186)[0;0m INFO 02-24 19:26:17 [vllm.py:624] Asynchronous scheduling is enabled.
2026-02-24T19:26:17.8780482Z [0;36m(ApiServer_1 pid=186)[0;0m INFO 02-24 19:26:17 [vllm.py:634] Disabling NCCL for DP synchronization when using async scheduling.
2026-02-24T19:26:17.8792227Z [0;36m(ApiServer_1 pid=186)[0;0m WARNING 02-24 19:26:17 [platform.py:730] Speculative quantization is set but Ascend automatically uses the main model's quantization method. Resetting to None.
2026-02-24T19:26:17.8802910Z [0;36m(ApiServer_1 pid=186)[0;0m WARNING 02-24 19:26:17 [platform.py:771] Ignored parameter 'use_trtllm_ragged_deepseek_prefill'. This is a GPU-specific feature not supported on Ascend. Resetting to False.
2026-02-24T19:26:17.8811099Z [0;36m(ApiServer_1 pid=186)[0;0m INFO 02-24 19:26:17 [ascend_config.py:412] Dynamic EPLB is False
2026-02-24T19:26:17.8820612Z [0;36m(ApiServer_1 pid=186)[0;0m INFO 02-24 19:26:17 [ascend_config.py:413] The number of redundant experts is 0
2026-02-24T19:26:17.8835203Z [0;36m(ApiServer_1 pid=186)[0;0m INFO 02-24 19:26:17 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-24T19:26:17.8845416Z [0;36m(ApiServer_1 pid=186)[0;0m WARNING 02-24 19:26:17 [vllm.py:1062] Batch sizes [3, 6, 9, 12, 15, 18, 21, 27, 30, 33, 36, 39, 42, 45] are removed because they are not multiple of tp_size 8 when sequence parallelism is enabled
2026-02-24T19:26:17.8855257Z [0;36m(ApiServer_1 pid=186)[0;0m INFO 02-24 19:26:17 [platform.py:318] FULL_DECODE_ONLY compilation enabled on NPU. use_inductor not supported - using only ACL Graph mode
2026-02-24T19:26:17.8863738Z [0;36m(ApiServer_1 pid=186)[0;0m WARNING 02-24 19:26:17 [platform.py:335] [91m
2026-02-24T19:26:17.8873339Z [0;36m(ApiServer_1 pid=186)[0;0m WARNING 02-24 19:26:17 [platform.py:335]             **********************************************************************************
2026-02-24T19:26:17.8882776Z [0;36m(ApiServer_1 pid=186)[0;0m WARNING 02-24 19:26:17 [platform.py:335]             * WARNING: You have enabled the *full graph* feature.
2026-02-24T19:26:17.8892545Z [0;36m(ApiServer_1 pid=186)[0;0m WARNING 02-24 19:26:17 [platform.py:335]             * This is an early experimental stage and may involve various unknown issues.
2026-02-24T19:26:17.8901668Z [0;36m(ApiServer_1 pid=186)[0;0m WARNING 02-24 19:26:17 [platform.py:335]             * A known problem is that capturing too many batch sizes can lead to OOM
2026-02-24T19:26:17.8911517Z [0;36m(ApiServer_1 pid=186)[0;0m WARNING 02-24 19:26:17 [platform.py:335]             * (Out of Memory) errors or inference hangs. If you encounter such issues,
2026-02-24T19:26:17.8920961Z [0;36m(ApiServer_1 pid=186)[0;0m WARNING 02-24 19:26:17 [platform.py:335]             * consider reducing `gpu_memory_utilization` or manually specifying a smaller
2026-02-24T19:26:17.8930100Z [0;36m(ApiServer_1 pid=186)[0;0m WARNING 02-24 19:26:17 [platform.py:335]             * batch size for graph capture.
2026-02-24T19:26:17.8939484Z [0;36m(ApiServer_1 pid=186)[0;0m WARNING 02-24 19:26:17 [platform.py:335]             * For more details, please refer to:
2026-02-24T19:26:17.8949312Z [0;36m(ApiServer_1 pid=186)[0;0m WARNING 02-24 19:26:17 [platform.py:335]             * https://docs.vllm.ai/en/stable/configuration/conserving_memory.html#reduce-cuda-graphs
2026-02-24T19:26:17.8958876Z [0;36m(ApiServer_1 pid=186)[0;0m WARNING 02-24 19:26:17 [platform.py:335]             **********************************************************************************[0m
2026-02-24T19:26:17.8968353Z [0;36m(ApiServer_1 pid=186)[0;0m WARNING 02-24 19:26:17 [platform.py:335]             
2026-02-24T19:26:17.8978062Z [0;36m(ApiServer_1 pid=186)[0;0m INFO 02-24 19:26:17 [platform.py:443] Set PYTORCH_NPU_ALLOC_CONF=expandable_segments:True
2026-02-24T19:26:20.6386225Z INFO 02-24 19:26:20 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-24T19:26:20.6395874Z INFO 02-24 19:26:20 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-24T19:26:20.6407821Z INFO 02-24 19:26:20 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-24T19:26:20.6457662Z INFO 02-24 19:26:20 [__init__.py:217] Platform plugin ascend is activated
2026-02-24T19:26:20.6938298Z INFO 02-24 19:26:20 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-24T19:26:20.6948552Z INFO 02-24 19:26:20 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-24T19:26:20.6960794Z INFO 02-24 19:26:20 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-24T19:26:20.7018642Z INFO 02-24 19:26:20 [__init__.py:217] Platform plugin ascend is activated
2026-02-24T19:26:21.1830521Z INFO 02-24 19:26:21 [ascend_config.py:412] Dynamic EPLB is False
2026-02-24T19:26:21.1839358Z INFO 02-24 19:26:21 [ascend_config.py:413] The number of redundant experts is 0
2026-02-24T19:26:21.1851584Z INFO 02-24 19:26:21 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-24T19:26:21.1861034Z INFO 02-24 19:26:21 [ascend_config.py:412] Dynamic EPLB is False
2026-02-24T19:26:21.1872259Z INFO 02-24 19:26:21 [ascend_config.py:413] The number of redundant experts is 0
2026-02-24T19:26:21.1883143Z INFO 02-24 19:26:21 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-24T19:26:21.2849337Z INFO 02-24 19:26:21 [parallel_state.py:1212] world_size=32 rank=0 local_rank=0 distributed_init_method=tcp://10.0.0.169:43337 backend=hccl
2026-02-24T19:26:21.2870976Z INFO 02-24 19:26:21 [parallel_state.py:1212] world_size=32 rank=8 local_rank=0 distributed_init_method=tcp://10.0.0.169:43337 backend=hccl
2026-02-24T19:26:25.7546305Z 2026-02-24 19:26:25,752 - 252 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-24T19:26:25.7602937Z INFO 02-24 19:26:25 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-24T19:26:25.8403226Z 2026-02-24 19:26:25,838 - 255 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-24T19:26:25.8465617Z INFO 02-24 19:26:25 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-24T19:26:27.1726161Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-24T19:26:27.1733431Z   warnings.warn(
2026-02-24T19:26:27.2229302Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-24T19:26:27.2230104Z   warnings.warn(
2026-02-24T19:26:29.2882100Z INFO 02-24 19:26:29 [ascend_config.py:412] Dynamic EPLB is False
2026-02-24T19:26:29.2888523Z INFO 02-24 19:26:29 [ascend_config.py:413] The number of redundant experts is 0
2026-02-24T19:26:29.2900002Z INFO 02-24 19:26:29 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-24T19:26:29.3310028Z INFO 02-24 19:26:29 [ascend_config.py:412] Dynamic EPLB is False
2026-02-24T19:26:29.3319281Z INFO 02-24 19:26:29 [ascend_config.py:413] The number of redundant experts is 0
2026-02-24T19:26:29.3329388Z INFO 02-24 19:26:29 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-24T19:26:29.7140079Z INFO 02-24 19:26:29 [parallel_state.py:1212] world_size=32 rank=1 local_rank=1 distributed_init_method=tcp://10.0.0.169:43337 backend=hccl
2026-02-24T19:26:29.7545729Z INFO 02-24 19:26:29 [parallel_state.py:1212] world_size=32 rank=9 local_rank=1 distributed_init_method=tcp://10.0.0.169:43337 backend=hccl
2026-02-24T19:26:30.2575968Z INFO 02-24 19:26:30 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-24T19:26:30.2584289Z INFO 02-24 19:26:30 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-24T19:26:30.2593833Z INFO 02-24 19:26:30 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-24T19:26:30.2647533Z INFO 02-24 19:26:30 [__init__.py:217] Platform plugin ascend is activated
2026-02-24T19:26:30.5425141Z INFO 02-24 19:26:30 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-24T19:26:30.5432588Z INFO 02-24 19:26:30 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-24T19:26:30.5442277Z INFO 02-24 19:26:30 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-24T19:26:30.5508186Z INFO 02-24 19:26:30 [__init__.py:217] Platform plugin ascend is activated
2026-02-24T19:26:35.2468864Z 2026-02-24 19:26:35,243 - 371 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-24T19:26:35.2517553Z INFO 02-24 19:26:35 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-24T19:26:35.5639207Z 2026-02-24 19:26:35,559 - 370 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-24T19:26:35.5714635Z INFO 02-24 19:26:35 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-24T19:26:36.5385160Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-24T19:26:36.5391949Z   warnings.warn(
2026-02-24T19:26:36.8814123Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-24T19:26:36.8820587Z   warnings.warn(
2026-02-24T19:26:38.5894500Z INFO 02-24 19:26:38 [ascend_config.py:412] Dynamic EPLB is False
2026-02-24T19:26:38.5902895Z INFO 02-24 19:26:38 [ascend_config.py:413] The number of redundant experts is 0
2026-02-24T19:26:38.5914411Z INFO 02-24 19:26:38 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-24T19:26:39.0185635Z INFO 02-24 19:26:39 [parallel_state.py:1212] world_size=32 rank=10 local_rank=2 distributed_init_method=tcp://10.0.0.169:43337 backend=hccl
2026-02-24T19:26:39.0324792Z INFO 02-24 19:26:39 [ascend_config.py:412] Dynamic EPLB is False
2026-02-24T19:26:39.0334639Z INFO 02-24 19:26:39 [ascend_config.py:413] The number of redundant experts is 0
2026-02-24T19:26:39.0345362Z INFO 02-24 19:26:39 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-24T19:26:39.4633488Z INFO 02-24 19:26:39 [parallel_state.py:1212] world_size=32 rank=2 local_rank=2 distributed_init_method=tcp://10.0.0.169:43337 backend=hccl
2026-02-24T19:26:39.8181101Z INFO 02-24 19:26:39 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-24T19:26:39.8189721Z INFO 02-24 19:26:39 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-24T19:26:39.8199573Z INFO 02-24 19:26:39 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-24T19:26:39.8273144Z INFO 02-24 19:26:39 [__init__.py:217] Platform plugin ascend is activated
2026-02-24T19:26:40.3204081Z INFO 02-24 19:26:40 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-24T19:26:40.3213073Z INFO 02-24 19:26:40 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-24T19:26:40.3222891Z INFO 02-24 19:26:40 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-24T19:26:40.3280818Z INFO 02-24 19:26:40 [__init__.py:217] Platform plugin ascend is activated
2026-02-24T19:26:44.8077392Z 2026-02-24 19:26:44,805 - 474 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-24T19:26:44.8132302Z INFO 02-24 19:26:44 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-24T19:26:45.6918771Z 2026-02-24 19:26:45,688 - 477 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-24T19:26:45.6968047Z INFO 02-24 19:26:45 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-24T19:26:46.1056725Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-24T19:26:46.1063715Z   warnings.warn(
2026-02-24T19:26:47.0736641Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-24T19:26:47.0744119Z   warnings.warn(
2026-02-24T19:26:48.1352864Z INFO 02-24 19:26:48 [ascend_config.py:412] Dynamic EPLB is False
2026-02-24T19:26:48.1361203Z INFO 02-24 19:26:48 [ascend_config.py:413] The number of redundant experts is 0
2026-02-24T19:26:48.1372125Z INFO 02-24 19:26:48 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-24T19:26:48.5727908Z INFO 02-24 19:26:48 [parallel_state.py:1212] world_size=32 rank=11 local_rank=3 distributed_init_method=tcp://10.0.0.169:43337 backend=hccl
2026-02-24T19:26:49.1981796Z INFO 02-24 19:26:49 [ascend_config.py:412] Dynamic EPLB is False
2026-02-24T19:26:49.1989914Z INFO 02-24 19:26:49 [ascend_config.py:413] The number of redundant experts is 0
2026-02-24T19:26:49.2000506Z INFO 02-24 19:26:49 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-24T19:26:49.4573103Z INFO 02-24 19:26:49 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-24T19:26:49.4580778Z INFO 02-24 19:26:49 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-24T19:26:49.4590082Z INFO 02-24 19:26:49 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-24T19:26:49.4651797Z INFO 02-24 19:26:49 [__init__.py:217] Platform plugin ascend is activated
2026-02-24T19:26:49.6271636Z INFO 02-24 19:26:49 [parallel_state.py:1212] world_size=32 rank=3 local_rank=3 distributed_init_method=tcp://10.0.0.169:43337 backend=hccl
2026-02-24T19:26:50.1815316Z INFO 02-24 19:26:50 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-24T19:26:50.1823821Z INFO 02-24 19:26:50 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-24T19:26:50.1833583Z INFO 02-24 19:26:50 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-24T19:26:50.1888032Z INFO 02-24 19:26:50 [__init__.py:217] Platform plugin ascend is activated
2026-02-24T19:26:54.6883435Z 2026-02-24 19:26:54,685 - 578 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-24T19:26:54.6943852Z INFO 02-24 19:26:54 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-24T19:26:55.1927021Z 2026-02-24 19:26:55,190 - 581 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-24T19:26:55.1987116Z INFO 02-24 19:26:55 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-24T19:26:55.9710055Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-24T19:26:55.9715862Z   warnings.warn(
2026-02-24T19:26:56.5263255Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-24T19:26:56.5270497Z   warnings.warn(
2026-02-24T19:26:58.0619872Z INFO 02-24 19:26:58 [ascend_config.py:412] Dynamic EPLB is False
2026-02-24T19:26:58.0628400Z INFO 02-24 19:26:58 [ascend_config.py:413] The number of redundant experts is 0
2026-02-24T19:26:58.0638534Z INFO 02-24 19:26:58 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-24T19:26:58.5091705Z INFO 02-24 19:26:58 [parallel_state.py:1212] world_size=32 rank=12 local_rank=4 distributed_init_method=tcp://10.0.0.169:43337 backend=hccl
2026-02-24T19:26:58.6338940Z INFO 02-24 19:26:58 [ascend_config.py:412] Dynamic EPLB is False
2026-02-24T19:26:58.6347876Z INFO 02-24 19:26:58 [ascend_config.py:413] The number of redundant experts is 0
2026-02-24T19:26:58.6357542Z INFO 02-24 19:26:58 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-24T19:26:59.0761676Z INFO 02-24 19:26:59 [parallel_state.py:1212] world_size=32 rank=4 local_rank=4 distributed_init_method=tcp://10.0.0.169:43337 backend=hccl
2026-02-24T19:26:59.1055474Z INFO 02-24 19:26:59 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-24T19:26:59.1064239Z INFO 02-24 19:26:59 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-24T19:26:59.1073281Z INFO 02-24 19:26:59 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-24T19:26:59.1131080Z INFO 02-24 19:26:59 [__init__.py:217] Platform plugin ascend is activated
2026-02-24T19:26:59.4093599Z INFO 02-24 19:26:59 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-24T19:26:59.4101029Z INFO 02-24 19:26:59 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-24T19:26:59.4110527Z INFO 02-24 19:26:59 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-24T19:26:59.4162425Z INFO 02-24 19:26:59 [__init__.py:217] Platform plugin ascend is activated
2026-02-24T19:27:04.3357610Z 2026-02-24 19:27:04,333 - 685 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-24T19:27:04.3413990Z INFO 02-24 19:27:04 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-24T19:27:04.3877458Z 2026-02-24 19:27:04,385 - 682 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-24T19:27:04.3917917Z INFO 02-24 19:27:04 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-24T19:27:05.8674193Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-24T19:27:05.8682273Z   warnings.warn(
2026-02-24T19:27:05.8766869Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-24T19:27:05.8776362Z   warnings.warn(
2026-02-24T19:27:07.9100165Z INFO 02-24 19:27:07 [ascend_config.py:412] Dynamic EPLB is False
2026-02-24T19:27:07.9110576Z INFO 02-24 19:27:07 [ascend_config.py:413] The number of redundant experts is 0
2026-02-24T19:27:07.9124066Z INFO 02-24 19:27:07 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-24T19:27:08.1027556Z INFO 02-24 19:27:08 [ascend_config.py:412] Dynamic EPLB is False
2026-02-24T19:27:08.1036615Z INFO 02-24 19:27:08 [ascend_config.py:413] The number of redundant experts is 0
2026-02-24T19:27:08.1048179Z INFO 02-24 19:27:08 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-24T19:27:08.3369278Z INFO 02-24 19:27:08 [parallel_state.py:1212] world_size=32 rank=5 local_rank=5 distributed_init_method=tcp://10.0.0.169:43337 backend=hccl
2026-02-24T19:27:08.5481869Z INFO 02-24 19:27:08 [parallel_state.py:1212] world_size=32 rank=13 local_rank=5 distributed_init_method=tcp://10.0.0.169:43337 backend=hccl
2026-02-24T19:27:09.0921389Z INFO 02-24 19:27:09 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-24T19:27:09.0928598Z INFO 02-24 19:27:09 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-24T19:27:09.0938180Z INFO 02-24 19:27:09 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-24T19:27:09.0993333Z INFO 02-24 19:27:09 [__init__.py:217] Platform plugin ascend is activated
2026-02-24T19:27:09.3068774Z INFO 02-24 19:27:09 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-24T19:27:09.3077651Z INFO 02-24 19:27:09 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-24T19:27:09.3093070Z INFO 02-24 19:27:09 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-24T19:27:09.3147945Z INFO 02-24 19:27:09 [__init__.py:217] Platform plugin ascend is activated
2026-02-24T19:27:14.1144735Z 2026-02-24 19:27:14,110 - 786 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-24T19:27:14.1185689Z INFO 02-24 19:27:14 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-24T19:27:14.3325329Z 2026-02-24 19:27:14,330 - 787 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-24T19:27:14.3360578Z INFO 02-24 19:27:14 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-24T19:27:15.4385899Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-24T19:27:15.4393124Z   warnings.warn(
2026-02-24T19:27:15.8339861Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-24T19:27:15.8347286Z   warnings.warn(
2026-02-24T19:27:17.5547707Z INFO 02-24 19:27:17 [ascend_config.py:412] Dynamic EPLB is False
2026-02-24T19:27:17.5555736Z INFO 02-24 19:27:17 [ascend_config.py:413] The number of redundant experts is 0
2026-02-24T19:27:17.5567299Z INFO 02-24 19:27:17 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-24T19:27:17.9914344Z INFO 02-24 19:27:17 [parallel_state.py:1212] world_size=32 rank=6 local_rank=6 distributed_init_method=tcp://10.0.0.169:43337 backend=hccl
2026-02-24T19:27:18.3620962Z INFO 02-24 19:27:18 [ascend_config.py:412] Dynamic EPLB is False
2026-02-24T19:27:18.3628393Z INFO 02-24 19:27:18 [ascend_config.py:413] The number of redundant experts is 0
2026-02-24T19:27:18.3639116Z INFO 02-24 19:27:18 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-24T19:27:18.8008265Z INFO 02-24 19:27:18 [parallel_state.py:1212] world_size=32 rank=14 local_rank=6 distributed_init_method=tcp://10.0.0.169:43337 backend=hccl
2026-02-24T19:27:18.8059260Z INFO 02-24 19:27:18 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-24T19:27:18.8074776Z INFO 02-24 19:27:18 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-24T19:27:18.8085199Z INFO 02-24 19:27:18 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-24T19:27:18.8135433Z INFO 02-24 19:27:18 [__init__.py:217] Platform plugin ascend is activated
2026-02-24T19:27:18.9707399Z INFO 02-24 19:27:18 [__init__.py:43] Available plugins for group vllm.platform_plugins:
2026-02-24T19:27:18.9715821Z INFO 02-24 19:27:18 [__init__.py:45] - ascend -> vllm_ascend:register
2026-02-24T19:27:18.9726464Z INFO 02-24 19:27:18 [__init__.py:48] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
2026-02-24T19:27:18.9800494Z INFO 02-24 19:27:18 [__init__.py:217] Platform plugin ascend is activated
2026-02-24T19:27:23.8275717Z 2026-02-24 19:27:23,823 - 890 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-24T19:27:23.8310463Z INFO 02-24 19:27:23 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-24T19:27:24.0332224Z 2026-02-24 19:27:24,031 - 893 - vllmProfiler - INFO - VLLM_USE_V1 not set, auto-detected via vLLM 0.15.0+empty: default 1
2026-02-24T19:27:24.0388096Z INFO 02-24 19:27:24 [__init__.py:108] Registered model loader `<class 'vllm_ascend.model_loader.netloader.netloader.ModelNetLoaderElastic'>` with load format `netloader`
2026-02-24T19:27:25.1591618Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-24T19:27:25.1598797Z   warnings.warn(
2026-02-24T19:27:25.4289165Z /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-24T19:27:25.4295533Z   warnings.warn(
2026-02-24T19:27:27.2219777Z INFO 02-24 19:27:27 [ascend_config.py:412] Dynamic EPLB is False
2026-02-24T19:27:27.2232402Z INFO 02-24 19:27:27 [ascend_config.py:413] The number of redundant experts is 0
2026-02-24T19:27:27.2244394Z INFO 02-24 19:27:27 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-24T19:27:27.5134161Z INFO 02-24 19:27:27 [ascend_config.py:412] Dynamic EPLB is False
2026-02-24T19:27:27.5142135Z INFO 02-24 19:27:27 [ascend_config.py:413] The number of redundant experts is 0
2026-02-24T19:27:27.5153009Z INFO 02-24 19:27:27 [ascend_config.py:54] Linear layer sharding enabled with config: ['q_b_proj', 'o_proj']. Note: This feature works optimally with FLASHCOMM2 and DSA-CP enabled; using it without these features may result in significant performance degradation.
2026-02-24T19:27:27.6404251Z INFO 02-24 19:27:27 [parallel_state.py:1212] world_size=32 rank=7 local_rank=7 distributed_init_method=tcp://10.0.0.169:43337 backend=hccl
2026-02-24T19:27:27.9569369Z INFO 02-24 19:27:27 [parallel_state.py:1212] world_size=32 rank=15 local_rank=7 distributed_init_method=tcp://10.0.0.169:43337 backend=hccl
2026-02-24T19:27:27.9991756Z [Gloo] Rank 0 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-24T19:27:28.0023354Z [Gloo] Rank 2 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-24T19:27:28.0033672Z [Gloo] Rank 3 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-24T19:27:28.0043781Z [Gloo] Rank 4 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-24T19:27:28.0053921Z [Gloo] Rank 6 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-24T19:27:28.0067319Z [Gloo] Rank 5 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-24T19:27:28.0075131Z [Gloo] Rank 7 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-24T19:27:28.0483916Z [Gloo] Rank 9 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-24T19:27:28.0605627Z [Gloo] Rank 1 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-24T19:27:28.0631810Z [Gloo] Rank 8 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-24T19:27:28.0717971Z [Gloo] Rank 10 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-24T19:27:28.0760850Z [Gloo] Rank 11 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-24T19:27:28.0782173Z [Gloo] Rank 12 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-24T19:27:28.0792348Z [Gloo] Rank 13 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-24T19:27:28.0802307Z [Gloo] Rank 15 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-24T19:27:28.0812397Z [Gloo] Rank 14 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-24T19:27:28.1139190Z [Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-24T19:27:28.1148506Z [Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-24T19:27:28.1161587Z [Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-24T19:27:28.1170840Z [Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-24T19:27:28.1180151Z [Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-24T19:27:28.1189245Z [Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-24T19:27:28.1199362Z [Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-24T19:27:28.1208568Z [Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-24T19:27:28.1218136Z [Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-24T19:27:28.1227745Z [Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-24T19:27:28.1237585Z [Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-24T19:27:28.1247033Z [Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-24T19:27:28.1256528Z [Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-24T19:27:28.1265620Z [Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-24T19:27:28.1274892Z [Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-24T19:27:28.1285569Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-24T19:27:28.1294484Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-24T19:27:28.1304266Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-24T19:27:28.1313975Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-24T19:27:28.1323559Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-24T19:27:28.1332836Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-24T19:27:28.1342164Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-24T19:27:28.1350753Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-24T19:27:28.1360882Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-24T19:27:28.1370730Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-24T19:27:28.1380207Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-24T19:27:28.1390029Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-24T19:27:28.1399975Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-24T19:27:28.1409160Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-24T19:27:28.1418411Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-24T19:27:28.1427753Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-24T19:27:28.1436721Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-24T19:27:28.1446316Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-24T19:27:28.1455353Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-24T19:27:28.1465067Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-24T19:27:28.1474556Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-24T19:27:28.1485104Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-24T19:27:28.1494178Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-24T19:27:28.1504431Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-24T19:27:28.1799131Z [Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
2026-02-24T19:27:28.1897505Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-24T19:27:28.1916518Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-24T19:27:28.1925414Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-24T19:27:28.1934997Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-24T19:27:28.1943759Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-24T19:27:28.1953249Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-24T19:27:28.1963155Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-24T19:27:28.1972866Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-24T19:27:28.1982278Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-24T19:27:28.1992153Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-24T19:27:28.2001280Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-24T19:27:28.2010911Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-24T19:27:28.2020742Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-24T19:27:28.2029691Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-24T19:27:28.2039569Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-24T19:27:28.2049453Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-24T19:27:28.2058489Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-24T19:27:28.2067873Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-24T19:27:28.2077625Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-24T19:27:28.2087236Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-24T19:27:28.2096162Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-24T19:27:28.2105631Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-24T19:27:28.2117182Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-24T19:27:28.2123859Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-02-24T19:27:28.2133616Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-24T19:27:28.2142791Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-24T19:27:28.2152140Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-24T19:27:28.2161741Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-24T19:27:28.2171406Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-24T19:27:28.2181094Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-24T19:27:28.2189940Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-24T19:27:28.2199916Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-24T19:27:28.2209333Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-24T19:27:28.2218776Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-24T19:27:28.2227749Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-24T19:27:28.2237185Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-24T19:27:28.2247328Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-24T19:27:28.2256013Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-24T19:27:28.2265232Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-24T19:27:28.2274120Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-24T19:27:28.2388168Z [Gloo] Rank 0 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-24T19:27:28.2408385Z INFO 02-24 19:27:28 [parallel_state.py:1423] rank 0 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
2026-02-24T19:27:28.3118805Z [Gloo] Rank 1 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-24T19:27:28.3139114Z INFO 02-24 19:27:28 [parallel_state.py:1423] rank 1 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 1, EP rank 1
2026-02-24T19:27:28.4322170Z [Gloo] Rank 2 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-24T19:27:28.4340394Z [Gloo] Rank 3 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-24T19:27:28.4350858Z [Gloo] Rank 6 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-24T19:27:28.4360643Z [Gloo] Rank 7 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-24T19:27:28.4370182Z INFO 02-24 19:27:28 [parallel_state.py:1423] rank 2 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 2, EP rank 2
2026-02-24T19:27:28.4382393Z [Gloo] Rank 5 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-24T19:27:28.4387669Z [Gloo] Rank 4 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-24T19:27:28.4397680Z [Gloo] Rank 11 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-24T19:27:28.4408082Z INFO 02-24 19:27:28 [parallel_state.py:1423] rank 3 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 3, EP rank 3
2026-02-24T19:27:28.4416845Z [Gloo] Rank 12 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-24T19:27:28.4426388Z INFO 02-24 19:27:28 [parallel_state.py:1423] rank 6 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 6, EP rank 6
2026-02-24T19:27:28.4436387Z INFO 02-24 19:27:28 [parallel_state.py:1423] rank 7 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 7, EP rank 7
2026-02-24T19:27:28.4445446Z [Gloo] Rank 8 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-24T19:27:28.4454725Z [Gloo] Rank 15 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-24T19:27:28.4463782Z [Gloo] Rank 13 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-24T19:27:28.4473799Z [Gloo] Rank 9 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-24T19:27:28.4483627Z [Gloo] Rank 10 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-24T19:27:28.4493255Z [Gloo] Rank 14 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-24T19:27:28.4504250Z INFO 02-24 19:27:28 [parallel_state.py:1423] rank 4 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 4, EP rank 4
2026-02-24T19:27:28.4512466Z INFO 02-24 19:27:28 [parallel_state.py:1423] rank 8 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 0, EP rank 8
2026-02-24T19:27:28.4521717Z INFO 02-24 19:27:28 [parallel_state.py:1423] rank 13 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 5, EP rank 13
2026-02-24T19:27:28.4531239Z INFO 02-24 19:27:28 [parallel_state.py:1423] rank 15 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 7, EP rank 15
2026-02-24T19:27:28.4540517Z INFO 02-24 19:27:28 [parallel_state.py:1423] rank 12 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 4, EP rank 12
2026-02-24T19:27:28.4549915Z INFO 02-24 19:27:28 [parallel_state.py:1423] rank 14 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 6, EP rank 14
2026-02-24T19:27:28.4559753Z INFO 02-24 19:27:28 [parallel_state.py:1423] rank 10 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 2, EP rank 10
2026-02-24T19:27:28.4569065Z INFO 02-24 19:27:28 [parallel_state.py:1423] rank 9 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 1, EP rank 9
2026-02-24T19:27:28.4578560Z INFO 02-24 19:27:28 [parallel_state.py:1423] rank 11 in world size 32 is assigned as DP rank 1, PP rank 0, PCP rank 0, TP rank 3, EP rank 11
2026-02-24T19:27:28.4587971Z INFO 02-24 19:27:28 [parallel_state.py:1423] rank 5 in world size 32 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 5, EP rank 5
2026-02-24T19:27:28.4700971Z [Gloo] Rank 0 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-24T19:27:28.4723148Z [Gloo] Rank 1 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-24T19:27:28.4737014Z [Gloo] Rank 2 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-24T19:27:28.4741961Z [Gloo] Rank 4 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-24T19:27:28.4750500Z [Gloo] Rank 3 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-24T19:27:28.4760318Z [Gloo] Rank 6 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-24T19:27:28.4770210Z [Gloo] Rank 5 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-24T19:27:28.4779080Z [Gloo] Rank 7 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-24T19:27:28.4788263Z [Gloo] Rank 8 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-24T19:27:28.4797812Z [Gloo] Rank 10 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-24T19:27:28.4807311Z [Gloo] Rank 9 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-24T19:27:28.4816092Z [Gloo] Rank 11 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-24T19:27:28.4825410Z [Gloo] Rank 12 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-24T19:27:28.4834688Z [Gloo] Rank 13 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-24T19:27:28.4844580Z [Gloo] Rank 15 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-24T19:27:28.4854284Z [Gloo] Rank 14 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
2026-02-24T19:27:28.4863012Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-24T19:27:28.4872298Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-24T19:27:28.4881594Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-24T19:27:28.4890846Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-24T19:27:28.4899738Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-24T19:27:28.4909300Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-24T19:27:28.4918658Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-24T19:27:28.4931661Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-24T19:27:28.4937818Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-24T19:27:28.4947202Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-24T19:27:28.4956440Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-24T19:27:28.4966492Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-24T19:27:28.4975682Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-24T19:27:28.4986175Z [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-24T19:27:28.4994324Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-24T19:27:28.5004379Z [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
2026-02-24T19:27:28.6090705Z WARNING 02-24 19:27:28 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-24T19:27:28.6155068Z WARNING 02-24 19:27:28 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-24T19:27:28.6179193Z WARNING 02-24 19:27:28 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-24T19:27:28.6374377Z WARNING 02-24 19:27:28 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-24T19:27:28.6569474Z WARNING 02-24 19:27:28 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-24T19:27:28.6613570Z WARNING 02-24 19:27:28 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-24T19:27:28.6634688Z WARNING 02-24 19:27:28 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-24T19:27:28.6644635Z WARNING 02-24 19:27:28 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-24T19:27:28.6654951Z WARNING 02-24 19:27:28 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-24T19:27:28.6663784Z WARNING 02-24 19:27:28 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-24T19:27:28.6673424Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m INFO 02-24 19:27:28 [model_runner_v1.py:2318] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-24T19:27:28.6682731Z WARNING 02-24 19:27:28 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-24T19:27:28.6702155Z WARNING 02-24 19:27:28 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-24T19:27:28.6710483Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m INFO 02-24 19:27:28 [model_runner_v1.py:2318] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-24T19:27:28.6720267Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m INFO 02-24 19:27:28 [model_runner_v1.py:2318] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-24T19:27:28.6729963Z WARNING 02-24 19:27:28 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-24T19:27:28.6738723Z WARNING 02-24 19:27:28 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-24T19:27:28.6748926Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m INFO 02-24 19:27:28 [model_runner_v1.py:2318] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-24T19:27:28.6770791Z WARNING 02-24 19:27:28 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-24T19:27:28.6812103Z WARNING 02-24 19:27:28 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-24T19:27:28.6844613Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m INFO 02-24 19:27:28 [model_runner_v1.py:2318] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-24T19:27:28.6870849Z WARNING 02-24 19:27:28 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-24T19:27:28.6892874Z WARNING 02-24 19:27:28 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-24T19:27:28.6940372Z WARNING 02-24 19:27:28 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-24T19:27:28.6949599Z WARNING 02-24 19:27:28 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-24T19:27:28.6959536Z WARNING 02-24 19:27:28 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-24T19:27:28.7004127Z WARNING 02-24 19:27:28 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-24T19:27:28.7012494Z WARNING 02-24 19:27:28 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-24T19:27:28.7021786Z WARNING 02-24 19:27:28 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-24T19:27:28.7032509Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m INFO 02-24 19:27:28 [model_runner_v1.py:2318] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-24T19:27:28.7042870Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m INFO 02-24 19:27:28 [model_runner_v1.py:2318] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-24T19:27:28.7051325Z WARNING 02-24 19:27:28 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-24T19:27:28.7060550Z WARNING 02-24 19:27:28 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-24T19:27:28.7069904Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m INFO 02-24 19:27:28 [model_runner_v1.py:2318] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-24T19:27:28.7080472Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m INFO 02-24 19:27:28 [model_runner_v1.py:2318] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-24T19:27:28.7089078Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m INFO 02-24 19:27:28 [model_runner_v1.py:2318] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-24T19:27:28.7154409Z WARNING 02-24 19:27:28 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-24T19:27:28.7204034Z WARNING 02-24 19:27:28 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-24T19:27:28.7218279Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m INFO 02-24 19:27:28 [model_runner_v1.py:2318] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-24T19:27:28.7228074Z WARNING 02-24 19:27:28 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-24T19:27:28.7240698Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m INFO 02-24 19:27:28 [model_runner_v1.py:2318] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-24T19:27:28.7322283Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m INFO 02-24 19:27:28 [model_runner_v1.py:2318] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-24T19:27:28.7389140Z WARNING 02-24 19:27:28 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-24T19:27:28.7484248Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m INFO 02-24 19:27:28 [model_runner_v1.py:2318] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-24T19:27:28.7524663Z WARNING 02-24 19:27:28 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-24T19:27:28.7872754Z WARNING 02-24 19:27:28 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
2026-02-24T19:27:28.8074798Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m INFO 02-24 19:27:28 [model_runner_v1.py:2318] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-24T19:27:29.0250235Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m INFO 02-24 19:27:29 [model_runner_v1.py:2318] Starting to load model /root/.cache/modelscope/hub/models/vllm-ascend/DeepSeek-V3___2-W8A8...
2026-02-24T19:27:29.0914351Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m [2026-02-24 19:27:29] INFO modelslim_config.py:286: Using the vLLM Ascend modelslim Quantization now!
2026-02-24T19:27:29.1182057Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m [2026-02-24 19:27:29] INFO modelslim_config.py:286: Using the vLLM Ascend modelslim Quantization now!
2026-02-24T19:27:29.1214914Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m [2026-02-24 19:27:29] INFO modelslim_config.py:286: Using the vLLM Ascend modelslim Quantization now!
2026-02-24T19:27:29.1394426Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m [2026-02-24 19:27:29] INFO modelslim_config.py:286: Using the vLLM Ascend modelslim Quantization now!
2026-02-24T19:27:29.1521660Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m [2026-02-24 19:27:29] INFO modelslim_config.py:286: Using the vLLM Ascend modelslim Quantization now!
2026-02-24T19:27:29.1708563Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m [2026-02-24 19:27:29] INFO modelslim_config.py:286: Using the vLLM Ascend modelslim Quantization now!
2026-02-24T19:27:29.1845987Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m [2026-02-24 19:27:29] INFO modelslim_config.py:286: Using the vLLM Ascend modelslim Quantization now!
2026-02-24T19:27:29.2752879Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m INFO 02-24 19:27:29 [layer.py:475] [EP Rank 2/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->16, 1->17, 2->18, 3->19, 4->20, 5->21, 6->22, 7->23.
2026-02-24T19:27:29.2763640Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m INFO 02-24 19:27:29 [layer.py:475] [EP Rank 1/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->8, 1->9, 2->10, 3->11, 4->12, 5->13, 6->14, 7->15.
2026-02-24T19:27:29.2773946Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m INFO 02-24 19:27:29 [layer.py:475] [EP Rank 15/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->120, 1->121, 2->122, 3->123, 4->124, 5->125, 6->126, 7->127.
2026-02-24T19:27:29.2784884Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m INFO 02-24 19:27:29 [layer.py:475] [EP Rank 13/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->104, 1->105, 2->106, 3->107, 4->108, 5->109, 6->110, 7->111.
2026-02-24T19:27:29.2795140Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m INFO 02-24 19:27:29 [layer.py:475] [EP Rank 7/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->56, 1->57, 2->58, 3->59, 4->60, 5->61, 6->62, 7->63.
2026-02-24T19:27:29.2910581Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m INFO 02-24 19:27:29 [layer.py:475] [EP Rank 10/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->80, 1->81, 2->82, 3->83, 4->84, 5->85, 6->86, 7->87.
2026-02-24T19:27:29.2987654Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m INFO 02-24 19:27:29 [layer.py:475] [EP Rank 8/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->64, 1->65, 2->66, 3->67, 4->68, 5->69, 6->70, 7->71.
2026-02-24T19:27:29.3080601Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m [2026-02-24 19:27:29] INFO modelslim_config.py:286: Using the vLLM Ascend modelslim Quantization now!
2026-02-24T19:27:29.4176814Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m INFO 02-24 19:27:29 [layer.py:475] [EP Rank 12/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->96, 1->97, 2->98, 3->99, 4->100, 5->101, 6->102, 7->103.
2026-02-24T19:27:29.4225878Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m [2026-02-24 19:27:29] INFO modelslim_config.py:286: Using the vLLM Ascend modelslim Quantization now!
2026-02-24T19:27:29.4577468Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m [2026-02-24 19:27:29] INFO modelslim_config.py:286: Using the vLLM Ascend modelslim Quantization now!
2026-02-24T19:27:29.4963392Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m [2026-02-24 19:27:29] INFO modelslim_config.py:286: Using the vLLM Ascend modelslim Quantization now!
2026-02-24T19:27:29.5008035Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m [2026-02-24 19:27:29] INFO modelslim_config.py:286: Using the vLLM Ascend modelslim Quantization now!
2026-02-24T19:27:29.5353263Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m INFO 02-24 19:27:29 [layer.py:475] [EP Rank 14/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->112, 1->113, 2->114, 3->115, 4->116, 5->117, 6->118, 7->119.
2026-02-24T19:27:29.5743829Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m INFO 02-24 19:27:29 [layer.py:475] [EP Rank 9/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->72, 1->73, 2->74, 3->75, 4->76, 5->77, 6->78, 7->79.
2026-02-24T19:27:29.6100755Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m INFO 02-24 19:27:29 [layer.py:475] [EP Rank 6/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->48, 1->49, 2->50, 3->51, 4->52, 5->53, 6->54, 7->55.
2026-02-24T19:27:29.6145594Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m INFO 02-24 19:27:29 [layer.py:475] [EP Rank 4/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->32, 1->33, 2->34, 3->35, 4->36, 5->37, 6->38, 7->39.
2026-02-24T19:27:29.8229563Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m [2026-02-24 19:27:29] INFO modelslim_config.py:286: Using the vLLM Ascend modelslim Quantization now!
2026-02-24T19:27:29.9340643Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m INFO 02-24 19:27:29 [layer.py:475] [EP Rank 3/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->24, 1->25, 2->26, 3->27, 4->28, 5->29, 6->30, 7->31.
2026-02-24T19:27:30.1196961Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m [2026-02-24 19:27:30] INFO modelslim_config.py:286: Using the vLLM Ascend modelslim Quantization now!
2026-02-24T19:27:30.2783743Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m INFO 02-24 19:27:30 [layer.py:475] [EP Rank 0/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->0, 1->1, 2->2, 3->3, 4->4, 5->5, 6->6, 7->7.
2026-02-24T19:27:30.3056871Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m [2026-02-24 19:27:30] INFO modelslim_config.py:286: Using the vLLM Ascend modelslim Quantization now!
2026-02-24T19:27:30.4195102Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m [2026-02-24 19:27:30] INFO modelslim_config.py:286: Using the vLLM Ascend modelslim Quantization now!
2026-02-24T19:27:30.4263550Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m INFO 02-24 19:27:30 [layer.py:475] [EP Rank 5/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->40, 1->41, 2->42, 3->43, 4->44, 5->45, 6->46, 7->47.
2026-02-24T19:27:30.5335102Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m INFO 02-24 19:27:30 [layer.py:475] [EP Rank 11/32] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 8/256. Experts local to global index map: 0->88, 1->89, 2->90, 3->91, 4->92, 5->93, 6->94, 7->95.
2026-02-24T19:27:31.9452560Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-24T19:27:31.9461576Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-24T19:27:31.9472962Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-24T19:27:31.9484085Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-24T19:27:31.9492710Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:31.9502660Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-24T19:27:31.9512103Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-24T19:27:31.9570079Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 404, in load_model
2026-02-24T19:27:31.9572214Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-24T19:27:31.9573050Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2321, in load_model
2026-02-24T19:27:31.9574202Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-24T19:27:31.9574857Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:31.9575667Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-24T19:27:31.9581746Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]     return loader.load_model(
2026-02-24T19:27:31.9591623Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:31.9602730Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-24T19:27:31.9613414Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]     model = initialize_model(
2026-02-24T19:27:31.9621281Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-24T19:27:31.9631503Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-24T19:27:31.9642465Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-24T19:27:31.9652531Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:31.9662289Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-24T19:27:31.9672106Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-24T19:27:31.9682138Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-24T19:27:31.9692572Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-24T19:27:31.9701788Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-24T19:27:31.9711971Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-24T19:27:31.9723045Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-24T19:27:31.9732160Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-24T19:27:31.9742331Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-24T19:27:31.9751981Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]     + [
2026-02-24T19:27:31.9762286Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]       ^
2026-02-24T19:27:31.9778710Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-24T19:27:31.9787041Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-24T19:27:31.9795756Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:31.9804009Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-24T19:27:31.9814611Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-24T19:27:31.9824679Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:31.9835126Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-24T19:27:31.9847444Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-24T19:27:31.9858475Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-24T19:27:31.9866778Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-24T19:27:31.9876619Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-24T19:27:31.9887389Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-24T19:27:31.9898243Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 401, in __init__
2026-02-24T19:27:31.9908096Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-24T19:27:31.9919456Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 162, in __init__
2026-02-24T19:27:31.9928554Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-24T19:27:31.9939034Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-24T19:27:31.9948343Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-24T19:27:31.9958928Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:31.9969521Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-24T19:27:31.9979604Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-24T19:27:31.9989385Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.0000579Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 419, in get_quant_method
2026-02-24T19:27:32.0010466Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-24T19:27:32.0020395Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.0031502Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 295, in create_scheme_for_layer
2026-02-24T19:27:32.0040338Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]     return scheme_cls()
2026-02-24T19:27:32.0050134Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-24T19:27:32.0060172Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-24T19:27:32.0071051Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-24T19:27:32.0085473Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.0097130Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-24T19:27:32.0108492Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772] [ERROR] 2026-02-24-19:27:31 (PID:787, Device:6, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-24T19:27:32.0117806Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m ERROR 02-24 19:27:31 [multiproc_executor.py:772] 
2026-02-24T19:27:32.0127891Z [0;36m(Worker_DP1_TP6_EP14 pid=787)[0;0m INFO 02-24 19:27:31 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-24T19:27:32.0826867Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m INFO 02-24 19:27:32 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-24T19:27:32.0865605Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-24T19:27:32.0876036Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-24T19:27:32.0886675Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-24T19:27:32.0895693Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-24T19:27:32.0905374Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.0916153Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-24T19:27:32.0926670Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-24T19:27:32.0937854Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 404, in load_model
2026-02-24T19:27:32.0947588Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-24T19:27:32.0959281Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2321, in load_model
2026-02-24T19:27:32.0969532Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-24T19:27:32.0979150Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.0989103Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-24T19:27:32.0999512Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     return loader.load_model(
2026-02-24T19:27:32.1009760Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.1019317Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-24T19:27:32.1028673Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     model = initialize_model(
2026-02-24T19:27:32.1038721Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.1049300Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-24T19:27:32.1058409Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-24T19:27:32.1069878Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.1077851Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-24T19:27:32.1087764Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-24T19:27:32.1099674Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-24T19:27:32.1106579Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-24T19:27:32.1117101Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-24T19:27:32.1126251Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-24T19:27:32.1135714Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-24T19:27:32.1144992Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-24T19:27:32.1157409Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-24T19:27:32.1164923Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     + [
2026-02-24T19:27:32.1174356Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]       ^
2026-02-24T19:27:32.1183683Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-24T19:27:32.1193067Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-24T19:27:32.1203232Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.1213398Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-24T19:27:32.1222403Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-24T19:27:32.1232109Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.1245855Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-24T19:27:32.1255123Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-24T19:27:32.1264262Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-24T19:27:32.1275146Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-24T19:27:32.1291038Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-24T19:27:32.1301965Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-24T19:27:32.1316013Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 401, in __init__
2026-02-24T19:27:32.1327012Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-24T19:27:32.1339707Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 162, in __init__
2026-02-24T19:27:32.1352378Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-24T19:27:32.1360679Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-24T19:27:32.1369823Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-24T19:27:32.1378393Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.1388389Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-24T19:27:32.1398034Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-24T19:27:32.1408040Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.1421880Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 419, in get_quant_method
2026-02-24T19:27:32.1427870Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-24T19:27:32.1437239Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.1447671Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 295, in create_scheme_for_layer
2026-02-24T19:27:32.1456782Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     return scheme_cls()
2026-02-24T19:27:32.1466130Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-24T19:27:32.1476366Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-24T19:27:32.1518684Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-24T19:27:32.1519385Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.1520534Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-24T19:27:32.1521740Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] [ERROR] 2026-02-24-19:27:31 (PID:203, Device:0, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-24T19:27:32.1534621Z [0;36m(Worker_DP1_TP0_EP8 pid=203)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] 
2026-02-24T19:27:32.2205442Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m INFO 02-24 19:27:32 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-24T19:27:32.2497784Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m INFO 02-24 19:27:32 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-24T19:27:32.2538281Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-24T19:27:32.2551047Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-24T19:27:32.2599309Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-24T19:27:32.2600114Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-24T19:27:32.2600695Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.2601422Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-24T19:27:32.2602541Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-24T19:27:32.2606125Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 404, in load_model
2026-02-24T19:27:32.2615652Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-24T19:27:32.2624761Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2321, in load_model
2026-02-24T19:27:32.2647916Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-24T19:27:32.2648584Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.2655358Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-24T19:27:32.2663026Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     return loader.load_model(
2026-02-24T19:27:32.2671897Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.2682063Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-24T19:27:32.2691260Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     model = initialize_model(
2026-02-24T19:27:32.2723321Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.2724068Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-24T19:27:32.2724866Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-24T19:27:32.2730093Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.2740080Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-24T19:27:32.2749201Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-24T19:27:32.2761733Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-24T19:27:32.2770434Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-24T19:27:32.2780320Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-24T19:27:32.2790315Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-24T19:27:32.2801953Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-24T19:27:32.2810489Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-24T19:27:32.2819734Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-24T19:27:32.2829066Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     + [
2026-02-24T19:27:32.2838757Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]       ^
2026-02-24T19:27:32.2848691Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-24T19:27:32.2857881Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-24T19:27:32.2867730Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.2877633Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-24T19:27:32.2887917Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-24T19:27:32.2896489Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.2906295Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-24T19:27:32.2915893Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-24T19:27:32.2926222Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-24T19:27:32.2936540Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-24T19:27:32.2945402Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-24T19:27:32.2954116Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-24T19:27:32.2964252Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 401, in __init__
2026-02-24T19:27:32.2974382Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-24T19:27:32.2983392Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 162, in __init__
2026-02-24T19:27:32.2992687Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-24T19:27:32.3002901Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-24T19:27:32.3012591Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-24T19:27:32.3022109Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.3032279Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-24T19:27:32.3041440Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-24T19:27:32.3050853Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.3060679Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 419, in get_quant_method
2026-02-24T19:27:32.3069974Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-24T19:27:32.3079571Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.3089871Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 295, in create_scheme_for_layer
2026-02-24T19:27:32.3098929Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     return scheme_cls()
2026-02-24T19:27:32.3108383Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-24T19:27:32.3118496Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-24T19:27:32.3128062Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-24T19:27:32.3137371Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.3147271Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-24T19:27:32.3156081Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] [ERROR] 2026-02-24-19:27:31 (PID:682, Device:5, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-24T19:27:32.3168807Z [0;36m(Worker_DP1_TP5_EP13 pid=682)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] 
2026-02-24T19:27:32.3268388Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m INFO 02-24 19:27:32 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-24T19:27:32.3309839Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-24T19:27:32.3319905Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-24T19:27:32.3339743Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-24T19:27:32.3340486Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-24T19:27:32.3347890Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.3357777Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-24T19:27:32.3369900Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-24T19:27:32.3377208Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 404, in load_model
2026-02-24T19:27:32.3386433Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-24T19:27:32.3395573Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2321, in load_model
2026-02-24T19:27:32.3405945Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-24T19:27:32.3414737Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.3424595Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-24T19:27:32.3434305Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     return loader.load_model(
2026-02-24T19:27:32.3445078Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.3454325Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-24T19:27:32.3463300Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     model = initialize_model(
2026-02-24T19:27:32.3472473Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.3482232Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-24T19:27:32.3494506Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-24T19:27:32.3501187Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.3511176Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-24T19:27:32.3520508Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-24T19:27:32.3532201Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-24T19:27:32.3540695Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-24T19:27:32.3548933Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-24T19:27:32.3560919Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-24T19:27:32.3569969Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-24T19:27:32.3579901Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-24T19:27:32.3588102Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-24T19:27:32.3596564Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     + [
2026-02-24T19:27:32.3606318Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]       ^
2026-02-24T19:27:32.3615865Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-24T19:27:32.3625462Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-24T19:27:32.3635315Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.3645092Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-24T19:27:32.3654435Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-24T19:27:32.3663723Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.3674986Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-24T19:27:32.3683518Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-24T19:27:32.3693584Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-24T19:27:32.3715047Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-24T19:27:32.3715836Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-24T19:27:32.3720751Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-24T19:27:32.3732656Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 401, in __init__
2026-02-24T19:27:32.3742291Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-24T19:27:32.3751010Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 162, in __init__
2026-02-24T19:27:32.3761823Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-24T19:27:32.3772423Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-24T19:27:32.3783895Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-24T19:27:32.3794859Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.3806266Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-24T19:27:32.3815757Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-24T19:27:32.3823935Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.3833993Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 419, in get_quant_method
2026-02-24T19:27:32.3844241Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-24T19:27:32.3853593Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.3864130Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 295, in create_scheme_for_layer
2026-02-24T19:27:32.3872112Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     return scheme_cls()
2026-02-24T19:27:32.3881893Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-24T19:27:32.3898680Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-24T19:27:32.3902411Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-24T19:27:32.3911449Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.3921620Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-24T19:27:32.3931457Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] [ERROR] 2026-02-24-19:27:31 (PID:893, Device:7, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-24T19:27:32.3939180Z [0;36m(Worker_DP1_TP7_EP15 pid=893)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] 
2026-02-24T19:27:32.3947965Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-24T19:27:32.3958069Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-24T19:27:32.3972561Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-24T19:27:32.3976164Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-24T19:27:32.3986527Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.3995535Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-24T19:27:32.4004998Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-24T19:27:32.4014800Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 404, in load_model
2026-02-24T19:27:32.4024002Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-24T19:27:32.4033842Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2321, in load_model
2026-02-24T19:27:32.4043137Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-24T19:27:32.4053177Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.4063478Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-24T19:27:32.4071907Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     return loader.load_model(
2026-02-24T19:27:32.4081871Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.4091758Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-24T19:27:32.4101603Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     model = initialize_model(
2026-02-24T19:27:32.4109636Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.4119686Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-24T19:27:32.4129652Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-24T19:27:32.4138879Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.4148601Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-24T19:27:32.4158245Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-24T19:27:32.4167809Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-24T19:27:32.4177782Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-24T19:27:32.4186642Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-24T19:27:32.4196299Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-24T19:27:32.4206968Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-24T19:27:32.4217270Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-24T19:27:32.4226089Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-24T19:27:32.4235054Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     + [
2026-02-24T19:27:32.4245185Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]       ^
2026-02-24T19:27:32.4254830Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-24T19:27:32.4264361Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-24T19:27:32.4274761Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.4283921Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-24T19:27:32.4293323Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-24T19:27:32.4302516Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.4314211Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-24T19:27:32.4325275Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-24T19:27:32.4334354Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-24T19:27:32.4345512Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-24T19:27:32.4355836Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-24T19:27:32.4370051Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-24T19:27:32.4384629Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 401, in __init__
2026-02-24T19:27:32.4394963Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-24T19:27:32.4409894Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 162, in __init__
2026-02-24T19:27:32.4421027Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-24T19:27:32.4431937Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-24T19:27:32.4441750Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-24T19:27:32.4451161Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.4461319Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-24T19:27:32.4470489Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-24T19:27:32.4480276Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.4490434Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 419, in get_quant_method
2026-02-24T19:27:32.4499816Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-24T19:27:32.4509264Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.4520145Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 295, in create_scheme_for_layer
2026-02-24T19:27:32.4529270Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     return scheme_cls()
2026-02-24T19:27:32.4538764Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-24T19:27:32.4549442Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-24T19:27:32.4557928Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-24T19:27:32.4567876Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.4579087Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-24T19:27:32.4588215Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] [ERROR] 2026-02-24-19:27:31 (PID:685, Device:5, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-24T19:27:32.4596241Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] 
2026-02-24T19:27:32.4606124Z [0;36m(Worker_DP0_TP5_EP5 pid=685)[0;0m INFO 02-24 19:27:32 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-24T19:27:32.4615932Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m INFO 02-24 19:27:32 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-24T19:27:32.4624600Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m INFO 02-24 19:27:32 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-24T19:27:32.4633976Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-24T19:27:32.4642981Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-24T19:27:32.4653127Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-24T19:27:32.4662139Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-24T19:27:32.4671456Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.4681324Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-24T19:27:32.4691080Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-24T19:27:32.4700653Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 404, in load_model
2026-02-24T19:27:32.4709695Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-24T19:27:32.4719671Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2321, in load_model
2026-02-24T19:27:32.4729215Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-24T19:27:32.4738568Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.4747925Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-24T19:27:32.4757093Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     return loader.load_model(
2026-02-24T19:27:32.4767471Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.4779253Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-24T19:27:32.4788394Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     model = initialize_model(
2026-02-24T19:27:32.4799257Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.4809602Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-24T19:27:32.4818875Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-24T19:27:32.4830103Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.4840917Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-24T19:27:32.4849208Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-24T19:27:32.4858458Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-24T19:27:32.4868063Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-24T19:27:32.4876824Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-24T19:27:32.4887437Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-24T19:27:32.4897143Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-24T19:27:32.4906513Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-24T19:27:32.4915909Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-24T19:27:32.4925470Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     + [
2026-02-24T19:27:32.4934209Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]       ^
2026-02-24T19:27:32.4944137Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-24T19:27:32.4953247Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-24T19:27:32.4961957Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.4971922Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-24T19:27:32.4981115Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-24T19:27:32.4990521Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.5000871Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-24T19:27:32.5010047Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-24T19:27:32.5019490Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-24T19:27:32.5028378Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-24T19:27:32.5038151Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-24T19:27:32.5047540Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-24T19:27:32.5057613Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 401, in __init__
2026-02-24T19:27:32.5066468Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-24T19:27:32.5076515Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 162, in __init__
2026-02-24T19:27:32.5086127Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-24T19:27:32.5096764Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-24T19:27:32.5105900Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-24T19:27:32.5114695Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.5125245Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-24T19:27:32.5134933Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-24T19:27:32.5143838Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.5154089Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 419, in get_quant_method
2026-02-24T19:27:32.5164043Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-24T19:27:32.5173750Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.5184836Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 295, in create_scheme_for_layer
2026-02-24T19:27:32.5195994Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     return scheme_cls()
2026-02-24T19:27:32.5204397Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-24T19:27:32.5214044Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-24T19:27:32.5225679Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-24T19:27:32.5235631Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.5246831Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-24T19:27:32.5255905Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] [ERROR] 2026-02-24-19:27:31 (PID:202, Device:0, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-24T19:27:32.5265120Z [0;36m(Worker_DP0_TP0_EP0 pid=202)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] 
2026-02-24T19:27:32.5279280Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m INFO 02-24 19:27:32 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-24T19:27:32.5284023Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m INFO 02-24 19:27:32 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-24T19:27:32.5293417Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-24T19:27:32.5302956Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-24T19:27:32.5315780Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-24T19:27:32.5322417Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-24T19:27:32.5332483Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.5342359Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-24T19:27:32.5351945Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-24T19:27:32.5362175Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 404, in load_model
2026-02-24T19:27:32.5371844Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-24T19:27:32.5381879Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2321, in load_model
2026-02-24T19:27:32.5390890Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-24T19:27:32.5400791Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.5411017Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-24T19:27:32.5419692Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     return loader.load_model(
2026-02-24T19:27:32.5429038Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.5438843Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-24T19:27:32.5448285Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     model = initialize_model(
2026-02-24T19:27:32.5457764Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.5467328Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-24T19:27:32.5478046Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-24T19:27:32.5486547Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.5496223Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-24T19:27:32.5505306Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-24T19:27:32.5514710Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-24T19:27:32.5524456Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-24T19:27:32.5533625Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-24T19:27:32.5543505Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-24T19:27:32.5553070Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-24T19:27:32.5562342Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-24T19:27:32.5572414Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-24T19:27:32.5581536Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     + [
2026-02-24T19:27:32.5590908Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]       ^
2026-02-24T19:27:32.5601068Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-24T19:27:32.5610561Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-24T19:27:32.5619892Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.5631583Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-24T19:27:32.5639874Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-24T19:27:32.5648459Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.5657785Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-24T19:27:32.5666674Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-24T19:27:32.5676280Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-24T19:27:32.5686000Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-24T19:27:32.5695256Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-24T19:27:32.5704537Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-24T19:27:32.5714091Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 401, in __init__
2026-02-24T19:27:32.5724015Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-24T19:27:32.5733527Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 162, in __init__
2026-02-24T19:27:32.5742292Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-24T19:27:32.5751933Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-24T19:27:32.5761888Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-24T19:27:32.5771893Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.5782122Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-24T19:27:32.5791894Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-24T19:27:32.5801597Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.5811380Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 419, in get_quant_method
2026-02-24T19:27:32.5821090Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-24T19:27:32.5830625Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.5841102Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 295, in create_scheme_for_layer
2026-02-24T19:27:32.5850677Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     return scheme_cls()
2026-02-24T19:27:32.5859616Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-24T19:27:32.5869659Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-24T19:27:32.5880434Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-24T19:27:32.5889216Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.5899400Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-24T19:27:32.5908919Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] [ERROR] 2026-02-24-19:27:31 (PID:370, Device:2, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-24T19:27:32.5918248Z [0;36m(Worker_DP0_TP2_EP2 pid=370)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] 
2026-02-24T19:27:32.5928500Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m INFO 02-24 19:27:32 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-24T19:27:32.5937505Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-24T19:27:32.5946567Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-24T19:27:32.5955976Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-24T19:27:32.5965711Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-24T19:27:32.5975200Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.5984707Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-24T19:27:32.5993652Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-24T19:27:32.6004689Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 404, in load_model
2026-02-24T19:27:32.6013171Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-24T19:27:32.6022738Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2321, in load_model
2026-02-24T19:27:32.6031969Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-24T19:27:32.6042052Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.6051510Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-24T19:27:32.6060952Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     return loader.load_model(
2026-02-24T19:27:32.6070450Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.6080821Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-24T19:27:32.6090000Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     model = initialize_model(
2026-02-24T19:27:32.6099479Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.6108837Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-24T19:27:32.6119696Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-24T19:27:32.6129805Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.6139399Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-24T19:27:32.6158611Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-24T19:27:32.6159250Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-24T19:27:32.6168057Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-24T19:27:32.6177368Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-24T19:27:32.6187358Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-24T19:27:32.6196387Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-24T19:27:32.6206464Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-24T19:27:32.6215912Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-24T19:27:32.6224792Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     + [
2026-02-24T19:27:32.6234091Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]       ^
2026-02-24T19:27:32.6244741Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-24T19:27:32.6254661Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-24T19:27:32.6266691Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.6279212Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-24T19:27:32.6290436Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-24T19:27:32.6300606Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.6310550Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-24T19:27:32.6320096Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-24T19:27:32.6329577Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-24T19:27:32.6339026Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-24T19:27:32.6348313Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-24T19:27:32.6357563Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-24T19:27:32.6367678Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 401, in __init__
2026-02-24T19:27:32.6377534Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-24T19:27:32.6386259Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 162, in __init__
2026-02-24T19:27:32.6395566Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-24T19:27:32.6407283Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-24T19:27:32.6417303Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-24T19:27:32.6424904Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.6434396Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-24T19:27:32.6444487Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-24T19:27:32.6454835Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.6464501Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 419, in get_quant_method
2026-02-24T19:27:32.6473811Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-24T19:27:32.6484671Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.6493559Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 295, in create_scheme_for_layer
2026-02-24T19:27:32.6502351Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     return scheme_cls()
2026-02-24T19:27:32.6511518Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-24T19:27:32.6522421Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-24T19:27:32.6532672Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-24T19:27:32.6542470Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.6553140Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-24T19:27:32.6563335Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] [ERROR] 2026-02-24-19:27:31 (PID:371, Device:2, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-24T19:27:32.6571914Z [0;36m(Worker_DP1_TP2_EP10 pid=371)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] 
2026-02-24T19:27:32.6581232Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-24T19:27:32.6590819Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-24T19:27:32.6600751Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-24T19:27:32.6610475Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-24T19:27:32.6619547Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.6629663Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-24T19:27:32.6639201Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-24T19:27:32.6649120Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 404, in load_model
2026-02-24T19:27:32.6658449Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-24T19:27:32.6668226Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2321, in load_model
2026-02-24T19:27:32.6678036Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-24T19:27:32.6688092Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.6697677Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-24T19:27:32.6706112Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     return loader.load_model(
2026-02-24T19:27:32.6714855Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.6724773Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-24T19:27:32.6734264Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     model = initialize_model(
2026-02-24T19:27:32.6743560Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.6753201Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-24T19:27:32.6763306Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-24T19:27:32.6773602Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.6784874Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-24T19:27:32.6794891Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-24T19:27:32.6805033Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-24T19:27:32.6816755Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-24T19:27:32.6823655Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-24T19:27:32.6833307Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-24T19:27:32.6843071Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-24T19:27:32.6853261Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-24T19:27:32.6862881Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-24T19:27:32.6871217Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     + [
2026-02-24T19:27:32.6881692Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]       ^
2026-02-24T19:27:32.6890595Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-24T19:27:32.6903819Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-24T19:27:32.6909535Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.6919554Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-24T19:27:32.6929132Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-24T19:27:32.6938854Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.6948439Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-24T19:27:32.6957196Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-24T19:27:32.6966936Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-24T19:27:32.6976592Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-24T19:27:32.6985811Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-24T19:27:32.6995287Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-24T19:27:32.7005909Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 401, in __init__
2026-02-24T19:27:32.7014753Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-24T19:27:32.7025255Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 162, in __init__
2026-02-24T19:27:32.7033760Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-24T19:27:32.7043453Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-24T19:27:32.7053534Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-24T19:27:32.7062651Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.7072992Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-24T19:27:32.7081674Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-24T19:27:32.7092206Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.7101192Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 419, in get_quant_method
2026-02-24T19:27:32.7111109Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-24T19:27:32.7121145Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.7131173Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 295, in create_scheme_for_layer
2026-02-24T19:27:32.7139962Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     return scheme_cls()
2026-02-24T19:27:32.7149504Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-24T19:27:32.7160464Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-24T19:27:32.7170002Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-24T19:27:32.7179423Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.7189176Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-24T19:27:32.7201020Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] [ERROR] 2026-02-24-19:27:31 (PID:474, Device:3, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-24T19:27:32.7207901Z [0;36m(Worker_DP1_TP3_EP11 pid=474)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] 
2026-02-24T19:27:32.7217793Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m INFO 02-24 19:27:32 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-24T19:27:32.7227038Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m INFO 02-24 19:27:32 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-24T19:27:32.7236387Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m INFO 02-24 19:27:32 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-24T19:27:32.7246326Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-24T19:27:32.7255809Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-24T19:27:32.7265584Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-24T19:27:32.7274859Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-24T19:27:32.7284519Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.7294373Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-24T19:27:32.7303663Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-24T19:27:32.7313457Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 404, in load_model
2026-02-24T19:27:32.7322578Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-24T19:27:32.7332747Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2321, in load_model
2026-02-24T19:27:32.7342099Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-24T19:27:32.7351446Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.7361191Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-24T19:27:32.7372999Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     return loader.load_model(
2026-02-24T19:27:32.7382925Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.7391845Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-24T19:27:32.7401425Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     model = initialize_model(
2026-02-24T19:27:32.7411281Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.7421500Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-24T19:27:32.7434851Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-24T19:27:32.7446116Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.7458805Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-24T19:27:32.7473211Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-24T19:27:32.7484293Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-24T19:27:32.7495391Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-24T19:27:32.7504589Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-24T19:27:32.7514953Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-24T19:27:32.7524433Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-24T19:27:32.7534062Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-24T19:27:32.7544159Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-24T19:27:32.7553210Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     + [
2026-02-24T19:27:32.7563005Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]       ^
2026-02-24T19:27:32.7573076Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-24T19:27:32.7582452Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-24T19:27:32.7592115Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.7601858Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-24T19:27:32.7610947Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-24T19:27:32.7622560Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.7635016Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-24T19:27:32.7641117Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-24T19:27:32.7650432Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-24T19:27:32.7659887Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-24T19:27:32.7668938Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-24T19:27:32.7678529Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-24T19:27:32.7688423Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 401, in __init__
2026-02-24T19:27:32.7697644Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-24T19:27:32.7707411Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 162, in __init__
2026-02-24T19:27:32.7716284Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-24T19:27:32.7726616Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-24T19:27:32.7735863Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-24T19:27:32.7745883Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.7755387Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-24T19:27:32.7765746Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-24T19:27:32.7775499Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.7785632Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 419, in get_quant_method
2026-02-24T19:27:32.7795451Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-24T19:27:32.7805936Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.7815017Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 295, in create_scheme_for_layer
2026-02-24T19:27:32.7823643Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     return scheme_cls()
2026-02-24T19:27:32.7832817Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-24T19:27:32.7843559Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-24T19:27:32.7851928Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-24T19:27:32.7862092Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.7872386Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-24T19:27:32.7883949Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] [ERROR] 2026-02-24-19:27:31 (PID:477, Device:3, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-24T19:27:32.7890482Z [0;36m(Worker_DP0_TP3_EP3 pid=477)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] 
2026-02-24T19:27:32.7900283Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-24T19:27:32.7910588Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-24T19:27:32.7920515Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-24T19:27:32.7928590Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-24T19:27:32.7937582Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.7947919Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-24T19:27:32.7956322Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-24T19:27:32.7966610Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 404, in load_model
2026-02-24T19:27:32.7975751Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-24T19:27:32.7985546Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2321, in load_model
2026-02-24T19:27:32.7994589Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-24T19:27:32.8004644Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.8013812Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-24T19:27:32.8023088Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     return loader.load_model(
2026-02-24T19:27:32.8031900Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.8042450Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-24T19:27:32.8051441Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     model = initialize_model(
2026-02-24T19:27:32.8060917Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.8070594Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-24T19:27:32.8080044Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-24T19:27:32.8090216Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.8099851Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-24T19:27:32.8109457Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-24T19:27:32.8118226Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-24T19:27:32.8129579Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-24T19:27:32.8138886Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-24T19:27:32.8147645Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-24T19:27:32.8156419Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-24T19:27:32.8166483Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-24T19:27:32.8176564Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-24T19:27:32.8185296Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     + [
2026-02-24T19:27:32.8194678Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]       ^
2026-02-24T19:27:32.8205299Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-24T19:27:32.8215989Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-24T19:27:32.8228078Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.8237731Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-24T19:27:32.8247424Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-24T19:27:32.8257405Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.8267015Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-24T19:27:32.8276469Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-24T19:27:32.8289491Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-24T19:27:32.8299327Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-24T19:27:32.8308390Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-24T19:27:32.8318002Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-24T19:27:32.8328488Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 401, in __init__
2026-02-24T19:27:32.8337279Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-24T19:27:32.8347136Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 162, in __init__
2026-02-24T19:27:32.8359062Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-24T19:27:32.8367945Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-24T19:27:32.8376174Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-24T19:27:32.8385488Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.8395645Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-24T19:27:32.8405942Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-24T19:27:32.8415503Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.8429118Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 419, in get_quant_method
2026-02-24T19:27:32.8435571Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-24T19:27:32.8445238Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.8454877Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 295, in create_scheme_for_layer
2026-02-24T19:27:32.8463838Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     return scheme_cls()
2026-02-24T19:27:32.8472987Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-24T19:27:32.8483455Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-24T19:27:32.8493005Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-24T19:27:32.8501735Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.8512343Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-24T19:27:32.8522251Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] [ERROR] 2026-02-24-19:27:31 (PID:786, Device:6, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-24T19:27:32.8531554Z [0;36m(Worker_DP0_TP6_EP6 pid=786)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] 
2026-02-24T19:27:32.9204878Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m INFO 02-24 19:27:32 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-24T19:27:32.9249249Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-24T19:27:32.9260097Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-24T19:27:32.9269477Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-24T19:27:32.9278374Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-24T19:27:32.9287833Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.9297414Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-24T19:27:32.9306342Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-24T19:27:32.9315575Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 404, in load_model
2026-02-24T19:27:32.9325056Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-24T19:27:32.9335784Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2321, in load_model
2026-02-24T19:27:32.9351297Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-24T19:27:32.9357336Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.9368234Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-24T19:27:32.9377469Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     return loader.load_model(
2026-02-24T19:27:32.9387392Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.9397705Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-24T19:27:32.9407869Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     model = initialize_model(
2026-02-24T19:27:32.9417274Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.9426318Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-24T19:27:32.9435870Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-24T19:27:32.9445553Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.9455465Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-24T19:27:32.9464695Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-24T19:27:32.9473935Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-24T19:27:32.9485055Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-24T19:27:32.9493368Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-24T19:27:32.9502868Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-24T19:27:32.9512540Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-24T19:27:32.9522966Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-24T19:27:32.9533254Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-24T19:27:32.9542394Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     + [
2026-02-24T19:27:32.9551680Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]       ^
2026-02-24T19:27:32.9562070Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-24T19:27:32.9571831Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-24T19:27:32.9583772Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.9593654Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-24T19:27:32.9603269Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-24T19:27:32.9615105Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.9625403Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-24T19:27:32.9634474Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-24T19:27:32.9644059Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-24T19:27:32.9654093Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-24T19:27:32.9663234Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-24T19:27:32.9672521Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-24T19:27:32.9682977Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 401, in __init__
2026-02-24T19:27:32.9691975Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-24T19:27:32.9701591Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 162, in __init__
2026-02-24T19:27:32.9711102Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-24T19:27:32.9720498Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-24T19:27:32.9736696Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-24T19:27:32.9798227Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.9891885Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-24T19:27:32.9907982Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-24T19:27:32.9916407Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.9922515Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 419, in get_quant_method
2026-02-24T19:27:32.9936539Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-24T19:27:32.9946593Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:32.9957966Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 295, in create_scheme_for_layer
2026-02-24T19:27:32.9967775Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     return scheme_cls()
2026-02-24T19:27:32.9977775Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-24T19:27:32.9987593Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-24T19:27:32.9997131Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-24T19:27:33.0007211Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:33.0018263Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-24T19:27:33.0026559Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] [ERROR] 2026-02-24-19:27:31 (PID:252, Device:1, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-24T19:27:33.0035026Z [0;36m(Worker_DP0_TP1_EP1 pid=252)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] 
2026-02-24T19:27:33.0044906Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m INFO 02-24 19:27:32 [multiproc_executor.py:730] Parent process exited, terminating worker
2026-02-24T19:27:33.0054596Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-24T19:27:33.0064128Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-24T19:27:33.0073667Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-24T19:27:33.0083079Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-24T19:27:33.0093025Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:33.0102626Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-24T19:27:33.0111528Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-24T19:27:33.0122204Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 404, in load_model
2026-02-24T19:27:33.0130906Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-24T19:27:33.0140542Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2321, in load_model
2026-02-24T19:27:33.0149765Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-24T19:27:33.0159344Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:33.0169101Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-24T19:27:33.0178348Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     return loader.load_model(
2026-02-24T19:27:33.0187711Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:33.0198148Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-24T19:27:33.0207288Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     model = initialize_model(
2026-02-24T19:27:33.0216669Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-24T19:27:33.0226573Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-24T19:27:33.0236285Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-24T19:27:33.0245942Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:33.0255598Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-24T19:27:33.0264698Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-24T19:27:33.0274483Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-24T19:27:33.0283959Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-24T19:27:33.0293512Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-24T19:27:33.0303226Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-24T19:27:33.0312513Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-24T19:27:33.0321698Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-24T19:27:33.0331937Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-24T19:27:33.0340590Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     + [
2026-02-24T19:27:33.0349782Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]       ^
2026-02-24T19:27:33.0360615Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-24T19:27:33.0370331Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-24T19:27:33.0379807Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:33.0389526Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-24T19:27:33.0399325Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-24T19:27:33.0408955Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:33.0418121Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-24T19:27:33.0427545Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-24T19:27:33.0436755Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-24T19:27:33.0447458Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-24T19:27:33.0456514Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-24T19:27:33.0466380Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-24T19:27:33.0477794Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 401, in __init__
2026-02-24T19:27:33.0495547Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-24T19:27:33.0505708Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 162, in __init__
2026-02-24T19:27:33.0515803Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-24T19:27:33.0530488Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-24T19:27:33.0567844Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-24T19:27:33.0568704Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:33.0569639Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-24T19:27:33.0582148Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-24T19:27:33.0594984Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:33.0596687Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 419, in get_quant_method
2026-02-24T19:27:33.0607376Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-24T19:27:33.0616401Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:33.0626463Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 295, in create_scheme_for_layer
2026-02-24T19:27:33.0653918Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     return scheme_cls()
2026-02-24T19:27:33.0654503Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-24T19:27:33.0655596Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-24T19:27:33.0665471Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-24T19:27:33.0675316Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:33.0685855Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-24T19:27:33.0694722Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] [ERROR] 2026-02-24-19:27:31 (PID:581, Device:4, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-24T19:27:33.0703778Z [0;36m(Worker_DP0_TP4_EP4 pid=581)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] 
2026-02-24T19:27:33.0713046Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-24T19:27:33.0723190Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-24T19:27:33.0733251Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-24T19:27:33.0742475Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-24T19:27:33.0751740Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:33.0763576Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-24T19:27:33.0774910Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-24T19:27:33.0786619Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 404, in load_model
2026-02-24T19:27:33.0796689Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-24T19:27:33.0807285Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2321, in load_model
2026-02-24T19:27:33.0816682Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-24T19:27:33.0826360Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:33.0835787Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-24T19:27:33.0845553Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     return loader.load_model(
2026-02-24T19:27:33.0854743Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:33.0864730Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-24T19:27:33.0873695Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     model = initialize_model(
2026-02-24T19:27:33.0883212Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-24T19:27:33.0893930Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-24T19:27:33.0903168Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-24T19:27:33.0912095Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:33.0922282Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-24T19:27:33.0931574Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-24T19:27:33.0940706Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-24T19:27:33.0950788Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-24T19:27:33.0959878Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-24T19:27:33.0969929Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-24T19:27:33.0979350Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-24T19:27:33.0989081Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-24T19:27:33.1001078Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-24T19:27:33.1010596Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     + [
2026-02-24T19:27:33.1020846Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]       ^
2026-02-24T19:27:33.1031263Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-24T19:27:33.1041035Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-24T19:27:33.1050589Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:33.1060215Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-24T19:27:33.1069629Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-24T19:27:33.1079363Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:33.1088808Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-24T19:27:33.1098104Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-24T19:27:33.1107257Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-24T19:27:33.1117167Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-24T19:27:33.1127126Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-24T19:27:33.1136383Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-24T19:27:33.1145888Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 401, in __init__
2026-02-24T19:27:33.1155331Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-24T19:27:33.1165384Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 162, in __init__
2026-02-24T19:27:33.1174663Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-24T19:27:33.1184334Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-24T19:27:33.1193689Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-24T19:27:33.1203549Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:33.1213295Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-24T19:27:33.1222615Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-24T19:27:33.1231970Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:33.1242258Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 419, in get_quant_method
2026-02-24T19:27:33.1252154Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-24T19:27:33.1263932Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:33.1271277Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 295, in create_scheme_for_layer
2026-02-24T19:27:33.1280507Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     return scheme_cls()
2026-02-24T19:27:33.1290616Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-24T19:27:33.1300978Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-24T19:27:33.1309624Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-24T19:27:33.1320169Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:33.1330774Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-24T19:27:33.1340188Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] [ERROR] 2026-02-24-19:27:31 (PID:255, Device:1, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-24T19:27:33.1349755Z [0;36m(Worker_DP1_TP1_EP9 pid=255)[0;0m ERROR 02-24 19:27:32 [multiproc_executor.py:772] 
2026-02-24T19:27:33.2690748Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-24T19:27:33.2697937Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-24T19:27:33.2707682Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-24T19:27:33.2716524Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-24T19:27:33.2726228Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:33.2736763Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-24T19:27:33.2745116Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-24T19:27:33.2756460Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 404, in load_model
2026-02-24T19:27:33.2766029Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-24T19:27:33.2776298Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2321, in load_model
2026-02-24T19:27:33.2786277Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-24T19:27:33.2796205Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:33.2806888Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-24T19:27:33.2816100Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]     return loader.load_model(
2026-02-24T19:27:33.2826071Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:33.2835753Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-24T19:27:33.2846033Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]     model = initialize_model(
2026-02-24T19:27:33.2855652Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-24T19:27:33.2865990Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-24T19:27:33.2875754Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-24T19:27:33.2885310Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:33.2895205Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-24T19:27:33.2904779Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-24T19:27:33.2914293Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-24T19:27:33.2924327Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-24T19:27:33.2933442Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-24T19:27:33.2943676Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-24T19:27:33.2953493Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-24T19:27:33.2964267Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-24T19:27:33.2974505Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-24T19:27:33.2983553Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]     + [
2026-02-24T19:27:33.2993111Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]       ^
2026-02-24T19:27:33.3003599Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-24T19:27:33.3013788Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-24T19:27:33.3023911Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:33.3034493Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-24T19:27:33.3044065Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-24T19:27:33.3054462Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:33.3064235Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-24T19:27:33.3074100Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-24T19:27:33.3084148Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-24T19:27:33.3094096Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-24T19:27:33.3103775Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-24T19:27:33.3113943Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-24T19:27:33.3123684Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 401, in __init__
2026-02-24T19:27:33.3133271Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-24T19:27:33.3143485Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 162, in __init__
2026-02-24T19:27:33.3152558Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-24T19:27:33.3163256Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-24T19:27:33.3172677Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-24T19:27:33.3182700Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:33.3192707Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-24T19:27:33.3206966Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-24T19:27:33.3212492Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:33.3222330Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 419, in get_quant_method
2026-02-24T19:27:33.3232513Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-24T19:27:33.3242112Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:33.3252331Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 295, in create_scheme_for_layer
2026-02-24T19:27:33.3261309Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]     return scheme_cls()
2026-02-24T19:27:33.3271183Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-24T19:27:33.3281558Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-24T19:27:33.3291415Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-24T19:27:33.3300742Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:33.3311499Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-24T19:27:33.3321412Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772] [ERROR] 2026-02-24-19:27:31 (PID:890, Device:7, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-24T19:27:33.3330257Z [0;36m(Worker_DP0_TP7_EP7 pid=890)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772] 
2026-02-24T19:27:33.3340044Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772] WorkerProc failed to start.
2026-02-24T19:27:33.3349552Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772] Traceback (most recent call last):
2026-02-24T19:27:33.3360391Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 743, in worker_main
2026-02-24T19:27:33.3369669Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]     worker = WorkerProc(*args, **kwargs)
2026-02-24T19:27:33.3378963Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:33.3388883Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 578, in __init__
2026-02-24T19:27:33.3398825Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]     self.worker.load_model()
2026-02-24T19:27:33.3408646Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/worker.py", line 404, in load_model
2026-02-24T19:27:33.3418158Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]     self.model_runner.load_model()
2026-02-24T19:27:33.3428357Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/worker/model_runner_v1.py", line 2321, in load_model
2026-02-24T19:27:33.3438022Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]     self.model = get_model(vllm_config=self.vllm_config)
2026-02-24T19:27:33.3447947Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:33.3458021Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py", line 135, in get_model
2026-02-24T19:27:33.3467738Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]     return loader.load_model(
2026-02-24T19:27:33.3477557Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:33.3487852Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
2026-02-24T19:27:33.3497248Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]     model = initialize_model(
2026-02-24T19:27:33.3506566Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]             ^^^^^^^^^^^^^^^^^
2026-02-24T19:27:33.3517190Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
2026-02-24T19:27:33.3526655Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]     return model_class(vllm_config=vllm_config, prefix=prefix)
2026-02-24T19:27:33.3536199Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:33.3546145Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1210, in __init__
2026-02-24T19:27:33.3556485Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]     self.model = self.model_cls(
2026-02-24T19:27:33.3567901Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]                  ^^^^^^^^^^^^^^^
2026-02-24T19:27:33.3582622Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/compilation/decorators.py", line 306, in __init__
2026-02-24T19:27:33.3597819Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]     old_init(self, **kwargs)
2026-02-24T19:27:33.3606303Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1067, in __init__
2026-02-24T19:27:33.3616395Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]     self.start_layer, self.end_layer, self.layers = make_layers(
2026-02-24T19:27:33.3626856Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]                                                     ^^^^^^^^^^^^
2026-02-24T19:27:33.3640599Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 706, in make_layers
2026-02-24T19:27:33.3650751Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]     + [
2026-02-24T19:27:33.3660163Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]       ^
2026-02-24T19:27:33.3669808Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/utils.py", line 707, in <listcomp>
2026-02-24T19:27:33.3680004Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
2026-02-24T19:27:33.3688657Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:33.3698249Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 1069, in <lambda>
2026-02-24T19:27:33.3707999Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]     lambda prefix: DeepseekV2DecoderLayer(
2026-02-24T19:27:33.3720893Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:33.3726671Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 963, in __init__
2026-02-24T19:27:33.3735629Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]     self.mlp = DeepseekV2MoE(
2026-02-24T19:27:33.3744685Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]                ^^^^^^^^^^^^^^
2026-02-24T19:27:33.3754850Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/models/deepseek_v2.py", line 298, in __init__
2026-02-24T19:27:33.3765104Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]     self.experts = SharedFusedMoE(
2026-02-24T19:27:33.3775584Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^
2026-02-24T19:27:33.3786623Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 401, in __init__
2026-02-24T19:27:33.3797040Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]     AscendFusedMoE.__init__(self, **kwargs)
2026-02-24T19:27:33.3807777Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/ops/fused_moe/fused_moe.py", line 162, in __init__
2026-02-24T19:27:33.3817434Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]     super().__init__(*args, **kwargs)
2026-02-24T19:27:33.3827342Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 603, in __init__
2026-02-24T19:27:33.3837593Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]     self.quant_method: FusedMoEMethodBase = _get_quant_method()
2026-02-24T19:27:33.3869709Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]                                             ^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:33.3870573Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]   File "/vllm-workspace/vllm/vllm/model_executor/layers/fused_moe/layer.py", line 595, in _get_quant_method
2026-02-24T19:27:33.3877731Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]     quant_method = self.quant_config.get_quant_method(self, prefix)
2026-02-24T19:27:33.3895909Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:33.3907760Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 419, in get_quant_method
2026-02-24T19:27:33.3919740Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]     scheme = create_scheme_for_layer(self.quant_description, prefix, "moe", self.packed_modules_mapping)
2026-02-24T19:27:33.3934821Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:33.3939244Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/modelslim_config.py", line 295, in create_scheme_for_layer
2026-02-24T19:27:33.3949413Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]     return scheme_cls()
2026-02-24T19:27:33.3959767Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]            ^^^^^^^^^^^^
2026-02-24T19:27:33.3969917Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]   File "/vllm-workspace/vllm-ascend/vllm_ascend/quantization/methods/w8a8_dynamic.py", line 128, in __init__
2026-02-24T19:27:33.3979454Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]     self.moe_all_to_all_group_name = backend.get_hccl_comm_name(local_rank)
2026-02-24T19:27:33.3989419Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:33.4000183Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772] RuntimeError: create_config:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:130 HCCL function error: hcclCommInitRootInfoConfig(numRanks, &rootInfo, rank, config, &(comm->hcclComm_)), error code is 7
2026-02-24T19:27:33.4010435Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772] [ERROR] 2026-02-24-19:27:31 (PID:578, Device:4, RankID:-1) ERR02200 DIST call hccl api failed.
2026-02-24T19:27:33.4021085Z [0;36m(Worker_DP1_TP4_EP12 pid=578)[0;0m ERROR 02-24 19:27:33 [multiproc_executor.py:772] 
2026-02-24T19:27:36.6589786Z [0;36m(EngineCore_DP1 pid=174)[0;0m ERROR 02-24 19:27:36 [core.py:946] EngineCore failed to start.
2026-02-24T19:27:36.6595757Z [0;36m(EngineCore_DP1 pid=174)[0;0m ERROR 02-24 19:27:36 [core.py:946] Traceback (most recent call last):
2026-02-24T19:27:36.6605852Z [0;36m(EngineCore_DP1 pid=174)[0;0m ERROR 02-24 19:27:36 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 929, in run_engine_core
2026-02-24T19:27:36.6615288Z [0;36m(EngineCore_DP1 pid=174)[0;0m ERROR 02-24 19:27:36 [core.py:946]     engine_core = DPEngineCoreProc(*args, **kwargs)
2026-02-24T19:27:36.6625687Z [0;36m(EngineCore_DP1 pid=174)[0;0m ERROR 02-24 19:27:36 [core.py:946]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:36.6635362Z [0;36m(EngineCore_DP1 pid=174)[0;0m ERROR 02-24 19:27:36 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 1279, in __init__
2026-02-24T19:27:36.6646369Z [0;36m(EngineCore_DP1 pid=174)[0;0m ERROR 02-24 19:27:36 [core.py:946]     super().__init__(
2026-02-24T19:27:36.6654996Z [0;36m(EngineCore_DP1 pid=174)[0;0m ERROR 02-24 19:27:36 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 691, in __init__
2026-02-24T19:27:36.6664229Z [0;36m(EngineCore_DP1 pid=174)[0;0m ERROR 02-24 19:27:36 [core.py:946]     super().__init__(
2026-02-24T19:27:36.6674724Z [0;36m(EngineCore_DP1 pid=174)[0;0m ERROR 02-24 19:27:36 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 105, in __init__
2026-02-24T19:27:36.6684849Z [0;36m(EngineCore_DP1 pid=174)[0;0m ERROR 02-24 19:27:36 [core.py:946]     self.model_executor = executor_class(vllm_config)
2026-02-24T19:27:36.6694187Z [0;36m(EngineCore_DP1 pid=174)[0;0m ERROR 02-24 19:27:36 [core.py:946]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:36.6704064Z [0;36m(EngineCore_DP1 pid=174)[0;0m ERROR 02-24 19:27:36 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 97, in __init__
2026-02-24T19:27:36.6713512Z [0;36m(EngineCore_DP1 pid=174)[0;0m ERROR 02-24 19:27:36 [core.py:946]     super().__init__(vllm_config)
2026-02-24T19:27:36.6723686Z [0;36m(EngineCore_DP1 pid=174)[0;0m ERROR 02-24 19:27:36 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/executor/abstract.py", line 101, in __init__
2026-02-24T19:27:36.6733225Z [0;36m(EngineCore_DP1 pid=174)[0;0m ERROR 02-24 19:27:36 [core.py:946]     self._init_executor()
2026-02-24T19:27:36.6743164Z [0;36m(EngineCore_DP1 pid=174)[0;0m ERROR 02-24 19:27:36 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 165, in _init_executor
2026-02-24T19:27:36.6752489Z [0;36m(EngineCore_DP1 pid=174)[0;0m ERROR 02-24 19:27:36 [core.py:946]     self.workers = WorkerProc.wait_for_ready(unready_workers)
2026-02-24T19:27:36.6763651Z [0;36m(EngineCore_DP1 pid=174)[0;0m ERROR 02-24 19:27:36 [core.py:946]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:36.6775892Z [0;36m(EngineCore_DP1 pid=174)[0;0m ERROR 02-24 19:27:36 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 678, in wait_for_ready
2026-02-24T19:27:36.6786381Z [0;36m(EngineCore_DP1 pid=174)[0;0m ERROR 02-24 19:27:36 [core.py:946]     raise e from None
2026-02-24T19:27:36.6799228Z [0;36m(EngineCore_DP1 pid=174)[0;0m ERROR 02-24 19:27:36 [core.py:946] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
2026-02-24T19:27:36.6806526Z [0;36m(EngineCore_DP1 pid=174)[0;0m Process EngineCore_DP1:
2026-02-24T19:27:36.6815685Z [0;36m(EngineCore_DP1 pid=174)[0;0m Traceback (most recent call last):
2026-02-24T19:27:36.6827395Z [0;36m(EngineCore_DP1 pid=174)[0;0m   File "/usr/local/python3.11.14/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
2026-02-24T19:27:36.6834629Z [0;36m(EngineCore_DP1 pid=174)[0;0m     self.run()
2026-02-24T19:27:36.6845673Z [0;36m(EngineCore_DP1 pid=174)[0;0m   File "/usr/local/python3.11.14/lib/python3.11/multiprocessing/process.py", line 108, in run
2026-02-24T19:27:36.6858508Z [0;36m(EngineCore_DP1 pid=174)[0;0m     self._target(*self._args, **self._kwargs)
2026-02-24T19:27:36.6863323Z [0;36m(EngineCore_DP1 pid=174)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 950, in run_engine_core
2026-02-24T19:27:36.6872271Z [0;36m(EngineCore_DP1 pid=174)[0;0m     raise e
2026-02-24T19:27:36.6882628Z [0;36m(EngineCore_DP1 pid=174)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 929, in run_engine_core
2026-02-24T19:27:36.6891759Z [0;36m(EngineCore_DP1 pid=174)[0;0m     engine_core = DPEngineCoreProc(*args, **kwargs)
2026-02-24T19:27:36.6900988Z [0;36m(EngineCore_DP1 pid=174)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:36.6910536Z [0;36m(EngineCore_DP1 pid=174)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 1279, in __init__
2026-02-24T19:27:36.6920401Z [0;36m(EngineCore_DP1 pid=174)[0;0m     super().__init__(
2026-02-24T19:27:36.6930263Z [0;36m(EngineCore_DP1 pid=174)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 691, in __init__
2026-02-24T19:27:36.6940954Z [0;36m(EngineCore_DP1 pid=174)[0;0m     super().__init__(
2026-02-24T19:27:36.6951152Z [0;36m(EngineCore_DP1 pid=174)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 105, in __init__
2026-02-24T19:27:36.6959247Z [0;36m(EngineCore_DP1 pid=174)[0;0m     self.model_executor = executor_class(vllm_config)
2026-02-24T19:27:36.6968805Z [0;36m(EngineCore_DP1 pid=174)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:36.6978644Z [0;36m(EngineCore_DP1 pid=174)[0;0m   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 97, in __init__
2026-02-24T19:27:36.6987504Z [0;36m(EngineCore_DP1 pid=174)[0;0m     super().__init__(vllm_config)
2026-02-24T19:27:36.6997562Z [0;36m(EngineCore_DP1 pid=174)[0;0m   File "/vllm-workspace/vllm/vllm/v1/executor/abstract.py", line 101, in __init__
2026-02-24T19:27:36.7007640Z [0;36m(EngineCore_DP1 pid=174)[0;0m     self._init_executor()
2026-02-24T19:27:36.7017561Z [0;36m(EngineCore_DP1 pid=174)[0;0m   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 165, in _init_executor
2026-02-24T19:27:36.7037964Z [0;36m(EngineCore_DP1 pid=174)[0;0m     self.workers = WorkerProc.wait_for_ready(unready_workers)
2026-02-24T19:27:36.7038456Z [0;36m(EngineCore_DP1 pid=174)[0;0m                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:36.7045382Z [0;36m(EngineCore_DP1 pid=174)[0;0m   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 678, in wait_for_ready
2026-02-24T19:27:36.7054636Z [0;36m(EngineCore_DP1 pid=174)[0;0m     raise e from None
2026-02-24T19:27:36.7064325Z [0;36m(EngineCore_DP1 pid=174)[0;0m Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
2026-02-24T19:27:37.0858786Z [0;36m(EngineCore_DP0 pid=155)[0;0m ERROR 02-24 19:27:37 [core.py:946] EngineCore failed to start.
2026-02-24T19:27:37.0866418Z [0;36m(EngineCore_DP0 pid=155)[0;0m ERROR 02-24 19:27:37 [core.py:946] Traceback (most recent call last):
2026-02-24T19:27:37.0874099Z [0;36m(EngineCore_DP0 pid=155)[0;0m ERROR 02-24 19:27:37 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 929, in run_engine_core
2026-02-24T19:27:37.0883714Z [0;36m(EngineCore_DP0 pid=155)[0;0m ERROR 02-24 19:27:37 [core.py:946]     engine_core = DPEngineCoreProc(*args, **kwargs)
2026-02-24T19:27:37.0893054Z [0;36m(EngineCore_DP0 pid=155)[0;0m ERROR 02-24 19:27:37 [core.py:946]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:37.0902524Z [0;36m(EngineCore_DP0 pid=155)[0;0m ERROR 02-24 19:27:37 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 1279, in __init__
2026-02-24T19:27:37.0911145Z [0;36m(EngineCore_DP0 pid=155)[0;0m ERROR 02-24 19:27:37 [core.py:946]     super().__init__(
2026-02-24T19:27:37.0922058Z [0;36m(EngineCore_DP0 pid=155)[0;0m ERROR 02-24 19:27:37 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 691, in __init__
2026-02-24T19:27:37.0930419Z [0;36m(EngineCore_DP0 pid=155)[0;0m ERROR 02-24 19:27:37 [core.py:946]     super().__init__(
2026-02-24T19:27:37.0939690Z [0;36m(EngineCore_DP0 pid=155)[0;0m ERROR 02-24 19:27:37 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 105, in __init__
2026-02-24T19:27:37.0948718Z [0;36m(EngineCore_DP0 pid=155)[0;0m ERROR 02-24 19:27:37 [core.py:946]     self.model_executor = executor_class(vllm_config)
2026-02-24T19:27:37.0958723Z [0;36m(EngineCore_DP0 pid=155)[0;0m ERROR 02-24 19:27:37 [core.py:946]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:37.0968953Z [0;36m(EngineCore_DP0 pid=155)[0;0m ERROR 02-24 19:27:37 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 97, in __init__
2026-02-24T19:27:37.0977891Z [0;36m(EngineCore_DP0 pid=155)[0;0m ERROR 02-24 19:27:37 [core.py:946]     super().__init__(vllm_config)
2026-02-24T19:27:37.0987258Z [0;36m(EngineCore_DP0 pid=155)[0;0m ERROR 02-24 19:27:37 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/executor/abstract.py", line 101, in __init__
2026-02-24T19:27:37.0996471Z [0;36m(EngineCore_DP0 pid=155)[0;0m ERROR 02-24 19:27:37 [core.py:946]     self._init_executor()
2026-02-24T19:27:37.1006910Z [0;36m(EngineCore_DP0 pid=155)[0;0m ERROR 02-24 19:27:37 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 165, in _init_executor
2026-02-24T19:27:37.1015568Z [0;36m(EngineCore_DP0 pid=155)[0;0m ERROR 02-24 19:27:37 [core.py:946]     self.workers = WorkerProc.wait_for_ready(unready_workers)
2026-02-24T19:27:37.1025099Z [0;36m(EngineCore_DP0 pid=155)[0;0m ERROR 02-24 19:27:37 [core.py:946]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:37.1034528Z [0;36m(EngineCore_DP0 pid=155)[0;0m ERROR 02-24 19:27:37 [core.py:946]   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 678, in wait_for_ready
2026-02-24T19:27:37.1046686Z [0;36m(EngineCore_DP0 pid=155)[0;0m ERROR 02-24 19:27:37 [core.py:946]     raise e from None
2026-02-24T19:27:37.1054307Z [0;36m(EngineCore_DP0 pid=155)[0;0m ERROR 02-24 19:27:37 [core.py:946] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
2026-02-24T19:27:37.1065491Z [0;36m(EngineCore_DP0 pid=155)[0;0m Process EngineCore_DP0:
2026-02-24T19:27:37.1074123Z [0;36m(EngineCore_DP0 pid=155)[0;0m Traceback (most recent call last):
2026-02-24T19:27:37.1084286Z [0;36m(EngineCore_DP0 pid=155)[0;0m   File "/usr/local/python3.11.14/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
2026-02-24T19:27:37.1093915Z [0;36m(EngineCore_DP0 pid=155)[0;0m     self.run()
2026-02-24T19:27:37.1106025Z [0;36m(EngineCore_DP0 pid=155)[0;0m   File "/usr/local/python3.11.14/lib/python3.11/multiprocessing/process.py", line 108, in run
2026-02-24T19:27:37.1117065Z [0;36m(EngineCore_DP0 pid=155)[0;0m     self._target(*self._args, **self._kwargs)
2026-02-24T19:27:37.1126344Z [0;36m(EngineCore_DP0 pid=155)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 950, in run_engine_core
2026-02-24T19:27:37.1137244Z [0;36m(EngineCore_DP0 pid=155)[0;0m     raise e
2026-02-24T19:27:37.1146539Z [0;36m(EngineCore_DP0 pid=155)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 929, in run_engine_core
2026-02-24T19:27:37.1155654Z [0;36m(EngineCore_DP0 pid=155)[0;0m     engine_core = DPEngineCoreProc(*args, **kwargs)
2026-02-24T19:27:37.1168205Z [0;36m(EngineCore_DP0 pid=155)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:37.1176600Z [0;36m(EngineCore_DP0 pid=155)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 1279, in __init__
2026-02-24T19:27:37.1185686Z [0;36m(EngineCore_DP0 pid=155)[0;0m     super().__init__(
2026-02-24T19:27:37.1194965Z [0;36m(EngineCore_DP0 pid=155)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 691, in __init__
2026-02-24T19:27:37.1206153Z [0;36m(EngineCore_DP0 pid=155)[0;0m     super().__init__(
2026-02-24T19:27:37.1214223Z [0;36m(EngineCore_DP0 pid=155)[0;0m   File "/vllm-workspace/vllm/vllm/v1/engine/core.py", line 105, in __init__
2026-02-24T19:27:37.1226364Z [0;36m(EngineCore_DP0 pid=155)[0;0m     self.model_executor = executor_class(vllm_config)
2026-02-24T19:27:37.1233248Z [0;36m(EngineCore_DP0 pid=155)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:37.1242720Z [0;36m(EngineCore_DP0 pid=155)[0;0m   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 97, in __init__
2026-02-24T19:27:37.1251802Z [0;36m(EngineCore_DP0 pid=155)[0;0m     super().__init__(vllm_config)
2026-02-24T19:27:37.1261528Z [0;36m(EngineCore_DP0 pid=155)[0;0m   File "/vllm-workspace/vllm/vllm/v1/executor/abstract.py", line 101, in __init__
2026-02-24T19:27:37.1271262Z [0;36m(EngineCore_DP0 pid=155)[0;0m     self._init_executor()
2026-02-24T19:27:37.1280748Z [0;36m(EngineCore_DP0 pid=155)[0;0m   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 165, in _init_executor
2026-02-24T19:27:37.1290261Z [0;36m(EngineCore_DP0 pid=155)[0;0m     self.workers = WorkerProc.wait_for_ready(unready_workers)
2026-02-24T19:27:37.1299330Z [0;36m(EngineCore_DP0 pid=155)[0;0m                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2026-02-24T19:27:37.1308929Z [0;36m(EngineCore_DP0 pid=155)[0;0m   File "/vllm-workspace/vllm/vllm/v1/executor/multiproc_executor.py", line 678, in wait_for_ready
2026-02-24T19:27:37.1317930Z [0;36m(EngineCore_DP0 pid=155)[0;0m     raise e from None
2026-02-24T19:27:37.1329446Z [0;36m(EngineCore_DP0 pid=155)[0;0m Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
2026-02-24T19:27:38.5747250Z Traceback (most recent call last):
2026-02-24T19:27:38.5754216Z   File "/usr/local/python3.11.14/bin/vllm", line 7, in <module>
2026-02-24T19:27:38.5763666Z     sys.exit(main())
2026-02-24T19:27:38.5773564Z              ^^^^^^
2026-02-24T19:27:38.5783250Z   File "/vllm-workspace/vllm/vllm/entrypoints/cli/main.py", line 73, in main
2026-02-24T19:27:38.5793579Z     args.dispatch_function(args)
2026-02-24T19:27:38.5802420Z   File "/vllm-workspace/vllm/vllm/entrypoints/cli/serve.py", line 108, in cmd
2026-02-24T19:27:38.5813111Z     run_multi_api_server(args)
2026-02-24T19:27:38.5821188Z   File "/vllm-workspace/vllm/vllm/entrypoints/cli/serve.py", line 248, in run_multi_api_server
2026-02-24T19:27:38.5830489Z     with launch_core_engines(
2026-02-24T19:27:38.5839720Z   File "/usr/local/python3.11.14/lib/python3.11/contextlib.py", line 144, in __exit__
2026-02-24T19:27:38.5848831Z     next(self.gen)
2026-02-24T19:27:38.5858079Z   File "/vllm-workspace/vllm/vllm/v1/engine/utils.py", line 933, in launch_core_engines
2026-02-24T19:27:38.5866957Z     wait_for_engine_startup(
2026-02-24T19:27:38.5876660Z   File "/vllm-workspace/vllm/vllm/v1/engine/utils.py", line 992, in wait_for_engine_startup
2026-02-24T19:27:38.5888348Z     raise RuntimeError(
2026-02-24T19:27:38.5895205Z RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}
2026-02-24T19:27:39.4333344Z [ERROR] 2026-02-24-19:27:38 (PID:139, Device:-1, RankID:-1) ERR99999 UNKNOWN applicaiton exception
2026-02-24T19:27:39.7222067Z sys:1: DeprecationWarning: builtin type swigvarlink has no __module__ attribute
2026-02-24T19:27:41.3306413Z /usr/local/python3.11.14/lib/python3.11/multiprocessing/resource_tracker.py:254: UserWarning: resource_tracker: There appear to be 18 leaked shared_memory objects to clean up at shutdown
2026-02-24T19:27:41.3313848Z   warnings.warn('resource_tracker: There appear to be %d '
2026-02-24T19:27:46.5983274Z FAILED
2026-02-24T19:27:46.5993449Z 
2026-02-24T19:27:46.6005373Z =================================== FAILURES ===================================
2026-02-24T19:27:46.6016072Z _______________________________ test_multi_node ________________________________
2026-02-24T19:27:46.6024917Z 
2026-02-24T19:27:46.6035214Z     @pytest.mark.asyncio
2026-02-24T19:27:46.6044865Z     async def test_multi_node() -> None:
2026-02-24T19:27:46.6054023Z         config = MultiNodeConfigLoader.from_yaml()
2026-02-24T19:27:46.6063268Z     
2026-02-24T19:27:46.6072548Z         with ProxyLauncher(
2026-02-24T19:27:46.6082731Z                 nodes=config.nodes,
2026-02-24T19:27:46.6092318Z                 disagg_cfg=config.disagg_cfg,
2026-02-24T19:27:46.6101230Z                 envs=config.envs,
2026-02-24T19:27:46.6111115Z                 proxy_port=config.proxy_port,
2026-02-24T19:27:46.6121478Z                 cur_index=config.cur_index,
2026-02-24T19:27:46.6130462Z         ) as proxy:
2026-02-24T19:27:46.6139480Z     
2026-02-24T19:27:46.6149126Z >           with RemoteOpenAIServer(
2026-02-24T19:27:46.6158677Z                     model=config.model,
2026-02-24T19:27:46.6168195Z                     vllm_serve_args=config.server_cmd,
2026-02-24T19:27:46.6177938Z                     server_port=config.server_port,
2026-02-24T19:27:46.6186672Z                     server_host=config.master_ip,
2026-02-24T19:27:46.6195823Z                     env_dict=config.envs,
2026-02-24T19:27:46.6205954Z                     auto_port=False,
2026-02-24T19:27:46.6215448Z                     proxy_port=proxy.proxy_port,
2026-02-24T19:27:46.6224799Z                     disaggregated_prefill=config.disagg_cfg,
2026-02-24T19:27:46.6233856Z                     nodes_info=config.nodes,
2026-02-24T19:27:46.6243287Z                     max_wait_seconds=2800,
2026-02-24T19:27:46.6252411Z             ) as server:
2026-02-24T19:27:46.6261618Z 
2026-02-24T19:27:46.6271034Z tests/e2e/nightly/multi_node/scripts/test_multi_node.py:21: 
2026-02-24T19:27:46.6280373Z _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
2026-02-24T19:27:46.6289473Z tests/e2e/conftest.py:306: in __init__
2026-02-24T19:27:46.6298371Z     self._wait_for_multiple_servers(
2026-02-24T19:27:46.6308861Z _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
2026-02-24T19:27:46.6317440Z 
2026-02-24T19:27:46.6327127Z self = <tests.e2e.conftest.RemoteOpenAIServer object at 0xffff0a80bf90>
2026-02-24T19:27:46.6336561Z targets = [('10.0.0.169', 'http://10.0.0.169:8080/health')], timeout = 2800
2026-02-24T19:27:46.6345280Z log_interval = 30.0
2026-02-24T19:27:46.6354397Z 
2026-02-24T19:27:46.6364162Z     def _wait_for_multiple_servers(self,
2026-02-24T19:27:46.6373768Z                                    targets,
2026-02-24T19:27:46.6383143Z                                    timeout: float,
2026-02-24T19:27:46.6396783Z                                    log_interval: float = 30.0):
2026-02-24T19:27:46.6407267Z         """
2026-02-24T19:27:46.6417417Z         targets: List[(node_ip, url)]
2026-02-24T19:27:46.6429499Z         log_interval
2026-02-24T19:27:46.6443743Z         """
2026-02-24T19:27:46.6452315Z         start = time.time()
2026-02-24T19:27:46.6464293Z         client = requests
2026-02-24T19:27:46.6474119Z     
2026-02-24T19:27:46.6485040Z         ready = {node_ip: False for node_ip, _ in targets}
2026-02-24T19:27:46.6492959Z     
2026-02-24T19:27:46.6501623Z         last_log_time = 0.0
2026-02-24T19:27:46.6510902Z     
2026-02-24T19:27:46.6521132Z         while True:
2026-02-24T19:27:46.6530871Z             now = time.time()
2026-02-24T19:27:46.6539774Z             all_ready = True
2026-02-24T19:27:46.6549102Z             should_log = (now - last_log_time) >= log_interval
2026-02-24T19:27:46.6559288Z     
2026-02-24T19:27:46.6588183Z             for node_ip, url in targets:
2026-02-24T19:27:46.6588523Z                 if ready[node_ip]:
2026-02-24T19:27:46.6591258Z                     continue
2026-02-24T19:27:46.6601494Z     
2026-02-24T19:27:46.6611681Z                 try:
2026-02-24T19:27:46.6620794Z                     resp = client.get(url)
2026-02-24T19:27:46.6630137Z                     if resp.status_code == 200:
2026-02-24T19:27:46.6639718Z                         ready[node_ip] = True
2026-02-24T19:27:46.6649696Z                         logger.info(f"[READY] Node {node_ip} is ready.")
2026-02-24T19:27:46.6659214Z                 except RequestException:
2026-02-24T19:27:46.6667806Z                     all_ready = False
2026-02-24T19:27:46.6677413Z                     if should_log:
2026-02-24T19:27:46.6687013Z                         logger.debug(f"[WAIT] {url}: connection failed")
2026-02-24T19:27:46.6695729Z     
2026-02-24T19:27:46.6704941Z                     # check unexpected exit
2026-02-24T19:27:46.6713973Z                     result = self._poll()
2026-02-24T19:27:46.6727364Z                     if result is not None and result != 0:
2026-02-24T19:27:46.6733296Z >                       raise RuntimeError(
2026-02-24T19:27:46.6742394Z                             f"Server at {node_ip} exited unexpectedly."
2026-02-24T19:27:46.6751439Z                         ) from None
2026-02-24T19:27:46.6763369Z E                       RuntimeError: Server at 10.0.0.169 exited unexpectedly.
2026-02-24T19:27:46.6771561Z 
2026-02-24T19:27:46.6781173Z tests/e2e/conftest.py:399: RuntimeError
2026-02-24T19:27:46.6791947Z =============================== warnings summary ===============================
2026-02-24T19:27:46.6801222Z <frozen importlib._bootstrap>:241
2026-02-24T19:27:46.6811364Z   <frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyPacked has no __module__ attribute
2026-02-24T19:27:46.6819999Z 
2026-02-24T19:27:46.6829735Z <frozen importlib._bootstrap>:241
2026-02-24T19:27:46.6839760Z   <frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyObject has no __module__ attribute
2026-02-24T19:27:46.6849078Z 
2026-02-24T19:27:46.6859450Z ../../usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647
2026-02-24T19:27:46.6870057Z   /usr/local/python3.11.14/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
2026-02-24T19:27:46.6878470Z     warnings.warn(
2026-02-24T19:27:46.6887870Z 
2026-02-24T19:27:46.6897657Z ../../usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/__init__.py:8
2026-02-24T19:27:46.6907785Z   /usr/local/python3.11.14/lib/python3.11/site-packages/torch_npu/dynamo/torchair/__init__.py:8: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html
2026-02-24T19:27:46.6916520Z     import pkg_resources
2026-02-24T19:27:46.6926580Z 
2026-02-24T19:27:46.6936637Z -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
2026-02-24T19:27:46.6945672Z =========================== short test summary info ============================
2026-02-24T19:27:46.6954899Z FAILED tests/e2e/nightly/multi_node/scripts/test_multi_node.py::test_multi_node
2026-02-24T19:27:46.6964693Z ================== 1 failed, 4 warnings in 130.89s (0:02:10) ===================
2026-02-24T19:27:48.3778822Z [0;31mFAIL_TAG_DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml âœ— ERROR: Some tests failed, please check the error stack above for details. If this is insufficient to pinpoint the error, please download and review the logs of all other nodes from the job's summary.[0m
2026-02-24T19:27:48.6206084Z Cleaning up background log streams...
2026-02-24T19:27:48.6911573Z ##[error]Error: failed to run script step: Error: command terminated with non-zero exit code: command terminated with exit code 1
2026-02-24T19:27:48.6950949Z ##[error]Process completed with exit code 1.
2026-02-24T19:27:48.7039708Z ##[error]Executing the custom container implementation failed. Please contact your self hosted runner administrator.
2026-02-24T19:27:48.7447299Z ##[group]Run actions/upload-artifact@v6
2026-02-24T19:27:48.7447572Z with:
2026-02-24T19:27:48.7447837Z   name: DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml-pod-logs
2026-02-24T19:27:48.7448149Z   path: /tmp/vllm*_logs.txt
2026-02-24T19:27:48.7448390Z   retention-days: 7
2026-02-24T19:27:48.7448615Z   if-no-files-found: warn
2026-02-24T19:27:48.7448848Z   compression-level: 6
2026-02-24T19:27:48.7449067Z   overwrite: false
2026-02-24T19:27:48.7449293Z   include-hidden-files: false
2026-02-24T19:27:48.7449512Z env:
2026-02-24T19:27:48.7449771Z   FAIL_TAG: FAIL_TAG_DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-02-24T19:27:48.7450064Z ##[endgroup]
2026-02-24T19:27:48.7476727Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-24T19:27:48.7477546Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-24T19:27:48.7477809Z ##[endgroup]
2026-02-24T19:27:49.1013903Z (node:869) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-24T19:27:49.1014661Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-24T19:27:50.0594823Z With the provided path, there will be 1 file uploaded
2026-02-24T19:27:50.0596672Z Artifact name is valid!
2026-02-24T19:27:50.0597831Z Root directory input is valid!
2026-02-24T19:27:50.9156456Z Beginning upload of artifact content to blob storage
2026-02-24T19:27:52.0209847Z Uploaded bytes 16470
2026-02-24T19:27:52.2413280Z Finished uploading artifact content to blob storage!
2026-02-24T19:27:52.2413848Z SHA256 digest of uploaded artifact zip is aa14893a93d958f6b0085451383bc63a8fbe2f1b306bf3fe22a44dc8d04ef9a6
2026-02-24T19:27:52.2414322Z Finalizing artifact upload
2026-02-24T19:27:53.0713434Z Artifact DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml-pod-logs.zip successfully finalized. Artifact ID 5641425397
2026-02-24T19:27:53.0714223Z Artifact DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml-pod-logs has been successfully uploaded! Final size is 16470 bytes. Artifact ID is 5641425397
2026-02-24T19:27:53.0715292Z Artifact download URL: https://github.com/vllm-project/vllm-ascend/actions/runs/22360966349/artifacts/5641425397
2026-02-24T19:27:54.7444897Z ##[group]Run kubectl get pods -n "$NAMESPACE" --ignore-not-found=true
2026-02-24T19:27:54.7445362Z [36;1mkubectl get pods -n "$NAMESPACE" --ignore-not-found=true[0m
2026-02-24T19:27:54.7445789Z [36;1mkubectl delete -f ./lws.yaml --ignore-not-found=true || true[0m
2026-02-24T19:27:54.7446222Z shell: bash -el {0}
2026-02-24T19:27:54.7446443Z env:
2026-02-24T19:27:54.7446748Z   FAIL_TAG: FAIL_TAG_DeepSeek-V3_2-W8A8-A3-dual-nodes.yaml
2026-02-24T19:27:54.7447031Z ##[endgroup]
2026-02-24T19:27:54.7547012Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-24T19:27:54.7548286Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-24T19:27:54.7548658Z ##[endgroup]
2026-02-24T19:27:55.1057038Z (node:1031) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-24T19:27:55.1057863Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-24T19:27:55.7637815Z NAME                                             READY   STATUS    RESTARTS     AGE
2026-02-24T19:27:55.7638376Z linux-aarch64-a3-0-n4cwm-runner-znfxh            1/1     Running   0            4m53s
2026-02-24T19:27:55.7638986Z linux-aarch64-a3-0-n4cwm-runner-znfxh-workflow   1/1     Running   0            4m17s
2026-02-24T19:27:55.7639447Z vllm-0                                           1/1     Running   1 (7s ago)   3m52s
2026-02-24T19:27:55.7639768Z vllm-0-1                                         1/1     Running   0            3m51s
2026-02-24T19:27:55.8262132Z leaderworkerset.leaderworkerset.x-k8s.io "vllm" deleted from vllm-project namespace
2026-02-24T19:27:55.8627323Z service "vllm-leader" deleted from vllm-project namespace
2026-02-24T19:27:56.3313606Z Post job cleanup.
2026-02-24T19:27:56.3337445Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-24T19:27:56.3338377Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-24T19:27:56.3338673Z ##[endgroup]
2026-02-24T19:27:56.6886443Z (node:1156) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
2026-02-24T19:27:56.6887214Z (Use `node --trace-deprecation ...` to show where the warning was created)
2026-02-24T19:27:57.3105635Z [command]/usr/bin/git version
2026-02-24T19:27:57.3277815Z git version 2.34.1
2026-02-24T19:27:57.3307361Z Copying '/root/.gitconfig' to '/__w/_temp/050a34cc-9e35-48e6-8254-ca3f842df0be/.gitconfig'
2026-02-24T19:27:57.3318547Z Temporarily overriding HOME='/__w/_temp/050a34cc-9e35-48e6-8254-ca3f842df0be' before making global git config changes
2026-02-24T19:27:57.3319184Z Adding repository directory to the temporary git global config as a safe directory
2026-02-24T19:27:57.3323195Z [command]/usr/bin/git config --global --add safe.directory /__w/vllm-ascend/vllm-ascend
2026-02-24T19:27:57.3358268Z Removing SSH command configuration
2026-02-24T19:27:57.3361925Z [command]/usr/bin/git config --local --name-only --get-regexp core\.sshCommand
2026-02-24T19:27:57.3413133Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'core\.sshCommand' && git config --local --unset-all 'core.sshCommand' || :"
2026-02-24T19:27:57.3871940Z Removing HTTP extra header
2026-02-24T19:27:57.3874788Z [command]/usr/bin/git config --local --name-only --get-regexp http\.https\:\/\/github\.com\/\.extraheader
2026-02-24T19:27:57.3899324Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'http\.https\:\/\/github\.com\/\.extraheader' && git config --local --unset-all 'http.https://github.com/.extraheader' || :"
2026-02-24T19:27:57.4072867Z Removing includeIf entries pointing to credentials config files
2026-02-24T19:27:57.4076025Z [command]/usr/bin/git config --local --name-only --get-regexp ^includeIf\.gitdir:
2026-02-24T19:27:57.4093709Z includeif.gitdir:/__w/vllm-ascend/vllm-ascend/.git.path
2026-02-24T19:27:57.4094151Z includeif.gitdir:/__w/vllm-ascend/vllm-ascend/.git/worktrees/*.path
2026-02-24T19:27:57.4094570Z includeif.gitdir:/github/workspace/.git.path
2026-02-24T19:27:57.4094907Z includeif.gitdir:/github/workspace/.git/worktrees/*.path
2026-02-24T19:27:57.4100480Z [command]/usr/bin/git config --local --get-all includeif.gitdir:/__w/vllm-ascend/vllm-ascend/.git.path
2026-02-24T19:27:57.4116880Z /__w/_temp/git-credentials-849bb984-ca42-40d5-9d28-03b71029e9d7.config
2026-02-24T19:27:57.4124357Z [command]/usr/bin/git config --local --unset includeif.gitdir:/__w/vllm-ascend/vllm-ascend/.git.path /__w/_temp/git-credentials-849bb984-ca42-40d5-9d28-03b71029e9d7.config
2026-02-24T19:27:57.4154883Z [command]/usr/bin/git config --local --get-all includeif.gitdir:/__w/vllm-ascend/vllm-ascend/.git/worktrees/*.path
2026-02-24T19:27:57.4171837Z /__w/_temp/git-credentials-849bb984-ca42-40d5-9d28-03b71029e9d7.config
2026-02-24T19:27:57.4178477Z [command]/usr/bin/git config --local --unset includeif.gitdir:/__w/vllm-ascend/vllm-ascend/.git/worktrees/*.path /__w/_temp/git-credentials-849bb984-ca42-40d5-9d28-03b71029e9d7.config
2026-02-24T19:27:57.4207403Z [command]/usr/bin/git config --local --get-all includeif.gitdir:/github/workspace/.git.path
2026-02-24T19:27:57.4223589Z /github/runner_temp/git-credentials-849bb984-ca42-40d5-9d28-03b71029e9d7.config
2026-02-24T19:27:57.4230309Z [command]/usr/bin/git config --local --unset includeif.gitdir:/github/workspace/.git.path /github/runner_temp/git-credentials-849bb984-ca42-40d5-9d28-03b71029e9d7.config
2026-02-24T19:27:57.4254715Z [command]/usr/bin/git config --local --get-all includeif.gitdir:/github/workspace/.git/worktrees/*.path
2026-02-24T19:27:57.4271548Z /github/runner_temp/git-credentials-849bb984-ca42-40d5-9d28-03b71029e9d7.config
2026-02-24T19:27:57.4277490Z [command]/usr/bin/git config --local --unset includeif.gitdir:/github/workspace/.git/worktrees/*.path /github/runner_temp/git-credentials-849bb984-ca42-40d5-9d28-03b71029e9d7.config
2026-02-24T19:27:57.4306767Z [command]/usr/bin/git submodule foreach --recursive git config --local --show-origin --name-only --get-regexp remote.origin.url
2026-02-24T19:27:57.4478715Z Removing credentials config '/__w/_temp/git-credentials-849bb984-ca42-40d5-9d28-03b71029e9d7.config'
2026-02-24T19:28:15.9048740Z ##[group]Run '/home/runner/k8s/index.js'
2026-02-24T19:28:15.9049575Z shell: /home/runner/externals/node20/bin/node {0}
2026-02-24T19:28:15.9049892Z ##[endgroup]
2026-02-24T19:28:16.3262978Z Cleaning up orphan processes
